name: Trigger CNN Pipeline
description: Triggers an Elyra Kubeflow pipeline for CNN training with DQN optimization.
inputs:
  - {name: pickle_cdn_url, type: String, description: "URL to the uploaded pickle file"}
  - {name: config_cdn_url, type: String, description: "URL to the uploaded config string"}
  - {name: access_token, type: string, description: "Bearer token for pipeline trigger authentication"}
  - {name: domain, type: String, description: "Domain for the pipeline trigger API (e.g., https://ig.mobiusdtaas.ai)"}
  - {name: pipeline_id, type: String, description: "ID of the Elyra Kubeflow pipeline to trigger"}
  - {name: experiment_id, type: String, description: "ID of the Kubeflow experiment"}
  - {name: model_config, type: String, description: "JSON string for model configuration"}
  - {name: model_name, type: String, description: "Name of the model to be used"}
  - {name: execution_id, type: String, description: "exec id for the run"}
  - {name: model_id, type: String, description: "ID of the model"}
  - {name: project_id, type: String, description: "Project ID"}
  - {name: splitting_strategy, type: String, description: "Splitting strategy for continual learning tasks"}
  - {name: num_tasks, type: Integer, description: "Number of continual learning tasks"}
  - {name: userName, type: String, description: "Username for IAM authentication"}
  - {name: password, type: String, description: "Password for IAM authentication"}
  - {name: requesttype, type: String, description: "Request type for IAM authentication"}
  - {name: productid, type: String, description: "Product ID for IAM authentication"}
  - {name: model_schema, type: String, description: "Schema ID for model metrics"}
  - {name: train_schema, type: String, description: "Schema ID for training history"}
  - {name: eval_schema, type: String, description: "Schema ID for evaluation metrics"}
  - {name: dqn_pipeline_id, type: String, description: "ID of the DQN RLAF pipeline to trigger from within the CNN pipeline"}
  - {name: rlaf_schema, type: String, description: "Schema ID for RLAF (Reinforcement Learning Agent Framework) metrics"}  # Added RLAF schema
implementation:
  container:
    image: python:3.8-slim
    command:
      - sh
      - -ec
      - |
        if ! command -v curl &> /dev/null; then
            echo "curl could not be found, installing..."
            apt-get update > /dev/null && apt-get install -y curl > /dev/null
        fi
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import subprocess
        import json
        import os
        import urllib.parse

        parser = argparse.ArgumentParser(description="Trigger a CNN Kubeflow pipeline.")
        parser.add_argument('--pickle_cdn_url', type=str, required=True, help='URL to the uploaded pickle file.')
        parser.add_argument('--config_cdn_url', type=str, required=True, help='URL to the uploaded config string.')
        parser.add_argument('--access_token', type=str, required=True, help='Bearer token for pipeline trigger authentication.')
        parser.add_argument('--domain', type=str, required=True, help='Domain for the pipeline trigger API.')
        parser.add_argument('--pipeline_id', type=str, required=True, help='ID of the Elyra Kubeflow pipeline to trigger.')
        parser.add_argument('--experiment_id', type=str, required=True, help='ID of the Kubeflow experiment.')
        parser.add_argument('--model_config', type=str, required=True, help='JSON string for model configuration.')
        parser.add_argument('--model_name', type=str, required=True, help='Name of the model to be used.')
        parser.add_argument('--execution_id', type=str, required=True, help='exec id for the run.')
        parser.add_argument('--model_id', type=str, required=True, help='ID of the model.')
        parser.add_argument('--project_id', type=str, required=True, help='Project ID.')
        parser.add_argument('--splitting_strategy', type=str, required=True, help='Splitting strategy for continual learning tasks.')
        parser.add_argument('--num_tasks', type=int, required=True, help='Number of continual learning tasks.')
        parser.add_argument('--userName', type=str, required=True, help='Username for IAM authentication.')
        parser.add_argument('--password', type=str, required=True, help='Password for IAM authentication.')
        parser.add_argument('--requesttype', type=str, required=True, help='Request type for IAM authentication.')
        parser.add_argument('--productid', type=str, required=True, help='Product ID for IAM authentication.')
        parser.add_argument('--model_schema', type=str, required=True, help='Schema ID for model metrics.')
        parser.add_argument('--train_schema', type=str, required=True, help='Schema ID for training history.')
        parser.add_argument('--eval_schema', type=str, required=True, help='Schema ID for evaluation metrics.')
        parser.add_argument('--dqn_pipeline_id', type=str, required=True, help='ID of the DQN RLAF pipeline.')
        parser.add_argument('--rlaf_schema', type=str, required=True, help='Schema ID for RLAF metrics.')  # Added RLAF schema argument
        args = parser.parse_args()

        # URL encode problematic characters in CDN URLs
        def encode_cdn_url(url):
            # First, replace known problematic patterns
            url = url.replace("(", "%28")
            url = url.replace(")", "%29")
            url = url.replace("$", "%24")
            url = url.replace(" ", "%20")
            
            # Additional encoding for other special characters
            url = url.replace("[", "%5B")
            url = url.replace("]", "%5D")
            url = url.replace("{", "%7B")
            url = url.replace("}", "%7D")
            
            # For the _ENC pattern that appears in CDN URLs
            url = url.replace("_ENC", "_ENC")
            
            print(f"Original URL: {url[:100]}...")
            
            # Additional URL encoding for safety
            if "://" in url:
                protocol, rest = url.split("://", 1)
                # Encode the rest of the URL
                rest = urllib.parse.quote(rest, safe="/:?=&%_")
                url = f"{protocol}://{rest}"
            else:
                url = urllib.parse.quote(url, safe="/:?=&%_")
            
            print(f"Encoded URL: {url[:100]}...")
            return url

        # Encode both CDN URLs
        args.pickle_cdn_url = encode_cdn_url(args.pickle_cdn_url)
        args.config_cdn_url = encode_cdn_url(args.config_cdn_url)

        # The pipeline_id argument is used in the trigger URL
        trigger_url = f"{args.domain}/bob-service-test/v1.0/pipeline/trigger/ml?pipelineId={args.pipeline_id}"
        with open(args.access_token, 'r') as f:
            access_token = f.read().strip()
        headers = {
            "accept": "application/json",
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }

        # Build payload with all pipeline parameters including rlaf_schema
        payload = {
            "pipelineType": "ML",
            "containerResources": {},
            "experimentId": args.experiment_id,
            "enableCaching": True,
            "parameters": {
                "pickle_cdn_url": args.pickle_cdn_url,
                "config_cdn_url": args.config_cdn_url,
                "model_name": args.model_name,
                "model_config": args.model_config,
                "execution_id": args.execution_id,
                "experiment_id": args.experiment_id,
                "model_id": args.model_id,
                "project_id": args.project_id,
                "splitting_strategy": args.splitting_strategy,
                "num_tasks": args.num_tasks,
                "userName": args.userName,
                "password": args.password,
                "requesttype": args.requesttype,
                "productid": args.productid,
                "domain": args.domain,
                "model_schema": args.model_schema,
                "train_schema": args.train_schema,
                "eval_schema": args.eval_schema,
                "pipeline_id": args.dqn_pipeline_id,
                "dqn_pipeline_id": args.dqn_pipeline_id,
                "rlaf_schema": args.rlaf_schema  # Added RLAF schema parameter
            },
            "version": 1
        }

        print(f"Triggering CNN pipeline at: {trigger_url}")
        print(f"CNN Pipeline ID (to trigger): {args.pipeline_id}")
        print(f"DQN Pipeline ID (parameter): {args.dqn_pipeline_id}")
        print(f"RLAF Schema ID: {args.rlaf_schema}")  # Added RLAF schema print
        print(f"Payload parameters preview:")
        
        # Group parameters for better readability
        print("\\n=== CDN URLs ===")
        print(f"pickle_cdn_url: {args.pickle_cdn_url[:80]}...")
        print(f"config_cdn_url: {args.config_cdn_url[:80]}...")
        
        print("\\n=== Model Parameters ===")
        print(f"model_name: {args.model_name}")
        print(f"model_id: {args.model_id}")
        print(f"model_schema: {args.model_schema}")
        
        print("\\n=== Pipeline IDs ===")
        print(f"pipeline_id (for trigger URL): {args.pipeline_id}")
        print(f"dqn_pipeline_id (parameter): {args.dqn_pipeline_id}")
        print(f"experiment_id: {args.experiment_id}")
        print(f"execution_id: {args.execution_id}")
        
        print("\\n=== Schema IDs ===")  # Consolidated schema section
        print(f"project_id: {args.project_id}")
        print(f"train_schema: {args.train_schema}")
        print(f"eval_schema: {args.eval_schema}")
        print(f"rlaf_schema: {args.rlaf_schema}")  # Added RLAF schema
        
        print("\\n=== Continual Learning ===")
        print(f"splitting_strategy: {args.splitting_strategy}")
        print(f"num_tasks: {args.num_tasks}")
        
        print("\\n=== Authentication ===")
        print(f"userName: {args.userName}")
        print(f"password: [REDACTED]")
        print(f"requesttype: {args.requesttype}")
        print(f"productid: {args.productid}")
        print(f"domain: {args.domain}")

        import time
        curl_command = [
            "curl",
            "--location", trigger_url,
            "--header", f"accept: {headers['accept']}",
            "--header", f"Authorization: {headers['Authorization']}",
            "--header", f"Content-Type: {headers['Content-Type']}",
            "--data", json.dumps(payload),
            "--fail",
            "--show-error",
            "--connect-timeout", "30"
        ]

        retries = 5
        retry_delay = 60
        for i in range(retries):
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    check=True,
                    text=True
                )
                print("Pipeline trigger successful. Raw response:")
                print(process.stdout)
                
                # Try to parse and pretty print the response
                try:
                    response_json = json.loads(process.stdout)
                    print("\\nParsed response:")
                    print(json.dumps(response_json, indent=2))
                except:
                    print("Could not parse response as JSON")
                    
                break
            except subprocess.CalledProcessError as e:
                print(f"Attempt {i+1} failed with return code {e.returncode}.")
                print(f"Stderr: {e.stderr}")
                print(f"Stdout: {e.stdout}")
                
                if i < retries - 1:
                    # Check if the error is a 5xx server error to retry
                    if e.returncode == 22:
                         print(f"Retrying in {retry_delay} seconds...")
                         time.sleep(retry_delay)
                         continue
                    else:
                        print("Non-retriable error encountered.")
                        raise e
                else:
                    print("Max retries reached. Failing.")
                    raise e
            except Exception as e:
                print(f"An unexpected error occurred: {e}")
                raise e
    args:
      - --pickle_cdn_url
      - {inputValue: pickle_cdn_url}
      - --config_cdn_url
      - {inputValue: config_cdn_url}
      - --access_token
      - {inputPath: access_token}
      - --domain
      - {inputValue: domain}
      - --pipeline_id
      - {inputValue: pipeline_id}
      - --experiment_id
      - {inputValue: experiment_id}
      - --model_config
      - {inputValue: model_config}
      - --model_name
      - {inputValue: model_name}
      - --execution_id
      - {inputValue: execution_id}
      - --model_id
      - {inputValue: model_id}
      - --project_id
      - {inputValue: project_id}
      - --splitting_strategy
      - {inputValue: splitting_strategy}
      - --num_tasks
      - {inputValue: num_tasks}
      - --userName
      - {inputValue: userName}
      - --password
      - {inputValue: password}
      - --requesttype
      - {inputValue: requesttype}
      - --productid
      - {inputValue: productid}
      - --model_schema
      - {inputValue: model_schema}
      - --train_schema
      - {inputValue: train_schema}
      - --eval_schema
      - {inputValue: eval_schema}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --rlaf_schema
      - {inputValue: rlaf_schema}  # Added RLAF schema argument
