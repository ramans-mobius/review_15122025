name: Trigger CNN Pipeline v9
description: Triggers an Elyra Kubeflow pipeline for CNN training with DQN optimization.
inputs:
  - {name: pickle_cdn_url, type: String, description: "URL to the uploaded pickle file"}
  - {name: config_cdn_url, type: String, description: "URL to the uploaded config string"}
  - {name: access_token, type: String, description: "Bearer token for pipeline trigger authentication"}
  - {name: domain, type: String, description: "Domain for the pipeline trigger API (e.g., https://ig.mobiusdtaas.ai)"}
  - {name: pipeline_id, type: String, description: "ID of the Elyra Kubeflow pipeline to trigger"}
  - {name: experiment_id, type: String, description: "ID of the Kubeflow experiment"}
  - {name: model_config, type: String, description: "JSON string for model configuration"}
  - {name: model_name, type: String, description: "Name of the model to be used"}
  - {name: execution_id, type: String, description: "exec id for the run"}
  - {name: model_id, type: String, description: "ID of the model"}
  - {name: project_id, type: String, description: "Project ID"}
  - {name: splitting_strategy, type: String, description: "Splitting strategy for continual learning tasks"}
  - {name: num_tasks, type: Integer, description: "Number of continual learning tasks"}
  - {name: userName, type: String, description: "Username for IAM authentication"}
  - {name: password, type: String, description: "Password for IAM authentication"}
  - {name: requesttype, type: String, description: "Request type for IAM authentication"}
  - {name: productid, type: String, description: "Product ID for IAM authentication"}
  - {name: model_schema, type: String, description: "Schema ID for model metrics"}
  - {name: train_schema, type: String, description: "Schema ID for training history"}
  - {name: eval_schema, type: String, description: "Schema ID for evaluation metrics"}
  - {name: dqn_pipeline_id, type: String, description: "ID of the DQN RLAF pipeline to trigger from within the CNN pipeline"}
  - {name: rlaf_schema, type: String, description: "Schema ID for RLAF (Reinforcement Learning Agent Framework) metrics"}
  # Added missing parameters from pipeline definition
  - {name: architecture_type, type: String, description: "Architecture type for the model"}
  - {name: cdn_url, type: String, description: "CDN URL for loading pre-trained models"}
  - {name: load_from_cdn_url, type: String, description: "Flag to indicate whether to load model from CDN"}
implementation:
  container:
    image: python:3.8-slim
    command:
      - sh
      - -ec
      - |
        if ! command -v curl &> /dev/null; then
            echo "curl could not be found, installing..."
            apt-get update > /dev/null && apt-get install -y curl > /dev/null
        fi
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import subprocess
        import json
        import os
        import urllib.parse

        parser = argparse.ArgumentParser(description="Trigger a CNN Kubeflow pipeline.")
        parser.add_argument('--pickle_cdn_url', type=str, required=True, help='URL to the uploaded pickle file.')
        parser.add_argument('--config_cdn_url', type=str, required=True, help='URL to the uploaded config string.')
        parser.add_argument('--access_token', type=str, required=True, help='Bearer token for pipeline trigger authentication.')
        parser.add_argument('--domain', type=str, required=True, help='Domain for the pipeline trigger API.')
        parser.add_argument('--pipeline_id', type=str, required=True, help='ID of the Elyra Kubeflow pipeline to trigger.')
        parser.add_argument('--experiment_id', type=str, required=True, help='ID of the Kubeflow experiment.')
        parser.add_argument('--model_config', type=str, required=True, help='JSON string for model configuration.')
        parser.add_argument('--model_name', type=str, required=True, help='Name of the model to be used.')
        parser.add_argument('--execution_id', type=str, required=True, help='exec id for the run.')
        parser.add_argument('--model_id', type=str, required=True, help='ID of the model.')
        parser.add_argument('--project_id', type=str, required=True, help='Project ID.')
        parser.add_argument('--splitting_strategy', type=str, required=True, help='Splitting strategy for continual learning tasks.')
        parser.add_argument('--num_tasks', type=int, required=True, help='Number of continual learning tasks.')
        parser.add_argument('--userName', type=str, required=True, help='Username for IAM authentication.')
        parser.add_argument('--password', type=str, required=True, help='Password for IAM authentication.')
        parser.add_argument('--requesttype', type=str, required=True, help='Request type for IAM authentication.')
        parser.add_argument('--productid', type=str, required=True, help='Product ID for IAM authentication.')
        parser.add_argument('--model_schema', type=str, required=True, help='Schema ID for model metrics.')
        parser.add_argument('--train_schema', type=str, required=True, help='Schema ID for training history.')
        parser.add_argument('--eval_schema', type=str, required=True, help='Schema ID for evaluation metrics.')
        parser.add_argument('--dqn_pipeline_id', type=str, required=True, help='ID of the DQN RLAF pipeline.')
        parser.add_argument('--rlaf_schema', type=str, required=True, help='Schema ID for RLAF metrics.')
        # Added arguments for missing parameters
        parser.add_argument('--architecture_type', type=str, required=True, help='Architecture type for the model.')
        parser.add_argument('--cdn_url', type=str, required=True, help='CDN URL for loading pre-trained models.')
        parser.add_argument('--load_from_cdn_url', type=str, required=True, help='Flag to indicate whether to load model from CDN.')
        args = parser.parse_args()

        def fix_cdn_url(url):
          
            print(f"\\n=== Processing URL ===")
            print(f"Input URL: {url[:]}...")
            
            # Step 1: First, decode any existing URL encoding
            try:
                url = urllib.parse.unquote(url)
            except:
                pass
            
            print(f"After unquote: {url[:]}...")
            
            # Step 2: CRITICAL - Restore the $$ pattern from _$_
            # Replace _$_ with _$$_ (double dollar)
            if "_$_" in url:
                print(f"Found _$_ pattern at positions: {[i for i in range(len(url)) if url.startswith('_$_', i)]}")
                url = url.replace("_$_", "_$$_")
                print(f"Restored to _$$_: {url[:]}...")
            
            # Step 3: Also check for other single dollar patterns that should be double
            # Look for pattern: _X$X_ where X is any character or end of string
            import re
            
            # Find patterns like: something_$something (single dollar between underscores)
            single_dollar_patterns = re.findall(r'([a-zA-Z0-9]+)_\$([a-zA-Z0-9]+)', url)
            if single_dollar_patterns:
                print(f"Found other single dollar patterns: {single_dollar_patterns}")
                # For each match, replace with double dollar
                for before, after in single_dollar_patterns:
                    pattern = f"{before}_${after}"
                    replacement = f"{before}_$${after}"
                    url = url.replace(pattern, replacement)
            
            print(f"After dollar restoration: {url[:]}...")
            
            # Step 4: Handle _ENC( pattern
            if "_ENC(" in url:
                print(f"Found _ENC( pattern - preserving")
            elif "_ENC%28" in url:
                print(f"Found _ENC%28 pattern, converting to _ENC(")
                url = url.replace("_ENC%28", "_ENC(")
            
            # Step 5: Remove any spaces
            url = url.replace(" ", "")
            
            print(f"After cleanup: {url}...")
            
            # Step 6: Now properly URL encode for JSON transmission
            # We need to encode $ as %24, so _$$_ becomes _%24%24_
            # Also encode parentheses: ( -> %28, ) -> %29
            
            # First, handle special patterns we want to preserve
            # Replace _ENC( with placeholder
            url = url.replace("_ENC(", "__ENC_PAREN_PLACEHOLDER__")
            
            # Now encode the URL
            if "://" in url:
                parts = list(urllib.parse.urlsplit(url))
                # Encode the path
                parts[2] = urllib.parse.quote(parts[2], safe="/")
                # Encode query
                if parts[3]:
                    parts[3] = urllib.parse.quote(parts[3], safe="=&")
                # Encode fragment
                if parts[4]:
                    parts[4] = urllib.parse.quote(parts[4], safe="")
                encoded_url = urllib.parse.urlunsplit(parts)
            else:
                encoded_url = urllib.parse.quote(url, safe="/:?=&%")
            
            # Restore _ENC( pattern
            encoded_url = encoded_url.replace("__ENC_PAREN_PLACEHOLDER__", "_ENC%28")
            
            # Also encode closing parenthesis if it follows _ENC%28
            if "_ENC%28" in encoded_url and ")" in encoded_url:
                # Find the position and encode the closing paren
                enc_pos = encoded_url.find("_ENC%28")
                # Find the matching closing paren
                # This is simplified - assumes ) appears after _ENC%28
                paren_pos = encoded_url.find(")", enc_pos)
                if paren_pos != -1:
                    encoded_url = encoded_url[:paren_pos] + "%29" + encoded_url[paren_pos+1:]
            
            print(f"Final encoded URL: {encoded_url[:]}...")
            print(f"Contains %24%24 (double dollar encoded): {'%24%24' in encoded_url}")
            print(f"Contains _ENC%28: {'_ENC%28' in encoded_url}")
            
            return encoded_url
            
        # Fix both CDN URLs
        args.pickle_cdn_url = fix_cdn_url(args.pickle_cdn_url)
        args.config_cdn_url = fix_cdn_url(args.config_cdn_url)

        # The pipeline_id argument is used in the trigger URL
        trigger_url = f"{args.domain}/bob-service-test/v1.0/pipeline/trigger/ml?pipelineId={args.pipeline_id}"
        with open(args.access_token, 'r') as f:
            access_token = f.read().strip()
        headers = {
            "accept": "application/json",
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }

        # Build payload with all pipeline parameters including rlaf_schema
        payload = {
            "pipelineType": "ML",
            "containerResources": {},
            "experimentId": args.experiment_id,
            "enableCaching": True,
            "parameters": {
                "pickle_cdn_url": args.pickle_cdn_url,
                "config_cdn_url": args.config_cdn_url,
                "model_name": args.model_name,
                "model_config": args.model_config,
                "execution_id": args.execution_id,
                "experiment_id": args.experiment_id,
                "model_id": args.model_id,
                "project_id": args.project_id,
                "splitting_strategy": args.splitting_strategy,
                "num_tasks": args.num_tasks,
                "userName": args.userName,
                "password": args.password,
                "requesttype": args.requesttype,
                "productid": args.productid,
                "domain": args.domain,
                "model_schema": args.model_schema,
                "train_schema": args.train_schema,
                "eval_schema": args.eval_schema,
                "pipeline_id": args.dqn_pipeline_id,
                "rlaf_schema": args.rlaf_schema,
                # Added missing parameters to payload
                "architecture_type": args.architecture_type,
                "cdn_url": args.cdn_url,
                "load_from_cdn_url": args.load_from_cdn_url
            },
            "version": 1
        }

        print(f"\\n=== PAYLOAD FOR MANUAL TRIGGER ===")
        print("=" * 80)
        print("\\nFULL PAYLOAD JSON:")
        print("=" * 80)
        print(json.dumps(payload, indent=2))
        print("=" * 80)
        
        print(f"\\nTriggering CNN pipeline at: {trigger_url}")
        print(f"CNN Pipeline ID (to trigger): {args.pipeline_id}")
        print(f"DQN Pipeline ID (parameter): {args.dqn_pipeline_id}")
        print(f"RLAF Schema ID: {args.rlaf_schema}")
        
        print(f"\\n=== FINAL PARAMETERS ===")
        print(f"pickle_cdn_url (first 100 chars): {args.pickle_cdn_url[:]}")
        print(f"config_cdn_url (first 100 chars): {args.config_cdn_url[:]}")

        # Print the full curl command
        print("\\n=== FULL CURL COMMAND ===")
        print("=" * 80)
        print()
        print("curl -X POST \\\\")
        print(f"  '{trigger_url}' \\\\")
        print("  -H 'accept: application/json' \\\\")
        print(f"  -H 'Authorization: Bearer {access_token}' \\\\")
        print("  -H 'Content-Type: application/json' \\\\")
        print(f"  -d '{json.dumps(payload)}'")
        print("=" * 80)
        print()

        # Also save payload to file for manual use
        with open('/tmp/pipeline_payload.json', 'w') as f:
            json.dump(payload, f, indent=2)
        print(f"\\nPayload saved to /tmp/pipeline_payload.json for manual use")
        
        # To manually trigger from command line, you can use:
        print("\\n=== MANUAL TRIGGER INSTRUCTIONS ===")
        print("=" * 80)
        print("1. Copy the curl command above")
        print("2. Or use the saved payload file:")
        print(f"   curl -X POST '{trigger_url}' \\\\")
        print("     -H 'accept: application/json' \\\\")
        print(f"     -H 'Authorization: Bearer YOUR_TOKEN_HERE' \\\\")
        print("     -H 'Content-Type: application/json' \\\\")
        print("     -d @/tmp/pipeline_payload.json")
        print("=" * 80)
        print()

        import time
        curl_command = [
            "curl",
            "--location", trigger_url,
            "--header", f"accept: {headers['accept']}",
            "--header", f"Authorization: {headers['Authorization']}",
            "--header", f"Content-Type: {headers['Content-Type']}",
            "--data", json.dumps(payload),
            "--fail",
            "--show-error",
            "--connect-timeout", "30"
        ]

        retries = 5
        retry_delay = 60
        for i in range(retries):
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    check=True,
                    text=True
                )
                print("Pipeline trigger successful. Raw response:")
                print(process.stdout)
                
                # Try to parse and pretty print the response
                try:
                    response_json = json.loads(process.stdout)
                    print("\\nParsed response:")
                    print(json.dumps(response_json, indent=2))
                except:
                    print("Could not parse response as JSON")
                    
                break
            except subprocess.CalledProcessError as e:
                print(f"Attempt {i+1} failed with return code {e.returncode}.")
                print(f"Stderr: {e.stderr}")
                print(f"Stdout: {e.stdout}")
                
                if i < retries - 1:
                    if e.returncode == 22:
                         print(f"Retrying in {retry_delay} seconds...")
                         time.sleep(retry_delay)
                         continue
                    else:
                        print("Non-retriable error encountered.")
                        raise e
                else:
                    print("Max retries reached. Failing.")
                    raise e
            except Exception as e:
                print(f"An unexpected error occurred: {e}")
                raise e
    args:
      - --pickle_cdn_url
      - {inputValue: pickle_cdn_url}
      - --config_cdn_url
      - {inputValue: config_cdn_url}
      - --access_token
      - {inputPath: access_token}
      - --domain
      - {inputValue: domain}
      - --pipeline_id
      - {inputValue: pipeline_id}
      - --experiment_id
      - {inputValue: experiment_id}
      - --model_config
      - {inputValue: model_config}
      - --model_name
      - {inputValue: model_name}
      - --execution_id
      - {inputValue: execution_id}
      - --model_id
      - {inputValue: model_id}
      - --project_id
      - {inputValue: project_id}
      - --splitting_strategy
      - {inputValue: splitting_strategy}
      - --num_tasks
      - {inputValue: num_tasks}
      - --userName
      - {inputValue: userName}
      - --password
      - {inputValue: password}
      - --requesttype
      - {inputValue: requesttype}
      - --productid
      - {inputValue: productid}
      - --model_schema
      - {inputValue: model_schema}
      - --train_schema
      - {inputValue: train_schema}
      - --eval_schema
      - {inputValue: eval_schema}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --rlaf_schema
      - {inputValue: rlaf_schema}
      # Added args for missing parameters
      - --architecture_type
      - {inputValue: architecture_type}
      - --cdn_url
      - {inputValue: cdn_url}
      - --load_from_cdn_url
      - {inputValue: load_from_cdn_url}
