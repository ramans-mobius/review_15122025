name: Trigger CNN Pipeline v6
description: Triggers an Elyra Kubeflow pipeline for CNN training with DQN optimization.
inputs:
  - {name: pickle_cdn_url, type: String, description: "URL to the uploaded pickle file"}
  - {name: config_cdn_url, type: String, description: "URL to the uploaded config string"}
  - {name: access_token, type: String, description: "Bearer token for pipeline trigger authentication"}
  - {name: domain, type: String, description: "Domain for the pipeline trigger API (e.g., https://ig.mobiusdtaas.ai)"}
  - {name: pipeline_id, type: String, description: "ID of the Elyra Kubeflow pipeline to trigger"}
  - {name: experiment_id, type: String, description: "ID of the Kubeflow experiment"}
  - {name: model_config, type: String, description: "JSON string for model configuration"}
  - {name: model_name, type: String, description: "Name of the model to be used"}
  - {name: execution_id, type: String, description: "exec id for the run"}
  - {name: model_id, type: String, description: "ID of the model"}
  - {name: project_id, type: String, description: "Project ID"}
  - {name: splitting_strategy, type: String, description: "Splitting strategy for continual learning tasks"}
  - {name: num_tasks, type: Integer, description: "Number of continual learning tasks"}
  - {name: userName, type: String, description: "Username for IAM authentication"}
  - {name: password, type: String, description: "Password for IAM authentication"}
  - {name: requesttype, type: String, description: "Request type for IAM authentication"}
  - {name: productid, type: String, description: "Product ID for IAM authentication"}
  - {name: model_schema, type: String, description: "Schema ID for model metrics"}
  - {name: train_schema, type: String, description: "Schema ID for training history"}
  - {name: eval_schema, type: String, description: "Schema ID for evaluation metrics"}
  - {name: dqn_pipeline_id, type: String, description: "ID of the DQN RLAF pipeline to trigger from within the CNN pipeline"}
  - {name: rlaf_schema, type: String, description: "Schema ID for RLAF (Reinforcement Learning Agent Framework) metrics"}  # Added RLAF schema
implementation:
  container:
    image: python:3.8-slim
    command:
      - sh
      - -ec
      - |
        if ! command -v curl &> /dev/null; then
            echo "curl could not be found, installing..."
            apt-get update > /dev/null && apt-get install -y curl > /dev/null
        fi
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import subprocess
        import json
        import os
        import urllib.parse

        parser = argparse.ArgumentParser(description="Trigger a CNN Kubeflow pipeline.")
        parser.add_argument('--pickle_cdn_url', type=str, required=True, help='URL to the uploaded pickle file.')
        parser.add_argument('--config_cdn_url', type=str, required=True, help='URL to the uploaded config string.')
        parser.add_argument('--access_token', type=str, required=True, help='Bearer token for pipeline trigger authentication.')
        parser.add_argument('--domain', type=str, required=True, help='Domain for the pipeline trigger API.')
        parser.add_argument('--pipeline_id', type=str, required=True, help='ID of the Elyra Kubeflow pipeline to trigger.')
        parser.add_argument('--experiment_id', type=str, required=True, help='ID of the Kubeflow experiment.')
        parser.add_argument('--model_config', type=str, required=True, help='JSON string for model configuration.')
        parser.add_argument('--model_name', type=str, required=True, help='Name of the model to be used.')
        parser.add_argument('--execution_id', type=str, required=True, help='exec id for the run.')
        parser.add_argument('--model_id', type=str, required=True, help='ID of the model.')
        parser.add_argument('--project_id', type=str, required=True, help='Project ID.')
        parser.add_argument('--splitting_strategy', type=str, required=True, help='Splitting strategy for continual learning tasks.')
        parser.add_argument('--num_tasks', type=int, required=True, help='Number of continual learning tasks.')
        parser.add_argument('--userName', type=str, required=True, help='Username for IAM authentication.')
        parser.add_argument('--password', type=str, required=True, help='Password for IAM authentication.')
        parser.add_argument('--requesttype', type=str, required=True, help='Request type for IAM authentication.')
        parser.add_argument('--productid', type=str, required=True, help='Product ID for IAM authentication.')
        parser.add_argument('--model_schema', type=str, required=True, help='Schema ID for model metrics.')
        parser.add_argument('--train_schema', type=str, required=True, help='Schema ID for training history.')
        parser.add_argument('--eval_schema', type=str, required=True, help='Schema ID for evaluation metrics.')
        parser.add_argument('--dqn_pipeline_id', type=str, required=True, help='ID of the DQN RLAF pipeline.')
        parser.add_argument('--rlaf_schema', type=str, required=True, help='Schema ID for RLAF metrics.')  # Added RLAF schema argument
        args = parser.parse_args()

        def fix_cdn_url(url):
           
            print(f"\\n=== Processing URL ===")
            print(f"Input URL: {url[:]}...")
            
            # Step 1: First, decode any existing URL encoding
            try:
                url = urllib.parse.unquote(url)
            except:
                pass
            
            print(f"After unquote: {url[:]}...")
            
            # Step 2: CRITICAL - Restore the $$ pattern
            # Look for patterns like: _$_ or %24_%24 or _%24_
            # Replace with $$
            
            # Pattern 1: _$_ (already single dollar)
            if "_$_" in url:
                print(f"Found _$_ pattern, restoring to $$")
                url = url.replace("_$_", "_$$_")
            
            # Pattern 2: %24_%24 (URL encoded dollar signs)
            if "%24_%24" in url:
                print(f"Found %24_%24 pattern, restoring to $$")
                url = url.replace("%24_%24", "$$")
            
            # Pattern 3: _%24_ (mixed pattern)
            if "_%24_" in url:
                print(f"Found _%24_ pattern, restoring to $$")
                url = url.replace("_%24_", "_$$_")
            
            # Pattern 4: Single $ that should be $$
            # This is tricky - we need to identify where single $ should be double
            # Look for pattern: something_$something
            import re
            # Find all occurrences of _ followed by $ followed by _
            matches = re.finditer(r'(_\$_)', url)
            for match in matches:
                print(f"Found single dollar pattern at position {match.start()}")
            
            # For now, let's just ensure we preserve any existing $$
            if "$$" in url:
                print(f"Found $$ pattern in URL - GOOD!")
            
            print(f"After $$ restoration: {url[:]}...")
            
            # Step 3: Handle _ENC( pattern
            if "_ENC(" in url:
                print(f"Found _ENC( pattern - preserving")
            elif "_ENC%28" in url:
                print(f"Found _ENC%28 pattern, converting to _ENC(")
                url = url.replace("_ENC%28", "_ENC(")
            
            # Step 4: Remove any spaces
            url = url.replace(" ", "")
            
            print(f"After cleanup: {url[:]}...")
            
            # Step 5: Properly encode the URL for curl
            # Split into parts and encode only the path
            if "://" in url:
                parts = list(urllib.parse.urlsplit(url))
                # Encode the path but preserve / and other safe chars
                parts[2] = urllib.parse.quote(parts[2], safe="/")
                # Encode query and fragment if present
                if parts[3]:  # query
                    parts[3] = urllib.parse.quote(parts[3], safe="=&")
                if parts[4]:  # fragment
                    parts[4] = urllib.parse.quote(parts[4], safe="")
                final_url = urllib.parse.urlunsplit(parts)
            else:
                # Fallback: encode everything
                final_url = urllib.parse.quote(url, safe="/:?=&%")
            
            print(f"Final encoded URL: {final_url[:]}...")
            print(f"Contains $$: {'$$' in final_url}")
            print(f"Contains _ENC(: {'_ENC(' in final_url}")
            
            return final_url

        # Fix both CDN URLs
        args.pickle_cdn_url = fix_cdn_url(args.pickle_cdn_url)
        args.config_cdn_url = fix_cdn_url(args.config_cdn_url)

        # The pipeline_id argument is used in the trigger URL
        trigger_url = f"{args.domain}/bob-service-test/v1.0/pipeline/trigger/ml?pipelineId={args.pipeline_id}"
        with open(args.access_token, 'r') as f:
            access_token = f.read().strip()
        headers = {
            "accept": "application/json",
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }

        # Build payload with all pipeline parameters including rlaf_schema
        payload = {
            "pipelineType": "ML",
            "containerResources": {},
            "experimentId": args.experiment_id,
            "enableCaching": True,
            "parameters": {
                "pickle_cdn_url": args.pickle_cdn_url,
                "config_cdn_url": args.config_cdn_url,
                "model_name": args.model_name,
                "model_config": args.model_config,
                "execution_id": args.execution_id,
                "experiment_id": args.experiment_id,
                "model_id": args.model_id,
                "project_id": args.project_id,
                "splitting_strategy": args.splitting_strategy,
                "num_tasks": args.num_tasks,
                "userName": args.userName,
                "password": args.password,
                "requesttype": args.requesttype,
                "productid": args.productid,
                "domain": args.domain,
                "model_schema": args.model_schema,
                "train_schema": args.train_schema,
                "eval_schema": args.eval_schema,
                "pipeline_id": args.dqn_pipeline_id,
                "rlaf_schema": args.rlaf_schema  
            },
            "version": 1
        }

        print(f"\\nTriggering CNN pipeline at: {trigger_url}")
        print(f"CNN Pipeline ID (to trigger): {args.pipeline_id}")
        print(f"DQN Pipeline ID (parameter): {args.dqn_pipeline_id}")
        print(f"RLAF Schema ID: {args.rlaf_schema}")
        
        print(f"\\n=== FINAL PARAMETERS ===")
        print(f"pickle_cdn_url (first 100 chars): {args.pickle_cdn_url[:]}")
        print(f"config_cdn_url (first 100 chars): {args.config_cdn_url[:]}")

        # Print the full curl command
        print("\\n=== FULL CURL COMMAND ===")
        print()
        print("curl -X POST \\\\")
        print(f"  '{trigger_url}' \\\\")
        print("  -H 'accept: application/json' \\\\")
        print(f"  -H 'Authorization: Bearer {access_token}' \\\\")
        print("  -H 'Content-Type: application/json' \\\\")
        print(f"  -d '{json.dumps(payload)}'")
        print()

        import time
        curl_command = [
            "curl",
            "--location", trigger_url,
            "--header", f"accept: {headers['accept']}",
            "--header", f"Authorization: {headers['Authorization']}",
            "--header", f"Content-Type: {headers['Content-Type']}",
            "--data", json.dumps(payload),
            "--fail",
            "--show-error",
            "--connect-timeout", "30"
        ]

        retries = 5
        retry_delay = 60
        for i in range(retries):
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    check=True,
                    text=True
                )
                print("Pipeline trigger successful. Raw response:")
                print(process.stdout)
                
                # Try to parse and pretty print the response
                try:
                    response_json = json.loads(process.stdout)
                    print("\\nParsed response:")
                    print(json.dumps(response_json, indent=2))
                except:
                    print("Could not parse response as JSON")
                    
                break
            except subprocess.CalledProcessError as e:
                print(f"Attempt {i+1} failed with return code {e.returncode}.")
                print(f"Stderr: {e.stderr}")
                print(f"Stdout: {e.stdout}")
                
                if i < retries - 1:
                    if e.returncode == 22:
                         print(f"Retrying in {retry_delay} seconds...")
                         time.sleep(retry_delay)
                         continue
                    else:
                        print("Non-retriable error encountered.")
                        raise e
                else:
                    print("Max retries reached. Failing.")
                    raise e
            except Exception as e:
                print(f"An unexpected error occurred: {e}")
                raise e
    args:
      - --pickle_cdn_url
      - {inputValue: pickle_cdn_url}
      - --config_cdn_url
      - {inputValue: config_cdn_url}
      - --access_token
      - {inputPath: access_token}
      - --domain
      - {inputValue: domain}
      - --pipeline_id
      - {inputValue: pipeline_id}
      - --experiment_id
      - {inputValue: experiment_id}
      - --model_config
      - {inputValue: model_config}
      - --model_name
      - {inputValue: model_name}
      - --execution_id
      - {inputValue: execution_id}
      - --model_id
      - {inputValue: model_id}
      - --project_id
      - {inputValue: project_id}
      - --splitting_strategy
      - {inputValue: splitting_strategy}
      - --num_tasks
      - {inputValue: num_tasks}
      - --userName
      - {inputValue: userName}
      - --password
      - {inputValue: password}
      - --requesttype
      - {inputValue: requesttype}
      - --productid
      - {inputValue: productid}
      - --model_schema
      - {inputValue: model_schema}
      - --train_schema
      - {inputValue: train_schema}
      - --eval_schema
      - {inputValue: eval_schema}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --rlaf_schema
      - {inputValue: rlaf_schema}
