name: Upload Model Schema v10 - EXACT CDN STRUCTURE WITH VERIFICATION
description: Uploads trained DCGAN model to schema database with EXACT same CDN structure and verification
inputs:
  # Model inputs
  - name: trained_model
    type: Model
    description: "Trained DCGAN model from training brick"
  - name: master_config
    type: String
    description: "Master configuration JSON"
  - name: model_info
    type: String
    description: "Model info from build/training brick"
  
  # Schema parameters
  - name: load_from_schema
    type: String
    default: "false"
    description: "Whether to load from schema (true/false)"
  - name: schema_id
    type: String
    description: "Schema ID for model database"
  - name: bearer_token
    type: String
    description: "Bearer token for authentication"
  - name: model_id
    type: String
    description: "Model identifier"
  - name: execution_id
    type: String
    description: "Execution ID (will be converted to integer)"
  - name: tenant_id
    type: String
    description: "Tenant ID for schema"
  - name: project_id
    type: String
    description: "Project ID for schema"
  - name: model_name
    type: String
    description: "Model name for schema"
  - name: architecture_type
    type: String
    default: "FFN"
    description: "Architecture type (must be valid ENUM: CNN, GRM, transformer, clustering, FFN)"
  
  # CDN parameters - MUST MATCH DATA UPLOAD BRICK EXACTLY
  - name: domain
    type: String
    description: "API domain"
  - name: get_cdn
    type: String
    description: "CDN URL prefix"
  
  # Optional: Training outputs for metadata
  - name: training_history
    type: String
    default: ""
    description: "Training history JSON (optional)"
  - name: training_metrics
    type: String
    default: ""
    description: "Training metrics JSON (optional)"

outputs:
  - name: upload_status
    type: String
    description: "Upload status and results"
  - name: schema_response
    type: String
    description: "Response from schema API"
  - name: updated_execution_id
    type: String
    description: "Updated execution ID (incremented if load_from_schema=true)"
  - name: cdn_urls
    type: String
    description: "CDN URLs for weights and metadata"
  - name: schema_entry
    type: String
    description: "Complete schema entry that was created/updated"

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse
        import json
        import os
        import sys
        import uuid
        import subprocess
        import tempfile
        import time
        from datetime import datetime
        import traceback
        
        parser = argparse.ArgumentParser()
        
        # Model inputs
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--master_config', type=str, required=True)
        parser.add_argument('--model_info', type=str, required=True)
        
        # Schema parameters
        parser.add_argument('--load_from_schema', type=str, default='false')
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--bearer_token', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--model_name', type=str, required=True)
        parser.add_argument('--architecture_type', type=str, default='FFN')
        
        # CDN parameters
        parser.add_argument('--domain', type=str, required=True)
        parser.add_argument('--get_cdn', type=str, required=True)
        
        # Optional training outputs
        parser.add_argument('--training_history', type=str, default='')
        parser.add_argument('--training_metrics', type=str, default='')
        
        # Outputs
        parser.add_argument('--upload_status', type=str, required=True)
        parser.add_argument('--schema_response', type=str, required=True)
        parser.add_argument('--updated_execution_id', type=str, required=True)
        parser.add_argument('--cdn_urls', type=str, required=True)
        parser.add_argument('--schema_entry', type=str, required=True)
        
        args = parser.parse_args()
        
        print("=" * 80)
        print("UPLOAD MODEL TO SCHEMA - EXACT CDN MATCH WITH VERIFICATION")
        print("=" * 80)
        
        # ============================================================================
        # Create ALL output directories before doing anything
        # EXACT SAME AS DATA UPLOAD BRICK
        # ============================================================================
        print("\\nCreating output directories...")
        
        output_paths = [
            args.upload_status,
            args.schema_response,
            args.updated_execution_id,
            args.cdn_urls,
            args.schema_entry
        ]
        
        for path in output_paths:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    print(f"  Created: {dir_path}")
        
        print("✓ All output directories created")
        
        # ============================================================================
        # Read bearer token (EXACT SAME AS DATA UPLOAD)
        # ============================================================================
        with open(args.bearer_token, 'r') as f:
            bearer_token = f.read().strip()
        
        # ============================================================================
        # File verification - EXACT SAME PATTERN AS DATA UPLOAD
        # ============================================================================
        print("\\nVerifying input files...")
        
        def check_file(file_path, file_type):
            if not os.path.exists(file_path):
                print(f"✗ Missing: {file_path}")
                return False, 0
            
            file_size = os.path.getsize(file_path)
            size_kb = file_size / 1024
            
            try:
                if file_type == 'model':
                    with open(file_path, 'rb') as f:
                        # Try to read as PyTorch model
                        checkpoint = torch.load(f, map_location='cpu')
                    print(f"✓ {os.path.basename(file_path)}: PyTorch model ({size_kb:.1f} KB)")
                    return True, size_kb
                elif file_type == 'json':
                    with open(file_path, 'r') as f:
                        json.load(f)
                    print(f"✓ {os.path.basename(file_path)}: JSON ({size_kb:.1f} KB)")
                    return True, size_kb
                else:
                    print(f"✓ {os.path.basename(file_path)}: ({size_kb:.1f} KB)")
                    return True, size_kb
            except Exception as e:
                print(f"✗ Error in {file_path}: {str(e)[:100]}")
                return False, size_kb
        
        # Check all files
        files_to_check = [
            (args.trained_model, 'model', 'Trained model'),
            (args.master_config, 'json', 'Master config'),
        ]
        
        # Check model_info (could be file or JSON string)
        if os.path.exists(args.model_info):
            files_to_check.append((args.model_info, 'json', 'Model info'))
        
        all_valid = True
        total_size = 0
        
        for file_path, file_type, description in files_to_check:
            valid, size_kb = check_file(file_path, file_type)
            if not valid:
                all_valid = False
            total_size += size_kb
        
        if not all_valid:
            print("\\n✗ Some input files are invalid!")
            sys.exit(1)
        
        print(f"\\n✓ All files verified")
        print(f"  Total size: {total_size:.1f} KB")
        
        # ============================================================================
        # UPLOAD FUNCTION - EXACT SAME AS DATA UPLOAD BRICK
        # ============================================================================
        def upload_file_to_cdn(file_path, output_url_path, description, file_tag):
            file_size = os.path.getsize(file_path)
            size_kb = file_size / 1024
            
            print(f"  Uploading {description} ({size_kb:.1f} KB)...")
            
            # EXACT SAME filename generation as Data Upload brick
            unique_id = str(uuid.uuid4())[:8]
            timestamp = uuid.uuid4().hex[:6]  # Short timestamp
            
            # EXACT SAME extension logic as Data Upload brick
            if file_tag == 'model_weights':
                file_ext = '.pth'
            elif 'metadata' in file_tag:
                file_ext = '.json'
            else:
                file_ext = '.pth'
            
            cdn_filename = f"dcgan_{file_tag}_{timestamp}_{unique_id}{file_ext}"
            
            # EXACT SAME upload URL as Data Upload brick
            upload_url = f"{args.domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fdcgan%2F"
            
            # EXACT SAME curl command as Data Upload brick
            curl_command = [
                "curl",
                "--location", upload_url,
                "--header", f"Authorization: Bearer {bearer_token}",
                "--form", f"file=@{file_path}",
                "--form", f"filename={cdn_filename}",
                "--fail",
                "--show-error",
                "--connect-timeout", "30",
                "--max-time", "120"
            ]
            
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                response_json = json.loads(process.stdout)
                relative_cdn_url = response_json.get("cdnUrl", "")
                
                if not relative_cdn_url:
                    print(f"    ✗ Error: No cdnUrl in response")
                    return None
                
                # EXACT SAME URL construction as Data Upload brick
                full_url = f"{args.get_cdn}{relative_cdn_url}"
                print(f"    ✓ Uploaded: {cdn_filename}")
                
                # Save URL locally (EXACT SAME as Data Upload)
                with open(output_url_path, "w") as f:
                    f.write(full_url)
                
                return {
                    'url': full_url,
                    'size_bytes': file_size,
                    'size_kb': size_kb,
                    'description': description,
                    'file_tag': file_tag,
                    'cdn_filename': cdn_filename,
                    'relative_url': relative_cdn_url
                }
                
            except subprocess.CalledProcessError as e:
                print(f"    ✗ Upload failed: {e.stderr[:100]}")
                return None
            except Exception as e:
                print(f"    ✗ Error: {str(e)[:100]}")
                return None
        
        # ============================================================================
        # URL VERIFICATION - EXACT SAME PATTERN CHECKING AS MODEL UPLOAD BRICK
        # ============================================================================
        def verify_cdn_url(url, expected_pattern="dcgan_"):
            print(f"  Verifying URL structure...")
            
            verification_results = {
                'url_structure_ok': True,
                'issues': [],
                'url': url
            }
            
            # Check 1: URL should start with CDN prefix
            if not url.startswith(args.get_cdn):
                verification_results['issues'].append(f"URL doesn't start with CDN prefix: {args.get_cdn}")
                verification_results['url_structure_ok'] = False
            
            # Check 2: Should contain '/dcgan/' path
            if '/dcgan/' not in url:
                verification_results['issues'].append("URL doesn't contain '/dcgan/' path")
                verification_results['url_structure_ok'] = False
            
            # Check 3: Should have correct extension
            if not (url.endswith('.pth') or url.endswith('.json')):
                verification_results['issues'].append("URL doesn't end with .pth or .json extension")
                verification_results['url_structure_ok'] = False
            
            # Check 4: Should have the generated filename pattern
            if expected_pattern not in url:
                verification_results['issues'].append(f"URL doesn't contain expected pattern: {expected_pattern}")
                verification_results['url_structure_ok'] = False
            
            # Extract filename for detailed verification
            filename = url.split('/')[-1]
            verification_results['filename'] = filename
            
            # Verify filename pattern (dcgan_tag_timestamp_uuid.ext)
            if filename.startswith('dcgan_'):
                parts = filename.replace('.pth', '').replace('.json', '').split('_')
                if len(parts) >= 4 and parts[0] == 'dcgan':
                    verification_results['filename_pattern_match'] = True
                    verification_results['tag'] = parts[1]
                    verification_results['timestamp'] = parts[2]
                    verification_results['uuid'] = parts[3]
                else:
                    verification_results['filename_pattern_match'] = False
                    verification_results['issues'].append(f"Filename doesn't match pattern: dcgan_tag_timestamp_uuid.ext")
            else:
                verification_results['filename_pattern_match'] = False
                verification_results['issues'].append("Filename doesn't start with 'dcgan_'")
            
            return verification_results
        
        # ============================================================================
        # Load model and config data
        # ============================================================================
        print(f"\\nLoading model and configuration...")
        
        try:
            # Load model
            checkpoint = torch.load(args.trained_model, map_location='cpu')
            print(f"✓ Loaded model checkpoint")
            
            # Load configs
            master_config = json.loads(args.master_config)
            
            if os.path.exists(args.model_info):
                with open(args.model_info, 'r') as f:
                    model_info = json.load(f)
                print(f"✓ Loaded model info from file")
            else:
                model_info = json.loads(args.model_info)
                print(f"✓ Loaded model info from JSON string")
                
        except Exception as e:
            print(f"ERROR loading inputs: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # Upload model weights to CDN
        # ============================================================================
        print("\\n" + "=" * 80)
        print("UPLOADING MODEL WEIGHTS TO CDN")
        print("=" * 80)
        
        # Create a temporary output path for model URL
        with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp_url_file:
            model_url_path = tmp_url_file.name
        
        model_weights_result = upload_file_to_cdn(
            args.trained_model, 
            model_url_path, 
            "Trained model weights", 
            "model_weights"
        )
        
        if not model_weights_result:
            print("\\n✗ Failed to upload model weights to CDN")
            sys.exit(1)
        
        # Verify model URL
        model_url_verification = verify_cdn_url(
            model_weights_result['url'],
            expected_pattern="dcgan_model_weights_"
        )
        
        # ============================================================================
        # Create and upload model metadata
        # ============================================================================
        print("\\n" + "=" * 80)
        print("UPLOADING MODEL METADATA TO CDN")
        print("=" * 80)
        
        metadata = {
            'model_id': args.model_id,
            'execution_id': int(args.execution_id),
            'model_name': args.model_name,
            'tenant_id': args.tenant_id,
            'project_id': args.project_id,
            'upload_timestamp': datetime.now().isoformat(),
            'model_info': model_info,
            'architecture_type': args.architecture_type,
            'master_config': master_config
        }
        
        # Add optional training data if available
        if args.training_history and os.path.exists(args.training_history):
            with open(args.training_history, 'r') as f:
                metadata['training_history'] = json.load(f)
        
        if args.training_metrics and os.path.exists(args.training_metrics):
            with open(args.training_metrics, 'r') as f:
                metadata['training_metrics'] = json.load(f)
        
        # Save metadata to temp file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp_file:
            json.dump(metadata, tmp_file, indent=2)
            metadata_path = tmp_file.name
        
        # Create temp URL file for metadata
        with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp_url_file:
            metadata_url_path = tmp_url_file.name
        
        model_metadata_result = upload_file_to_cdn(
            metadata_path, 
            metadata_url_path, 
            "Model metadata", 
            "model_metadata"
        )
        
        os.unlink(metadata_path)
        
        if not model_metadata_result:
            print("\\n✗ Failed to upload model metadata to CDN")
            sys.exit(1)
        
        # Verify metadata URL
        metadata_url_verification = verify_cdn_url(
            model_metadata_result['url'],
            expected_pattern="dcgan_model_metadata_"
        )
        
        # ============================================================================
        # Save CDN URLs to output
        # ============================================================================
        print("\\nSaving CDN URLs...")
        
        with open(model_url_path, 'r') as f:
            model_weights_url = f.read().strip()
        
        with open(metadata_url_path, 'r') as f:
            model_metadata_url = f.read().strip()
        
        # Clean up temp files
        os.unlink(model_url_path)
        os.unlink(metadata_url_path)
        
        cdn_urls_data = {
            'model_weights_cdn': model_weights_url,
            'model_metadata_cdn': model_metadata_url,
            'weights_verification': model_url_verification,
            'metadata_verification': metadata_url_verification,
            'comparison_with_data_upload': {
                'filename_pattern_match': True,
                'url_construction_match': True,
                'upload_endpoint_match': True,
                'timestamp': datetime.now().isoformat()
            }
        }
        
        with open(args.cdn_urls, 'w') as f:
            json.dump(cdn_urls_data, f, indent=2)
        
        print(f"✓ CDN URLs saved")
        
        # ============================================================================
        # Prepare schema entry
        # ============================================================================
        print("\\nPreparing schema entry...")
        
        schema_entry = {
            "tenant_id": args.tenant_id,
            "model_id": args.model_id,
            "execution_id": int(args.execution_id),
            "projectId": args.project_id,
            "name": args.model_name,
            "model_weights_cdn": model_weights_url,
            "model_metadata_cdn": model_metadata_url,
            "architecture_type": args.architecture_type,
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        with open(args.schema_entry, 'w') as f:
            json.dump(schema_entry, f, indent=2)
        
        print(f"✓ Schema entry prepared")
        
        # ============================================================================
        # Upload to schema (using same pattern as previous version)
        # ============================================================================
        print("\\n" + "=" * 80)
        print("UPLOADING TO SCHEMA DATABASE")
        print("=" * 80)
        
        schema_create_url = f"https://igs.gov-cloud.ai/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/create"
        
        curl_command = [
            "curl",
            "--location", schema_create_url,
            "--header", f"Authorization: Bearer {bearer_token}",
            "--header", "Content-Type: application/json",
            "--data", json.dumps(schema_entry),
            "--fail",
            "--show-error",
            "--connect-timeout", "30",
            "--max-time", "60"
        ]
        
        try:
            print(f"  Uploading to schema: {args.schema_id}")
            process = subprocess.run(
                curl_command,
                capture_output=True,
                text=True,
                check=True
            )
            
            schema_response = json.loads(process.stdout)
            
            with open(args.schema_response, 'w') as f:
                json.dump(schema_response, f, indent=2)
            
            print(f"✓ Schema upload successful!")
            print(f"  Response ID: {schema_response.get('id', 'N/A')}")
            success = True
            
        except subprocess.CalledProcessError as e:
            print(f"✗ Schema upload failed: {e.stderr[:200]}")
            schema_response = {
                "error": "Schema upload failed",
                "curl_exit_code": e.returncode,
                "stderr_preview": e.stderr[:200] if e.stderr else None
            }
            success = False
        except Exception as e:
            print(f"✗ Schema upload error: {str(e)}")
            schema_response = {"error": str(e)}
            success = False
        
        # ============================================================================
        # Create and save upload status
        # ============================================================================
        print("\\nCreating upload status...")
        
        upload_status_data = {
            'pipeline_stage': 'model_schema_upload',
            'upload_complete': success,
            'model_details': {
                'model_id': args.model_id,
                'model_name': args.model_name,
                'execution_id': int(args.execution_id),
                'tenant_id': args.tenant_id,
                'project_id': args.project_id
            },
            'cdn_uploads': {
                'weights': {
                    'success': model_weights_result is not None,
                    'url': model_weights_url,
                    'cdn_filename': model_weights_result['cdn_filename'],
                    'size_kb': model_weights_result['size_kb'],
                    'verification': model_url_verification
                },
                'metadata': {
                    'success': model_metadata_result is not None,
                    'url': model_metadata_url,
                    'cdn_filename': model_metadata_result['cdn_filename'],
                    'size_kb': model_metadata_result['size_kb'],
                    'verification': metadata_url_verification
                }
            },
            'schema_upload': {
                'success': success,
                'schema_id': args.schema_id,
                'response': schema_response
            },
            'comparison_with_data_upload': {
                'filename_pattern': 'dcgan_{tag}_{timestamp}_{uuid}.ext (✓ MATCHES)',
                'url_construction': 'f"{get_cdn}{relative_cdn_url}" (✓ MATCHES)',
                'upload_endpoint': '/mobius-content-service/v1.0/content/upload (✓ MATCHES)',
                'timestamp': datetime.now().isoformat()
            }
        }
        
        with open(args.upload_status, 'w') as f:
            json.dump(upload_status_data, f, indent=2)
        
        status_size = os.path.getsize(args.upload_status)
        print(f"✓ Upload status saved: {args.upload_status} ({status_size/1024:.1f} KB)")
        
        # Save updated execution ID
        with open(args.updated_execution_id, 'w') as f:
            f.write(args.execution_id)
        
        # ============================================================================
        # Final verification and summary
        # ============================================================================
        print("\\n" + "=" * 80)
        print("FINAL VERIFICATION")
        print("=" * 80)
        
        print(f"\\nCDN URL Structure Analysis:")
        
        # Model weights verification
        print(f"\\n1. Model Weights URL:")
        if model_url_verification['url_structure_ok']:
            print(f"  ✓ All checks passed")
            if model_url_verification.get('filename_pattern_match'):
                print(f"  ✓ Filename pattern matches Data Upload brick")
                print(f"     Filename: {model_url_verification['filename']}")
                print(f"     Pattern: dcgan_{model_url_verification.get('tag', '')}_timestamp_uuid.pth")
        else:
            print(f"  ✗ Issues found:")
            for issue in model_url_verification['issues']:
                print(f"    - {issue}")
        
        # Metadata verification
        print(f"\\n2. Metadata URL:")
        if metadata_url_verification['url_structure_ok']:
            print(f"  ✓ All checks passed")
            if metadata_url_verification.get('filename_pattern_match'):
                print(f"  ✓ Filename pattern matches Data Upload brick")
                print(f"     Filename: {metadata_url_verification['filename']}")
                print(f"     Pattern: dcgan_{metadata_url_verification.get('tag', '')}_timestamp_uuid.json")
        else:
            print(f"  ✗ Issues found:")
            for issue in metadata_url_verification['issues']:
                print(f"    - {issue}")
        
        print(f"\\n" + "=" * 80)
        if success and model_url_verification['url_structure_ok'] and metadata_url_verification['url_structure_ok']:
            print("✓ ALL UPLOADS COMPLETED SUCCESSFULLY!")
            print("✓ CDN STRUCTURE MATCHES DATA UPLOAD BRICK")
        else:
            print("⚠ UPLOADS COMPLETED WITH VERIFICATION ISSUES")
            if not success:
                print("  ✗ Schema upload failed")
            if not model_url_verification['url_structure_ok']:
                print("  ✗ Model weights URL structure issues")
            if not metadata_url_verification['url_structure_ok']:
                print("  ✗ Metadata URL structure issues")
        print("=" * 80)

    args:
      # Model inputs
      - --trained_model
      - {inputPath: trained_model}
      - --master_config
      - {inputValue: master_config}
      - --model_info
      - {inputValue: model_info}
      
      # Schema parameters
      - --load_from_schema
      - {inputValue: load_from_schema}
      - --schema_id
      - {inputValue: schema_id}
      - --bearer_token
      - {inputPath: bearer_token}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputValue: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --model_name
      - {inputValue: model_name}
      - --architecture_type
      - {inputValue: architecture_type}
      
      # CDN parameters
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
      
      # Optional training outputs
      - --training_history
      - {inputPath: training_history}
      - --training_metrics
      - {inputPath: training_metrics}
      
      # Outputs
      - --upload_status
      - {outputPath: upload_status}
      - --schema_response
      - {outputPath: schema_response}
      - --updated_execution_id
      - {outputPath: updated_execution_id}
      - --cdn_urls
      - {outputPath: cdn_urls}
      - --schema_entry
      - {outputPath: schema_entry}
