name: Upload Model To Schema Complete v2
description: Uploads model to schema with complete required fields only
inputs:
  # Model inputs
  - name: trained_model
    type: Model
    description: "Trained DCGAN model"
  - name: model_weights_cdn_url
    type: String
    description: "CDN URL for model weights (from upload brick)"
  - name: model_metadata_cdn_url
    type: String
    description: "CDN URL for model metadata (from upload brick)"
  - name: master_config
    type: String
    description: "Master configuration JSON"
  - name: model_info
    type: String
    description: "Model info from build/training brick"
  
  # Schema parameters
  - name: schema_id
    type: String
    description: "Schema ID for model database"
  - name: bearer_token
    type: String
    description: "Bearer token for authentication"
  - name: model_id
    type: String
    description: "Model identifier"
  - name: execution_id
    type: String
    description: "Execution ID (will be converted to integer)"
  - name: tenant_id
    type: String
    description: "Tenant ID for schema"
  - name: project_id
    type: String
    description: "Project ID for schema"
  - name: model_name
    type: String
    description: "Model name for schema"
  - name: architecture_type
    type: String
    default: "FFN"
    description: "Architecture type"

outputs:
  - name: schema_response
    type: String
    description: "Full response from schema API"
  - name: schema_entry
    type: String
    description: "Schema entry that was submitted"
  - name: upload_status
    type: String
    description: "Upload status summary"

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        apt-get update > /dev/null && apt-get install -y curl jq > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse
        import json
        import os
        import sys
        import subprocess
        import tempfile
        from datetime import datetime
        import traceback
        import urllib.parse
        
        parser = argparse.ArgumentParser()
        
        # Model inputs
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--model_weights_cdn_url', type=str, required=True)
        parser.add_argument('--model_metadata_cdn_url', type=str, required=True)
        parser.add_argument('--master_config', type=str, required=True)
        parser.add_argument('--model_info', type=str, required=True)
        
        # Schema parameters
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--bearer_token', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--model_name', type=str, required=True)
        parser.add_argument('--architecture_type', type=str, default='FFN')
        
        # Outputs
        parser.add_argument('--schema_response', type=str, required=True)
        parser.add_argument('--schema_entry', type=str, required=True)
        parser.add_argument('--upload_status', type=str, required=True)
        
        args = parser.parse_args()
        
        print("=" * 80)
        print("UPLOAD MODEL TO SCHEMA COMPLETE v2 - DEBUG VERSION")
        print("=" * 80)
        print("Schema fields: model_weights_cdn, model_url (same), model_metadata_cdn")
        print("Hardcoded source: manual")
        print("=" * 80)
        
        # Create output directories
        for path in [args.schema_response, args.schema_entry, args.upload_status]:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
        
        # ============================================================================
        # DEBUG: Print all input values
        # ============================================================================
        print("\\nDEBUG - INPUT VALUES:")
        print("-" * 60)
        print(f"trained_model path: {args.trained_model}")
        print(f"model_weights_cdn_url: {args.model_weights_cdn_url}")
        print(f"model_metadata_cdn_url: {args.model_metadata_cdn_url}")
        print(f"master_config: {args.master_config[:100]}...")
        print(f"model_info: {args.model_info[:100]}...")
        print(f"schema_id: {args.schema_id}")
        print(f"bearer_token length: {len(args.bearer_token)}")
        print(f"model_id: {args.model_id}")
        print(f"execution_id: {args.execution_id}")
        print(f"tenant_id: {args.tenant_id}")
        print(f"project_id: {args.project_id}")
        print(f"model_name: {args.model_name}")
        print(f"architecture_type: {args.architecture_type}")
        print("-" * 60)
        
        # Read bearer token (it's already a string, but if it's a file path, read it)
        if os.path.exists(args.bearer_token) and os.path.isfile(args.bearer_token):
            with open(args.bearer_token, 'r') as f:
                bearer_token = f.read().strip()
            print(f"✓ Bearer token read from file")
        else:
            bearer_token = args.bearer_token
            print(f"✓ Bearer token used as string")
        
        # ============================================================================
        # Read CDN URLs - FIXED
        # ============================================================================
        print("\\nReading CDN URLs...")
        
        # Handle CDN URLs - they should be passed as strings, not file paths
        if args.model_weights_cdn_url.startswith('http'):
            model_weights_cdn = args.model_weights_cdn_url.strip()
            print(f"✓ Model weights CDN from string input")
        elif os.path.exists(args.model_weights_cdn_url) and os.path.isfile(args.model_weights_cdn_url):
            with open(args.model_weights_cdn_url, 'r') as f:
                model_weights_cdn = f.read().strip()
            print(f"✓ Model weights CDN read from file")
        else:
            model_weights_cdn = args.model_weights_cdn_url.strip()
            print(f"✓ Model weights CDN from string (not a file)")
        
        if args.model_metadata_cdn_url.startswith('http'):
            model_metadata_cdn = args.model_metadata_cdn_url.strip()
            print(f"✓ Model metadata CDN from string input")
        elif os.path.exists(args.model_metadata_cdn_url) and os.path.isfile(args.model_metadata_cdn_url):
            with open(args.model_metadata_cdn_url, 'r') as f:
                model_metadata_cdn = f.read().strip()
            print(f"✓ Model metadata CDN read from file")
        else:
            model_metadata_cdn = args.model_metadata_cdn_url.strip()
            print(f"✓ Model metadata CDN from string (not a file)")
        
        # DEBUG: Show the actual URLs
        print("\\nDEBUG - ACTUAL CDN URLS:")
        print("-" * 60)
        print(f"model_weights_cdn (raw): {model_weights_cdn}")
        print(f"model_weights_cdn length: {len(model_weights_cdn)}")
        print(f"model_metadata_cdn (raw): {model_metadata_cdn}")
        print(f"model_metadata_cdn length: {len(model_metadata_cdn)}")
        
        # Check for encoding issues
        print("\\nURL ENCODING CHECK:")
        print(f"Contains $$: {'$$' in model_weights_cdn}")
        print(f"Contains $_: '$_' in model_weights_cdn")
        print(f"Contains special chars: {[c for c in model_weights_cdn if ord(c) > 127 or c in '$&+,\\:;=?@#']}")
        
        # Fix URL encoding if needed
        if '$_' in model_weights_cdn:
            print("⚠ Found $_ in URL, this might need encoding")
            # Try to properly encode the URL
            parsed = urllib.parse.urlparse(model_weights_cdn)
            print(f"Parsed scheme: {parsed.scheme}")
            print(f"Parsed netloc: {parsed.netloc}")
            print(f"Parsed path: {parsed.path[:100]}...")
        
        print("-" * 60)
        
        # Load model to extract metadata
        print("\\nLoading model to extract metadata...")
        try:
            if os.path.exists(args.trained_model):
                checkpoint = torch.load(args.trained_model, map_location='cpu', weights_only=False)
                
                # Extract model metadata
                latent_dim = checkpoint.get('latent_dim', 100)
                image_size = checkpoint.get('image_size', 64)
                channels = checkpoint.get('channels', 3)
                
                # Count parameters
                generator_params = 0
                discriminator_params = 0
                
                if 'generator_state_dict' in checkpoint:
                    generator_params = sum(p.numel() for p in checkpoint['generator_state_dict'].values())
                
                if 'discriminator_state_dict' in checkpoint:
                    discriminator_params = sum(p.numel() for p in checkpoint['discriminator_state_dict'].values())
                
                total_params = generator_params + discriminator_params
                
                print(f"✓ Model loaded:")
                print(f"  Latent dim: {latent_dim}")
                print(f"  Image size: {image_size}")
                print(f"  Channels: {channels}")
                print(f"  Generator params: {generator_params:,}")
                print(f"  Discriminator params: {discriminator_params:,}")
                print(f"  Total params: {total_params:,}")
                
            else:
                print(f"⚠ Model file not found at: {args.trained_model}")
                latent_dim = 100
                image_size = 64
                channels = 3
                total_params = 0
                
        except Exception as e:
            print(f"⚠ Could not load model for metadata: {e}")
            print(f"Error details: {traceback.format_exc()}")
            latent_dim = 100
            image_size = 64
            channels = 3
            total_params = 0
        
        # Load configs
        try:
            master_config = json.loads(args.master_config)
            print(f"✓ Master config loaded: {len(master_config)} keys")
        except:
            print(f"⚠ Could not parse master_config as JSON, using empty dict")
            master_config = {}
        
        try:
            if os.path.exists(args.model_info):
                with open(args.model_info, 'r') as f:
                    model_info = json.load(f)
                print(f"✓ Model info loaded from file")
            else:
                model_info = json.loads(args.model_info)
                print(f"✓ Model info parsed from string")
        except:
            print(f"⚠ Could not load model_info, using empty dict")
            model_info = {}
        
        # ============================================================================
        # Prepare COMPLETE schema entry - ONLY required and important fields
        # ============================================================================
        print("\\n" + "=" * 80)
        print("PREPARING SCHEMA ENTRY")
        print("=" * 80)
        
        # Calculate shapes for DCGAN
        input_shape = f"[{latent_dim}]"  # Latent vector input
        output_shape = f"[{channels}, {image_size}, {image_size}]"  # Generated image output
        
        schema_entry = {
            # REQUIRED FIELDS (from schema)
            "tenant_id": args.tenant_id,
            "model_id": args.model_id,
            "execution_id": int(args.execution_id),
            "projectId": args.project_id,
            "name": args.model_name,
            
            # HARDCODED SOURCE
            "source": "manual",
            
            # CDN URLs (ALL THREE as per schema)
            "model_weights_cdn": model_weights_cdn,
            "model_metadata_cdn": model_metadata_cdn,
            "model_url": model_weights_cdn,  # Same as model_weights_cdn
            
            # Architecture
            "architecture_type": args.architecture_type,
            
            # Model shapes
            "input_shape": input_shape,
            "output_shape": output_shape,
            
            # Parameter count
            "parameter_count": str(total_params),
            
            # Model-specific config (simplified)
            "model_specific_config": {
                "model_type": "DCGAN",
                "latent_dim": latent_dim,
                "image_size": image_size,
                "channels": channels,
                "config_source": "master_config"
            },
            
            # Creation info
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "created_by": "DCGAN Pipeline"
        }
        
        # Add optional fields as null
        optional_fields = ["experiment_id", "symbolic_profile"]
        for field in optional_fields:
            if field not in schema_entry:
                schema_entry[field] = None
        
        # DEBUG: Print schema entry with types
        print("\\nSCHEMA ENTRY WITH DATA TYPES:")
        print("-" * 80)
        for key, value in schema_entry.items():
            value_type = type(value).__name__
            if isinstance(value, str):
                value_preview = f"'{value[:50]}...'" if len(value) > 50 else f"'{value}'"
                print(f"  {key}: {value_preview} (type: {value_type}, length: {len(value)})")
            elif isinstance(value, (int, float, bool)):
                print(f"  {key}: {value} (type: {value_type})")
            elif value is None:
                print(f"  {key}: null (type: None)")
            elif isinstance(value, dict):
                print(f"  {key}: dict with keys: {list(value.keys())} (type: {value_type})")
            else:
                print(f"  {key}: {value} (type: {value_type})")
        print("-" * 80)
        
        # Save schema entry
        with open(args.schema_entry, 'w') as f:
            json.dump(schema_entry, f, indent=2)
        print(f"✓ Schema entry saved to: {args.schema_entry}")
        
        # ============================================================================
        # Upload to schema with DETAILED RESPONSE
        # ============================================================================
        print("\\n" + "=" * 80)
        print("UPLOADING TO SCHEMA DATABASE")
        print("=" * 80)
        
        schema_create_url = f"https://igs.gov-cloud.ai/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/create"
        
        # Prepare curl command with verbose output
        curl_command = [
            "curl",
            "--location", schema_create_url,
            "--header", f"Authorization: Bearer {bearer_token}",
            "--header", "Content-Type: application/json",
            "--data", json.dumps(schema_entry),
            "--verbose",
            "--fail",
            "--show-error",
            "--connect-timeout", "30",
            "--max-time", "120"
        ]
        
        print(f"Uploading to schema: {args.schema_id}")
        print(f"URL: {schema_create_url}")
        print(f"Bearer token preview: {bearer_token[:20]}...")
        print(f"Data size: {len(json.dumps(schema_entry)):,} bytes")
        print(f"\\nCurl command preview:")
        print(f"  curl --location '{schema_create_url}'")
        print(f"    --header 'Authorization: Bearer {bearer_token[:20]}...'")
        print(f"    --header 'Content-Type: application/json'")
        print(f"    --data '[{len(json.dumps(schema_entry)):,} bytes of JSON]'")
        
        try:
            print("\\n" + "-" * 80)
            print("EXECUTING CURL COMMAND...")
            print("-" * 80)
            
            process = subprocess.run(
                curl_command,
                capture_output=True,
                text=True,
                check=True
            )
            
            print(f"\\n✓ Schema upload successful!")
            print(f"Exit code: {process.returncode}")
            
            # Parse and display response
            try:
                schema_response = json.loads(process.stdout)
                print("\\nFULL RESPONSE JSON:")
                print("-" * 80)
                print(json.dumps(schema_response, indent=2))
                print("-" * 80)
                
                # Extract key information
                print("\\nEXTRACTED INFORMATION:")
                print("-" * 40)
                if 'id' in schema_response:
                    print(f"Response ID: {schema_response['id']}")
                if 'status' in schema_response:
                    print(f"Status: {schema_response['status']}")
                if 'message' in schema_response:
                    print(f"Message: {schema_response['message']}")
                if 'data' in schema_response:
                    data = schema_response['data']
                    if isinstance(data, dict):
                        print(f"Data fields: {list(data.keys())}")
                        # Print all data fields
                        for key, value in data.items():
                            if isinstance(value, (str, int, float, bool)):
                                print(f"  {key}: {value}")
                            elif value is None:
                                print(f"  {key}: null")
                            else:
                                print(f"  {key}: {type(value).__name__}")
                    else:
                        print(f"Data type: {type(data).__name__}")
                        print(f"Data value: {data}")
                
            except json.JSONDecodeError as e:
                print(f"⚠ Response is not valid JSON: {e}")
                print(f"Raw response (first 1000 chars):")
                print("-" * 40)
                print(process.stdout[:1000])
                if len(process.stdout) > 1000:
                    print(f"... [{len(process.stdout) - 1000} more characters]")
                print("-" * 40)
                schema_response = {"raw_response": process.stdout, "json_error": str(e)}
            
            # Save response
            with open(args.schema_response, 'w') as f:
                if isinstance(schema_response, dict):
                    json.dump(schema_response, f, indent=2)
                else:
                    f.write(str(schema_response))
            
            upload_success = True
            
        except subprocess.CalledProcessError as e:
            print(f"\\n✗ Schema upload failed!")
            print(f"Exit code: {e.returncode}")
            
            # Show verbose output from curl
            print("\\nCURL VERBOSE OUTPUT:")
            print("-" * 80)
            print(e.stderr)
            print("-" * 80)
            
            # Try to parse error
            error_data = None
            if e.stdout:
                print("\\nRESPONSE BODY:")
                print("-" * 40)
                print(e.stdout)
                print("-" * 40)
                try:
                    error_data = json.loads(e.stdout)
                    print(f"\\nError response (parsed JSON):")
                    print(json.dumps(error_data, indent=2))
                except json.JSONDecodeError:
                    print(f"\\nError response (raw, not JSON):")
                    print(e.stdout[:2000])
                    error_data = {"raw_error": e.stdout[:2000]}
            else:
                print("No response body received")
            
            schema_response = {
                "error": "Schema upload failed",
                "curl_exit_code": e.returncode,
                "stdout": error_data if error_data else e.stdout[:2000] if e.stdout else None,
                "stderr": e.stderr[:2000] if e.stderr else None,
                "schema_entry_submitted": schema_entry
            }
            
            with open(args.schema_response, 'w') as f:
                json.dump(schema_response, f, indent=2)
            
            upload_success = False
            
        except Exception as e:
            print(f"\\n✗ Unexpected error: {e}")
            print("\\nTRACEBACK:")
            print("-" * 80)
            traceback.print_exc()
            print("-" * 80)
            
            schema_response = {
                "error": str(e),
                "traceback": traceback.format_exc(),
                "schema_entry": schema_entry
            }
            
            with open(args.schema_response, 'w') as f:
                json.dump(schema_response, f, indent=2)
            
            upload_success = False
        
        # ============================================================================
        # Create upload status summary
        # ============================================================================
        print("\\n" + "=" * 80)
        print("UPLOAD STATUS SUMMARY")
        print("=" * 80)
        
        upload_status_data = {
            "timestamp": datetime.now().isoformat(),
            "overall_success": upload_success,
            "schema_id": args.schema_id,
            "model_id": args.model_id,
            "model_name": args.model_name,
            "execution_id": int(args.execution_id),
            "fields_submitted": {
                "total": len(schema_entry),
                "required_fields": ["tenant_id", "model_id", "execution_id", "projectId", "name", "source"],
                "all_required_present": all(field in schema_entry for field in ["tenant_id", "model_id", "execution_id", "projectId", "name", "source"]),
                "cdn_urls_present": all(field in schema_entry for field in ["model_weights_cdn", "model_metadata_cdn", "model_url"]),
                "source_field": schema_entry.get("source", "missing")
            },
            "cdn_urls_debug": {
                "model_weights_cdn_length": len(model_weights_cdn),
                "model_weights_cdn_preview": model_weights_cdn[:200] + "..." if len(model_weights_cdn) > 200 else model_weights_cdn,
                "model_metadata_cdn_length": len(model_metadata_cdn),
                "model_metadata_cdn_preview": model_metadata_cdn[:200] + "..." if len(model_metadata_cdn) > 200 else model_metadata_cdn,
                "model_url_same_as_weights": model_weights_cdn == schema_entry.get("model_url", "")
            },
            "data_types_check": {
                "execution_id_type": type(schema_entry.get("execution_id")).__name__,
                "parameter_count_type": type(schema_entry.get("parameter_count")).__name__,
                "input_shape_type": type(schema_entry.get("input_shape")).__name__,
                "output_shape_type": type(schema_entry.get("output_shape")).__name__
            },
            "schema_response_summary": {
                "has_id": 'id' in schema_response if isinstance(schema_response, dict) else False,
                "has_status": 'status' in schema_response if isinstance(schema_response, dict) else False,
                "success": upload_success,
                "error_message": schema_response.get('error') if isinstance(schema_response, dict) and 'error' in schema_response else None
            }
        }
        
        with open(args.upload_status, 'w') as f:
            json.dump(upload_status_data, f, indent=2)
        
        print(f"✓ Upload status saved")
        
        # ============================================================================
        # Final summary
        # ============================================================================
        print("\\n" + "=" * 80)
        if upload_success:
            print("✓ ALL UPLOADS COMPLETED SUCCESSFULLY!")
        else:
            print("✗ UPLOAD FAILED - CHECK ERROR DETAILS ABOVE")
        print("=" * 80)
        
        print(f"\\nFinal Summary:")
        print(f"  Model: {args.model_name} ({args.model_id})")
        print(f"  Schema: {args.schema_id}")
        print(f"  Execution ID: {args.execution_id} (as int: {int(args.execution_id)})")
        print(f"  CDN URLs included: ✓" if upload_success else "  CDN URLs included: ✗")
        print(f"  Source field: {schema_entry.get('source', 'missing')}")
        print(f"  Overall Success: {'✓ YES' if upload_success else '✗ NO'}")
        
        if not upload_success and isinstance(schema_response, dict):
            print(f"\\nError Details:")
            if 'error' in schema_response:
                print(f"  Error: {schema_response['error']}")
            if 'curl_exit_code' in schema_response:
                print(f"  Curl Exit Code: {schema_response['curl_exit_code']}")
        
        print("=" * 80)
        
        # Exit with appropriate code
        sys.exit(0 if upload_success else 1)

    args:
      # Model inputs - NOTE: Using inputValue for URLs since they're strings
      - --trained_model
      - {inputPath: trained_model}
      - --model_weights_cdn_url
      - {inputValue: model_weights_cdn_url}  # CHANGED from inputPath to inputValue
      - --model_metadata_cdn_url
      - {inputValue: model_metadata_cdn_url}  # CHANGED from inputPath to inputValue
      - --master_config
      - {inputValue: master_config}
      - --model_info
      - {inputValue: model_info}
      
      # Schema parameters
      - --schema_id
      - {inputValue: schema_id}
      - --bearer_token
      - {inputValue: bearer_token}  # CHANGED from inputPath to inputValue
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputValue: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --model_name
      - {inputValue: model_name}
      - --architecture_type
      - {inputValue: architecture_type}
      
      # Outputs
      - --schema_response
      - {outputPath: schema_response}
      - --schema_entry
      - {outputPath: schema_entry}
      - --upload_status
      - {outputPath: upload_status}
