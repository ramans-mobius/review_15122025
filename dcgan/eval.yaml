name: Evaluate v3
description: Evaluates DCGAN model using single master config
inputs:
  - name: trained_model
    type: Model
  - name: test_data
    type: Dataset
  - name: preprocess_metadata
    type: String
  - name: master_config
    type: String
outputs:
  - name: metrics
    type: Metrics
  - name: metrics_json
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -c
      - |
        echo "Checking for torchvision..."
        python3 -c "import torchvision; print(f'torchvision version: {torchvision.__version__}')" 2>/dev/null || {
          echo "torchvision not found, installing 0.17.0..."
          pip install torchvision==0.17.0 pillow
        }
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse, pickle, json, os, io, traceback
        import numpy as np
        import torchvision.transforms as transforms
        import torch.nn.functional as F
        from PIL import Image
        from torch.utils.data import DataLoader, Dataset
        import base64
        
        # ============================================================================
        # Define classes needed for unpickling
        # ============================================================================
        class GANDataset:
            def __init__(self, data_list, transform=None, image_size=64, channels=3):
                self.data_list = data_list
                self.transform = transform
                self.image_size = image_size
                self.channels = channels
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                item = self.data_list[idx]
                try:
                    # Create a dummy image since we don't have real images
                    if self.channels == 1:
                        img = Image.new('L', (self.image_size, self.image_size), color=128)
                    else:
                        img = Image.new('RGB', (self.image_size, self.image_size), color=(128, 128, 128))
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img
                except Exception as e:
                    print(f"Error creating dummy image {idx}: {e}")
                    return torch.zeros(self.channels, self.image_size, self.image_size)
        
        class GANDataWrapper:
            def __init__(self, dataset, model_type='dcgan', image_size=64, channels=3, 
                        transform_params=None):
                self.dataset = dataset
                self.model_type = model_type
                self.image_size = image_size
                self.channels = channels
                self.transform_params = transform_params or {}
                self.num_samples = len(dataset)
            
            def __len__(self):
                return len(self.dataset)
            
            def __getitem__(self, idx):
                return self.dataset[idx]
        
        # Define PreprocessMetadata class
        class PreprocessMetadata:
            def __init__(self, image_size=64, channels=3, model_type='dcgan',
                        mean=(0.5,), std=(0.5,), transform_params=None):
                self.image_size = image_size
                self.channels = channels
                self.model_type = model_type
                self.mean = mean
                self.std = std
                self.transform_params = transform_params or {}
        
        # ============================================================================
        # Import DCGAN modules
        # ============================================================================
        try:
            from nesy_factory.GANs.dcgan import (
                create_dcgan,
                DcganMetrics,
                DCGANEvaluator
            )
            print(" Successfully imported DCGAN modules")
        except ImportError as e:
            print(f" ERROR: nesyfactory not available: {e}")
            sys.exit(1)
        
        parser = argparse.ArgumentParser()
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--test_data", required=True)
        parser.add_argument("--preprocess_metadata", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--metrics", required=True)
        parser.add_argument("--metrics_json", required=True)
        args = parser.parse_args()
        
        print("=== STARTING DCGAN EVALUATION ===")
        
        # Define custom unpickler
        class SafeUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                # Allow our custom classes
                if name == 'GANDataWrapper':
                    return GANDataWrapper
                elif name == 'GANDataset':
                    return GANDataset
                elif name == 'PreprocessMetadata':
                    return PreprocessMetadata
                return super().find_class(module, name)
        
        # Load raw test data
        with open(args.test_data, "rb") as f:
            unpickler = SafeUnpickler(f)
            test_data_raw = unpickler.load()
        
        print(f"Loaded test data: {len(test_data_raw) if hasattr(test_data_raw, '__len__') else 'unknown'} samples")
        
        # Load preprocessing metadata
        with open(args.preprocess_metadata, "rb") as f:
            unpickler = SafeUnpickler(f)
            preprocess_meta = unpickler.load()
        
        print(f"Preprocessing metadata loaded:")
        print(f"  Image size: {preprocess_meta.image_size}")
        print(f"  Channels: {preprocess_meta.channels}")
        
        # Create the same transform used for training
        if preprocess_meta.channels == 1:
            transform = transforms.Compose([
                transforms.Resize(preprocess_meta.image_size),
                transforms.CenterCrop(preprocess_meta.image_size),
                transforms.ToTensor(),
                transforms.Normalize(preprocess_meta.mean, preprocess_meta.std)
            ])
        else:
            transform = transforms.Compose([
                transforms.Resize(preprocess_meta.image_size),
                transforms.CenterCrop(preprocess_meta.image_size),
                transforms.ToTensor(),
                transforms.Normalize(preprocess_meta.mean, preprocess_meta.std)
            ])
        
        # Create preprocessed test dataset
        test_dataset = GANDataset(
            test_data_raw,
            transform=transform,
            image_size=preprocess_meta.image_size,
            channels=preprocess_meta.channels
        )
        
        print(f"Preprocessed test dataset: {len(test_dataset)} samples")
        
        # ============================================================================
        # LOAD MODEL - USE CONFIG FROM CHECKPOINT, NOT MASTER CONFIG
        # ============================================================================
        print("\\nLoading trained model...")
        checkpoint = torch.load(args.trained_model, map_location='cpu')
        
        if isinstance(checkpoint, dict):
            # Use the EXACT config from training, not master config
            model_config = checkpoint.get('config', {})
            training_mode = checkpoint.get('training_mode', 'unknown')
            
            print(f"Model config from checkpoint:")
            print(f"  Training mode: {training_mode}")
            if 'generator' in model_config and 'hidden_dims' in model_config['generator']:
                print(f"  Generator hidden_dims: {model_config['generator']['hidden_dims']}")
            if 'discriminator' in model_config and 'hidden_dims' in model_config['discriminator']:
                print(f"  Discriminator hidden_dims: {model_config['discriminator']['hidden_dims']}")
            
            # Create DCGAN models WITH THE EXACT SAME CONFIG AS TRAINING
            generator, discriminator, full_config = create_dcgan(model_config)
            
            # Load state dicts
            if 'generator_state_dict' in checkpoint:
                generator.load_state_dict(checkpoint['generator_state_dict'], strict=True)
                print(f"✓ Generator state dict loaded")
            if 'discriminator_state_dict' in checkpoint:
                discriminator.load_state_dict(checkpoint['discriminator_state_dict'], strict=True)
                print(f"✓ Discriminator state dict loaded")
                
            print(f"✓ Model loaded successfully")
            print(f"  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}")
            print(f"  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}")
        else:
            print("✗ Invalid checkpoint format")
            sys.exit(1)
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Device: {device}")
        
        # Set device
        generator.to(device)
        discriminator.to(device)
        
        # Set to eval mode
        generator.eval()
        discriminator.eval()
        
        # Create data loader
        batch_size = 4  # Use small batch size for small dataset
        test_loader = DataLoader(test_dataset, batch_size=min(batch_size, len(test_dataset)), shuffle=False)
        
        # Evaluate
        print(f"\\nEvaluating DCGAN on {len(test_dataset)} test samples...")
        
        # Create evaluator
        evaluator = DCGANEvaluator(full_config, device)
        
        # Evaluate using DCGANEvaluator (skip if dataset too small)
        eval_metrics = {}
        if len(test_dataset) >= 2:  # Need at least 2 samples for metrics
            try:
                eval_metrics = evaluator.evaluate(
                    generator, discriminator, 
                    test_loader,
                    num_batches=min(2, len(test_dataset) // max(1, batch_size))
                )
                print(f"✓ DCGANEvaluator metrics calculated")
            except Exception as e:
                print(f"Warning: DCGANEvaluator failed: {e}")
                eval_metrics = {}
        else:
            print(f"Warning: Dataset too small ({len(test_dataset)} samples) for full evaluation")
        
        # Basic manual metrics
        all_preds, all_targets = [], []
        total_g_loss = 0.0
        total_d_loss = 0.0
        total_batches = 0
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(test_loader):
                if batch_idx >= 5:  # Limit to 5 batches
                    break
                    
                real_images = batch
                real_images = real_images.to(device)
                
                # Generate fake images
                z = torch.randn(real_images.size(0), generator.z_dim, device=device)
                fake_images = generator(z)
                
                # Discriminator outputs
                real_output = discriminator(real_images)
                fake_output = discriminator(fake_images)
                
                # Generator loss
                g_loss = generator.calculate_loss(fake_output)
                
                # Discriminator loss
                d_loss = discriminator.calculate_loss(real_output, fake_output)
                
                total_g_loss += g_loss.item()
                total_d_loss += d_loss.item()
                total_batches += 1
                
                # Collect discriminator scores
                real_preds = (real_output > 0).float()
                fake_preds = (fake_output < 0).float()
                
                all_preds.extend(real_preds.cpu().tolist())
                all_preds.extend(fake_preds.cpu().tolist())
                
                all_targets.extend([1] * len(real_preds))
                all_targets.extend([0] * len(fake_preds))
        
        # Calculate accuracy
        try:
            correct = sum(1 for p, t in zip(all_preds, all_targets) if abs(p - t) < 0.5)
            total = len(all_targets)
            accuracy = float(correct / total) if total > 0 else 0.0
        except Exception as e:
            print(f"Warning: accuracy calculation failed: {e}")
            accuracy = 0.0
        
        # Calculate average losses
        avg_g_loss = float(total_g_loss / max(1, total_batches))
        avg_d_loss = float(total_d_loss / max(1, total_batches))
        
        # Combine metrics
        metrics_output = {
            "accuracy": float(accuracy),
            "generator_loss": float(avg_g_loss),
            "discriminator_loss": float(avg_d_loss),
            "training_mode": training_mode,
            "num_samples": int(len(all_targets)),
            "num_test_samples": len(test_dataset),
            "evaluation_success": True
        }
        
        # Add DCGANEvaluator metrics if available
        for key, value in eval_metrics.items():
            if isinstance(value, (int, float)) and not np.isnan(value):
                metrics_output[f"dcgan_{key}"] = float(value)
        
        print(f"\\nEvaluation Metrics:")
        print(f"  Accuracy: {float(accuracy):.4f}")
        print(f"  Generator Loss: {avg_g_loss:.4f}")
        print(f"  Discriminator Loss: {avg_d_loss:.4f}")
        print(f"  Training Mode: {training_mode}")
        
        # Save outputs
        os.makedirs(os.path.dirname(args.metrics), exist_ok=True)
        os.makedirs(os.path.dirname(args.metrics_json), exist_ok=True)
        
        with open(args.metrics_json, "w") as f:
            json.dump(metrics_output, f, indent=2)
        
        # KFP metrics format
        with open(args.metrics, "w") as f:
            f.write(f"accuracy: {float(accuracy)}\\n")
            f.write(f"generator_loss: {float(avg_g_loss)}\\n")
            f.write(f"discriminator_loss: {float(avg_d_loss)}\\n")
            f.write(f"training_mode: {training_mode}\\n")
        
        print("\\n=== EVALUATION COMPLETE ===")
        
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --test_data
      - {inputPath: test_data}
      - --preprocess_metadata
      - {inputPath: preprocess_metadata}
      - --master_config
      - {inputValue: master_config}
      - --metrics
      - {outputPath: metrics}
      - --metrics_json
      - {outputPath: metrics_json}
