name: Evaluate DCGAN v18
description: Evaluates DCGAN with comprehensive metrics and uploads generated images as JPEG to CDN
inputs:
  - name: trained_model
    type: Model
  - name: raw_test_data
    type: Dataset
  - name: preprocessor_params
    type: String
    description: "Preprocessing parameters JSON from preprocess brick"
  - name: master_config
    type: String
  - name: bearer_token
    type: String
    description: "Bearer token for CDN upload"
  - name: domain
    type: String
    description: "CDN upload domain"
  - name: get_cdn
    type: String
    description: "CDN download prefix"
outputs:
  - name: evaluation_metrics
    type: String
  - name: generated_samples
    type: Dataset
  - name: evaluation_summary
    type: String
  - name: rlaf_metrics
    type: Metrics
  - name: evaluation_results_url
    type: String
    description: "URL to evaluation results on CDN"
  - name: generated_images_url
    type: String
    description: "URL to generated images JPEG file on CDN"

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        pip install --no-cache-dir scikit-image==0.21.0 scipy==1.11.0 pillow > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, pickle, json, os, torch, time, sys, uuid, subprocess
        import numpy as np
        import warnings
        warnings.filterwarnings('ignore')
        
        # ============================================================================
        # INCLUDE ALL NECESSARY CLASS DEFINITIONS FROM PREVIOUS BRICKS
        # ============================================================================
        
        # Classes from Load Data Brick
        class RawDatasetWrapper:
            def __init__(self, images, labels, dataset_name='mnist'):
                self.images = images
                self.labels = labels
                self.dataset_name = dataset_name
                self.preprocessed = False
                self._num_samples = len(images)
            
            def __len__(self):
                return self._num_samples
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx],
                    'index': idx,
                    'dataset': self.dataset_name,
                    'preprocessed': self.preprocessed
                }
        
        # Classes from Preprocess Brick
        class PreprocessedDataset:
            def __init__(self, images, labels, dataset_name, preprocessor_params):
                self.images = images
                self.labels = labels
                self.dataset_name = dataset_name
                self.preprocessed = True
                self.preprocessor_params = preprocessor_params
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx],
                    'index': idx,
                    'dataset': self.dataset_name,
                    'preprocessed': True
                }
        
        # Dataset info wrapper
        class DatasetInfoWrapper:
            def __init__(self, info_dict):
                self.__dict__.update(info_dict)
        
        # ============================================================================
        # CDN UPLOAD FUNCTION - SAVES AS JPEG
        # ============================================================================
        
        def upload_images_as_jpeg(images_tensor, description):
           
            if images_tensor is None or len(images_tensor) == 0:
                print(f"    ERROR: No images to upload")
                return None
            
            print(f"  CDN: Preparing {len(images_tensor)} images for JPEG upload...")
            
            try:
                # Import matplotlib for image creation
                import matplotlib
                matplotlib.use('Agg')  # Non-interactive backend
                import matplotlib.pyplot as plt
                
                # Convert tensor to numpy and denormalize from [-1, 1] to [0, 1]
                images_np = images_tensor.cpu().numpy()
                images_np = (images_np + 1) / 2  # Denormalize to [0, 1]
                images_np = np.clip(images_np, 0, 1)
                
                # Handle different tensor shapes
                if images_np.shape[1] == 1:  # Grayscale
                    images_np = images_np[:, 0, :, :]  # Remove channel dimension
                    cmap = 'gray'
                else:
                    # For RGB, transpose to (N, H, W, C)
                    images_np = np.transpose(images_np, (0, 2, 3, 1))
                    cmap = None
                
                # Create figure with grid of images
                n_images = min(len(images_np), 16)  # Max 16 images
                n_cols = 4
                n_rows = (n_images + n_cols - 1) // n_cols
                
                fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 3 * n_rows))
                axes = axes.flatten() if n_rows > 1 else [axes]
                
                for i, (ax, img) in enumerate(zip(axes, images_np[:n_images])):
                    ax.imshow(img, cmap=cmap)
                    ax.axis('off')
                    ax.set_title(f'Sample {i+1}', fontsize=8)
                
                # Hide unused axes
                for i in range(len(images_np[:n_images]), len(axes)):
                    axes[i].axis('off')
                
                plt.suptitle(f'DCGAN Generated Samples - {description}', fontsize=12)
                plt.tight_layout()
                
                # Save to temporary file
                temp_dir = "/tmp/generated_images"
                os.makedirs(temp_dir, exist_ok=True)
                
                unique_id = str(uuid.uuid4())[:8]
                jpeg_filename = f"dcgan_eval_{description.replace(' ', '_')}_{unique_id}.jpg"
                jpeg_path = os.path.join(temp_dir, jpeg_filename)
                
                plt.savefig(jpeg_path, dpi=150, bbox_inches='tight', pad_inches=0.1)
                plt.close(fig)
                
                file_size = os.path.getsize(jpeg_path)
                print(f"  CDN: Saved JPEG: {jpeg_filename} ({file_size:,} bytes)")
                
            except Exception as e:
                print(f"  CDN ERROR creating JPEG: {e}")
                import traceback
                traceback.print_exc()
                return None
            
            # Upload to CDN
            print(f"  CDN: Uploading JPEG to CDN...")
            
            # URL with proper $ handling
            upload_url = f"{args.domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fdcgan%2Fmodels%2F"
            upload_url_encoded = upload_url.replace("$$", "$$$")
            
            curl_cmd = [
                "curl", "--location", upload_url_encoded,
                "--header", f"Authorization: Bearer {args.bearer_token}",
                "--form", f"file=@{jpeg_path}", "--form", f"filename={jpeg_filename}",
                "--fail", "--show-error", "--connect-timeout", "30", "--max-time", "120",
                "--silent"
            ]
            
            try:
                process = subprocess.run(curl_cmd, capture_output=True, text=True, check=True)
                response = json.loads(process.stdout)
                cdn_path = response.get('cdnUrl') or response.get('info', {}).get('cdnUrl') or response.get('url')
                
                if cdn_path:
                    full_url = cdn_path if cdn_path.startswith("http") else f"{args.get_cdn}{cdn_path}"
                    
                    # Ensure proper $$ pattern
                    if "_V1_data" in full_url and "_$$_V1_data" not in full_url:
                        if "_$_V1_data" in full_url:
                            full_url = full_url.replace("_$_V1_data", "_$$_V1_data")
                    
                    print(f"    CDN: Upload successful!")
                    print(f"    CDN: Filename: {jpeg_filename}")
                    print(f"    CDN: Full URL: {full_url}")
                    return full_url
                    
            except subprocess.CalledProcessError as e:
                print(f"    CDN ERROR (curl): {e.stderr[:200]}")
            except Exception as e:
                print(f"    CDN ERROR: {str(e)}")
            
            return None
        
        # ============================================================================
        # MAIN CODE
        # ============================================================================
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--raw_test_data', type=str, required=True)
        parser.add_argument('--preprocessor_params', type=str, required=True)
        parser.add_argument('--master_config', type=str, required=True)
        parser.add_argument('--bearer_token', type=str, required=True)
        parser.add_argument('--domain', type=str, required=True)
        parser.add_argument('--get_cdn', type=str, required=True)
        parser.add_argument('--evaluation_metrics', type=str, required=True)
        parser.add_argument('--generated_samples', type=str, required=True)
        parser.add_argument('--evaluation_summary', type=str, required=True)
        parser.add_argument('--rlaf_metrics', type=str, required=True)
        parser.add_argument('--evaluation_results_url', type=str, required=True)
        parser.add_argument('--generated_images_url', type=str, required=True)
        args = parser.parse_args()
        
        print("=" * 80)
        print("EVALUATE DCGAN v17 - WITH JPEG CDN UPLOAD")
        print("=" * 80)
        
        # ============================================================================
        # CREATE ALL OUTPUT DIRECTORIES FIRST
        # ============================================================================
        print("\\nCreating output directories...")
        output_paths = [
            args.evaluation_metrics,
            args.generated_samples,
            args.evaluation_summary,
            args.rlaf_metrics,
            args.evaluation_results_url,
            args.generated_images_url
        ]
        
        for path in output_paths:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    print(f"  Created: {dir_path}")
        
        # ============================================================================
        # METRICS CALCULATION FUNCTIONS
        # ============================================================================
        
        def calculate_ssim_psnr(real_images, fake_images):
            try:
                from skimage.metrics import structural_similarity as ssim
                from skimage.metrics import peak_signal_noise_ratio as psnr
                
                real_np = real_images.cpu().numpy()
                fake_np = fake_images.cpu().numpy()
                
                ssim_scores = []
                psnr_scores = []
                
                num_samples = min(len(real_np), len(fake_np), 20)
                
                for i in range(num_samples):
                    # Handle both grayscale and color images
                    if len(real_np[i].shape) == 3 and real_np[i].shape[0] == 1:
                        real_img = real_np[i][0]
                        fake_img = fake_np[i][0]
                    elif len(real_np[i].shape) == 3:
                        real_img = real_np[i].transpose(1, 2, 0)
                        fake_img = fake_np[i].transpose(1, 2, 0)
                    else:
                        real_img = real_np[i]
                        fake_img = fake_np[i]
                    
                    # Denormalize from [-1, 1] to [0, 1]
                    real_img = (real_img + 1) / 2
                    fake_img = (fake_img + 1) / 2
                    
                    try:
                        ssim_score = ssim(real_img, fake_img, data_range=1.0, 
                                          channel_axis=-1 if real_img.ndim == 3 else None)
                        ssim_scores.append(ssim_score)
                    except:
                        ssim_scores.append(0.0)
                    
                    try:
                        psnr_score = psnr(real_img, fake_img, data_range=1.0)
                        psnr_scores.append(psnr_score)
                    except:
                        psnr_scores.append(0.0)
                
                return {
                    'ssim_mean': float(np.mean(ssim_scores)),
                    'ssim_std': float(np.std(ssim_scores)),
                    'psnr_mean': float(np.mean(psnr_scores)),
                    'psnr_std': float(np.std(psnr_scores))
                }
                    
            except Exception as e:
                print(f"Warning: SSIM/PSNR calculation failed: {e}")
                return {
                    'ssim_mean': 0.0,
                    'ssim_std': 0.0,
                    'psnr_mean': 0.0,
                    'psnr_std': 0.0
                }
        
        def calculate_diversity_score(images):
            try:
                images_np = images.cpu().numpy().reshape(images.shape[0], -1)
                
                if len(images_np) > 1:
                    n_samples = min(20, len(images_np))
                    subset = images_np[:n_samples]
                    
                    distances = []
                    for i in range(n_samples):
                        for j in range(i + 1, n_samples):
                            dist = np.linalg.norm(subset[i] - subset[j])
                            distances.append(dist)
                    
                    if distances:
                        return float(np.mean(distances))
                
                return 0.0
            except Exception as e:
                print(f"Warning: Diversity score calculation failed: {e}")
                return 0.0
        
        def calculate_fid_simple(real_images, fake_images):
            print("  Calculating simplified FID...")
            
            # Flatten images
            real_np = real_images.cpu().numpy().reshape(real_images.shape[0], -1)
            fake_np = fake_images.cpu().numpy().reshape(fake_images.shape[0], -1)
            
            # Calculate statistics
            mu_real = np.mean(real_np, axis=0)
            sigma_real = np.cov(real_np, rowvar=False)
            
            mu_fake = np.mean(fake_np, axis=0)
            sigma_fake = np.cov(fake_np, rowvar=False)
            
            # Calculate FID
            try:
                diff = mu_real - mu_fake
                # Add small epsilon for numerical stability
                eps = 1e-6
                sigma_real = sigma_real + eps * np.eye(sigma_real.shape[0])
                sigma_fake = sigma_fake + eps * np.eye(sigma_fake.shape[0])
                
                from scipy import linalg
                covmean = linalg.sqrtm(sigma_real.dot(sigma_fake))
                if np.iscomplexobj(covmean):
                    covmean = covmean.real
                
                fid = diff.dot(diff) + np.trace(sigma_real + sigma_fake - 2*covmean)
                return float(fid)
                
            except Exception as e:
                print(f"  Warning: Simplified FID calculation failed: {e}")
                return float('nan')
        
        def calculate_all_metrics(real_images, fake_images, algorithm_name=""):
            print(f"\\nCalculating comprehensive metrics for {algorithm_name}...")
            
            metrics = {
                'algorithm': algorithm_name,
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'num_samples': len(real_images)
            }
            
            # Basic statistics
            metrics['real_stats'] = {
                'mean': float(real_images.mean().item()),
                'std': float(real_images.std().item()),
                'min': float(real_images.min().item()),
                'max': float(real_images.max().item())
            }
            
            metrics['fake_stats'] = {
                'mean': float(fake_images.mean().item()),
                'std': float(fake_images.std().item()),
                'min': float(fake_images.min().item()),
                'max': float(fake_images.max().item())
            }
            
            # Pixel-level metrics
            print("  Calculating SSIM and PSNR...")
            ssim_psnr_results = calculate_ssim_psnr(real_images, fake_images)
            metrics.update(ssim_psnr_results)
            
            # Diversity score
            print("  Calculating diversity score...")
            diversity = calculate_diversity_score(fake_images)
            metrics['diversity_score'] = diversity
            
            # FID score (simplified)
            fid = calculate_fid_simple(real_images, fake_images)
            metrics['fid_score'] = fid
            
            # Additional metrics
            print("  Calculating additional metrics...")
            
            # Mean Absolute Error
            mae = torch.mean(torch.abs(real_images - fake_images)).item()
            metrics['mae'] = mae
            
            # MSE
            mse = torch.mean((real_images - fake_images) ** 2).item()
            metrics['mse'] = mse
            
            # Histogram correlation
            try:
                real_hist = torch.histc(real_images.flatten(), bins=256, min=-1, max=1)
                fake_hist = torch.histc(fake_images.flatten(), bins=256, min=-1, max=1)
                hist_corr = torch.corrcoef(torch.stack([real_hist, fake_hist]))[0, 1].item()
                metrics['histogram_correlation'] = hist_corr
            except:
                metrics['histogram_correlation'] = 0.0
            
            return metrics
        
        # ============================================================================
        # CREATE RLAF-COMPATIBLE METRICS
        # ============================================================================
        
        def create_rlaf_metrics(metrics_dict, algorithm, model_info):
            rlaf_metrics = {
                'evaluation_timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'algorithm': algorithm,
                'model_info': model_info,
                
                # Primary metrics for RLAF optimization
                'primary_metrics': {
                    'fid_score': metrics_dict.get('fid_score', float('nan')),
                    'ssim_mean': metrics_dict.get('ssim_mean', 0.0),
                    'psnr_mean': metrics_dict.get('psnr_mean', 0.0),
                    'diversity_score': metrics_dict.get('diversity_score', 0.0),
                    'generator_quality_score': 0.0,
                    'discriminator_quality_score': 0.0
                },
                
                # Secondary metrics
                'secondary_metrics': {
                    'mae': metrics_dict.get('mae', 0.0),
                    'mse': metrics_dict.get('mse', 0.0),
                    'histogram_correlation': metrics_dict.get('histogram_correlation', 0.0)
                },
                
                # Composite scores for RLAF
                'composite_scores': {
                    'overall_quality': 0.0,
                    'image_fidelity': 0.0,
                    'diversity_quality': 0.0
                },
                
                # Metrics specifically formatted for DQN parameters
                'dqn_parameters': []
            }
            
            # Calculate composite scores
            fid = metrics_dict.get('fid_score', float('nan'))
            ssim = metrics_dict.get('ssim_mean', 0.0)
            psnr = metrics_dict.get('psnr_mean', 0.0)
            diversity = metrics_dict.get('diversity_score', 0.0)
            
            # Normalize and calculate scores
            if not np.isnan(fid) and fid > 0:
                fid_score = max(0, 100 - min(fid, 100)) / 100
            else:
                fid_score = 0.5
            
            ssim_score = min(ssim, 1.0)
            psnr_score = min(psnr / 50.0, 1.0)
            diversity_score = min(diversity / 10.0, 1.0)
            
            # Calculate composite scores
            rlaf_metrics['composite_scores']['image_fidelity'] = (ssim_score + psnr_score) / 2
            rlaf_metrics['composite_scores']['diversity_quality'] = diversity_score
            
            # Overall quality (weighted average)
            overall = (fid_score * 0.3 + ssim_score * 0.3 + psnr_score * 0.2 + diversity_score * 0.2)
            rlaf_metrics['composite_scores']['overall_quality'] = overall
            
            # Update primary metrics
            rlaf_metrics['primary_metrics']['generator_quality_score'] = overall
            rlaf_metrics['primary_metrics']['discriminator_quality_score'] = fid_score
            
            # Create DQN parameters
            dqn_params = [
                {'key': 'fid_score', 'sign': '-', 'value': fid if not np.isnan(fid) else 0.0, 'weight': 0.3},
                {'key': 'ssim_mean', 'sign': '+', 'value': ssim, 'weight': 0.3},
                {'key': 'psnr_mean', 'sign': '+', 'value': psnr, 'weight': 0.2},
                {'key': 'diversity_score', 'sign': '+', 'value': diversity, 'weight': 0.2},
                {'key': 'overall_quality', 'sign': '+', 'value': overall, 'weight': 1.0}
            ]
            
            rlaf_metrics['dqn_parameters'] = dqn_params
            
            return rlaf_metrics
        
        # ============================================================================
        # MAIN EVALUATION LOGIC
        # ============================================================================
        
        print("\\nLoading inputs...")
        
        # Check file existence for files
        for path, name in [(args.trained_model, 'trained_model'), 
                          (args.raw_test_data, 'raw_test_data'),
                          (args.preprocessor_params, 'preprocessor_params')]:
            if not os.path.exists(path):
                print(f"ERROR: {name} file does not exist: {path}")
                sys.exit(1)
        
        # Load trained model
        checkpoint = torch.load(args.trained_model, map_location='cpu')
        print(f"✓ Trained model loaded")
        
        # Extract algorithm info
        algorithm = checkpoint.get('algorithm', 'unknown')
        print(f"  Algorithm: {algorithm}")
        
        # Load raw test data
        with open(args.raw_test_data, 'rb') as f:
            raw_test_dataset = pickle.load(f)
        
        # Handle different data wrapper types
        if hasattr(raw_test_dataset, 'images'):
            # RawDatasetWrapper from Load Data brick
            raw_images = raw_test_dataset.images
            raw_labels = raw_test_dataset.labels if hasattr(raw_test_dataset, 'labels') else None
            print(f"✓ Raw test data loaded (RawDatasetWrapper): {len(raw_images)} samples")
        elif hasattr(raw_test_dataset, '__len__'):
            # Direct dataset
            if isinstance(raw_test_dataset, (list, tuple)):
                raw_images = raw_test_dataset
            else:
                raw_images = [raw_test_dataset[i] for i in range(len(raw_test_dataset))]
            print(f"✓ Raw test data loaded: {len(raw_images)} samples")
        else:
            print(f"ERROR: Unsupported data format")
            sys.exit(1)
        
        # Load preprocessor params
        with open(args.preprocessor_params, 'r') as f:
            preprocess_params = json.load(f)
        print(f"✓ Preprocessor parameters loaded")
        
        # ============================================================================
        # APPLY PREPROCESSING TO TEST DATA
        # ============================================================================
        print("\\nApplying preprocessing to test data...")
        
        # Extract preprocessing parameters
        normalization = preprocess_params.get('normalization', {})
        scale = normalization.get('scale', 1.0)
        shift = normalization.get('shift', 0.0)
        
        print(f"  Preprocessing parameters: scale={scale:.6f}, shift={shift:.6f}")
        
        # Convert raw images to tensor if needed
        if isinstance(raw_images, list):
            # Stack list of tensors
            if isinstance(raw_images[0], torch.Tensor):
                raw_tensor = torch.stack(raw_images)
            else:
                # Convert to tensors first
                raw_tensor = torch.stack([torch.tensor(img) for img in raw_images])
        else:
            raw_tensor = raw_images
        
        # Apply same preprocessing as training
        print(f"  Applying normalization: x * {scale:.6f} + {shift:.6f}")
        processed_images = raw_tensor * scale + shift
        
        # ============================================================================
        # LOAD GENERATOR AND GENERATE SAMPLES
        # ============================================================================
        print("\\nLoading generator and generating samples...")
        
        try:
            # Check if generator exists in checkpoint
            if 'generator_state_dict' not in checkpoint:
                print("ERROR: No generator state dict in checkpoint")
                sys.exit(1)
            
            # Import nesy_factory modules
            try:
                from nesy_factory.GANs.dcgan import DCGANConfig
                from nesy_factory.GANs.dcgan import FullyConfigurableDCGANGenerator
                
                # Recreate config from checkpoint
                config_dict = checkpoint.get('config', {})
                if not config_dict:
                    # Create minimal config
                    config_dict = {
                        'image_size': 32,
                        'channels': 1,
                        'latent_dim': 100
                    }
                    dcgan_config = DCGANConfig.from_dict(config_dict)
                elif isinstance(config_dict, DCGANConfig):
                    dcgan_config = config_dict
                elif hasattr(config_dict, '__dataclass_fields__'):
                    dcgan_config = config_dict
                elif isinstance(config_dict, dict):
                    dcgan_config = DCGANConfig.from_dict(config_dict)
                else:
                    config_dict = {
                        'image_size': 32,
                        'channels': 1,
                        'latent_dim': 100
                    }
                    dcgan_config = DCGANConfig.from_dict(config_dict)
                
                # Create generator
                generator = FullyConfigurableDCGANGenerator(dcgan_config)
                generator.load_state_dict(checkpoint['generator_state_dict'])
                
                print(f"✓ Generator loaded via nesy_factory")
                
            except ImportError:
                print(" nesy_factory not available, using fallback generator loading")
                generator = torch.nn.Sequential(
                    torch.nn.Linear(100, 128 * 8 * 8),
                    torch.nn.ReLU(),
                    torch.nn.Unflatten(1, (128, 8, 8)),
                    torch.nn.ConvTranspose2d(128, 64, 4, 2, 1),
                    torch.nn.BatchNorm2d(64),
                    torch.nn.ReLU(),
                    torch.nn.ConvTranspose2d(64, 32, 4, 2, 1),
                    torch.nn.BatchNorm2d(32),
                    torch.nn.ReLU(),
                    torch.nn.ConvTranspose2d(32, 1, 4, 2, 1),
                    torch.nn.Tanh()
                )
                generator.load_state_dict(checkpoint['generator_state_dict'])
                generator.latent_dim = 100
                print(f"✓ Generator loaded via fallback")
            
            # Get latent dim
            if hasattr(generator, 'latent_dim'):
                latent_dim = generator.latent_dim
            elif 'latent_dim' in checkpoint:
                latent_dim = checkpoint['latent_dim']
            else:
                latent_dim = 100
            
            print(f"  Latent dim: {latent_dim}")
            
        except Exception as e:
            print(f"ERROR loading generator: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        
        # Set up device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        generator.to(device)
        generator.eval()
        
        # Determine number of samples
        num_eval_samples = min(100, len(processed_images))
        print(f"  Using {num_eval_samples} samples for evaluation")
        
        # Prepare real samples
        real_tensor = processed_images[:num_eval_samples].to(device)
        
        # Generate fake samples
        with torch.no_grad():
            z = torch.randn(num_eval_samples, latent_dim, device=device)
            fake_tensor = generator(z).cpu()
        
        print(f"✓ Generated {num_eval_samples} fake samples")
        print(f"  Real samples shape: {real_tensor.shape}")
        print(f"  Fake samples shape: {fake_tensor.shape}")
        
        # ============================================================================
        # UPLOAD GENERATED IMAGES AS JPEG TO CDN
        # ============================================================================
        print("\\n" + "=" * 60)
        print("UPLOADING GENERATED IMAGES AS JPEG TO CDN")
        print("=" * 60)
        
        generated_images_cdn_url = ""
        if args.bearer_token and args.bearer_token.strip():
            # Upload images as JPEG grid
            generated_images_cdn_url = upload_images_as_jpeg(fake_tensor, algorithm)
        else:
            print("  Skipping CDN upload (no bearer token)")
        
        # Save CDN URL to output
        with open(args.generated_images_url, 'w') as f:
            if generated_images_cdn_url:
                f.write(generated_images_cdn_url)
                print(f"✓ Generated images JPEG URL saved: {args.generated_images_url}")
            else:
                f.write("")
                print(f"⚠ No CDN URL for generated images (upload may have failed)")
        
        # ============================================================================
        # CALCULATE COMPREHENSIVE METRICS
        # ============================================================================
        print("\\n" + "=" * 60)
        print("CALCULATING METRICS")
        print("=" * 60)
        
        start_time = time.time()
        metrics = calculate_all_metrics(real_tensor.cpu(), fake_tensor, algorithm)
        metrics['calculation_time'] = time.time() - start_time
        
        # Add generated images info to metrics
        metrics['generated_images_info'] = {
            'num_samples': num_eval_samples,
            'shape': list(fake_tensor.shape),
            'cdn_url': generated_images_cdn_url if generated_images_cdn_url else None,
            'format': 'jpeg',
            'note': 'Images uploaded as JPEG grid to CDN'
        }
        
        # ============================================================================
        # CREATE RLAF METRICS
        # ============================================================================
        print("\\nCreating RLAF-compatible metrics...")
        
        model_info = {
            'latent_dim': latent_dim,
            'image_size': fake_tensor.shape[2] if len(fake_tensor.shape) > 2 else 32,
            'channels': fake_tensor.shape[1] if len(fake_tensor.shape) > 1 else 1,
            'algorithm': algorithm,
            'num_eval_samples': num_eval_samples,
            'preprocessing_applied': True,
            'preprocessing_params': {'scale': scale, 'shift': shift},
            'generated_images_available': generated_images_cdn_url is not None,
            'generated_images_format': 'jpeg'
        }
        
        rlaf_metrics = create_rlaf_metrics(metrics, algorithm, model_info)
        
        print(f"✓ RLAF metrics created:")
        print(f"  Overall quality: {rlaf_metrics['composite_scores']['overall_quality']:.3f}")
        print(f"  Image fidelity: {rlaf_metrics['composite_scores']['image_fidelity']:.3f}")
        print(f"  Diversity quality: {rlaf_metrics['composite_scores']['diversity_quality']:.3f}")
        
        # ============================================================================
        # UPLOAD RESULTS TO CDN
        # ============================================================================
        print("\\nUploading evaluation results to CDN...")
        
        # Create evaluation results package
        results_package = {
            'metrics': metrics,
            'rlaf_metrics': rlaf_metrics,
            'model_info': model_info,
            'generated_images_info': metrics['generated_images_info'],
            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
            'version': 'v17-with-jpeg-images'
        }
        
        # Save results package locally
        results_package_path = "/tmp/evaluation_results_package.json"
        with open(results_package_path, 'w') as f:
            json.dump(results_package, f, indent=2)
        
        # Upload results package using existing upload function
        results_package_url = None
        if args.bearer_token and args.bearer_token.strip():
            # Simple upload function for JSON
            upload_url = f"{args.domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fdcgan%2Fmodels%2F"
            upload_url_encoded = upload_url.replace("$$", "$$$")
            unique_id = str(uuid.uuid4())[:8]
            json_filename = f"dcgan_eval_results_{unique_id}.json"
            
            curl_cmd = [
                "curl", "--location", upload_url_encoded,
                "--header", f"Authorization: Bearer {args.bearer_token}",
                "--form", f"file=@{results_package_path}", "--form", f"filename={json_filename}",
                "--fail", "--show-error", "--connect-timeout", "30", "--max-time", "120",
                "--silent"
            ]
            
            try:
                process = subprocess.run(curl_cmd, capture_output=True, text=True, check=True)
                response = json.loads(process.stdout)
                cdn_path = response.get('cdnUrl') or response.get('info', {}).get('cdnUrl') or response.get('url')
                
                if cdn_path:
                    full_url = cdn_path if cdn_path.startswith("http") else f"{args.get_cdn}{cdn_path}"
                    results_package_url = full_url
                    print(f"  ✓ Evaluation results uploaded to CDN")
            except Exception as e:
                print(f"  ✗ Failed to upload evaluation results: {e}")
        
        # Save results URL
        with open(args.evaluation_results_url, 'w') as f:
            if results_package_url:
                f.write(results_package_url)
            else:
                f.write("")
        
        # ============================================================================
        # SAVE OUTPUTS
        # ============================================================================
        print("\\nSaving outputs...")
        
        # Save evaluation metrics
        with open(args.evaluation_metrics, 'w') as f:
            json.dump(metrics, f, indent=2)
        print(f"✓ Evaluation metrics saved: {args.evaluation_metrics}")
        
        # Save RLAF metrics
        with open(args.rlaf_metrics, 'w') as f:
            json.dump(rlaf_metrics, f, indent=2)
        print(f"✓ RLAF metrics saved: {args.rlaf_metrics}")
        
        # Save generated samples in PreprocessedDataset format for compatibility
        generated_dataset = PreprocessedDataset(
            fake_tensor,
            torch.zeros(len(fake_tensor)),  # Dummy labels
            f"dcgan_{algorithm}_generated",
            preprocess_params
        )
        
        with open(args.generated_samples, 'wb') as f:
            pickle.dump(generated_dataset, f)
        print(f"✓ Generated samples saved: {args.generated_samples}")
        
        # Create evaluation summary
        summary = {
            'evaluation_completed': True,
            'algorithm': algorithm,
            'test_samples_processed': len(processed_images),
            'evaluation_samples_used': num_eval_samples,
            'preprocessing_applied': True,
            'preprocessing_params': {'scale': scale, 'shift': shift},
            'key_metrics': {
                'fid_score': metrics.get('fid_score'),
                'ssim_mean': metrics.get('ssim_mean'),
                'psnr_mean': metrics.get('psnr_mean'),
                'diversity_score': metrics.get('diversity_score'),
                'mae': metrics.get('mae'),
                'mse': metrics.get('mse')
            },
            'rlaf_scores': {
                'overall_quality': rlaf_metrics['composite_scores']['overall_quality'],
                'image_fidelity': rlaf_metrics['composite_scores']['image_fidelity'],
                'diversity_quality': rlaf_metrics['composite_scores']['diversity_quality']
            },
            'generated_images_info': {
                'num_samples': num_eval_samples,
                'shape': list(fake_tensor.shape),
                'cdn_url': generated_images_cdn_url if generated_images_cdn_url else 'Not uploaded',
                'format': 'jpeg',
                'note': 'Grid of generated images'
            },
            'results_package_url': results_package_url if results_package_url else '',
            'calculation_time': metrics.get('calculation_time'),
            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
            'model_info': model_info,
            'note': 'Generated images uploaded as JPEG to CDN'
        }
        
        with open(args.evaluation_summary, 'w') as f:
            json.dump(summary, f, indent=2)
        print(f"✓ Evaluation summary saved: {args.evaluation_summary}")
        
        # ============================================================================
        # PRINT RESULTS
        # ============================================================================
        print("\\n" + "=" * 80)
        print("EVALUATION RESULTS SUMMARY")
        print("=" * 80)
        print(f"Algorithm: {algorithm.upper()}")
        print(f"Samples evaluated: {num_eval_samples}")
        print(f"Calculation time: {metrics.get('calculation_time', 0):.2f}s")
        print("\\n METRICS:")
        print(f"  FID Score: {metrics.get('fid_score', 'N/A')}")
        print(f"  SSIM: {metrics.get('ssim_mean', 0):.3f} ± {metrics.get('ssim_std', 0):.3f}")
        print(f"  PSNR: {metrics.get('psnr_mean', 0):.1f} dB ± {metrics.get('psnr_std', 0):.1f}")
        print(f"  Diversity: {metrics.get('diversity_score', 0):.3f}")
        print(f"  MAE: {metrics.get('mae', 0):.4f}")
        print(f"  MSE: {metrics.get('mse', 0):.4f}")
        print(f"  Histogram Correlation: {metrics.get('histogram_correlation', 0):.3f}")
        
        print("\\n GENERATED IMAGES (JPEG):")
        print(f"  Shape: {fake_tensor.shape}")
        print(f"  CDN URL: {'✓ Uploaded as JPEG' if generated_images_cdn_url else '✗ Not uploaded'}")
        if generated_images_cdn_url:
            print(f"  Full JPEG URL: {generated_images_cdn_url}")
        
        print("\\n REAL IMAGE STATISTICS:")
        real_stats = metrics.get('real_stats', {})
        print(f"  Mean: {real_stats.get('mean', 0):.3f}")
        print(f"  Std: {real_stats.get('std', 0):.3f}")
        print(f"  Min: {real_stats.get('min', 0):.3f}")
        print(f"  Max: {real_stats.get('max', 0):.3f}")
        
        print("\\n GENERATED IMAGE STATISTICS:")
        fake_stats = metrics.get('fake_stats', {})
        print(f"  Mean: {fake_stats.get('mean', 0):.3f}")
        print(f"  Std: {fake_stats.get('std', 0):.3f}")
        print(f"  Min: {fake_stats.get('min', 0):.3f}")
        print(f"  Max: {fake_stats.get('max', 0):.3f}")
        
        print("\\n RLAF SCORES:")
        print(f"  Overall Quality: {rlaf_metrics['composite_scores']['overall_quality']:.3f}")
        print(f"  Image Fidelity: {rlaf_metrics['composite_scores']['image_fidelity']:.3f}")
        print(f"  Diversity Quality: {rlaf_metrics['composite_scores']['diversity_quality']:.3f}")
        print(f"  Generator Quality: {rlaf_metrics['primary_metrics']['generator_quality_score']:.3f}")
        print(f"  Discriminator Quality: {rlaf_metrics['primary_metrics']['discriminator_quality_score']:.3f}")
        
        print("\\n CDN UPLOADS:")
        print(f"  Generated Images (JPEG): {'✓ Uploaded' if generated_images_cdn_url else '✗ Failed'}")
        print(f"  Results Package (JSON): {'✓ Uploaded' if results_package_url else '✗ Failed'}")
        
        print("\\n OUTPUT FILES:")
        print(f"  ✓ Evaluation metrics: {args.evaluation_metrics}")
        print(f"  ✓ RLAF metrics: {args.rlaf_metrics}")
        print(f"  ✓ Generated samples: {args.generated_samples}")
        print(f"  ✓ Evaluation summary: {args.evaluation_summary}")
        print(f"  ✓ Evaluation results URL: {args.evaluation_results_url}")
        print(f"  ✓ Generated images URL (JPEG): {args.generated_images_url}")
        
        print("=" * 80)
        
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --raw_test_data
      - {inputPath: raw_test_data}
      - --preprocessor_params
      - {inputPath: preprocessor_params}
      - --master_config
      - {inputValue: master_config}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
      - --evaluation_metrics
      - {outputPath: evaluation_metrics}
      - --generated_samples
      - {outputPath: generated_samples}
      - --evaluation_summary
      - {outputPath: evaluation_summary}
      - --rlaf_metrics
      - {outputPath: rlaf_metrics}
      - --evaluation_results_url
      - {outputPath: evaluation_results_url}
      - --generated_images_url
      - {outputPath: generated_images_url}
