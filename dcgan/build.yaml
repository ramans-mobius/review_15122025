name: Build Model v5
description: Builds DCGAN model using single master config
inputs:
  - name: master_config
    type: String
  - name: load_from_cdn
    type: String
    default: "false"
  - name: cdn_url
    type: String
outputs:
  - name: model_out
    type: Model
  - name: config_updated
    type: String
  - name: model_info_out
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -c
      - |
        echo "Building DCGAN Model with master config..."
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse
        import json
        import os
        import sys
        import tempfile
        import urllib.request
        from pathlib import Path
        
        def get_file_size(file_path):
            
            size_bytes = os.path.getsize(file_path)
            for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
                if size_bytes < 1024.0:
                    return f"{size_bytes:.2f} {unit}"
                size_bytes /= 1024.0
            return f"{size_bytes:.2f} PB"
        
        def deep_merge(base_dict, override_dict):
           
            result = base_dict.copy()
            
            for key, value in override_dict.items():
                if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                    # Recursively merge nested dictionaries
                    result[key] = deep_merge(result[key], value)
                else:
                    # Override the value
                    result[key] = value
            
            return result
        
        # Import the module dynamically to handle any import issues
        print("Importing nesy_factory.GANs.dcgan...")
        
        try:
            # First try to import directly
            from nesy_factory.GANs.dcgan import create_dcgan, DEFAULT_DCGAN_CONFIG
            print(" Successfully imported create_dcgan directly")
        except ImportError:
            # If direct import fails, import the module and get the function
            print(" Direct import failed, trying module import...")
            try:
                import nesy_factory.GANs.dcgan as dcgan_module
                
                # Get create_dcgan from the module
                if hasattr(dcgan_module, 'create_dcgan'):
                    create_dcgan = dcgan_module.create_dcgan
                    DEFAULT_DCGAN_CONFIG = dcgan_module.DEFAULT_DCGAN_CONFIG
                    print(" Successfully imported from module")
                else:
                    print(f" create_dcgan not found in module")
                    print(f"Available attributes: {[attr for attr in dir(dcgan_module) if not attr.startswith('_')][:20]}...")
                    sys.exit(1)
            except Exception as e:
                print(f" Failed to import nesy_factory.GANs.dcgan: {e}")
                sys.exit(1)
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--master_config', type=str, required=False, default='')
        parser.add_argument('--load_from_cdn', type=str, default='false')
        parser.add_argument('--cdn_url', type=str, default='')
        parser.add_argument('--model_out', type=str, required=True)
        parser.add_argument('--config_updated', type=str, required=True)
        parser.add_argument('--model_info_out', type=str, required=True)
        args = parser.parse_args()
        
        load_from_cdn = args.load_from_cdn.lower() == 'true'
        
        # BARE MINIMUM DCGAN CONFIG FOR FAST TESTING
        MINIMAL_DCGAN_CONFIG = {
            "model_type": "dcgan",
            "dataset": {
                "resize_size": 64,
                "name": "minimal_test"
            },
            "gan": {
                "z_dim": 100,
                "training": {
                    "algorithm": "standard",
                    "batch_size": 32,
                    "epochs": 5,
                    "sample_interval": 50
                },
                "generator": {
                    "hidden_dims": [64, 32],
                    "image_channels": 3,
                    "use_batchnorm": True,
                    "activation": "relu",
                    "output_activation": "tanh",
                    "learning_rate": 0.0002,
                    "loss_type": "bce_with_logits",
                    
                    # DCGAN-specific parameters
                    "kernel_sizes": [4, 4, 4],  # One for each layer: [hidden_dims[0], hidden_dims[1], image_channels]
                    "strides": [1, 2, 2],        # Based on dcgan.py defaults
                    "paddings": [0, 1, 1],       # Based on dcgan.py defaults
                    "output_paddings": [0, 0, 0], # Based on dcgan.py defaults
                    
                    # FF/CAFO settings
                    "use_forward_forward": False,
                    "ff_epochs_per_block": 1,
                    "ff_theta": 2.0,
                    "use_cafo": False,
                    "cafo_epochs_per_block": 1
                },
                "discriminator": {
                    "hidden_dims": [32, 64],
                    "image_channels": 3,
                    "use_batchnorm": False,
                    "activation": "leaky_relu",
                    "output_activation": "sigmoid",
                    "learning_rate": 0.0002,
                    "loss_type": "bce_with_logits",
                    "dropout": 0.2,
                    "label_smoothing": 0.0,
                    "n_critic": 1,
                    
                    # DCGAN-specific parameters
                    "kernel_sizes": [4, 4],      # One for each hidden_dim
                    "strides": [2, 1],           # Based on dcgan.py defaults
                    "paddings": [1, 0],          # Based on dcgan.py defaults
                    "output_dim": 1,
                    
                    # FF/CAFO settings
                    "use_forward_forward": False,
                    "ff_epochs_per_block": 1,
                    "ff_theta": 2.0,
                    "use_cafo": False,
                    "cafo_epochs_per_block": 1
                }
            },
            "model_source": "bare_minimum_dcgan_test_config"
        }
        
        # Parse and merge config
        if args.master_config and args.master_config.strip():
            try:
                provided_config = json.loads(args.master_config)
                print("Using provided master config")
                
                # Merge provided config with minimal defaults
                config = deep_merge(MINIMAL_DCGAN_CONFIG, provided_config)
                config['model_source'] = 'user_provided_merged'
                
                # Log what was overridden
                print("Config merging summary:")
                if 'dataset' in provided_config:
                    print("  ✓ Dataset config overridden")
                if 'gan' in provided_config:
                    print("  ✓ GAN config overridden")
                    if 'generator' in provided_config.get('gan', {}):
                        print("    - Generator config overridden")
                    if 'discriminator' in provided_config.get('gan', {}):
                        print("    - Discriminator config overridden")
                    if 'training' in provided_config.get('gan', {}):
                        print("    - Training config overridden")
                
            except json.JSONDecodeError as e:
                print(f"ERROR: Invalid JSON in master_config: {e}")
                print("Falling back to bare minimum DCGAN config")
                config = MINIMAL_DCGAN_CONFIG
        else:
            config = MINIMAL_DCGAN_CONFIG
            print("Using bare minimum DCGAN config for fast testing")
        
        # Get config sections
        gan_cfg = config['gan']
        dataset_cfg = config['dataset']
        gen_cfg = gan_cfg['generator']
        disc_cfg = gan_cfg['discriminator']
        
        # Print config summary
        print(f"\\nFINAL CONFIG SUMMARY:")
        print(f"  Model source: {config.get('model_source', 'unknown')}")
        print(f"  Model type: {config.get('model_type', 'dcgan')}")
        print(f"  Image size: {dataset_cfg.get('resize_size', 64)}")
        print(f"  Generator:")
        print(f"    - z_dim: {gen_cfg.get('z_dim', 100)}")
        print(f"    - hidden_dims: {gen_cfg.get('hidden_dims', [64, 32])}")
        print(f"    - image_channels: {gen_cfg.get('image_channels', 3)}")
        print(f"    - layers: {len(gen_cfg.get('hidden_dims', [64, 32])) + 1}")
        print(f"  Discriminator:")
        print(f"    - hidden_dims: {disc_cfg.get('hidden_dims', [32, 64])}")
        print(f"    - image_channels: {disc_cfg.get('image_channels', 3)}")
        print(f"    - layers: {len(disc_cfg.get('hidden_dims', [32, 64]))}")
        print(f"  Algorithm: {gan_cfg['training'].get('algorithm', 'standard')}")
        
        # Create output directories
        os.makedirs(os.path.dirname(args.model_out), exist_ok=True)
        os.makedirs(os.path.dirname(args.config_updated), exist_ok=True)
        os.makedirs(os.path.dirname(args.model_info_out), exist_ok=True)
        
        if load_from_cdn:
            # MODE 1: Download model from CDN
            if not args.cdn_url:
                print("ERROR: cdn_url is required when load_from_cdn=true")
                sys.exit(1)
                
            print(f"Loading DCGAN model from CDN: {args.cdn_url}")
            
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pth') as tmp_file:
                    tmp_path = tmp_file.name
                
                print(f"Downloading from {args.cdn_url}...")
                urllib.request.urlretrieve(args.cdn_url, tmp_path)
                print("Download completed")
                
                checkpoint = torch.load(tmp_path, map_location='cpu')
                torch.save(checkpoint, args.model_out)
                print(f"Model loaded from CDN and saved to: {args.model_out}")
                
                # Update config
                config['model_source'] = 'cdn'
                config['cdn_url'] = args.cdn_url
                
                with open(args.config_updated, 'w') as f:
                    json.dump(config, f, indent=2)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': 'cdn',
                    'cdn_url': args.cdn_url,
                    'model_file_size': model_file_size,
                    'checkpoint_keys': list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'state_dict'
                }
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"Model file size: {model_file_size}")
                os.unlink(tmp_path)
                
            except Exception as e:
                print(f"Failed to load model from CDN: {e}")
                sys.exit(1)
                
        else:
            # MODE 2: Build new DCGAN model using config
            print(f"\\nBuilding DCGAN model...")
            
            try:
                # Set algorithm-specific flags based on training.algorithm
                algorithm = gan_cfg['training'].get('algorithm', 'standard')
                use_ff = (algorithm == 'forward_forward')
                use_cafo = (algorithm == 'cafo')
                
                print(f"  Training Algorithm: {algorithm}")
                print(f"  use_forward_forward: {use_ff}")
                print(f"  use_cafo: {use_cafo}")
                
                # Update generator config with algorithm flags
                gen_cfg['use_forward_forward'] = use_ff
                gen_cfg['use_cafo'] = use_cafo
                
                # Update discriminator config with algorithm flags
                disc_cfg['use_forward_forward'] = use_ff
                disc_cfg['use_cafo'] = use_cafo
                
                # Convert config to DCGAN library format
                dcgan_config = {
                    'dataset': {
                        'resize_size': dataset_cfg.get('resize_size', 64)
                    },
                    'generator': {
                        'z_dim': gen_cfg.get('z_dim', 100),
                        'hidden_dims': gen_cfg.get('hidden_dims', [64, 32]),
                        'image_channels': gen_cfg.get('image_channels', 3),
                        'use_batchnorm': gen_cfg.get('use_batchnorm', True),
                        'activation': gen_cfg.get('activation', 'relu'),
                        'output_activation': gen_cfg.get('output_activation', 'tanh'),
                        'learning_rate': gen_cfg.get('learning_rate', 0.0002),
                        'loss_type': gen_cfg.get('loss_type', 'bce_with_logits'),
                        
                        # DCGAN-specific parameters
                        'kernel_sizes': gen_cfg.get('kernel_sizes', [4, 4, 4]),
                        'strides': gen_cfg.get('strides', [1, 2, 2]),
                        'paddings': gen_cfg.get('paddings', [0, 1, 1]),
                        'output_paddings': gen_cfg.get('output_paddings', [0, 0, 0]),
                        
                        # FF/CAFO settings
                        'use_forward_forward': use_ff,
                        'use_cafo': use_cafo,
                        'ff_epochs_per_block': gen_cfg.get('ff_epochs_per_block', 1),
                        'cafo_epochs_per_block': gen_cfg.get('cafo_epochs_per_block', 1)
                    },
                    'discriminator': {
                        'hidden_dims': disc_cfg.get('hidden_dims', [32, 64]),
                        'image_channels': disc_cfg.get('image_channels', 3),
                        'use_batchnorm': disc_cfg.get('use_batchnorm', False),
                        'activation': disc_cfg.get('activation', 'leaky_relu'),
                        'output_activation': disc_cfg.get('output_activation', 'sigmoid'),
                        'learning_rate': disc_cfg.get('learning_rate', 0.0002),
                        'loss_type': disc_cfg.get('loss_type', 'bce_with_logits'),
                        'dropout': disc_cfg.get('dropout', 0.2),
                        'label_smoothing': disc_cfg.get('label_smoothing', 0.0),
                        'n_critic': disc_cfg.get('n_critic', 1),
                        
                        # DCGAN-specific parameters
                        'kernel_sizes': disc_cfg.get('kernel_sizes', [4, 4]),
                        'strides': disc_cfg.get('strides', [2, 1]),
                        'paddings': disc_cfg.get('paddings', [1, 0]),
                        'output_dim': disc_cfg.get('output_dim', 1),
                        
                        # FF/CAFO settings
                        'use_forward_forward': use_ff,
                        'use_cafo': use_cafo,
                        'ff_epochs_per_block': disc_cfg.get('ff_epochs_per_block', 1),
                        'cafo_epochs_per_block': disc_cfg.get('cafo_epochs_per_block', 1)
                    }
                }
                
                print(f"\\n  DCGAN CONFIG DETAILS:")
                print(f"  Image Size: {dcgan_config['dataset']['resize_size']}x{dcgan_config['dataset']['resize_size']}")
                print(f"  Generator:")
                print(f"    - z_dim: {dcgan_config['generator']['z_dim']}")
                print(f"    - layers: {len(dcgan_config['generator']['hidden_dims']) + 1}")
                print(f"    - kernel_sizes: {dcgan_config['generator']['kernel_sizes']}")
                print(f"    - strides: {dcgan_config['generator']['strides']}")
                print(f"    - paddings: {dcgan_config['generator']['paddings']}")
                print(f"  Discriminator:")
                print(f"    - layers: {len(dcgan_config['discriminator']['hidden_dims'])}")
                print(f"    - kernel_sizes: {dcgan_config['discriminator']['kernel_sizes']}")
                print(f"    - strides: {dcgan_config['discriminator']['strides']}")
                print(f"    - paddings: {dcgan_config['discriminator']['paddings']}")
                
                # Create DCGAN models using the imported function
                generator, discriminator, full_config = create_dcgan(dcgan_config)
                
                print(f"\\n MODELS CREATED:")
                print(f"  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}")
                print(f"  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}")
                total_params = sum(p.numel() for p in generator.parameters()) + sum(p.numel() for p in discriminator.parameters())
                print(f"  Total parameters: {total_params:,}")
                
                # Create model info
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': config.get('model_source', 'unknown'),
                    'training_algorithm': algorithm,
                    'generator_params': sum(p.numel() for p in generator.parameters()),
                    'discriminator_params': sum(p.numel() for p in discriminator.parameters()),
                    'total_params': total_params,
                    'z_dim': generator.z_dim,
                    'image_channels': generator.image_channels,
                    'image_size': generator.image_size,
                    'config_source': config.get('model_source', 'unknown'),
                    'generator_layers': len(dcgan_config['generator']['hidden_dims']) + 1,
                    'discriminator_layers': len(dcgan_config['discriminator']['hidden_dims'])
                }
                
                # Save both models in a checkpoint
                checkpoint = {
                    'config': full_config,
                    'generator_state_dict': generator.state_dict(),
                    'discriminator_state_dict': discriminator.state_dict(),
                    'model_info': model_info,
                    'model_type': 'dcgan',
                    'training_algorithm': algorithm,
                    'master_config': config
                }
                
                torch.save(checkpoint, args.model_out)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                model_info['model_file_size'] = model_file_size
                
                # Save updated config
                with open(args.config_updated, 'w') as f:
                    json.dump(full_config, f, indent=2)
                    
                # Save model info
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"\\n DCGAN model built successfully!")
                print(f"  Saved to: {args.model_out}")
                print(f"  File size: {model_file_size}")
                
            except Exception as e:
                print(f" ERROR: Failed to build DCGAN model: {e}")
                import traceback
                traceback.print_exc()
                sys.exit(1)

    args:
      - --master_config
      - {inputValue: master_config}
      - --load_from_cdn
      - {inputValue: load_from_cdn}
      - --cdn_url
      - {inputValue: cdn_url}
      - --model_out
      - {outputPath: model_out}
      - --config_updated
      - {outputPath: config_updated}
      - --model_info_out
      - {outputPath: model_info_out}
