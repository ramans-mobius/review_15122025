name: Build Model v4
description: Builds DCGAN model using single master config
inputs:
  - name: master_config
    type: String
  - name: load_from_cdn
    type: String
    default: "false"
  - name: cdn_url
    type: String
outputs:
  - name: model_out
    type: Model
  - name: config_updated
    type: String
  - name: model_info_out
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -c
      - |
        echo "Building DCGAN Model with master config..."
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse
        import json
        import os
        import sys
        import tempfile
        import urllib.request
        from pathlib import Path
        
        def get_file_size(file_path):
          
            size_bytes = os.path.getsize(file_path)
            for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
                if size_bytes < 1024.0:
                    return f"{size_bytes:.2f} {unit}"
                size_bytes /= 1024.0
            return f"{size_bytes:.2f} PB"
        
        # Import the module dynamically to handle any import issues
        print("Importing nesy_factory.GANs.dcgan...")
        
        try:
            # First try to import directly
            from nesy_factory.GANs.dcgan import create_dcgan, DEFAULT_DCGAN_CONFIG
            print(" Successfully imported create_dcgan directly")
        except ImportError:
            # If direct import fails, import the module and get the function
            print(" Direct import failed, trying module import...")
            try:
                import nesy_factory.GANs.dcgan as dcgan_module
                
                # Get create_dcgan from the module
                if hasattr(dcgan_module, 'create_dcgan'):
                    create_dcgan = dcgan_module.create_dcgan
                    DEFAULT_DCGAN_CONFIG = dcgan_module.DEFAULT_DCGAN_CONFIG
                    print(" Successfully imported from module")
                else:
                    print(f" create_dcgan not found in module")
                    print(f"Available attributes: {[attr for attr in dir(dcgan_module) if not attr.startswith('_')][:20]}...")
                    sys.exit(1)
            except Exception as e:
                print(f" Failed to import nesy_factory.GANs.dcgan: {e}")
                sys.exit(1)
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--master_config', type=str, required=False, default='')
        parser.add_argument('--load_from_cdn', type=str, default='false')
        parser.add_argument('--cdn_url', type=str, default='')
        parser.add_argument('--model_out', type=str, required=True)
        parser.add_argument('--config_updated', type=str, required=True)
        parser.add_argument('--model_info_out', type=str, required=True)
        args = parser.parse_args()
        
        load_from_cdn = args.load_from_cdn.lower() == 'true'
        
        # MINIMAL DCGAN CONFIG FOR TESTING
        MINIMAL_DCGAN_CONFIG = {
            "model_type": "dcgan",
            "dataset": {
                "image_size": 64,
                "channels": 3,
                "name": "minimal_test"
            },
            "gan": {
                "z_dim": 100,
                "training": {
                    "algorithm": "standard",
                    "batch_size": 64,
                    "epochs": 10,
                    "sample_interval": 100
                },
                "generator": {
                    "hidden_dims": [256, 128, 64],
                    "learning_rate": 0.0002,
                    "loss_type": "standard",
                    "ff_epochs_per_block": 2,
                    "cafo_epochs_per_block": 2
                },
                "discriminator": {
                    "hidden_dims": [64, 128, 256],
                    "learning_rate": 0.0002,
                    "loss_type": "standard",
                    "dropout": 0.3,
                    "label_smoothing": 0.0,
                    "ff_epochs_per_block": 2,
                    "cafo_epochs_per_block": 2
                }
            },
            "model_source": "minimal_dcgan_config"
        }
        
        # Parse or use minimal config
        if args.master_config and args.master_config.strip():
            try:
                config = json.loads(args.master_config)
                print("Using provided master config")
                config['model_source'] = 'user_provided'
            except json.JSONDecodeError as e:
                print(f"ERROR: Invalid JSON in master_config: {e}")
                print("Falling back to minimal DCGAN config")
                config = MINIMAL_DCGAN_CONFIG
        else:
            config = MINIMAL_DCGAN_CONFIG
            print("Using minimal DCGAN config for quick testing")
        
        # Validate config has required sections
        if 'gan' not in config:
            print("WARNING: 'gan' section missing in config, using minimal defaults")
            config['gan'] = MINIMAL_DCGAN_CONFIG['gan']
        
        if 'dataset' not in config:
            print("WARNING: 'dataset' section missing in config, using minimal defaults")
            config['dataset'] = MINIMAL_DCGAN_CONFIG['dataset']
        
        # Get config sections
        gan_cfg = config['gan']
        dataset_cfg = config['dataset']
        
        # Set defaults if missing
        if 'training' not in gan_cfg:
            gan_cfg['training'] = {'algorithm': 'standard'}
        
        if 'generator' not in gan_cfg:
            gan_cfg['generator'] = MINIMAL_DCGAN_CONFIG['gan']['generator']
        
        if 'discriminator' not in gan_cfg:
            gan_cfg['discriminator'] = MINIMAL_DCGAN_CONFIG['gan']['discriminator']
        
        # Print config summary
        print(f"\\nCONFIG SUMMARY:")
        print(f"  Model source: {config.get('model_source', 'unknown')}")
        print(f"  Model type: {config.get('model_type', 'dcgan')}")
        print(f"  Image size: {dataset_cfg.get('image_size', 64)}")
        print(f"  Channels: {dataset_cfg.get('channels', 3)}")
        print(f"  z_dim: {gan_cfg.get('z_dim', 100)}")
        print(f"  Algorithm: {gan_cfg['training'].get('algorithm', 'standard')}")
        print(f"  Generator layers: {len(gan_cfg['generator'].get('hidden_dims', [256, 128, 64]))}")
        print(f"  Discriminator layers: {len(gan_cfg['discriminator'].get('hidden_dims', [64, 128, 256]))}")
        
        # Create output directories
        os.makedirs(os.path.dirname(args.model_out), exist_ok=True)
        os.makedirs(os.path.dirname(args.config_updated), exist_ok=True)
        os.makedirs(os.path.dirname(args.model_info_out), exist_ok=True)
        
        if load_from_cdn:
            # MODE 1: Download model from CDN
            if not args.cdn_url:
                print("ERROR: cdn_url is required when load_from_cdn=true")
                sys.exit(1)
                
            print(f"Loading DCGAN model from CDN: {args.cdn_url}")
            
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pth') as tmp_file:
                    tmp_path = tmp_file.name
                
                print(f"Downloading from {args.cdn_url}...")
                urllib.request.urlretrieve(args.cdn_url, tmp_path)
                print("Download completed")
                
                checkpoint = torch.load(tmp_path, map_location='cpu')
                torch.save(checkpoint, args.model_out)
                print(f"Model loaded from CDN and saved to: {args.model_out}")
                
                # Update config
                config['model_source'] = 'cdn'
                config['cdn_url'] = args.cdn_url
                
                with open(args.config_updated, 'w') as f:
                    json.dump(config, f, indent=2)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': 'cdn',
                    'cdn_url': args.cdn_url,
                    'model_file_size': model_file_size,
                    'checkpoint_keys': list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'state_dict'
                }
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"Model file size: {model_file_size}")
                os.unlink(tmp_path)
                
            except Exception as e:
                print(f"Failed to load model from CDN: {e}")
                sys.exit(1)
                
        else:
            # MODE 2: Build new DCGAN model using config
            print(f"\\nBuilding new DCGAN model...")
            
            try:
                # Set algorithm-specific flags based on training.algorithm
                algorithm = gan_cfg['training'].get('algorithm', 'standard')
                use_ff = (algorithm == 'forward_forward')
                use_cafo = (algorithm == 'cafo')
                
                print(f"  Training Algorithm: {algorithm}")
                print(f"  use_forward_forward: {use_ff}")
                print(f"  use_cafo: {use_cafo}")
                
                # Get generator and discriminator configs
                gen_cfg = gan_cfg['generator']
                disc_cfg = gan_cfg['discriminator']
                
                # Convert config to DCGAN library format
                dcgan_config = {
                    'dataset': {
                        'resize_size': dataset_cfg.get('image_size', 64)
                    },
                    'generator': {
                        'z_dim': gan_cfg.get('z_dim', 100),
                        'hidden_dims': gen_cfg.get('hidden_dims', [256, 128, 64]),
                        'image_channels': dataset_cfg.get('channels', 3),
                        'use_batchnorm': True,
                        'activation': 'relu',
                        'output_activation': 'tanh',
                        'learning_rate': gen_cfg.get('learning_rate', 0.0002),
                        'loss_type': gen_cfg.get('loss_type', 'standard'),
                        
                        # Layer configurations
                        'kernel_sizes': [4] * (len(gen_cfg.get('hidden_dims', [256, 128, 64])) + 1),
                        'strides': [1] + [2] * len(gen_cfg.get('hidden_dims', [256, 128, 64])),
                        'paddings': [0] * (len(gen_cfg.get('hidden_dims', [256, 128, 64])) + 1),
                        'output_paddings': [0] * (len(gen_cfg.get('hidden_dims', [256, 128, 64])) + 1),
                        
                        # FF/CAFO settings - set based on algorithm
                        'use_forward_forward': use_ff,
                        'use_cafo': use_cafo,
                        'ff_epochs_per_block': gen_cfg.get('ff_epochs_per_block', 2),
                        'cafo_epochs_per_block': gen_cfg.get('cafo_epochs_per_block', 2)
                    },
                    'discriminator': {
                        'hidden_dims': disc_cfg.get('hidden_dims', [64, 128, 256]),
                        'image_channels': dataset_cfg.get('channels', 3),
                        'use_batchnorm': False,
                        'activation': 'leaky_relu',
                        'output_activation': 'sigmoid',
                        'learning_rate': disc_cfg.get('learning_rate', 0.0002),
                        'loss_type': disc_cfg.get('loss_type', 'standard'),
                        'dropout': disc_cfg.get('dropout', 0.3),
                        'label_smoothing': disc_cfg.get('label_smoothing', 0.0),
                        'n_critic': 1,
                        
                        # Layer configurations
                        'kernel_sizes': [4] * len(disc_cfg.get('hidden_dims', [64, 128, 256])),
                        'strides': [2] * (len(disc_cfg.get('hidden_dims', [64, 128, 256])) - 1) + [1],
                        'paddings': [1] * (len(disc_cfg.get('hidden_dims', [64, 128, 256])) - 1) + [0],
                        'output_dim': 1,
                        
                        # FF/CAFO settings - set based on algorithm
                        'use_forward_forward': use_ff,
                        'use_cafo': use_cafo,
                        'ff_epochs_per_block': disc_cfg.get('ff_epochs_per_block', 2),
                        'cafo_epochs_per_block': disc_cfg.get('cafo_epochs_per_block', 2)
                    }
                }
                
                print(f"\\n  DCGAN CONFIG SUMMARY:")
                print(f"  Image Size: {dcgan_config['dataset']['resize_size']}x{dcgan_config['dataset']['resize_size']}")
                print(f"  Channels: {dataset_cfg.get('channels', 3)}")
                print(f"  Generator z_dim: {dcgan_config['generator']['z_dim']}")
                print(f"  Generator layers: {len(dcgan_config['generator']['hidden_dims'])}")
                print(f"  Discriminator layers: {len(dcgan_config['discriminator']['hidden_dims'])}")
                
                # Create DCGAN models using the imported function
                generator, discriminator, full_config = create_dcgan(dcgan_config)
                
                print(f"\\n MODELS CREATED:")
                print(f"  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}")
                print(f"  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}")
                total_params = sum(p.numel() for p in generator.parameters()) + sum(p.numel() for p in discriminator.parameters())
                print(f"  Total parameters: {total_params:,}")
                
                # Create model info
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': config.get('model_source', 'unknown'),
                    'training_algorithm': algorithm,
                    'generator_params': sum(p.numel() for p in generator.parameters()),
                    'discriminator_params': sum(p.numel() for p in discriminator.parameters()),
                    'total_params': total_params,
                    'z_dim': generator.z_dim,
                    'image_channels': generator.image_channels,
                    'image_size': generator.image_size,
                    'config_source': config.get('model_source', 'unknown')
                }
                
                # Save both models in a checkpoint
                checkpoint = {
                    'config': full_config,
                    'generator_state_dict': generator.state_dict(),
                    'discriminator_state_dict': discriminator.state_dict(),
                    'model_info': model_info,
                    'model_type': 'dcgan',
                    'training_algorithm': algorithm,
                    'master_config': config  # Keep original master config
                }
                
                torch.save(checkpoint, args.model_out)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                model_info['model_file_size'] = model_file_size
                
                # Save updated config
                with open(args.config_updated, 'w') as f:
                    json.dump(full_config, f, indent=2)
                    
                # Save model info
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"\\n DCGAN model built successfully!")
                print(f"  Saved to: {args.model_out}")
                print(f"  File size: {model_file_size}")
                
            except Exception as e:
                print(f" ERROR: Failed to build DCGAN model: {e}")
                import traceback
                traceback.print_exc()
                sys.exit(1)

    args:
      - --master_config
      - {inputValue: master_config}
      - --load_from_cdn
      - {inputValue: load_from_cdn}
      - --cdn_url
      - {inputValue: cdn_url}
      - --model_out
      - {outputPath: model_out}
      - --config_updated
      - {outputPath: config_updated}
      - --model_info_out
      - {outputPath: model_info_out}
