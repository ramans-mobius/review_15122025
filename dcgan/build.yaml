name: Build DCGAN Model v6 - FIXED
description: Builds DCGAN model compatible with Backprop, CAFO, and Forward-Forward
inputs:
  - name: master_config
    type: String
  - name: load_from_schema
    type: String
    default: "false"
  - name: schema_id
    type: String
    default: ""
  - name: model_id
    type: String
    default: ""
  - name: execution_id
    type: String
    default: ""
  - name: load_from_cdn
    type: String
    default: "false"
  - name: cdn_url
    type: String
    default: ""
outputs:
  - name: model_out
    type: Model
  - name: config_updated
    type: String
  - name: model_info_out
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        echo "Building DCGAN Model..."
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse
        import json
        import os
        import sys
        import tempfile
        import urllib.request
        import requests
        from pathlib import Path
        import traceback
        
        def get_file_size(file_path):
            size_bytes = os.path.getsize(file_path)
            for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
                if size_bytes < 1024.0:
                    return f"{size_bytes:.2f} {unit}"
                size_bytes /= 1024.0
            return f"{size_bytes:.2f} PB"
        
        def deep_merge(base_dict, override_dict):
            result = base_dict.copy()
            
            for key, value in override_dict.items():
                if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                    result[key] = deep_merge(result[key], value)
                else:
                    result[key] = value
            
            return result
        
        # Import the DCGAN module
        print("Importing nesy_factory.GANs.dcgan...")
        
        try:
            from nesy_factory.GANs.dcgan import (
                DCGANConfig, TrainingAlgorithm, DCGANLayerConfig,
                ActivationConfig, LossConfig, OptimizerConfig,
                BlockTrainingConfig, BalancedTrainingConfig, AdversarialTrainingConfig,
                create_dcgan, validate_config,
                FullyConfigurableDCGANGenerator,
                FullyConfigurableDCGANDiscriminator,
                EnhancedDCGANTrainer
            )
            print(" Successfully imported DCGAN modules")
        except ImportError as e:
            print(f" Failed to import nesy_factory.GANs.dcgan: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--master_config', type=str, required=False, default='')
        parser.add_argument('--load_from_schema', type=str, default='false')
        parser.add_argument('--schema_id', type=str, default='')
        parser.add_argument('--model_id', type=str, default='')
        parser.add_argument('--execution_id', type=str, default='')
        parser.add_argument('--load_from_cdn', type=str, default='false')
        parser.add_argument('--cdn_url', type=str, default='')
        parser.add_argument('--model_out', type=str, required=True)
        parser.add_argument('--config_updated', type=str, required=True)
        parser.add_argument('--model_info_out', type=str, required=True)
        args = parser.parse_args()
        
        load_from_schema = args.load_from_schema.lower() == 'true'
        load_from_cdn = args.load_from_cdn.lower() == 'true'
        
        # DEFAULT DCGAN CONFIG FOR ALL ALGORITHMS
        DEFAULT_DCGAN_CONFIG = {
            "model_type": "dcgan",
            "dataset": {
                "name": "mnist",
                "image_size": 32,
                "channels": 1,
                "num_samples": 100
            },
            "gan": {
                "training": {
                    "algorithm": "backprop",
                    "batch_size": 16,
                    "epochs": 2,
                    "device": "cuda" if torch.cuda.is_available() else "cpu"
                },
                "generator": {
                    "latent_dim": 100,
                    "layers": [
                        {"channels": 128, "kernel_size": 4, "stride": 1, "padding": 0},
                        {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 1, "kernel_size": 4, "stride": 2, "padding": 1}
                    ],
                    "activation": "leaky_relu",
                    "output_activation": "tanh",
                    "use_batchnorm": True,
                    "use_attention": False
                },
                "discriminator": {
                    "layers": [
                        {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 128, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 1, "kernel_size": 4, "stride": 1, "padding": 0}
                    ],
                    "activation": "leaky_relu",
                    "output_activation": "sigmoid",
                    "use_batchnorm": False,
                    "use_attention": False
                },
                "block_training": {
                    "enabled": False,
                    "num_blocks": 3,
                    "epochs_per_block": 3,
                    "block_learning_rate": 0.001
                },
                "balanced_training": {
                    "enabled": True,
                    "discriminator_steps": 1,
                    "generator_steps": 1,
                    "label_smoothing": 0.1
                }
            },
            "model_source": "default_dcgan_config"
        }
        
        def get_schema_url(schema_id, model_id, execution_id):
            # This is a placeholder - implement your schema service logic here
            schema_service_url = "https://your-schema-service.example.com"
            
            try:
                response = requests.get(
                    f"{schema_service_url}/models/{schema_id}/{model_id}/{execution_id}",
                    timeout=30
                )
                if response.status_code == 200:
                    data = response.json()
                    return data.get('cdn_url', '')
                else:
                    print(f"Schema service error: {response.status_code}")
                    return ''
            except Exception as e:
                print(f"Error accessing schema service: {e}")
                return ''
        
        def create_dcgan_config_from_master(master_config):
           
            try:
                # Extract parameters
                gan_cfg = master_config['gan']
                dataset_cfg = master_config['dataset']
                gen_cfg = gan_cfg.get('generator', {})
                disc_cfg = gan_cfg.get('discriminator', {})
                train_cfg = gan_cfg.get('training', {})
                block_cfg = gan_cfg.get('block_training', {})
                balanced_cfg = gan_cfg.get('balanced_training', {})
                
                # Determine algorithm
                algorithm = train_cfg.get('algorithm', 'backprop')
                algorithm_map = {
                    'backprop': TrainingAlgorithm.BACKPROP,
                    'cafo': TrainingAlgorithm.CAFO,
                    'forward_forward': TrainingAlgorithm.FORWARD_FORWARD,
                    'hybrid': TrainingAlgorithm.HYBRID
                }
                training_algorithm = algorithm_map.get(algorithm, TrainingAlgorithm.BACKPROP)
                
                # Set algorithm flags based on algorithm
                use_cafo = algorithm == 'cafo'
                use_forward_forward = algorithm == 'forward_forward'
                use_hybrid = algorithm == 'hybrid'
                
                # Create generator layers
                generator_layers = []
                for layer in gen_cfg.get('layers', []):
                    generator_layers.append(DCGANLayerConfig(
                        channels=layer['channels'],
                        kernel_size=layer['kernel_size'],
                        stride=layer['stride'],
                        padding=layer['padding']
                    ))
                
                # Create discriminator layers
                discriminator_layers = []
                for layer in disc_cfg.get('layers', []):
                    discriminator_layers.append(DCGANLayerConfig(
                        channels=layer['channels'],
                        kernel_size=layer['kernel_size'],
                        stride=layer['stride'],
                        padding=layer['padding']
                    ))
                
                # Create block training config
                block_training = BlockTrainingConfig(
                    enabled=block_cfg.get('enabled', use_cafo or use_forward_forward),
                    num_blocks=block_cfg.get('num_blocks', min(3, len(generator_layers) - 1)),
                    epochs_per_block=block_cfg.get('epochs_per_block', 3),
                    block_learning_rate=block_cfg.get('block_learning_rate', 0.001),
                    freeze_previous_blocks=block_cfg.get('freeze_previous_blocks', True),
                    train_generator_blocks=block_cfg.get('train_generator_blocks', True),
                    train_discriminator_blocks=block_cfg.get('train_discriminator_blocks', True),
                    ff_threshold=block_cfg.get('ff_threshold', 2.0),
                    ff_goodness_dim=block_cfg.get('ff_goodness_dim', 32)
                )
                
                # Create balanced training config
                balanced_training = BalancedTrainingConfig(
                    enabled=balanced_cfg.get('enabled', True),
                    discriminator_steps=balanced_cfg.get('discriminator_steps', 1),
                    generator_steps=balanced_cfg.get('generator_steps', 1),
                    discriminator_lr_multiplier=balanced_cfg.get('discriminator_lr_multiplier', 0.5),
                    label_smoothing=balanced_cfg.get('label_smoothing', 0.1),
                    feature_matching=balanced_cfg.get('feature_matching', False),
                    feature_matching_weight=balanced_cfg.get('feature_matching_weight', 10.0)
                )
                
                # Create adversarial training config
                adversarial_training = AdversarialTrainingConfig(
                    n_critic=balanced_cfg.get('discriminator_steps', 1),
                    generator_steps=balanced_cfg.get('generator_steps', 1),
                    discriminator_steps=balanced_cfg.get('discriminator_steps', 1),
                    gradient_penalty_weight=balanced_cfg.get('gradient_penalty_weight', 10.0),
                    gradient_penalty_interval=1
                )
                
                # Create config
                config = DCGANConfig(
                    image_size=dataset_cfg.get('image_size', 32),
                    channels=dataset_cfg.get('channels', 1),
                    latent_dim=gen_cfg.get('latent_dim', 100),
                    generator_layers=generator_layers,
                    discriminator_layers=discriminator_layers,
                    training_algorithm=training_algorithm,
                    use_cafo=use_cafo,
                    use_forward_forward=use_forward_forward,
                    use_hybrid=use_hybrid,
                    block_training=block_training,
                    balanced_training=balanced_training,
                    adversarial_training=adversarial_training,
                    generator_activation=ActivationConfig(
                        name=gen_cfg.get('activation', 'leaky_relu'),
                        negative_slope=0.2
                    ),
                    discriminator_activation=ActivationConfig(
                        name=disc_cfg.get('activation', 'leaky_relu'),
                        negative_slope=0.2
                    ),
                    generator_output_activation=ActivationConfig(
                        name=gen_cfg.get('output_activation', 'tanh')
                    ),
                    discriminator_output_activation=ActivationConfig(
                        name=disc_cfg.get('output_activation', 'sigmoid')
                    ),
                    generator_use_batchnorm=gen_cfg.get('use_batchnorm', True),
                    discriminator_use_batchnorm=disc_cfg.get('use_batchnorm', False),
                    generator_spectral_norm=gen_cfg.get('spectral_norm', False),
                    discriminator_spectral_norm=disc_cfg.get('spectral_norm', False),
                    batch_size=train_cfg.get('batch_size', 16),
                    epochs=train_cfg.get('epochs', 2),
                    device=train_cfg.get('device', 'auto'),
                    seed=train_cfg.get('seed', 42)
                )
                
                return config
                
            except Exception as e:
                print(f"Error creating DCGAN config: {e}")
                traceback.print_exc()
                return None
        
        # Parse and merge config
        if args.master_config and args.master_config.strip():
            try:
                provided_config = json.loads(args.master_config)
                print("Using provided master config")
                
                # Merge provided config with defaults
                config = deep_merge(DEFAULT_DCGAN_CONFIG, provided_config)
                config['model_source'] = 'user_provided_merged'
                
            except json.JSONDecodeError as e:
                print(f"ERROR: Invalid JSON in master_config: {e}")
                print("Falling back to default DCGAN config")
                config = DEFAULT_DCGAN_CONFIG
        else:
            config = DEFAULT_DCGAN_CONFIG
            print("Using default DCGAN config")
        
        # Create output directories
        os.makedirs(os.path.dirname(args.model_out), exist_ok=True)
        os.makedirs(os.path.dirname(args.config_updated), exist_ok=True)
        os.makedirs(os.path.dirname(args.model_info_out), exist_ok=True)
        
        # MODE 1: Load from Schema
        if load_from_schema:
            print(f"Loading model from schema...")
            print(f"  Schema ID: {args.schema_id}")
            print(f"  Model ID: {args.model_id}")
            print(f"  Execution ID: {args.execution_id}")
            
            if not args.schema_id or not args.model_id or not args.execution_id:
                print("ERROR: schema_id, model_id, and execution_id are required when load_from_schema=true")
                sys.exit(1)
            
            # Get URL from schema service
            cdn_url = get_schema_url(args.schema_id, args.model_id, args.execution_id)
            if not cdn_url:
                print("ERROR: Could not get CDN URL from schema service")
                sys.exit(1)
            
            # Download from CDN
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pt') as tmp_file:
                    tmp_path = tmp_file.name
                
                print(f"Downloading from schema CDN: {cdn_url}")
                urllib.request.urlretrieve(cdn_url, tmp_path)
                print("Download completed")
                
                checkpoint = torch.load(tmp_path, map_location='cpu')
                torch.save(checkpoint, args.model_out)
                print(f"Model loaded from schema and saved to: {args.model_out}")
                
                # Update config
                config['model_source'] = 'schema'
                config['schema_id'] = args.schema_id
                config['model_id'] = args.model_id
                config['execution_id'] = args.execution_id
                config['cdn_url'] = cdn_url
                
                with open(args.config_updated, 'w') as f:
                    json.dump(config, f, indent=2)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': 'schema',
                    'schema_id': args.schema_id,
                    'model_id': args.model_id,
                    'execution_id': args.execution_id,
                    'cdn_url': cdn_url,
                    'model_file_size': model_file_size,
                    'checkpoint_keys': list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'state_dict'
                }
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"Model file size: {model_file_size}")
                os.unlink(tmp_path)
                
            except Exception as e:
                print(f"Failed to load model from schema: {e}")
                traceback.print_exc()
                sys.exit(1)
                
        # MODE 2: Load from direct CDN URL
        elif load_from_cdn:
            print(f"Loading model from direct CDN URL...")
            
            if not args.cdn_url:
                print("ERROR: cdn_url is required when load_from_cdn=true")
                sys.exit(1)
            
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pt') as tmp_file:
                    tmp_path = tmp_file.name
                
                print(f"Downloading from CDN: {args.cdn_url}")
                urllib.request.urlretrieve(args.cdn_url, tmp_path)
                print("Download completed")
                
                checkpoint = torch.load(tmp_path, map_location='cpu')
                torch.save(checkpoint, args.model_out)
                print(f"Model loaded from CDN and saved to: {args.model_out}")
                
                # Update config
                config['model_source'] = 'cdn'
                config['cdn_url'] = args.cdn_url
                
                with open(args.config_updated, 'w') as f:
                    json.dump(config, f, indent=2)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': 'cdn',
                    'cdn_url': args.cdn_url,
                    'model_file_size': model_file_size,
                    'checkpoint_keys': list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'state_dict'
                }
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"Model file size: {model_file_size}")
                os.unlink(tmp_path)
                
            except Exception as e:
                print(f"Failed to load model from CDN: {e}")
                traceback.print_exc()
                sys.exit(1)
                
        # MODE 3: Build new model
        else:
            print(f"\\nBuilding new DCGAN model...")
            
            try:
                # Create DCGAN config from master config
                dcgan_config = create_dcgan_config_from_master(config)
                if dcgan_config is None:
                    print("ERROR: Failed to create DCGAN config")
                    sys.exit(1)
                
                # Validate config
                is_valid, errors = validate_config(dcgan_config)
                if not is_valid:
                    print("Config validation errors:")
                    for error in errors:
                        print(f"  - {error}")
                    sys.exit(1)
                
                # Create models directly
                print(f"\\nCreating Generator...")
                generator = FullyConfigurableDCGANGenerator(dcgan_config)
                
                print(f"Creating Discriminator...")
                discriminator = FullyConfigurableDCGANDiscriminator(dcgan_config)
                
                print(f"\\n MODELS CREATED:")
                print(f"  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}")
                print(f"  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}")
                total_params = sum(p.numel() for p in generator.parameters()) + sum(p.numel() for p in discriminator.parameters())
                print(f"  Total parameters: {total_params:,}")
                
                # Print architecture details
                print(f"\\n ARCHITECTURE DETAILS:")
                print(f"  Generator blocks: {len(generator.blocks)}")
                for i, block in enumerate(generator.blocks):
                    block_type = block.__class__.__name__
                    channels = block.out_channels if hasattr(block, 'out_channels') else 'N/A'
                    print(f"    Block {i}: {block_type} (channels: {channels})")
                
                print(f"\\n  Discriminator blocks: {len(discriminator.blocks)}")
                for i, block in enumerate(discriminator.blocks):
                    block_type = block.__class__.__name__
                    channels = block.out_channels if hasattr(block, 'out_channels') else 'N/A'
                    print(f"    Block {i}: {block_type} (channels: {channels})")
                
                print(f"\\n TRAINING CONFIGURATION:")
                print(f"  Algorithm: {dcgan_config.training_algorithm.value}")
                print(f"  Block training: {'Enabled' if dcgan_config.block_training.enabled else 'Disabled'}")
                if dcgan_config.block_training.enabled:
                    print(f"  Blocks: {dcgan_config.block_training.num_blocks}")
                    print(f"  Epochs per block: {dcgan_config.block_training.epochs_per_block}")
                
                # Create model info
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': config.get('model_source', 'new_build'),
                    'training_algorithm': dcgan_config.training_algorithm.value,
                    'generator_params': sum(p.numel() for p in generator.parameters()),
                    'discriminator_params': sum(p.numel() for p in discriminator.parameters()),
                    'total_params': total_params,
                    'latent_dim': generator.latent_dim,
                    'image_channels': generator.config.channels,
                    'image_size': generator.config.image_size,
                    'generator_blocks': len(generator.blocks),
                    'discriminator_blocks': len(discriminator.blocks),
                    'block_training_enabled': dcgan_config.block_training.enabled,
                    'training_config': {
                        'algorithm': dcgan_config.training_algorithm.value,
                        'batch_size': dcgan_config.batch_size,
                        'epochs': dcgan_config.epochs,
                        'block_training_enabled': dcgan_config.block_training.enabled,
                        'num_blocks': dcgan_config.block_training.num_blocks if dcgan_config.block_training.enabled else 0,
                        'device': dcgan_config.device
                    }
                }
                
                # Save both models in a checkpoint
                checkpoint = {
                    'config': dcgan_config.to_dict(),
                    'generator_state_dict': generator.state_dict(),
                    'discriminator_state_dict': discriminator.state_dict(),
                    'model_info': model_info,
                    'model_type': 'dcgan',
                    'training_algorithm': dcgan_config.training_algorithm.value,
                    'master_config': config
                }
                
                torch.save(checkpoint, args.model_out)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                model_info['model_file_size'] = model_file_size
                
                # Save updated config (DCGAN config)
                with open(args.config_updated, 'w') as f:
                    json.dump(dcgan_config.to_dict(), f, indent=2)
                    
                # Save model info
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"\\n DCGAN model built successfully!")
                print(f"  Saved to: {args.model_out}")
                print(f"  File size: {model_file_size}")
                print(f"  Algorithm: {dcgan_config.training_algorithm.value}")
                print(f"  Block training: {'Enabled' if dcgan_config.block_training.enabled else 'Disabled'}")
                
            except Exception as e:
                print(f" ERROR: Failed to build DCGAN model: {e}")
                traceback.print_exc()
                sys.exit(1)

    args:
      - --master_config
      - {inputValue: master_config}
      - --load_from_schema
      - {inputValue: load_from_schema}
      - --schema_id
      - {inputValue: schema_id}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --load_from_cdn
      - {inputValue: load_from_cdn}
      - --cdn_url
      - {inputValue: cdn_url}
      - --model_out
      - {outputPath: model_out}
      - --config_updated
      - {outputPath: config_updated}
      - --model_info_out
      - {outputPath: model_info_out}
