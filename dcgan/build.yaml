name: Build DCGAN Model v10 
description: Builds or loads DCGAN models with schema and CDN support
inputs:
  - name: master_config
    type: String
  - name: load_from_schema
    type: String
    default: "false"
  - name: schema_id
    type: String
    default: ""
  - name: model_id
    type: String
    default: ""
  - name: execution_id
    type: String
    default: ""
  - name: bearer_token
    type: String
    default: ""
  - name: load_from_cdn
    type: String
    default: "false"
  - name: cdn_url
    type: String
    default: ""
outputs:
  - name: model_out
    type: Model
  - name: config_updated
    type: String
  - name: model_info_out
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        echo "Building DCGAN Model v10 - With Schema & CDN Loading..."
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import argparse
        import json
        import os
        import sys
        import tempfile
        import urllib.request
        import requests
        import subprocess
        import uuid
        from pathlib import Path
        import traceback
        import warnings
        
        def get_file_size(file_path):
            size_bytes = os.path.getsize(file_path)
            for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
                if size_bytes < 1024.0:
                    return f"{size_bytes:.2f} {unit}"
                size_bytes /= 1024.0
            return f"{size_bytes:.2f} PB"
        
        def deep_merge(base_dict, override_dict):
            result = base_dict.copy()
            
            for key, value in override_dict.items():
                if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                    result[key] = deep_merge(result[key], value)
                else:
                    result[key] = value
            
            return result
        
        # ============================================================================
        # IMPORT NESY FACTORY CLASSES
        # ============================================================================
        print("Importing nesy_factory.GANs.dcgan...")
        
        try:
            import nesy_factory.GANs.dcgan as dcgan_module
            print(" nesy_factory.GANs.dcgan imported successfully")
            
            # Try to import specific classes
            from nesy_factory.GANs.dcgan import (
                DCGANConfig, TrainingAlgorithm, DCGANLayerConfig,
                ActivationConfig, LossConfig, OptimizerConfig,
                BlockTrainingConfig, BalancedTrainingConfig, AdversarialTrainingConfig,
                FullyConfigurableDCGANGenerator,
                FullyConfigurableDCGANDiscriminator,
                EnhancedDCGANTrainer
            )
            
            print(" All necessary imports successful")
            
        except ImportError as e:
            print(f" Import error: {e}")
            traceback.print_exc()
            sys.exit(1)
        except Exception as e:
            print(f" Partial import issue: {e}")
            traceback.print_exc()
        
        # ============================================================================
        # SCHEMA FUNCTIONS
        # ============================================================================
        
        def query_schema_for_weights(schema_id, model_id, execution_id, bearer_token):
           
            schema_url = f"https://igs.gov-cloud.ai/pi-entity-instances-service/v3.0/schemas/{schema_id}/instances/list?size=1000"
            
            filter_data = {
                "dbType": "TIDB",
                "ownedOnly": True,
                "filter": {
                    "model_id": model_id,
                    "execution_id": int(execution_id)
                }
            }
            
            try:
                print(f"  Querying schema for model weights...")
                
                headers = {
                    'Authorization': f'Bearer {bearer_token}',
                    'Content-Type': 'application/json'
                }
                
                curl_command = [
                    "curl",
                    "--location", schema_url,
                    "--header", f"Authorization: Bearer {bearer_token}",
                    "--header", "Content-Type: application/json",
                    "--data", json.dumps(filter_data),
                    "--fail",
                    "--show-error",
                    "--connect-timeout", "30",
                    "--max-time", "60",
                    "--silent"
                ]
                
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                response_json = json.loads(process.stdout)
                
                if 'content' in response_json and len(response_json['content']) > 0:
                    instance = response_json['content'][0]
                    model_weights_cdn = instance.get('model_weights_cdn')
                    
                    if model_weights_cdn:
                        print(f"   Found model_weights_cdn: {model_weights_cdn}...")
                        return model_weights_cdn, instance
                    else:
                        print(f"   No model_weights_cdn found in schema entry")
                        return None, None
                else:
                    print(f"   No schema entry found for model_id={model_id}, execution_id={execution_id}")
                    return None, None
                    
            except subprocess.CalledProcessError as e:
                print(f"   Failed to query schema: {e.stderr[:200]}")
                return None, None
            except Exception as e:
                print(f"   Error querying schema: {str(e)[:100]}")
                return None, None
        
        def download_and_load_model(weights_url, master_config):
         
            try:
                print(f"  Downloading model weights from: {weights_url[:100]}...")
                
                # Download weights
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pth') as tmp_file:
                    tmp_path = tmp_file.name
                
                urllib.request.urlretrieve(weights_url, tmp_path)
                file_size = os.path.getsize(tmp_path)
                print(f"   Downloaded weights ({file_size:,} bytes)")
                
                # Load checkpoint
                checkpoint = torch.load(tmp_path, map_location='cpu')
                print(f"  Checkpoint type: {type(checkpoint)}")
                if isinstance(checkpoint, dict):
                    print(f"  Checkpoint keys: {list(checkpoint.keys())}")
                
                # Extract config from checkpoint or use master_config
                if isinstance(checkpoint, dict) and 'config' in checkpoint:
                    # Use config from checkpoint
                    checkpoint_config = checkpoint['config']
                    print("  Using config from checkpoint")
                    
                    # Create DCGANConfig from checkpoint config
                    try:
                        # Extract parameters from checkpoint config
                        image_size = checkpoint_config.get('image_size', 32)
                        channels = checkpoint_config.get('channels', 1)
                        latent_dim = checkpoint_config.get('latent_dim', 100)
                        
                        # Create DCGAN config
                        dcgan_config = DCGANConfig(
                            image_size=image_size,
                            channels=channels,
                            latent_dim=latent_dim,
                            # Use default values for other params
                            generator_layers=[],
                            discriminator_layers=[],
                            training_algorithm=TrainingAlgorithm.BACKPROP,
                            use_cafo=False,
                            use_forward_forward=False,
                            use_hybrid=False,
                            batch_size=16,
                            epochs=2,
                            device='cpu'
                        )
                    except:
                        # If can't create from checkpoint, use master_config
                        print("  Couldn't create config from checkpoint, using master_config")
                        dcgan_config = create_valid_dcgan_config(master_config)
                else:
                    # Use master_config to create model
                    print("  Using master_config to create model")
                    dcgan_config = create_valid_dcgan_config(master_config)
                
                if dcgan_config is None:
                    print(" Failed to create DCGAN config")
                    return None, None, None
                
                # Create models
                print(f"  Creating generator and discriminator...")
                generator = FullyConfigurableDCGANGenerator(dcgan_config)
                discriminator = FullyConfigurableDCGANDiscriminator(dcgan_config)
                
                # Load weights if available
                if isinstance(checkpoint, dict):
                    if 'generator_state_dict' in checkpoint:
                        generator.load_state_dict(checkpoint['generator_state_dict'])
                        print(f"   Loaded generator weights")
                    
                    if 'discriminator_state_dict' in checkpoint:
                        discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                        print(f"   Loaded discriminator weights")
                    
                    if 'model_state_dict' in checkpoint:
                        # Try to load as combined model
                        try:
                            generator.load_state_dict(checkpoint['model_state_dict'], strict=False)
                            print(f"   Loaded model_state_dict (generator)")
                        except:
                            pass
                else:
                    # Assume checkpoint is generator state_dict
                    try:
                        generator.load_state_dict(checkpoint)
                        print(f"   Loaded checkpoint as generator weights")
                    except:
                        print(f"   Could not load weights directly")
                
                # Calculate parameters
                gen_params = sum(p.numel() for p in generator.parameters())
                disc_params = sum(p.numel() for p in discriminator.parameters())
                total_params = gen_params + disc_params
                
                # Create model info
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': 'loaded_weights',
                    'image_size': dcgan_config.image_size,
                    'channels': dcgan_config.channels,
                    'latent_dim': dcgan_config.latent_dim,
                    'generator_params': gen_params,
                    'discriminator_params': disc_params,
                    'total_params': total_params,
                    'weights_url': weights_url,
                    'loaded_successfully': True
                }
                
                # Create checkpoint with loaded weights
                loaded_checkpoint = {
                    'config': dcgan_config,
                    'generator_state_dict': generator.state_dict(),
                    'discriminator_state_dict': discriminator.state_dict(),
                    'model_info': model_info,
                    'weights_source': weights_url
                }
                
                # Clean up
                os.unlink(tmp_path)
                
                return loaded_checkpoint, dcgan_config, model_info
                
            except Exception as e:
                print(f" Error loading model: {e}")
                traceback.print_exc()
                if 'tmp_path' in locals():
                    try:
                        os.unlink(tmp_path)
                    except:
                        pass
                return None, None, None
        
        def create_valid_dcgan_config(master_config: dict):
            
            try:
                # Extract parameters
                gan_cfg = master_config['gan']
                dataset_cfg = master_config['dataset']
                gen_cfg = gan_cfg.get('generator', {})
                disc_cfg = gan_cfg.get('discriminator', {})
                train_cfg = gan_cfg.get('training', {})
                
                # Determine algorithm
                algorithm = train_cfg.get('algorithm', 'backprop')
                algorithm_map = {
                    'backprop': TrainingAlgorithm.BACKPROP,
                    'cafo': TrainingAlgorithm.CAFO,
                    'forward_forward': TrainingAlgorithm.FORWARD_FORWARD,
                    'hybrid': TrainingAlgorithm.HYBRID
                }
                training_algorithm = algorithm_map.get(algorithm, TrainingAlgorithm.BACKPROP)
                
                # Set algorithm flags
                use_cafo = algorithm == 'cafo'
                use_forward_forward = algorithm == 'forward_forward'
                use_hybrid = algorithm == 'hybrid'
                
                # Image parameters
                image_size = dataset_cfg.get('image_size', 32)
                channels = dataset_cfg.get('channels', 1)
                
                # Default generator layers
                default_gen_layers = [
                    {"channels": 128, "kernel_size": 4, "stride": 1, "padding": 0, "output_padding": 0},
                    {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                    {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                    {"channels": channels, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                ]
                
                # Adjust for image size
                if image_size == 64:
                    default_gen_layers.insert(0, {"channels": 256, "kernel_size": 4, "stride": 1, "padding": 0, "output_padding": 0})
                    default_gen_layers[1]["channels"] = 128
                elif image_size == 128:
                    default_gen_layers = [
                        {"channels": 512, "kernel_size": 4, "stride": 1, "padding": 0, "output_padding": 0},
                        {"channels": 256, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                        {"channels": 128, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                        {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                        {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                        {"channels": channels, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                    ]
                
                gen_layers_config = gen_cfg.get('layers', default_gen_layers)
                generator_layers = []
                for layer in gen_layers_config:
                    if isinstance(layer, dict):
                        generator_layers.append(DCGANLayerConfig(
                            channels=layer['channels'],
                            kernel_size=layer['kernel_size'],
                            stride=layer['stride'],
                            padding=layer['padding'],
                            output_padding=layer.get('output_padding', 0)
                        ))
                    else:
                        generator_layers.append(layer)
                
                # Default discriminator layers
                default_disc_layers = [
                    {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1},
                    {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1},
                    {"channels": 128, "kernel_size": 4, "stride": 2, "padding": 1},
                    {"channels": 1, "kernel_size": 4, "stride": 1, "padding": 0},
                ]
                
                if image_size == 64:
                    default_disc_layers.insert(0, {"channels": 16, "kernel_size": 4, "stride": 2, "padding": 1})
                    default_disc_layers[1]["channels"] = 32
                elif image_size == 128:
                    default_disc_layers = [
                        {"channels": 16, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 128, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 256, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 1, "kernel_size": 4, "stride": 1, "padding": 0},
                    ]
                
                disc_layers_config = disc_cfg.get('layers', default_disc_layers)
                discriminator_layers = []
                for layer in disc_layers_config:
                    if isinstance(layer, dict):
                        discriminator_layers.append(DCGANLayerConfig(
                            channels=layer['channels'],
                            kernel_size=layer['kernel_size'],
                            stride=layer['stride'],
                            padding=layer['padding']
                        ))
                    else:
                        discriminator_layers.append(layer)
                
                # Create configs
                block_training = BlockTrainingConfig(
                    enabled=train_cfg.get('use_block_training', False),
                    num_blocks=3,
                    epochs_per_block=3,
                    block_learning_rate=0.001
                )
                
                balanced_training = BalancedTrainingConfig(
                    enabled=True,
                    discriminator_steps=1,
                    generator_steps=1
                )
                
                adversarial_training = AdversarialTrainingConfig(
                    n_critic=1,
                    generator_steps=1,
                    discriminator_steps=1
                )
                
                # Create DCGANConfig
                config = DCGANConfig(
                    image_size=image_size,
                    channels=channels,
                    latent_dim=gen_cfg.get('latent_dim', 100),
                    generator_layers=generator_layers,
                    discriminator_layers=discriminator_layers,
                    training_algorithm=training_algorithm,
                    use_cafo=use_cafo,
                    use_forward_forward=use_forward_forward,
                    use_hybrid=use_hybrid,
                    block_training=block_training,
                    balanced_training=balanced_training,
                    adversarial_training=adversarial_training,
                    generator_activation=ActivationConfig(name='leaky_relu', negative_slope=0.2),
                    discriminator_activation=ActivationConfig(name='leaky_relu', negative_slope=0.2),
                    generator_output_activation=ActivationConfig(name='tanh'),
                    discriminator_output_activation=ActivationConfig(name='sigmoid'),
                    generator_use_batchnorm=True,
                    discriminator_use_batchnorm=False,
                    generator_spectral_norm=False,
                    discriminator_spectral_norm=False,
                    batch_size=train_cfg.get('batch_size', 16),
                    epochs=train_cfg.get('epochs', 2),
                    device='cpu',
                    seed=42
                )
                
                return config
                
            except Exception as e:
                print(f" Error creating DCGAN config: {e}")
                traceback.print_exc()
                return None
        
        def build_new_model(master_config):
            
            try:
                print(f"  Building new DCGAN model...")
                
                # Create DCGAN config
                dcgan_config = create_valid_dcgan_config(master_config)
                if dcgan_config is None:
                    print(" Failed to create DCGAN config")
                    return None, None, None
                
                # Create models
                generator = FullyConfigurableDCGANGenerator(dcgan_config)
                discriminator = FullyConfigurableDCGANDiscriminator(dcgan_config)
                
                # Calculate parameters
                gen_params = sum(p.numel() for p in generator.parameters())
                disc_params = sum(p.numel() for p in discriminator.parameters())
                total_params = gen_params + disc_params
                
                print(f"   Model created:")
                print(f"    Image size: {dcgan_config.image_size}")
                print(f"    Channels: {dcgan_config.channels}")
                print(f"    Latent dim: {dcgan_config.latent_dim}")
                print(f"    Generator params: {gen_params:,}")
                print(f"    Discriminator params: {disc_params:,}")
                print(f"    Total params: {total_params:,}")
                
                # Create model info
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': 'new_build',
                    'image_size': dcgan_config.image_size,
                    'channels': dcgan_config.channels,
                    'latent_dim': dcgan_config.latent_dim,
                    'generator_params': gen_params,
                    'discriminator_params': disc_params,
                    'total_params': total_params,
                    'training_algorithm': dcgan_config.training_algorithm.value,
                    'use_cafo': dcgan_config.use_cafo,
                    'use_forward_forward': dcgan_config.use_forward_forward
                }
                
                # Create checkpoint
                checkpoint = {
                    'config': dcgan_config,
                    'generator_state_dict': generator.state_dict(),
                    'discriminator_state_dict': discriminator.state_dict(),
                    'model_info': model_info
                }
                
                return checkpoint, dcgan_config, model_info
                
            except Exception as e:
                print(f" Error building new model: {e}")
                traceback.print_exc()
                return None, None, None
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--master_config', type=str, required=False, default='')
        parser.add_argument('--load_from_schema', type=str, default='false')
        parser.add_argument('--schema_id', type=str, default='')
        parser.add_argument('--model_id', type=str, default='')
        parser.add_argument('--execution_id', type=str, default='')
        parser.add_argument('--bearer_token', type=str, default='')
        parser.add_argument('--load_from_cdn', type=str, default='false')
        parser.add_argument('--cdn_url', type=str, default='')
        parser.add_argument('--model_out', type=str, required=True)
        parser.add_argument('--config_updated', type=str, required=True)
        parser.add_argument('--model_info_out', type=str, required=True)
        args = parser.parse_args()
        
        load_from_schema = args.load_from_schema.lower() == 'true'
        load_from_cdn = args.load_from_cdn.lower() == 'true'
        
        print("=" * 80)
        print("BUILD DCGAN MODEL v10 - WITH SCHEMA & CDN LOADING")
        print("=" * 80)
        
        # Create output directories
        os.makedirs(os.path.dirname(args.model_out) or '.', exist_ok=True)
        os.makedirs(os.path.dirname(args.config_updated) or '.', exist_ok=True)
        os.makedirs(os.path.dirname(args.model_info_out) or '.', exist_ok=True)
        
        # Parse master config
        DEFAULT_CONFIG = {
            "model_type": "dcgan",
            "dataset": {"image_size": 32, "channels": 1},
            "gan": {
                "training": {"algorithm": "backprop", "batch_size": 16, "epochs": 2},
                "generator": {"latent_dim": 100},
                "discriminator": {}
            }
        }
        
        if args.master_config and args.master_config.strip():
            try:
                master_config = json.loads(args.master_config)
                print("Using provided master config")
            except:
                print("Invalid JSON, using default config")
                master_config = DEFAULT_CONFIG
        else:
            master_config = DEFAULT_CONFIG
            print("Using default config")
        
        # MAIN LOGIC
        checkpoint = None
        dcgan_config = None
        model_info = None
        source = "unknown"
        
        # MODE 1: Load from Schema
        if load_from_schema:
            print(f"\\nMODE 1: Loading from Schema")
            
            if not all([args.schema_id, args.model_id, args.execution_id, args.bearer_token]):
                print(" ERROR: schema_id, model_id, execution_id, and bearer_token are required when load_from_schema=true")
                sys.exit(1)
            
            try:
                execution_id_int = int(args.execution_id)
            except ValueError:
                print(f" ERROR: execution_id must be an integer. Got: {args.execution_id}")
                sys.exit(1)
            
            # Query schema for weights URL
            weights_url, schema_instance = query_schema_for_weights(
                args.schema_id, args.model_id, execution_id_int, args.bearer_token
            )
            
            if weights_url:
                print(f"  Loading model from schema URL...")
                checkpoint, dcgan_config, model_info = download_and_load_model(weights_url, master_config)
                source = "schema"
                
                if checkpoint:
                    # Add schema info to model_info
                    model_info['schema_id'] = args.schema_id
                    model_info['model_id'] = args.model_id
                    model_info['execution_id'] = execution_id_int
                    model_info['schema_instance'] = schema_instance
                    print(f" Model loaded from schema successfully")
                else:
                    print(f" Failed to load model from schema URL")
                    sys.exit(1)
            else:
                print(f" No weights URL found in schema, falling back to build mode")
                load_from_schema = False
        
        # MODE 2: Load from direct CDN URL
        if not checkpoint and load_from_cdn:
            print(f"\\nMODE 2: Loading from CDN URL")
            
            if not args.cdn_url:
                print(" ERROR: cdn_url is required when load_from_cdn=true")
                sys.exit(1)
            
            print(f"  Loading model from CDN URL: {args.cdn_url[:100]}...")
            checkpoint, dcgan_config, model_info = download_and_load_model(args.cdn_url, master_config)
            source = "cdn"
            
            if checkpoint:
                model_info['cdn_url'] = args.cdn_url
                print(f" Model loaded from CDN successfully")
            else:
                print(f" Failed to load model from CDN URL")
                sys.exit(1)
        
        # MODE 3: Build new model
        if not checkpoint:
            print(f"\\nMODE 3: Building new model")
            checkpoint, dcgan_config, model_info = build_new_model(master_config)
            source = "new_build"
            
            if not checkpoint:
                print(f" Failed to build new model")
                sys.exit(1)
        
        # Save outputs
        print(f"\\nSaving outputs...")
        
        try:
            # Save model checkpoint
            torch.save(checkpoint, args.model_out)
            model_file_size = get_file_size(args.model_out)
            print(f" Model saved: {args.model_out} ({model_file_size})")
            
            # Save config updated
            if dcgan_config:
                # Convert config to dict if needed
                if hasattr(dcgan_config, 'to_dict'):
                    config_dict = dcgan_config.to_dict()
                else:
                    config_dict = {
                        'image_size': getattr(dcgan_config, 'image_size', 32),
                        'channels': getattr(dcgan_config, 'channels', 1),
                        'latent_dim': getattr(dcgan_config, 'latent_dim', 100),
                        'training_algorithm': getattr(dcgan_config, 'training_algorithm', 'BACKPROP'),
                        'use_cafo': getattr(dcgan_config, 'use_cafo', False),
                        'use_forward_forward': getattr(dcgan_config, 'use_forward_forward', False),
                        'batch_size': getattr(dcgan_config, 'batch_size', 16),
                        'epochs': getattr(dcgan_config, 'epochs', 2)
                    }
                
                # Add source info
                config_dict['model_source'] = source
                if source == "schema":
                    config_dict['schema_id'] = args.schema_id
                    config_dict['model_id'] = args.model_id
                    config_dict['execution_id'] = args.execution_id
                elif source == "cdn":
                    config_dict['cdn_url'] = args.cdn_url
                
                with open(args.config_updated, 'w') as f:
                    json.dump(config_dict, f, indent=2)
                print(f" Config saved: {args.config_updated}")
            else:
                print(f" No config to save")
                with open(args.config_updated, 'w') as f:
                    json.dump({"error": "No config available"}, f, indent=2)
            
            # Save model info
            if model_info:
                model_info['model_file_size'] = model_file_size
                model_info['model_source'] = source
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                print(f" Model info saved: {args.model_info_out}")
            else:
                print(f" No model info to save")
                with open(args.model_info_out, 'w') as f:
                    json.dump({"error": "No model info available"}, f, indent=2)
            
            # Final summary
            print(f"\\n" + "=" * 80)
            print(f"BUILD COMPLETED SUCCESSFULLY!")
            print("=" * 80)
            print(f"Source: {source}")
            if model_info:
                print(f"Image size: {model_info.get('image_size', 'N/A')}")
                print(f"Channels: {model_info.get('channels', 'N/A')}")
                print(f"Latent dim: {model_info.get('latent_dim', 'N/A')}")
                print(f"Total parameters: {model_info.get('total_params', 'N/A'):,}")
            print(f"Model file: {args.model_out}")
            print(f"File size: {model_file_size}")
            print("=" * 80)
            
        except Exception as e:
            print(f" Error saving outputs: {e}")
            traceback.print_exc()
            sys.exit(1)

    args:
      - --master_config
      - {inputValue: master_config}
      - --load_from_schema
      - {inputValue: load_from_schema}
      - --schema_id
      - {inputValue: schema_id}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --bearer_token
      - {inputValue: bearer_token}
      - --load_from_cdn
      - {inputValue: load_from_cdn}
      - --cdn_url
      - {inputValue: cdn_url}
      - --model_out
      - {outputPath: model_out}
      - --config_updated
      - {outputPath: config_updated}
      - --model_info_out
      - {outputPath: model_info_out}
