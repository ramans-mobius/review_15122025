name: Build DCGAN Model v8 - PROPER CONFIGURABLE
description: Builds appropriate DCGAN models with full configurability and dimensional validation
inputs:
  - name: master_config
    type: String
  - name: load_from_schema
    type: String
    default: "false"
  - name: schema_id
    type: String
    default: ""
  - name: model_id
    type: String
    default: ""
  - name: execution_id
    type: String
    default: ""
  - name: load_from_cdn
    type: String
    default: "false"
  - name: cdn_url
    type: String
    default: ""
outputs:
  - name: model_out
    type: Model
  - name: config_updated
    type: String
  - name: model_info_out
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        echo "Building DCGAN Model v8 - Proper Configurable Architecture..."
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import argparse
        import json
        import os
        import sys
        import tempfile
        import urllib.request
        import requests
        from pathlib import Path
        import traceback
        import warnings
        
        def get_file_size(file_path):
            size_bytes = os.path.getsize(file_path)
            for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
                if size_bytes < 1024.0:
                    return f"{size_bytes:.2f} {unit}"
                size_bytes /= 1024.0
            return f"{size_bytes:.2f} PB"
        
        def deep_merge(base_dict, override_dict):
            result = base_dict.copy()
            
            for key, value in override_dict.items():
                if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                    result[key] = deep_merge(result[key], value)
                else:
                    result[key] = value
            
            return result
        
        # ============================================================================
        # IMPORT NESY FACTORY CLASSES
        # ============================================================================
        print("Importing nesy_factory.GANs.dcgan...")
        
        try:
            from nesy_factory.GANs.dcgan import (
                DCGANConfig, TrainingAlgorithm, DCGANLayerConfig,
                ActivationConfig, LossConfig, OptimizerConfig,
                BlockTrainingConfig, BalancedTrainingConfig, AdversarialTrainingConfig,
                create_dcgan, validate_config,
                FullyConfigurableDCGANGenerator,
                FullyConfigurableDCGANDiscriminator,
                EnhancedDCGANTrainer,
                create_generator,
                create_discriminator
            )
            print(" Successfully imported DCGAN modules")
        except ImportError as e:
            print(f" Import error: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # DIMENSIONAL VALIDATION FUNCTIONS
        # ============================================================================
        
        def validate_dcgan_dimensions(config: DCGANConfig) -> tuple:
          
            try:
                # Generator dimension calculation
                current_size = 1  # Starting from latent dim
                for i, layer in enumerate(config.generator_layers):
                    if hasattr(layer, 'kernel_size'):
                        kernel = layer.kernel_size
                        stride = layer.stride
                        padding = layer.padding
                        output_padding = getattr(layer, 'output_padding', 0)
                    else:
                        kernel = layer['kernel_size']
                        stride = layer['stride']
                        padding = layer['padding']
                        output_padding = layer.get('output_padding', 0)
                    
                    # ConvTranspose2d output size formula
                    current_size = (current_size - 1) * stride - 2 * padding + kernel + output_padding
                
                gen_output_size = current_size
                
                # Discriminator dimension calculation
                current_size = config.image_size
                for i, layer in enumerate(config.discriminator_layers):
                    if hasattr(layer, 'kernel_size'):
                        kernel = layer.kernel_size
                        stride = layer.stride
                        padding = layer.padding
                    else:
                        kernel = layer['kernel_size']
                        stride = layer['stride']
                        padding = layer['padding']
                    
                    # Conv2d output size formula
                    current_size = ((current_size + 2 * padding - kernel) // stride) + 1
                
                disc_final_size = current_size
                
                # Validate
                if gen_output_size != config.image_size:
                    return False, f"Generator output size ({gen_output_size}) doesn't match target image size ({config.image_size})", gen_output_size
                
                if disc_final_size != 1:
                    return False, f"Discriminator final feature map size should be 1, got {disc_final_size}", disc_final_size
                
                return True, "", gen_output_size
                
            except Exception as e:
                return False, f"Dimensional validation error: {str(e)}", 0
        
        def create_valid_dcgan_config(master_config: dict) -> DCGANConfig:
            
            try:
                # Extract parameters
                gan_cfg = master_config['gan']
                dataset_cfg = master_config['dataset']
                gen_cfg = gan_cfg.get('generator', {})
                disc_cfg = gan_cfg.get('discriminator', {})
                train_cfg = gan_cfg.get('training', {})
                block_cfg = gan_cfg.get('block_training', {})
                balanced_cfg = gan_cfg.get('balanced_training', {})
                
                # Determine algorithm
                algorithm = train_cfg.get('algorithm', 'backprop')
                algorithm_map = {
                    'backprop': TrainingAlgorithm.BACKPROP,
                    'cafo': TrainingAlgorithm.CAFO,
                    'forward_forward': TrainingAlgorithm.FORWARD_FORWARD,
                    'hybrid': TrainingAlgorithm.HYBRID
                }
                training_algorithm = algorithm_map.get(algorithm, TrainingAlgorithm.BACKPROP)
                
                # Set algorithm flags
                use_cafo = algorithm == 'cafo'
                use_forward_forward = algorithm == 'forward_forward'
                use_hybrid = algorithm == 'hybrid'
                
                # Image parameters
                image_size = dataset_cfg.get('image_size', 32)
                channels = dataset_cfg.get('channels', 1)
                
                # ========== GENERATOR LAYERS WITH VALIDATION ==========
                # Default generator layers for 32x32
                default_gen_layers = [
                    {"channels": 128, "kernel_size": 4, "stride": 1, "padding": 0, "output_padding": 0},
                    {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                    {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                    {"channels": channels, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                ]
                
                # Adjust layers based on image size
                if image_size == 64:
                    # Add an extra layer for 64x64
                    default_gen_layers.insert(0, {"channels": 256, "kernel_size": 4, "stride": 1, "padding": 0, "output_padding": 0})
                    default_gen_layers[1]["channels"] = 128
                elif image_size == 128:
                    # Add more layers for 128x128
                    default_gen_layers = [
                        {"channels": 512, "kernel_size": 4, "stride": 1, "padding": 0, "output_padding": 0},
                        {"channels": 256, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                        {"channels": 128, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                        {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                        {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                        {"channels": channels, "kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0},
                    ]
                
                # Use provided layers if available, otherwise use defaults
                gen_layers_config = gen_cfg.get('layers', default_gen_layers)
                
                # Convert to DCGANLayerConfig objects
                generator_layers = []
                for layer in gen_layers_config:
                    if isinstance(layer, dict):
                        generator_layers.append(DCGANLayerConfig(
                            channels=layer['channels'],
                            kernel_size=layer['kernel_size'],
                            stride=layer['stride'],
                            padding=layer['padding'],
                            output_padding=layer.get('output_padding', 0)
                        ))
                    else:
                        generator_layers.append(layer)
                
                # ========== DISCRIMINATOR LAYERS WITH VALIDATION ==========
                # Default discriminator layers
                default_disc_layers = [
                    {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1},
                    {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1},
                    {"channels": 128, "kernel_size": 4, "stride": 2, "padding": 1},
                    {"channels": 1, "kernel_size": 4, "stride": 1, "padding": 0},
                ]
                
                # Adjust for different image sizes
                if image_size == 64:
                    # Add an extra layer for 64x64
                    default_disc_layers.insert(0, {"channels": 16, "kernel_size": 4, "stride": 2, "padding": 1})
                    default_disc_layers[1]["channels"] = 32
                elif image_size == 128:
                    # Add more layers for 128x128
                    default_disc_layers = [
                        {"channels": 16, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 32, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 64, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 128, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 256, "kernel_size": 4, "stride": 2, "padding": 1},
                        {"channels": 1, "kernel_size": 4, "stride": 1, "padding": 0},
                    ]
                
                # Use provided layers if available, otherwise use defaults
                disc_layers_config = disc_cfg.get('layers', default_disc_layers)
                
                # Convert to DCGANLayerConfig objects
                discriminator_layers = []
                for layer in disc_layers_config:
                    if isinstance(layer, dict):
                        discriminator_layers.append(DCGANLayerConfig(
                            channels=layer['channels'],
                            kernel_size=layer['kernel_size'],
                            stride=layer['stride'],
                            padding=layer['padding']
                        ))
                    else:
                        discriminator_layers.append(layer)
                
                # ========== CREATE BLOCK TRAINING CONFIG ==========
                # Enable block training for CAFO and FF, disable for backprop
                enable_block_training = use_cafo or use_forward_forward or use_hybrid
                
                block_training = BlockTrainingConfig(
                    enabled=block_cfg.get('enabled', enable_block_training),
                    num_blocks=block_cfg.get('num_blocks', min(3, len(generator_layers) - 1)),
                    epochs_per_block=block_cfg.get('epochs_per_block', 3),
                    block_learning_rate=block_cfg.get('block_learning_rate', 0.001),
                    freeze_previous_blocks=block_cfg.get('freeze_previous_blocks', True),
                    train_generator_blocks=block_cfg.get('train_generator_blocks', True),
                    train_discriminator_blocks=block_cfg.get('train_discriminator_blocks', True),
                    cafo_local_predictor_dim=block_cfg.get('cafo_local_predictor_dim', 32),
                    ff_threshold=block_cfg.get('ff_threshold', 2.0),
                    ff_goodness_dim=block_cfg.get('ff_goodness_dim', 32)
                )
                
                # ========== CREATE BALANCED TRAINING CONFIG ==========
                balanced_training = BalancedTrainingConfig(
                    enabled=balanced_cfg.get('enabled', True),
                    discriminator_steps=balanced_cfg.get('discriminator_steps', 1),
                    generator_steps=balanced_cfg.get('generator_steps', 1),
                    discriminator_lr_multiplier=balanced_cfg.get('discriminator_lr_multiplier', 0.5),
                    label_smoothing=balanced_cfg.get('label_smoothing', 0.1),
                    feature_matching=balanced_cfg.get('feature_matching', False),
                    feature_matching_weight=balanced_cfg.get('feature_matching_weight', 10.0)
                )
                
                # ========== CREATE ADVERSARIAL TRAINING CONFIG ==========
                adversarial_training = AdversarialTrainingConfig(
                    n_critic=balanced_cfg.get('discriminator_steps', 1),
                    generator_steps=balanced_cfg.get('generator_steps', 1),
                    discriminator_steps=balanced_cfg.get('discriminator_steps', 1),
                    gradient_penalty_weight=balanced_cfg.get('gradient_penalty_weight', 10.0),
                    gradient_penalty_interval=1
                )
                
                # ========== CREATE DCGAN CONFIG ==========
                config = DCGANConfig(
                    image_size=image_size,
                    channels=channels,
                    latent_dim=gen_cfg.get('latent_dim', 100),
                    generator_layers=generator_layers,
                    discriminator_layers=discriminator_layers,
                    training_algorithm=training_algorithm,
                    use_cafo=use_cafo,
                    use_forward_forward=use_forward_forward,
                    use_hybrid=use_hybrid,
                    block_training=block_training,
                    balanced_training=balanced_training,
                    adversarial_training=adversarial_training,
                    generator_activation=ActivationConfig(
                        name=gen_cfg.get('activation', 'leaky_relu'),
                        negative_slope=0.2
                    ),
                    discriminator_activation=ActivationConfig(
                        name=disc_cfg.get('activation', 'leaky_relu'),
                        negative_slope=0.2
                    ),
                    generator_output_activation=ActivationConfig(
                        name=gen_cfg.get('output_activation', 'tanh')
                    ),
                    discriminator_output_activation=ActivationConfig(
                        name=disc_cfg.get('output_activation', 'sigmoid')
                    ),
                    generator_use_batchnorm=gen_cfg.get('use_batchnorm', True),
                    discriminator_use_batchnorm=disc_cfg.get('use_batchnorm', False),
                    generator_spectral_norm=gen_cfg.get('spectral_norm', False),
                    discriminator_spectral_norm=disc_cfg.get('spectral_norm', False),
                    batch_size=train_cfg.get('batch_size', 16),
                    epochs=train_cfg.get('epochs', 2),
                    device=train_cfg.get('device', 'auto'),
                    seed=train_cfg.get('seed', 42)
                )
                
                # Validate dimensions
                is_valid_dim, dim_error, output_size = validate_dcgan_dimensions(config)
                if not is_valid_dim:
                    print(f"  Dimensional issue: {dim_error}")
                    print(f"   Attempting to auto-correct configuration...")
                    
                    # Auto-correct by adjusting layers
                    # This is a simple auto-correction - in production you might want more sophisticated logic
                    if "Generator output size" in dim_error:
                        print(f"   Generator output size: {output_size}, Target: {image_size}")
                
                return config
                
            except Exception as e:
                print(f" Error creating DCGAN config: {e}")
                traceback.print_exc()
                return None
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--master_config', type=str, required=False, default='')
        parser.add_argument('--load_from_schema', type=str, default='false')
        parser.add_argument('--schema_id', type=str, default='')
        parser.add_argument('--model_id', type=str, default='')
        parser.add_argument('--execution_id', type=str, default='')
        parser.add_argument('--load_from_cdn', type=str, default='false')
        parser.add_argument('--cdn_url', type=str, default='')
        parser.add_argument('--model_out', type=str, required=True)
        parser.add_argument('--config_updated', type=str, required=True)
        parser.add_argument('--model_info_out', type=str, required=True)
        args = parser.parse_args()
        
        load_from_schema = args.load_from_schema.lower() == 'true'
        load_from_cdn = args.load_from_cdn.lower() == 'true'
        
        # DEFAULT CONFIG TEMPLATE
        DEFAULT_CONFIG = {
            "model_type": "dcgan",
            "dataset": {
                "name": "mnist",
                "image_size": 32,
                "channels": 1,
                "num_samples": 100
            },
            "gan": {
                "training": {
                    "algorithm": "backprop",
                    "batch_size": 16,
                    "epochs": 2,
                    "device": "cuda" if torch.cuda.is_available() else "cpu",
                    "seed": 42
                },
                "generator": {
                    "latent_dim": 100,
                    "activation": "leaky_relu",
                    "output_activation": "tanh",
                    "use_batchnorm": True,
                    "spectral_norm": False
                },
                "discriminator": {
                    "activation": "leaky_relu",
                    "output_activation": "sigmoid",
                    "use_batchnorm": False,
                    "spectral_norm": False
                },
                "block_training": {
                    "enabled": False,
                    "num_blocks": 3,
                    "epochs_per_block": 3,
                    "block_learning_rate": 0.001
                },
                "balanced_training": {
                    "enabled": True,
                    "discriminator_steps": 1,
                    "generator_steps": 1,
                    "label_smoothing": 0.1
                }
            },
            "model_source": "default_config"
        }
        
        def get_schema_url(schema_id, model_id, execution_id):
            # Placeholder for schema service logic
            # In practice, you would call your schema service
            return ""
        
        # ============================================================================
        # MAIN EXECUTION
        # ============================================================================
        print("=" * 80)
        print("BUILD DCGAN MODEL v8 - PROPER CONFIGURABLE")
        print("=" * 80)
        
        # Create output directories
        os.makedirs(os.path.dirname(args.model_out), exist_ok=True)
        os.makedirs(os.path.dirname(args.config_updated), exist_ok=True)
        os.makedirs(os.path.dirname(args.model_info_out), exist_ok=True)
        
        # Parse and merge config
        if args.master_config and args.master_config.strip():
            try:
                provided_config = json.loads(args.master_config)
                print("Using provided master config")
                
                # Merge provided config with defaults
                config = deep_merge(DEFAULT_CONFIG, provided_config)
                config['model_source'] = 'user_provided_merged'
                
            except json.JSONDecodeError as e:
                print(f"ERROR: Invalid JSON in master_config: {e}")
                print("Falling back to default config")
                config = DEFAULT_CONFIG
        else:
            config = DEFAULT_CONFIG
            print("Using default config")
        
        # MODE 1: Load from Schema
        if load_from_schema:
            print(f"Loading model from schema...")
            print(f"  Schema ID: {args.schema_id}")
            print(f"  Model ID: {args.model_id}")
            print(f"  Execution ID: {args.execution_id}")
            
            if not args.schema_id or not args.model_id or not args.execution_id:
                print("ERROR: schema_id, model_id, and execution_id are required when load_from_schema=true")
                sys.exit(1)
            
            # Get URL from schema service
            cdn_url = get_schema_url(args.schema_id, args.model_id, args.execution_id)
            if not cdn_url:
                print("ERROR: Could not get CDN URL from schema service")
                sys.exit(1)
            
            # Download from CDN
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pt') as tmp_file:
                    tmp_path = tmp_file.name
                
                print(f"Downloading from schema CDN: {cdn_url}")
                urllib.request.urlretrieve(cdn_url, tmp_path)
                print("Download completed")
                
                checkpoint = torch.load(tmp_path, map_location='cpu')
                torch.save(checkpoint, args.model_out)
                print(f"Model loaded from schema and saved to: {args.model_out}")
                
                # Update config
                config['model_source'] = 'schema'
                config['schema_id'] = args.schema_id
                config['model_id'] = args.model_id
                config['execution_id'] = args.execution_id
                config['cdn_url'] = cdn_url
                
                with open(args.config_updated, 'w') as f:
                    json.dump(config, f, indent=2)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': 'schema',
                    'schema_id': args.schema_id,
                    'model_id': args.model_id,
                    'execution_id': args.execution_id,
                    'cdn_url': cdn_url,
                    'model_file_size': model_file_size,
                    'checkpoint_keys': list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'state_dict'
                }
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"Model file size: {model_file_size}")
                os.unlink(tmp_path)
                
            except Exception as e:
                print(f"Failed to load model from schema: {e}")
                traceback.print_exc()
                sys.exit(1)
                
        # MODE 2: Load from direct CDN URL
        elif load_from_cdn:
            print(f"Loading model from direct CDN URL...")
            
            if not args.cdn_url:
                print("ERROR: cdn_url is required when load_from_cdn=true")
                sys.exit(1)
            
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pt') as tmp_file:
                    tmp_path = tmp_file.name
                
                print(f"Downloading from CDN: {args.cdn_url}")
                urllib.request.urlretrieve(args.cdn_url, tmp_path)
                print("Download completed")
                
                checkpoint = torch.load(tmp_path, map_location='cpu')
                torch.save(checkpoint, args.model_out)
                print(f"Model loaded from CDN and saved to: {args.model_out}")
                
                # Update config
                config['model_source'] = 'cdn'
                config['cdn_url'] = args.cdn_url
                
                with open(args.config_updated, 'w') as f:
                    json.dump(config, f, indent=2)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': 'cdn',
                    'cdn_url': args.cdn_url,
                    'model_file_size': model_file_size,
                    'checkpoint_keys': list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'state_dict'
                }
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"Model file size: {model_file_size}")
                os.unlink(tmp_path)
                
            except Exception as e:
                print(f"Failed to load model from CDN: {e}")
                traceback.print_exc()
                sys.exit(1)
                
        # MODE 3: Build new model
        else:
            print(f"\\nBuilding new DCGAN model...")
            
            try:
                # Create DCGAN config with dimensional validation
                dcgan_config = create_valid_dcgan_config(config)
                if dcgan_config is None:
                    print("ERROR: Failed to create DCGAN config")
                    sys.exit(1)
                
                # Validate config
                is_valid, errors = validate_config(dcgan_config)
                if not is_valid:
                    print("Config validation errors:")
                    for error in errors:
                        print(f"  - {error}")
                    sys.exit(1)
                
                # Validate dimensions
                is_valid_dim, dim_error, output_size = validate_dcgan_dimensions(dcgan_config)
                if not is_valid_dim:
                    print(f"WARNING: Dimensional issue: {dim_error}")
                    print(f"  Output size: {output_size}, Target: {dcgan_config.image_size}")
                
                # Create models using nesy_factory functions
                print(f"\\nCreating Generator...")
                generator = create_generator(dcgan_config)
                
                print(f"Creating Discriminator...")
                discriminator = create_discriminator(dcgan_config)
                
                print(f"\\n ARCHITECTURE DETAILS:")
                print(f"  Algorithm: {dcgan_config.training_algorithm.value}")
                print(f"  Image size: {dcgan_config.image_size}")
                print(f"  Channels: {dcgan_config.channels}")
                print(f"  Latent dim: {dcgan_config.latent_dim}")
                print(f"  Generator blocks: {len(generator.blocks)}")
                print(f"  Discriminator blocks: {len(discriminator.blocks)}")
                
                # Parameter counts
                gen_params = sum(p.numel() for p in generator.parameters())
                disc_params = sum(p.numel() for p in discriminator.parameters())
                total_params = gen_params + disc_params
                
                print(f"\\n PARAMETER COUNTS:")
                print(f"  Generator parameters: {gen_params:,}")
                print(f"  Discriminator parameters: {disc_params:,}")
                print(f"  Total parameters: {total_params:,}")
                
                # Test forward passes
                print(f"\\n Testing forward passes...")
                with torch.no_grad():
                    # Test generator
                    z = torch.randn(2, dcgan_config.latent_dim, 1, 1)
                    if torch.cuda.is_available():
                        z = z.cuda()
                        generator.cuda()
                    
                    gen_output = generator(z)
                    print(f"  Generator output shape: {gen_output.shape}")
                    print(f"  Generator output range: [{gen_output.min():.3f}, {gen_output.max():.3f}]")
                    
                    # Test discriminator
                    disc_output = discriminator(gen_output)
                    print(f"  Discriminator output shape: {disc_output.shape}")
                    print(f"  Discriminator output range: [{disc_output.min():.3f}, {disc_output.max():.3f}]")
                
                # Create model info
                model_info = {
                    'model_type': 'dcgan',
                    'model_source': config.get('model_source', 'new_build'),
                    'training_algorithm': dcgan_config.training_algorithm.value,
                    'image_size': dcgan_config.image_size,
                    'channels': dcgan_config.channels,
                    'latent_dim': dcgan_config.latent_dim,
                    'generator_params': gen_params,
                    'discriminator_params': disc_params,
                    'total_params': total_params,
                    'generator_blocks': len(generator.blocks),
                    'discriminator_blocks': len(discriminator.blocks),
                    'block_training_enabled': dcgan_config.block_training.enabled,
                    'use_cafo': dcgan_config.use_cafo,
                    'use_forward_forward': dcgan_config.use_forward_forward,
                    'use_hybrid': dcgan_config.use_hybrid,
                    'training_config': {
                        'algorithm': dcgan_config.training_algorithm.value,
                        'batch_size': dcgan_config.batch_size,
                        'epochs': dcgan_config.epochs,
                        'block_training_enabled': dcgan_config.block_training.enabled,
                        'num_blocks': dcgan_config.block_training.num_blocks if dcgan_config.block_training.enabled else 0,
                        'device': dcgan_config.device
                    },
                    'dimensional_validation': {
                        'valid': is_valid_dim,
                        'error': dim_error if not is_valid_dim else '',
                        'output_size': int(output_size) if output_size else 0,
                        'target_size': dcgan_config.image_size
                    }
                }
                
                # Save both models in a checkpoint
                checkpoint = {
                    'config': dcgan_config.to_dict(),
                    'generator_state_dict': generator.state_dict(),
                    'discriminator_state_dict': discriminator.state_dict(),
                    'model_info': model_info,
                    'model_type': 'dcgan',
                    'training_algorithm': dcgan_config.training_algorithm.value,
                    'master_config': config
                }
                
                torch.save(checkpoint, args.model_out)
                
                # Get file size
                model_file_size = get_file_size(args.model_out)
                model_info['model_file_size'] = model_file_size
                
                # Save updated config (DCGAN config)
                with open(args.config_updated, 'w') as f:
                    json.dump(dcgan_config.to_dict(), f, indent=2)
                    
                # Save model info
                with open(args.model_info_out, 'w') as f:
                    json.dump(model_info, f, indent=2)
                    
                print(f"\\n DCGAN model built successfully!")
                print(f"  Saved to: {args.model_out}")
                print(f"  File size: {model_file_size}")
                print(f"  Algorithm: {dcgan_config.training_algorithm.value}")
                print(f"  Block training: {'Enabled' if dcgan_config.block_training.enabled else 'Disabled'}")
                print(f"  CAFO: {'Yes' if dcgan_config.use_cafo else 'No'}")
                print(f"  Forward-Forward: {'Yes' if dcgan_config.use_forward_forward else 'No'}")
                print(f"  Dimensional validation: {' Pass' if is_valid_dim else ' Warning: ' + dim_error}")
                
            except Exception as e:
                print(f" ERROR: Failed to build DCGAN model: {e}")
                traceback.print_exc()
                sys.exit(1)

    args:
      - --master_config
      - {inputValue: master_config}
      - --load_from_schema
      - {inputValue: load_from_schema}
      - --schema_id
      - {inputValue: schema_id}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --load_from_cdn
      - {inputValue: load_from_cdn}
      - --cdn_url
      - {inputValue: cdn_url}
      - --model_out
      - {outputPath: model_out}
      - --config_updated
      - {outputPath: config_updated}
      - --model_info_out
      - {outputPath: model_info_out}
