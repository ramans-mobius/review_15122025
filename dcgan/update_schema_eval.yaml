name: Upload Evaluation Metrics to Schema v2
description: Uploads FID, SSIM, PSNR scores and required fields to performance matrix schema
inputs:
  # Evaluation outputs from Evaluate DCGAN brick
  - name: evaluation_metrics
    type: String
    description: "Evaluation metrics JSON from evaluation brick"
  
  # Schema parameters
  - name: schema_id
    type: String
    description: "Performance matrix schema ID"
  - name: bearer_token
    type: String
    description: "Bearer token for authentication"
  - name: model_id
    type: String
    description: "Model identifier"
  - name: execution_id
    type: String
    description: "Execution ID (will be converted to integer)"
  - name: tenant_id
    type: String
    description: "Tenant ID for schema"
  - name: project_id
    type: String
    description: "Project ID for schema"
  - name: model_name
    type: String
    description: "Model name"
  - name: model_type
    type: String
    default: "DCGAN"
    description: "Model type"

outputs:
  - name: upload_status
    type: String
    description: "Upload status and results"
  - name: schema_response
    type: String
    description: "Response from schema API"

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import sys
        import subprocess
        import time
        import numpy as np
        from datetime import datetime
        
        parser = argparse.ArgumentParser()
        
        # Evaluation outputs
        parser.add_argument('--evaluation_metrics', type=str, required=True)
        
        # Schema parameters
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--bearer_token', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--model_name', type=str, required=True)
        parser.add_argument('--model_type', type=str, default='DCGAN')
        
        # Outputs
        parser.add_argument('--upload_status', type=str, required=True)
        parser.add_argument('--schema_response', type=str, required=True)
        
        args = parser.parse_args()
        
        print("=" * 80)
        print("UPLOAD EVALUATION METRICS TO SCHEMA v1")
        print("=" * 80)
        
        # ============================================================================
        # Create output directories
        # ============================================================================
        print("\\nCreating output directories...")
        
        output_paths = [
            args.upload_status,
            args.schema_response
        ]
        
        for path in output_paths:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    print(f"  Created: {dir_path}")
        
        # ============================================================================
        # Parse inputs - CORRECTED bearer token handling
        # ============================================================================
        bearer_token = args.bearer_token.strip()  # Direct use, not from file
        print(f"Bearer token length: {len(bearer_token)} chars")
        print(f"Bearer token preview: {bearer_token[:50]}...")
        
        try:
            execution_id = int(args.execution_id)
            print(f"✓ Execution ID: {execution_id} (type: number)")
        except ValueError:
            print(f"ERROR: execution_id must be an integer. Got: {args.execution_id}")
            sys.exit(1)
        
        # Get current timestamp (number type)
        current_timestamp = int(time.time())
        
        print(f"\\nParameters:")
        print(f"  Schema ID: {args.schema_id}")
        print(f"  Model ID: {args.model_id}")
        print(f"  Model Name: {args.model_name}")
        print(f"  Model Type: {args.model_type}")
        print(f"  Execution ID: {execution_id}")
        print(f"  Tenant ID: {args.tenant_id}")
        print(f"  Project ID: {args.project_id}")
        print(f"  Timestamp: {current_timestamp}")
        
        # ============================================================================
        # Load evaluation data
        # ============================================================================
        print(f"\\nLoading evaluation data...")
        
        try:
            with open(args.evaluation_metrics, 'r') as f:
                eval_metrics = json.load(f)
            print(f"✓ Loaded evaluation metrics")
            
            # Show available metrics
            print(f"\\nAvailable metrics in evaluation_metrics:")
            for key, value in eval_metrics.items():
                print(f"  {key}: {value}")
            
        except Exception as e:
            print(f"ERROR loading evaluation data: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # Extract FID, SSIM, PSNR values
        # ============================================================================
        print(f"\\nExtracting FID, SSIM, PSNR values...")
        
        # Initialize with defaults
        fid_value = 0.0
        ssim_value = 0.0
        psnr_value = 0.0
        mse_value = 0.0
        mae_value = 0.0
        
        # Extract fid (could be 'fid', 'fid_score', etc.)
        fid_keys = ['fid', 'fid_score', 'FID', 'fid_value']
        for key in fid_keys:
            if key in eval_metrics:
                fid_value = float(eval_metrics[key])
                print(f"✓ Found FID: {key} = {fid_value}")
                break
        
        # Extract ssim (could be 'ssim', 'ssim_mean', etc.)
        ssim_keys = ['ssim', 'ssim_mean', 'SSIM', 'ssim_value']
        for key in ssim_keys:
            if key in eval_metrics:
                ssim_value = float(eval_metrics[key])
                print(f"✓ Found SSIM: {key} = {ssim_value}")
                break
        
        # Extract psnr (could be 'psnr', 'psnr_mean', etc.)
        psnr_keys = ['psnr', 'psnr_mean', 'PSNR', 'psnr_value']
        for key in psnr_keys:
            if key in eval_metrics:
                psnr_value = float(eval_metrics[key])
                print(f"✓ Found PSNR: {key} = {psnr_value}")
                break
        
        # Extract mse if available
        if 'mse' in eval_metrics:
            mse_value = float(eval_metrics['mse'])
            print(f"✓ Found MSE: {mse_value}")
        
        # Extract mae if available
        if 'mae' in eval_metrics:
            mae_value = float(eval_metrics['mae'])
            print(f"✓ Found MAE: {mae_value}")
        
        # Check if we found the metrics
        if fid_value == 0.0 and ssim_value == 0.0 and psnr_value == 0.0:
            print(f" Warning: Could not find FID, SSIM, or PSNR in evaluation metrics")
            print(f"  Available keys: {list(eval_metrics.keys())}")
        
        print(f"\\nExtracted values:")
        print(f"  FID: {fid_value}")
        print(f"  SSIM: {ssim_value}")
        print(f"  PSNR: {psnr_value}")
        if mse_value > 0:
            print(f"  MSE: {mse_value}")
        if mae_value > 0:
            print(f"  MAE: {mae_value}")
        
        # ============================================================================
        # Create schema entry - CORRECTED: Use schema fields directly
        # ============================================================================
        print(f"\\nCreating schema entry...")
        
        # REQUIRED FIELDS (must be present) - from your schema
        required_fields = {
            'tenant_id': args.tenant_id,
            'model_id': str(args.model_id),  # Schema expects string
            'execution_id': execution_id,    # Schema expects number
            'projectId': args.project_id,    # capital 'I' as per schema
            'timestamp': current_timestamp   # Schema expects number
        }
        
        # OPTIONAL FIELDS - using actual schema field names
        optional_fields = {
            'model_name': args.model_name,
            'model_type': args.model_type,
            'fid': float(fid_value),          # Direct mapping to schema field
            'ssim': float(ssim_value),        # Direct mapping to schema field
            'psnr': float(psnr_value),        # Direct mapping to schema field
            'mse': float(mse_value if mse_value > 0 else 10 ** (-psnr_value / 10) if psnr_value > 0 else 0.0),
            'rmse': str(np.sqrt(mse_value) if mse_value > 0 else np.sqrt(10 ** (-psnr_value / 10)) if psnr_value > 0 else "0.0"),
            'rmse_score': float(np.sqrt(mse_value) if mse_value > 0 else np.sqrt(10 ** (-psnr_value / 10)) if psnr_value > 0 else 0.0),
            'loss': float(fid_value),         # FID can also be considered as loss
            'accuracy': float(ssim_value),    # SSIM as accuracy proxy
            'precision_score': float(psnr_value),  # PSNR as precision
            'r2_score': float(ssim_value),    # SSIM as R² proxy
            # Default values for fields not applicable to GANs
            'roc_auc': 0,                     # integer
            'confusion_matrix': [],           # float_array (empty list)
            'recall': 0.0,                    # float
            'f1_score': 0.0                   # float
        }
        
        # Create final schema entry
        schema_entry = {**required_fields, **optional_fields}
        
        print(f"\\nSchema entry prepared ({len(schema_entry)} fields):")
        print(f"  Required fields: {len(required_fields)}")
        print(f"  Optional fields: {len(optional_fields)}")
        
        # Print the schema entry for debugging
        print(f"\\nSchema entry to upload:")
        for key, value in schema_entry.items():
            print(f"  {key}: {value} (type: {type(value).__name__})")
        
        # ============================================================================
        # Schema upload function - CORRECTED: Use bearer_token variable
        # ============================================================================
        def upload_to_schema(schema_data):
          
            # Try both endpoint formats
            endpoints = [
                f"https://igs.gov-cloud.ai/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/create",
                f"https://igs.gov-cloud.ai/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances"
            ]
            
            for endpoint_idx, schema_url in enumerate(endpoints):
                print(f"\\nTrying endpoint {endpoint_idx + 1}: {schema_url}")
                
                try:
                    # Create curl command
                    curl_command = [
                        "curl",
                        "--location", schema_url,
                        "--header", f"Authorization: Bearer {bearer_token}",  # Use bearer_token variable
                        "--header", "Content-Type: application/json",
                        "--data", json.dumps(schema_data),
                        "--fail",
                        "--show-error",
                        "--connect-timeout", "30",
                        "--max-time", "60"
                    ]
                    
                    print(f"    Executing curl command...")
                    
                    process = subprocess.run(
                        curl_command,
                        capture_output=True,
                        text=True,
                        check=False  # Don't raise exception, we'll handle it
                    )
                    
                    print(f"    Curl exit code: {process.returncode}")
                    
                    if process.returncode == 0:
                        print(f"    ✓ Upload successful")
                        
                        try:
                            response_data = json.loads(process.stdout)
                            print(f"    Response JSON received")
                            return True, response_data, None
                        except json.JSONDecodeError:
                            print(f"    Response (non-JSON): {process.stdout[:500]}")
                            return True, {"raw_response": process.stdout[:500]}, None
                    else:
                        print(f"    ✗ Upload failed (exit code: {process.returncode})")
                        print(f"    Stderr: {process.stderr[:200]}")
                        print(f"    Stdout: {process.stdout[:200]}")
                        
                        # Check if it's a 404 error
                        if "404" in process.stderr or "404" in process.stdout:
                            print(f"    Endpoint not found, trying alternative...")
                            continue  # Try next endpoint
                        
                        # Try to parse error
                        error_data = None
                        if process.stdout:
                            try:
                                error_data = json.loads(process.stdout)
                            except:
                                error_data = {"raw_error": process.stdout[:500]}
                        
                        return False, error_data, process.stderr[:500]
                        
                except Exception as e:
                    print(f"    ✗ Exception: {str(e)}")
                    return False, {"error": str(e)}, None
            
            # If we get here, all endpoints failed
            return False, {"error": "All endpoints failed (404 errors)"}, None
        
        # ============================================================================
        # Upload to schema
        # ============================================================================
        print(f"\\n" + "=" * 80)
        print("UPLOADING TO SCHEMA")
        print("=" * 80)
        
        success, response, error = upload_to_schema(schema_entry)
        
        if success:
            print(f"\\n✓ Upload successful!")
            if 'id' in response:
                print(f"  Response ID: {response.get('id')}")
            print(f"  Response keys: {list(response.keys())}")
        else:
            print(f"\\n✗ Upload failed")
            if error:
                print(f"  Error: {error}")
        
        # ============================================================================
        # Save outputs
        # ============================================================================
        print(f"\\nSaving outputs...")
        
        try:
            # Save upload status
            upload_status_data = {
                'success': success,
                'timestamp': current_timestamp,
                'model_id': args.model_id,
                'model_name': args.model_name,
                'execution_id': execution_id,
                'schema_id': args.schema_id,
                'metrics_uploaded': {
                    'fid': fid_value,
                    'ssim': ssim_value,
                    'psnr': psnr_value,
                    'mse': mse_value,
                    'mae': mae_value,
                    'mse_calculated': schema_entry['mse'],
                    'rmse_calculated': schema_entry['rmse_score']
                },
                'schema_fields_populated': len(schema_entry),
                'required_fields_included': list(required_fields.keys()),
                'upload_response': response if success else {"error": str(response.get('error', 'Unknown error')), "details": error},
                'upload_timestamp': int(time.time()),
                'evaluation_metrics_keys': list(eval_metrics.keys()),
                'schema_entry_sample': {k: v for i, (k, v) in enumerate(schema_entry.items()) if i < 10}  # First 10 items
            }
            
            with open(args.upload_status, 'w') as f:
                json.dump(upload_status_data, f, indent=2)
            print(f"✓ Upload status saved: {args.upload_status}")
            
            # Save schema response
            with open(args.schema_response, 'w') as f:
                json.dump(response if success else {"error": str(response.get('error', 'Unknown error')), "details": error}, f, indent=2)
            print(f"✓ Schema response saved: {args.schema_response}")
            
        except Exception as e:
            print(f"ERROR saving outputs: {e}")
            import traceback
            traceback.print_exc()
        
        # ============================================================================
        # Final summary
        # ============================================================================
        print(f"\\n" + "=" * 80)
        if success:
            print(" EVALUATION METRICS UPLOADED SUCCESSFULLY!")
        else:
            print(" EVALUATION METRICS UPLOAD FAILED")
        print("=" * 80)
        
        print(f"\\nUPLOADED METRICS (DIRECT TO SCHEMA FIELDS):")
        print(f"  fid: {fid_value:.2f}")
        print(f"  ssim: {ssim_value:.4f}")
        print(f"  psnr: {psnr_value:.2f} dB")
        if mse_value > 0:
            print(f"  mse: {mse_value:.6f}")
        else:
            print(f"  mse (calculated): {schema_entry['mse']:.6f}")
        print(f"  rmse: {schema_entry['rmse_score']:.6f}")
        
        print(f"\\nMAPPED TO OTHER SCHEMA FIELDS:")
        print(f"  loss: {fid_value:.2f} (FID mapped to loss)")
        print(f"  accuracy: {ssim_value:.4f} (SSIM mapped to accuracy)")
        print(f"  precision_score: {psnr_value:.2f} (PSNR mapped to precision)")
        print(f"  r2_score: {ssim_value:.4f} (SSIM mapped to R²)")
        
        print(f"\\nMODEL INFO:")
        print(f"  Model: {args.model_name} ({args.model_id})")
        print(f"  Type: {args.model_type}")
        print(f"  Execution ID: {execution_id}")
        print(f"  Schema ID: {args.schema_id}")
        print(f"  Project ID: {args.project_id}")
        print(f"  Tenant ID: {args.tenant_id}")
        
        print(f"\\nSTATUS: {'SUCCESS' if success else 'FAILED'}")
        print("=" * 80)
        
        if not success:
            sys.exit(1)

    args:
      # Evaluation outputs
      - --evaluation_metrics
      - {inputPath: evaluation_metrics}
      
      # Schema parameters
      - --schema_id
      - {inputValue: schema_id}
      - --bearer_token
      - {inputValue: bearer_token}  # This is correct - passes token as value
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputValue: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --model_name
      - {inputValue: model_name}
      - --model_type
      - {inputValue: model_type}
      
      # Outputs
      - --upload_status
      - {outputPath: upload_status}
      - --schema_response
      - {outputPath: schema_response}
