name: Upload Evaluation Metrics To Schema v10
description: Uploads FID, SSIM, PSNR scores to performance matrix schema
inputs:
  - name: evaluation_metrics
    type: String
  - name: schema_id
    type: String
  - name: bearer_token
    type: String
  - name: model_id
    type: String
  - name: execution_id
    type: String
  - name: tenant_id
    type: String
  - name: project_id
    type: String
  - name: model_name
    type: String
  - name: model_type
    type: String
    default: "DCGAN"
outputs:
  - name: upload_status
    type: String
  - name: schema_response
    type: String
implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import sys
        import subprocess
        import time
        import numpy as np
        from datetime import datetime
        import traceback
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--evaluation_metrics', type=str, required=True)
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--bearer_token', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--model_name', type=str, required=True)
        parser.add_argument('--model_type', type=str, default='DCGAN')
        parser.add_argument('--upload_status', type=str, required=True)
        parser.add_argument('--schema_response', type=str, required=True)
        args = parser.parse_args()
        
        print("=" * 80)
        print("UPLOAD EVALUATION METRICS TO SCHEMA v5")
        print("=" * 80)
        
        for path in [args.upload_status, args.schema_response]:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
        
        bearer_token = args.bearer_token.strip()
        print(f"Bearer token length: {len(bearer_token)} chars")
        
        try:
            execution_id = int(args.execution_id)
            print(f"Execution ID: {execution_id} (type: number)")
        except ValueError:
            print(f"ERROR: execution_id must be an integer. Got: {args.execution_id}")
            sys.exit(1)
        
        current_timestamp = int(time.time())
        
        print(f"Parameters:")
        print(f"  Schema ID: {args.schema_id}")
        print(f"  Model ID: {args.model_id}")
        print(f"  Model Name: {args.model_name}")
        print(f"  Model Type: {args.model_type}")
        print(f"  Execution ID: {execution_id}")
        print(f"  Tenant ID: {args.tenant_id}")
        print(f"  Project ID: {args.project_id}")
        print(f"  Timestamp: {current_timestamp}")
        
        try:
            with open(args.evaluation_metrics, 'r') as f:
                eval_metrics = json.load(f)
            print(f"Loaded evaluation metrics")
            
        except Exception as e:
            print(f"ERROR loading evaluation data: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        print(f"Extracting FID, SSIM, PSNR values...")
        
        fid_value = 0.0
        ssim_value = 0.0
        psnr_value = 0.0
        mse_value = 0.0
        
        fid_keys = ['fid', 'fid_score', 'FID', 'fid_value']
        for key in fid_keys:
            if key in eval_metrics:
                fid_value = float(eval_metrics[key])
                print(f"Found FID: {key} = {fid_value}")
                break
        
        ssim_keys = ['ssim', 'ssim_mean', 'SSIM', 'ssim_value']
        for key in ssim_keys:
            if key in eval_metrics:
                ssim_value = float(eval_metrics[key])
                print(f"Found SSIM: {key} = {ssim_value}")
                break
        
        psnr_keys = ['psnr', 'psnr_mean', 'PSNR', 'psnr_value']
        for key in psnr_keys:
            if key in eval_metrics:
                psnr_value = float(eval_metrics[key])
                print(f"Found PSNR: {key} = {psnr_value}")
                break
        
        if 'mse' in eval_metrics:
            mse_value = float(eval_metrics['mse'])
            print(f"Found MSE: {mse_value}")
        
        algorithm = eval_metrics.get('algorithm', 'unknown')
        
        print(f"Extracted values:")
        print(f"  FID: {fid_value}")
        print(f"  SSIM: {ssim_value}")
        print(f"  PSNR: {psnr_value}")
        if mse_value > 0:
            print(f"  MSE: {mse_value}")
        
        print(f"Creating schema entry...")
        
        rmse_value = np.sqrt(mse_value) if mse_value > 0 else np.sqrt(10 ** (-psnr_value / 10)) if psnr_value > 0 else 0.0
        
        schema_entry = {
            'tenant_id': str(args.tenant_id),
            'model_id': str(args.model_id),
            'execution_id': int(execution_id),
            'projectId': str(args.project_id),
            'timestamp': int(current_timestamp),
            'model_name': str(args.model_name),
            'model_type': str(args.model_type),
            'fid': float(fid_value),
            'ssim': float(ssim_value),
            'psnr': float(psnr_value),
            'mse': float(mse_value if mse_value > 0 else 10 ** (-psnr_value / 10) if psnr_value > 0 else 0.0),
            'loss': float(fid_value),
            'accuracy': float(ssim_value),
            'precision_score': float(psnr_value),
            'r2_score': float(ssim_value),
            'rmse_score': float(rmse_value),
            'rmse': str(rmse_value),
            'roc_auc': int(0),
            'confusion_matrix': [],
            'recall': float(0.0),
            'f1_score': float(0.0)
        }
        
        print(f"Schema entry prepared ({len(schema_entry)} fields):")
        for key, value in schema_entry.items():
            print(f"  {key}: {value} (type: {type(value).__name__})")
        
        def upload_to_schema(schema_data):
            endpoints = [
                f"https://igs.gov-cloud.ai/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances",
                f"https://igs.gov-cloud.ai/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances",
                f"https://igs.gov-cloud.ai/pi-entity-instances-service/schemas/{args.schema_id}/instances"
            ]
            
            for endpoint_idx, schema_url in enumerate(endpoints):
                clean_url = schema_url.replace('\\n', '').replace('\\r', '')
                print(f"Trying endpoint {endpoint_idx + 1}: {clean_url}")
                
                try:
                    curl_command = [
                        "curl",
                        "--location", clean_url,
                        "--header", f"Authorization: Bearer {bearer_token}",
                        "--header", "Content-Type: application/json",
                        "--data", json.dumps(schema_data),
                        "--fail",
                        "--show-error",
                        "--connect-timeout", "30",
                        "--max-time", "60"
                    ]
                    
                    print(f"Executing curl command...")
                    
                    process = subprocess.run(
                        curl_command,
                        capture_output=True,
                        text=True,
                        check=False
                    )
                    
                    print(f"Curl exit code: {process.returncode}")
                    
                    if process.returncode == 0:
                        print(f"Upload successful")
                        
                        print(f"Full response:")
                        print("-" * 40)
                        print(process.stdout)
                        print("-" * 40)
                        
                        try:
                            response_data = json.loads(process.stdout)
                            return True, response_data, None
                        except json.JSONDecodeError:
                            return True, {"raw_response": process.stdout}, None
                    else:
                        print(f"Upload failed (exit code: {process.returncode})")
                        print(f"Stderr: {process.stderr[:200]}")
                        print(f"Stdout: {process.stdout[:200]}")
                        
                        if "404" in process.stderr or "404" in process.stdout:
                            print(f"Endpoint not found, trying next...")
                            continue
                        
                        return False, {"error": process.stderr[:200]}, process.stderr[:500]
                        
                except Exception as e:
                    print(f"Exception: {str(e)}")
            
            return False, {"error": "All endpoints failed"}, None
        
        print("UPLOADING TO SCHEMA")
        print("=" * 80)
        
        success, response, error = upload_to_schema(schema_entry)
        
        print(f"Saving outputs...")
        
        try:
            upload_status_data = {
                'success': success,
                'timestamp': current_timestamp,
                'model_id': args.model_id,
                'model_name': args.model_name,
                'execution_id': execution_id,
                'schema_id': args.schema_id,
                'metrics_uploaded': {
                    'fid': fid_value,
                    'ssim': ssim_value,
                    'psnr': psnr_value,
                    'mse': mse_value
                },
                'schema_fields_populated': len(schema_entry),
                'upload_response': response if success else {"error": str(response.get('error', 'Unknown error')), "details": error},
                'upload_timestamp': int(time.time()),
                'schema_entry_sample': {k: v for i, (k, v) in enumerate(schema_entry.items()) if i < 10}
            }
            
            with open(args.upload_status, 'w') as f:
                json.dump(upload_status_data, f, indent=2)
            print(f"Upload status saved: {args.upload_status}")
            
            with open(args.schema_response, 'w') as f:
                json.dump(response if success else {"error": str(response.get('error', 'Unknown error')), "details": error}, f, indent=2)
            print(f"Schema response saved: {args.schema_response}")
            
        except Exception as e:
            print(f"ERROR saving outputs: {e}")
            traceback.print_exc()
        
        print("=" * 80)
        if success:
            print("EVALUATION METRICS UPLOADED SUCCESSFULLY!")
        else:
            print("EVALUATION METRICS UPLOAD FAILED")
        print("=" * 80)
        
        print(f"UPLOADED METRICS:")
        print(f"  fid: {fid_value:.2f}")
        print(f"  ssim: {ssim_value:.4f}")
        print(f"  psnr: {psnr_value:.2f} dB")
        print(f"  mse: {schema_entry['mse']:.6f}")
        
        print(f"MODEL INFO:")
        print(f"  Model: {args.model_name} ({args.model_id})")
        print(f"  Type: {args.model_type}")
        print(f"  Algorithm: {algorithm}")
        print(f"  Execution ID: {execution_id}")
        print(f"  Schema ID: {args.schema_id}")
        
        print(f"STATUS: {'SUCCESS' if success else 'FAILED'}")
        print("=" * 80)
        
        if not success:
            sys.exit(1)
    args:
      - --evaluation_metrics
      - {inputPath: evaluation_metrics}
      - --schema_id
      - {inputValue: schema_id}
      - --bearer_token
      - {inputValue: bearer_token}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputValue: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --model_name
      - {inputValue: model_name}
      - --model_type
      - {inputValue: model_type}
      - --upload_status
      - {outputPath: upload_status}
      - --schema_response
      - {outputPath: schema_response}
