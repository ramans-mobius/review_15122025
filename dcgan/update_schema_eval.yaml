name: Upload Evaluation Metrics To Schema v3
description: Uploads FID, SSIM, PSNR scores to performance matrix schema
inputs:
  # Evaluation outputs from Evaluate DCGAN brick
  - name: evaluation_metrics
    type: String
    description: "Evaluation metrics JSON from evaluation brick"
  
  # Schema parameters
  - name: schema_id
    type: String
    description: "Performance matrix schema ID"
  - name: bearer_token
    type: String
    description: "Bearer token for authentication"
  - name: model_id
    type: String
    description: "Model identifier"
  - name: execution_id
    type: String
    description: "Execution ID"
  - name: tenant_id
    type: String
    description: "Tenant ID for schema"
  - name: project_id
    type: String
    description: "Project ID for schema"
  - name: model_name
    type: String
    description: "Model name"
  - name: model_type
    type: String
    default: "DCGAN"
    description: "Model type"

outputs:
  - name: upload_status
    type: String
    description: "Upload status and results"
  - name: schema_response
    type: String
    description: "Response from schema API"

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import sys
        import subprocess
        import time
        import numpy as np
        from datetime import datetime
        
        parser = argparse.ArgumentParser()
        
        # Evaluation outputs
        parser.add_argument('--evaluation_metrics', type=str, required=True)
        
        # Schema parameters
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--bearer_token', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--model_name', type=str, required=True)
        parser.add_argument('--model_type', type=str, default='DCGAN')
        
        # Outputs
        parser.add_argument('--upload_status', type=str, required=True)
        parser.add_argument('--schema_response', type=str, required=True)
        
        args = parser.parse_args()
        
        print("=" * 80)
        print("UPLOAD EVALUATION METRICS TO SCHEMA v1")
        print("=" * 80)
        
        # Create output directories
        print("\\nCreating output directories...")
        
        output_paths = [
            args.upload_status,
            args.schema_response
        ]
        
        for path in output_paths:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    print(f"  Created: {dir_path}")
        
        # Parse inputs
        bearer_token = args.bearer_token.strip()
        print(f"Bearer token length: {len(bearer_token)} chars")
        
        try:
            execution_id = int(args.execution_id)
            print(f"✓ Execution ID: {execution_id} (type: number)")
        except ValueError:
            print(f"ERROR: execution_id must be an integer. Got: {args.execution_id}")
            sys.exit(1)
        
        current_timestamp = int(time.time())
        
        print(f"\\nParameters:")
        print(f"  Schema ID: {args.schema_id}")
        print(f"  Model ID: {args.model_id}")
        print(f"  Model Name: {args.model_name}")
        print(f"  Model Type: {args.model_type}")
        print(f"  Execution ID: {execution_id}")
        print(f"  Tenant ID: {args.tenant_id}")
        print(f"  Project ID: {args.project_id}")
        print(f"  Timestamp: {current_timestamp}")
        
        # Load evaluation data
        print(f"\\nLoading evaluation data...")
        
        try:
            with open(args.evaluation_metrics, 'r') as f:
                eval_metrics = json.load(f)
            print(f"✓ Loaded evaluation metrics")
            
        except Exception as e:
            print(f"ERROR loading evaluation data: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        
        # Extract FID, SSIM, PSNR values
        print(f"\\nExtracting FID, SSIM, PSNR values...")
        
        fid_value = 0.0
        ssim_value = 0.0
        psnr_value = 0.0
        mse_value = 0.0
        
        fid_keys = ['fid', 'fid_score', 'FID', 'fid_value']
        for key in fid_keys:
            if key in eval_metrics:
                fid_value = float(eval_metrics[key])
                print(f"✓ Found FID: {key} = {fid_value}")
                break
        
        ssim_keys = ['ssim', 'ssim_mean', 'SSIM', 'ssim_value']
        for key in ssim_keys:
            if key in eval_metrics:
                ssim_value = float(eval_metrics[key])
                print(f"✓ Found SSIM: {key} = {ssim_value}")
                break
        
        psnr_keys = ['psnr', 'psnr_mean', 'PSNR', 'psnr_value']
        for key in psnr_keys:
            if key in eval_metrics:
                psnr_value = float(eval_metrics[key])
                print(f"✓ Found PSNR: {key} = {psnr_value}")
                break
        
        if 'mse' in eval_metrics:
            mse_value = float(eval_metrics['mse'])
            print(f"✓ Found MSE: {mse_value}")
        
        algorithm = eval_metrics.get('algorithm', 'unknown')
        
        print(f"\\nExtracted values:")
        print(f"  FID: {fid_value}")
        print(f"  SSIM: {ssim_value}")
        print(f"  PSNR: {psnr_value}")
        if mse_value > 0:
            print(f"  MSE: {mse_value}")
        
        # Create schema entry with correct data types
        print(f"\\nCreating schema entry...")
        
        schema_entry = {
            'tenant_id': str(args.tenant_id),  # string
            'model_id': str(args.model_id),  # string
            'execution_id': int(execution_id),  # number
            'projectId': str(args.project_id),  # string (capital I)
            'timestamp': int(current_timestamp),  # number
            
            'model_name': str(args.model_name),  # string
            'model_type': str(args.model_type),  # string
            
            # Direct metric mappings
            'fid': float(fid_value),  # float
            'ssim': float(ssim_value),  # float
            'psnr': float(psnr_value),  # float
            'mse': float(mse_value if mse_value > 0 else 10 ** (-psnr_value / 10) if psnr_value > 0 else 0.0),  # float
            
            # Mapped fields
            'loss': float(fid_value),  # float
            'accuracy': float(ssim_value),  # float
            'precision_score': float(psnr_value),  # float
            'r2_score': float(ssim_value),  # float
            'rmse_score': float(np.sqrt(mse_value) if mse_value > 0 else np.sqrt(10 ** (-psnr_value / 10)) if psnr_value > 0 else 0.0),  # float
            'rmse': str(np.sqrt(mse_value) if mse_value > 0 else np.sqrt(10 ** (-psnr_value / 10)) if psnr_value > 0 else "0.0"),  # string
            
            # Default values for unused fields
            'roc_auc': int(0),  # integer
            'confusion_matrix': [],  # array
            'recall': float(0.0),  # float
            'f1_score': float(0.0)  # float
        }
        
        print(f"\\nSchema entry prepared ({len(schema_entry)} fields):")
        for key, value in schema_entry.items():
            print(f"  {key}: {value} (type: {type(value).__name__})")
        
        # Schema upload function
        def upload_to_schema(schema_data):
            # Try multiple endpoint formats
            endpoints = [
                f"https://igs.gov-cloud.ai/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/create",
                f"https://igs.gov-cloud.ai/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances",
                f"https://igs.gov-cloud.ai/pi-entity-instances-service/schemas/{args.schema_id}/instances/create"
            ]
            
            for endpoint_idx, schema_url in enumerate(endpoints):
                print(f"\\nTrying endpoint {endpoint_idx + 1}: {schema_url}")
                
                try:
                    curl_command = [
                        "curl",
                        "--location", schema_url,
                        "--header", f"Authorization: Bearer {bearer_token}",
                        "--header", "Content-Type: application/json",
                        "--data", json.dumps(schema_data),
                        "--fail",
                        "--show-error",
                        "--connect-timeout", "30",
                        "--max-time", "60"
                    ]
                    
                    print(f"    Executing curl command...")
                    
                    process = subprocess.run(
                        curl_command,
                        capture_output=True,
                        text=True,
                        check=False
                    )
                    
                    print(f"    Curl exit code: {process.returncode}")
                    
                    if process.returncode == 0:
                        print(f"    ✓ Upload successful")
                        
                        # Print full response
                        print(f"    Full response:")
                        print("-" * 40)
                        print(process.stdout)
                        print("-" * 40)
                        
                        try:
                            response_data = json.loads(process.stdout)
                            return True, response_data, None
                        except json.JSONDecodeError:
                            return True, {"raw_response": process.stdout}, None
                    else:
                        print(f"    ✗ Upload failed (exit code: {process.returncode})")
                        print(f"    Stderr: {process.stderr[:200]}")
                        print(f"    Stdout: {process.stdout[:200]}")
                        
                        if "404" in process.stderr or "404" in process.stdout:
                            print(f"    Endpoint not found, trying next...")
                            continue
                        
                        return False, {"error": process.stderr[:200]}, process.stderr[:500]
                        
                except Exception as e:
                    print(f"    ✗ Exception: {str(e)}")
            
            return False, {"error": "All endpoints failed"}, None
        
        # Upload to schema
        print(f"\\n" + "=" * 80)
        print("UPLOADING TO SCHEMA")
        print("=" * 80)
        
        success, response, error = upload_to_schema(schema_entry)
        
        # Save outputs
        print(f"\\nSaving outputs...")
        
        try:
            # Save upload status
            upload_status_data = {
                'success': success,
                'timestamp': current_timestamp,
                'model_id': args.model_id,
                'model_name': args.model_name,
                'execution_id': execution_id,
                'schema_id': args.schema_id,
                'metrics_uploaded': {
                    'fid': fid_value,
                    'ssim': ssim_value,
                    'psnr': psnr_value,
                    'mse': mse_value
                },
                'schema_fields_populated': len(schema_entry),
                'upload_response': response if success else {"error": str(response.get('error', 'Unknown error')), "details": error},
                'upload_timestamp': int(time.time()),
                'schema_entry_sample': {k: v for i, (k, v) in enumerate(schema_entry.items()) if i < 10}
            }
            
            with open(args.upload_status, 'w') as f:
                json.dump(upload_status_data, f, indent=2)
            print(f"✓ Upload status saved: {args.upload_status}")
            
            # Save schema response
            with open(args.schema_response, 'w') as f:
                json.dump(response if success else {"error": str(response.get('error', 'Unknown error')), "details": error}, f, indent=2)
            print(f"✓ Schema response saved: {args.schema_response}")
            
        except Exception as e:
            print(f"ERROR saving outputs: {e}")
            import traceback
            traceback.print_exc()
        
        # Final summary
        print(f"\\n" + "=" * 80)
        if success:
            print(" EVALUATION METRICS UPLOADED SUCCESSFULLY!")
        else:
            print(" EVALUATION METRICS UPLOAD FAILED")
        print("=" * 80)
        
        print(f"\\nUPLOADED METRICS:")
        print(f"  fid: {fid_value:.2f}")
        print(f"  ssim: {ssim_value:.4f}")
        print(f"  psnr: {psnr_value:.2f} dB")
        print(f"  mse: {schema_entry['mse']:.6f}")
        
        print(f"\\nMODEL INFO:")
        print(f"  Model: {args.model_name} ({args.model_id})")
        print(f"  Type: {args.model_type}")
        print(f"  Algorithm: {algorithm}")
        print(f"  Execution ID: {execution_id}")
        print(f"  Schema ID: {args.schema_id}")
        
        print(f"\\nSTATUS: {'SUCCESS' if success else 'FAILED'}")
        print("=" * 80)
        
        if not success:
            sys.exit(1)

    args:
      # Evaluation outputs
      - --evaluation_metrics
      - {inputPath: evaluation_metrics}
      
      # Schema parameters
      - --schema_id
      - {inputValue: schema_id}
      - --bearer_token
      - {inputValue: bearer_token}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputValue: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --model_name
      - {inputValue: model_name}
      - --model_type
      - {inputValue: model_type}
      
      # Outputs
      - --upload_status
      - {outputPath: upload_status}
      - --schema_response
      - {outputPath: schema_response}
