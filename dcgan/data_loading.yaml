name: Load Dataset v10
description: Universal dataset loader supporting CDN URLs, PyTorch datasets, HuggingFace, and local files.
inputs:
  - name: dataset_type
    type: String
    description: "Type: 'cdn_url', 'torchvision', 'huggingface', 'local_dir', 'custom_url'"
  - name: dataset_path
    type: String
    description: "Path/URL to dataset (for CDN: use $$$ for $$). Use 'none' for torchvision datasets."
  - name: dataset_name
    type: String
    description: "Dataset name (e.g., 'mnist', 'cifar10', 'naruto')"
  - name: config_json
    type: String
    description: "JSON configuration for dataset processing"
  - name: train_split
    type: Float
    default: '0.8'
    description: "Train split ratio"
  - name: shuffle_seed
    type: Integer
    default: '42'
    description: "Random seed for shuffling"
outputs:
  - name: train_data
    type: Dataset
    description: "Raw training data (base64 images)"
  - name: test_data
    type: Dataset
    description: "Raw test data (base64 images)"
  - name: dataset_info
    type: DatasetInfo
    description: "Dataset metadata and statistics"
  - name: data_config
    type: String
    description: "Data configuration for next steps"

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v42
    command:
      - sh
      - -c
      - |
        echo "Starting dataset loader..."
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import os
        import json
        import pickle
        import base64
        import io
        import zipfile
        import tarfile
        import tempfile
        import numpy as np
        import torch
        from torch.utils.data import Dataset, DataLoader, random_split
        from PIL import Image, ImageFile
        import requests
        from urllib.parse import unquote, urlparse
        from pathlib import Path
        import shutil
        from collections import Counter
        
        # Enable loading of truncated images
        ImageFile.LOAD_TRUNCATED_IMAGES = True
        
        parser = argparse.ArgumentParser(description='Universal Dataset Loader')
        parser.add_argument('--dataset_type', type=str, required=True)
        parser.add_argument('--dataset_path', type=str, required=True)
        parser.add_argument('--dataset_name', type=str, required=True)
        parser.add_argument('--config_json', type=str, required=True)
        parser.add_argument('--train_split', type=float, required=True)
        parser.add_argument('--shuffle_seed', type=int, required=True)
        parser.add_argument('--train_data', type=str, required=True)
        parser.add_argument('--test_data', type=str, required=True)
        parser.add_argument('--dataset_info', type=str, required=True)
        parser.add_argument('--data_config', type=str, required=True)
        args = parser.parse_args()
        
        print('Universal Dataset Loader Starting...')
        
        print('Parameters:')
        print(f'  Dataset Type: {args.dataset_type}')
        print(f'  Dataset Path: {args.dataset_path}')
        print(f'  Dataset Name: {args.dataset_name}')
        print(f'  Train Split: {args.train_split}')
        print(f'  Shuffle Seed: {args.shuffle_seed}')
        
        # Handle "none" or empty string for dataset_path
        if args.dataset_path.lower() in ['none', 'null', 'nil', '']:
            print('Dataset path is "none" or empty. Using default behavior for dataset type.')
            if args.dataset_type == 'torchvision':
                args.dataset_path = './data'  # Default path for torchvision downloads
                print(f'Setting default download path for torchvision: {args.dataset_path}')
            else:
                print(f'Warning: Dataset type {args.dataset_type} requires a path but got "none"')
        
        # Parse config
        config = json.loads(args.config_json) if args.config_json else {}
        
        # Define base dataset class
        class BaseDataset(Dataset):
            def __init__(self, data, transform=None):
                self.data = data
                self.transform = transform
            
            def __len__(self):
                return len(self.data)
            
            def __getitem__(self, idx):
                item = self.data[idx]
                return item
            
            def get_info(self):
                return {
                    'size': len(self.data),
                    'samples': self.data[:5] if self.data else []
                }
        
        # Download from URL/CDN
        def download_from_url(url, target_dir):
            print(f'Downloading from: {url[:100]}...')
            os.makedirs(target_dir, exist_ok=True)
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            try:
                # Decode URL if needed
                if '%24%24' in url:
                    url = url.replace('%24%24', '$$')
                
                response = requests.get(url, headers=headers, stream=True, timeout=60)
                response.raise_for_status()
                
                # Determine file type
                content_type = response.headers.get('content-type', '')
                filename = os.path.join(target_dir, 'downloaded_file')
                
                if 'zip' in content_type or url.endswith('.zip'):
                    filename += '.zip'
                elif 'tar' in content_type or url.endswith(('.tar', '.tar.gz', '.tgz')):
                    filename += '.tar.gz'
                else:
                    # Try to guess from URL
                    parsed = urlparse(url)
                    filename = os.path.join(target_dir, os.path.basename(parsed.path))
                
                # Download file
                with open(filename, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                
                file_size_mb = os.path.getsize(filename) / 1024 / 1024
                print(f'Downloaded: {filename} ({file_size_mb:.2f} MB)')
                return filename
                
            except Exception as e:
                print(f'Download failed: {e}')
                return None
        
        # Extract archive
        def extract_archive(archive_path, target_dir):
            print(f'Extracting: {archive_path}')
            os.makedirs(target_dir, exist_ok=True)
            
            try:
                if archive_path.endswith('.zip'):
                    with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                        zip_ref.extractall(target_dir)
                        extracted = zip_ref.namelist()
                        print(f'Extracted {len(extracted)} files')
                        return target_dir
                
                elif archive_path.endswith(('.tar', '.tar.gz', '.tgz')):
                    with tarfile.open(archive_path, 'r:*') as tar_ref:
                        tar_ref.extractall(target_dir)
                        extracted = tar_ref.getnames()
                        print(f'Extracted {len(extracted)} files')
                        return target_dir
                
                else:
                    print(f'Unknown archive format: {archive_path}')
                    return None
                    
            except Exception as e:
                print(f'Extraction failed: {e}')
                return None
        
        # Load images from directory
        def load_images_from_dir(directory, max_samples=None):
            print(f'Loading images from: {directory}')
            supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')
            image_files = []
            
            for root, dirs, files in os.walk(directory):
                for file in files:
                    if file.lower().endswith(supported_extensions):
                        full_path = os.path.join(root, file)
                        image_files.append(full_path)
            
            print(f'Found {len(image_files)} image files')
            
            # Limit samples if specified
            if max_samples and max_samples < len(image_files):
                import random
                random.shuffle(image_files)
                image_files = image_files[:max_samples]
                print(f'Limited to {max_samples} samples')
            
            dataset = []
            for img_path in image_files:
                try:
                    # Determine label from directory structure
                    rel_path = os.path.relpath(img_path, directory)
                    label = rel_path.split(os.path.sep)[0] if os.path.sep in rel_path else 'unknown'
                    
                    with open(img_path, 'rb') as f:
                        img_data = f.read()
                        base64_data = base64.b64encode(img_data).decode('utf-8')
                    
                    dataset.append({
                        'image_data': base64_data,
                        'label': label,
                        'filepath': img_path,
                        'filename': os.path.basename(img_path)
                    })
                    
                except Exception as e:
                    print(f'Failed to load image: {img_path} - {e}')
                    continue
            
            return dataset
        
        # Load PyTorch vision dataset with BOTH train and test splits
        def load_torchvision_dataset(dataset_name, config, download_path='./data'):
            print(f'Loading PyTorch dataset: {dataset_name}')
            print(f'Download path: {download_path}')
            
            try:
                import torchvision
                from torchvision import datasets, transforms
                
                dataset_name = dataset_name.lower()
                
                # Get image size and channels from config
                image_size = config.get('image_size', 64)
                channels = config.get('channels', 1)
                
                print(f'Config: image_size={image_size}, channels={channels}')
                
                # Create transform with resizing and normalization
                transform = transforms.Compose([
                    transforms.Resize((image_size, image_size)),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,) * channels, (0.5,) * channels)
                ])
                
                # Common dataset configurations
                dataset_configs = {
                    'mnist': {
                        'class': datasets.MNIST,
                        'root': os.path.join(download_path, 'mnist'),
                        'download': True,
                        'transform': transform
                    },
                    'fashionmnist': {
                        'class': datasets.FashionMNIST,
                        'root': os.path.join(download_path, 'fashion-mnist'),
                        'download': True,
                        'transform': transform
                    },
                    'cifar10': {
                        'class': datasets.CIFAR10,
                        'root': os.path.join(download_path, 'cifar10'),
                        'download': True,
                        'transform': transform
                    },
                    'cifar100': {
                        'class': datasets.CIFAR100,
                        'root': os.path.join(download_path, 'cifar100'),
                        'download': True,
                        'transform': transform
                    },
                    'celeba': {
                        'class': datasets.CelebA,
                        'root': os.path.join(download_path, 'celeba'),
                        'download': True,
                        'transform': transform
                    },
                    'stl10': {
                        'class': datasets.STL10,
                        'root': os.path.join(download_path, 'stl10'),
                        'download': True,
                        'transform': transform
                    }
                }
                
                if dataset_name not in dataset_configs:
                    print(f'Unsupported torchvision dataset: {dataset_name}')
                    print(f'Supported datasets: {list(dataset_configs.keys())}')
                    return [], []
                
                # Load dataset
                ds_config = dataset_configs[dataset_name]
                print(f'Loading from: {ds_config["root"]}')
                
                # LOAD BOTH TRAIN AND TEST SPLITS
                train_dataset = None
                test_dataset = None
                
                try:
                    if dataset_name == 'celeba':
                        # CelebA has splits parameter
                        train_dataset = ds_config['class'](
                            root=ds_config['root'],
                            split='train',
                            download=ds_config['download'],
                            transform=ds_config['transform']
                        )
                        test_dataset = ds_config['class'](
                            root=ds_config['root'],
                            split='test',
                            download=False,
                            transform=ds_config['transform']
                        )
                    elif dataset_name == 'stl10':
                        # STL10 has splits parameter
                        train_dataset = ds_config['class'](
                            root=ds_config['root'],
                            split='train',
                            download=ds_config['download'],
                            transform=ds_config['transform']
                        )
                        test_dataset = ds_config['class'](
                            root=ds_config['root'],
                            split='test',
                            download=False,
                            transform=ds_config['transform']
                        )
                    else:
                        # Standard datasets with train/test splits (MNIST, CIFAR, etc.)
                        train_dataset = ds_config['class'](
                            root=ds_config['root'],
                            train=True,
                            download=ds_config['download'],
                            transform=ds_config['transform']
                        )
                        test_dataset = ds_config['class'](
                            root=ds_config['root'],
                            train=False,
                            download=False,
                            transform=ds_config['transform']
                        )
                    
                    print(f'✓ Loaded {len(train_dataset)} training samples')
                    print(f'✓ Loaded {len(test_dataset)} test samples')
                    
                except Exception as e:
                    print(f'Failed to load dataset: {e}')
                    print('Trying without download...')
                    try:
                        if dataset_name == 'celeba':
                            train_dataset = ds_config['class'](
                                root=ds_config['root'],
                                split='train',
                                download=False,
                                transform=ds_config['transform']
                            )
                            test_dataset = ds_config['class'](
                                root=ds_config['root'],
                                split='test',
                                download=False,
                                transform=ds_config['transform']
                            )
                        elif dataset_name == 'stl10':
                            train_dataset = ds_config['class'](
                                root=ds_config['root'],
                                split='train',
                                download=False,
                                transform=ds_config['transform']
                            )
                            test_dataset = ds_config['class'](
                                root=ds_config['root'],
                                split='test',
                                download=False,
                                transform=ds_config['transform']
                            )
                        else:
                            train_dataset = ds_config['class'](
                                root=ds_config['root'],
                                train=True,
                                download=False,
                                transform=ds_config['transform']
                            )
                            test_dataset = ds_config['class'](
                                root=ds_config['root'],
                                train=False,
                                download=False,
                                transform=ds_config['transform']
                            )
                        
                        print(f'✓ Loaded {len(train_dataset)} training samples (without download)')
                        print(f'✓ Loaded {len(test_dataset)} test samples (without download)')
                        
                    except Exception as e2:
                        print(f'Failed even without download: {e2}')
                        return [], []
                
                # Convert to our format
                def convert_dataset_to_base64(dataset, dataset_name, split_name, sample_limit=None):
                    converted_data = []
                    
                    if sample_limit is None:
                        sample_limit = len(dataset)
                    
                    print(f'Converting {min(sample_limit, len(dataset))} {split_name} samples to base64 format...')
                    
                    for idx in range(min(sample_limit, len(dataset))):
                        try:
                            img, label = dataset[idx]
                            
                            # Convert tensor to PIL Image, then to bytes
                            if isinstance(img, torch.Tensor):
                                # Convert to PIL Image
                                if img.shape[0] == 1:  # Grayscale
                                    img_np = img.squeeze(0).numpy()
                                    # Denormalize: [-1, 1] -> [0, 1] -> [0, 255]
                                    img_np = ((img_np * 0.5 + 0.5) * 255).clip(0, 255).astype(np.uint8)
                                    img_pil = Image.fromarray(img_np, mode='L')
                                else:  # RGB or other channels
                                    # Permute to HWC format
                                    if len(img.shape) == 3:
                                        img_np = img.permute(1, 2, 0).numpy()
                                    else:
                                        img_np = img.numpy()
                                    # Denormalize
                                    img_np = ((img_np * 0.5 + 0.5) * 255).clip(0, 255).astype(np.uint8)
                                    if img_np.shape[2] == 3:
                                        img_pil = Image.fromarray(img_np, mode='RGB')
                                    elif img_np.shape[2] == 1:
                                        img_pil = Image.fromarray(img_np[:,:,0], mode='L')
                                    else:
                                        continue
                            else:
                                # Already PIL Image
                                img_pil = img
                            
                            # Convert to bytes
                            img_bytes = io.BytesIO()
                            img_pil.save(img_bytes, format='PNG')
                            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                            
                            converted_data.append({
                                'image_data': base64_data,
                                'label': str(label),
                                'dataset': dataset_name,
                                'split': split_name,
                                'index': idx,
                                'original_shape': list(img.shape) if isinstance(img, torch.Tensor) else 'pil'
                            })
                            
                            if idx % 1000 == 0 and idx > 0:
                                print(f'  Processed {idx} {split_name} samples...')
                                
                        except Exception as e:
                            print(f'Failed to process sample {idx}: {e}')
                            continue
                    
                    print(f'Successfully converted {len(converted_data)} {split_name} samples')
                    return converted_data
                
                # Convert both splits
                max_samples = config.get('max_samples')
                train_data = convert_dataset_to_base64(
                    train_dataset, dataset_name, 'train', 
                    max_samples if max_samples else None
                )
                
                test_data = convert_dataset_to_base64(
                    test_dataset, dataset_name, 'test',
                    max_samples if max_samples else None
                )
                
                return train_data, test_data
                
            except Exception as e:
                print(f'Failed to load torchvision dataset: {e}')
                import traceback
                traceback.print_exc()
                return [], []
        
        # Load HuggingFace dataset
        def load_huggingface_dataset(dataset_name, config):
            print(f'Loading HuggingFace dataset: {dataset_name}')
            
            try:
                from datasets import load_dataset
                
                # Split dataset name if it's in format 'repo/dataset'
                if '/' in dataset_name:
                    repo_id = dataset_name
                else:
                    repo_id = dataset_name
                
                # Load dataset
                hf_dataset = load_dataset(repo_id)
                
                # Get train and test splits
                train_split = config.get('split', 'train')
                test_split = config.get('test_split', 'test')
                
                if train_split not in hf_dataset:
                    train_split = 'train'
                if test_split not in hf_dataset:
                    test_split = 'test' if 'test' in hf_dataset else 'validation'
                
                train_data = []
                test_data = []
                sample_limit = config.get('max_samples')
                
                # Convert train split
                train_subset = hf_dataset[train_split]
                train_limit = sample_limit if sample_limit else len(train_subset)
                
                for idx, sample in enumerate(train_subset):
                    if idx >= train_limit:
                        break
                        
                    try:
                        if 'image' in sample:
                            img = sample['image']
                            if hasattr(img, 'save'):
                                img_bytes = io.BytesIO()
                                img.save(img_bytes, format='PNG')
                                base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                            else:
                                continue
                        else:
                            continue
                        
                        label = str(sample.get('label', sample.get('labels', idx)))
                        
                        train_data.append({
                            'image_data': base64_data,
                            'label': label,
                            'dataset': dataset_name,
                            'split': train_split,
                            'index': idx
                        })
                        
                    except Exception as e:
                        print(f'Failed to process train sample {idx}: {e}')
                        continue
                
                # Convert test split
                test_subset = hf_dataset[test_split]
                test_limit = sample_limit if sample_limit else len(test_subset)
                
                for idx, sample in enumerate(test_subset):
                    if idx >= test_limit:
                        break
                        
                    try:
                        if 'image' in sample:
                            img = sample['image']
                            if hasattr(img, 'save'):
                                img_bytes = io.BytesIO()
                                img.save(img_bytes, format='PNG')
                                base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                            else:
                                continue
                        else:
                            continue
                        
                        label = str(sample.get('label', sample.get('labels', idx)))
                        
                        test_data.append({
                            'image_data': base64_data,
                            'label': label,
                            'dataset': dataset_name,
                            'split': test_split,
                            'index': idx
                        })
                        
                    except Exception as e:
                        print(f'Failed to process test sample {idx}: {e}')
                        continue
                
                return train_data, test_data
                
            except Exception as e:
                print(f'Failed to load HuggingFace dataset: {e}')
                return [], []
        
        # Main loading logic
        loaded_train_data = []
        loaded_test_data = []
        
        print(f'\\nProcessing dataset type: {args.dataset_type}')
        
        if args.dataset_type == 'cdn_url' or args.dataset_type == 'custom_url':
            print('Processing URL/CDN dataset...')
            with tempfile.TemporaryDirectory() as temp_dir:
                archive_path = download_from_url(args.dataset_path, temp_dir)
                if archive_path:
                    extract_dir = os.path.join(temp_dir, 'extracted')
                    extracted_path = extract_archive(archive_path, extract_dir)
                    if extracted_path:
                        all_data = load_images_from_dir(extracted_path, config.get('max_samples'))
                        if all_data:
                            if len(all_data) > 1:
                                train_size = int(args.train_split * len(all_data))
                                test_size = len(all_data) - train_size
                                
                                if train_size > 0 and test_size > 0:
                                    train_indices, test_indices = random_split(
                                        range(len(all_data)), 
                                        [train_size, test_size],
                                        generator=torch.Generator().manual_seed(args.shuffle_seed)
                                    )
                                    
                                    loaded_train_data = [all_data[i] for i in train_indices]
                                    loaded_test_data = [all_data[i] for i in test_indices]
                                    print(f'Split: {len(loaded_train_data)} train, {len(loaded_test_data)} test samples')
                                else:
                                    print('Warning: Dataset too small for splitting')
                                    loaded_train_data = all_data
                                    loaded_test_data = []
                else:
                    print('Failed to download from URL')
        
        elif args.dataset_type == 'local_dir':
            print('Processing local directory dataset...')
            all_data = load_images_from_dir(args.dataset_path, config.get('max_samples'))
            if all_data:
                if len(all_data) > 1:
                    train_size = int(args.train_split * len(all_data))
                    test_size = len(all_data) - train_size
                    
                    if train_size > 0 and test_size > 0:
                        train_indices, test_indices = random_split(
                            range(len(all_data)), 
                            [train_size, test_size],
                            generator=torch.Generator().manual_seed(args.shuffle_seed)
                        )
                        
                        loaded_train_data = [all_data[i] for i in train_indices]
                        loaded_test_data = [all_data[i] for i in test_indices]
                        print(f'Split: {len(loaded_train_data)} train, {len(loaded_test_data)} test samples')
                    else:
                        print('Warning: Dataset too small for splitting')
                        loaded_train_data = all_data
                        loaded_test_data = []
        
        elif args.dataset_type == 'torchvision':
            print('Processing torchvision dataset...')
            download_path = args.dataset_path if args.dataset_path.lower() not in ['none', 'null', 'nil', ''] else './data'
            loaded_train_data, loaded_test_data = load_torchvision_dataset(
                args.dataset_name, config, download_path
            )
        
        elif args.dataset_type == 'huggingface':
            print('Processing HuggingFace dataset...')
            loaded_train_data, loaded_test_data = load_huggingface_dataset(args.dataset_name, config)
        
        else:
            print(f'Unknown dataset type: {args.dataset_type}')
        
        # Check if we got data
        if not loaded_train_data:
            print('No train data loaded. Creating dummy dataset for testing.')
            dummy_image = np.ones((64, 64, 3), dtype=np.uint8) * 255
            dummy_pil = Image.fromarray(dummy_image, mode='RGB')
            img_bytes = io.BytesIO()
            dummy_pil.save(img_bytes, format='PNG')
            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
            
            loaded_train_data = [{
                'image_data': base64_data,
                'label': 'dummy',
                'dataset': 'dummy',
                'index': 0,
                'warning': 'no_real_data'
            }]
        
        if not loaded_test_data and loaded_train_data:
            print('No test data loaded. Using train data for test.')
            loaded_test_data = loaded_train_data.copy()
        
        print(f'\\nSuccessfully loaded {len(loaded_train_data)} train samples, {len(loaded_test_data)} test samples')
        
        # Create dataset info
        train_labels = [item.get('label', 'unknown') for item in loaded_train_data]
        test_labels = [item.get('label', 'unknown') for item in loaded_test_data]
        all_labels = train_labels + test_labels
        
        unique_labels = sorted(list(set(all_labels)))
        label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}
        train_label_distribution = Counter(train_labels)
        test_label_distribution = Counter(test_labels)
        
        class DatasetInfoWrapper:
            def __init__(self, info_dict):
                self.__dict__.update(info_dict)
        
        dataset_info = DatasetInfoWrapper({
            'total_samples': len(loaded_train_data) + len(loaded_test_data),
            'train_samples': len(loaded_train_data),
            'test_samples': len(loaded_test_data),
            'classes': unique_labels,
            'train_class_distribution': dict(train_label_distribution),
            'test_class_distribution': dict(test_label_distribution),
            'label_to_idx': label_to_idx,
            'output_dim': len(unique_labels),
            'train_split_ratio': args.train_split,
            'shuffle_seed': args.shuffle_seed,
            'dataset_type': args.dataset_type,
            'dataset_name': args.dataset_name,
            'original_path': args.dataset_path,
            'image_size': config.get('image_size', 64),
            'channels': config.get('channels', 1),
            'dataset_format': 'base64_images',
            'requires_preprocessing': True
        })
        
        print(f'\\nDataset Info:')
        print(f'  Train samples: {len(loaded_train_data)}')
        print(f'  Test samples: {len(loaded_test_data)}')
        print(f'  Total samples: {len(loaded_train_data) + len(loaded_test_data)}')
        print(f'  Classes: {len(unique_labels)}')
        print(f'  Image size: {dataset_info.image_size}x{dataset_info.image_size}')
        print(f'  Channels: {dataset_info.channels}')
        
        # Save outputs
        os.makedirs(os.path.dirname(args.train_data) or '.', exist_ok=True)
        with open(args.train_data, 'wb') as f:
            pickle.dump(loaded_train_data, f)
        print(f'Saved train data to: {args.train_data} ({len(loaded_train_data)} samples)')
        
        os.makedirs(os.path.dirname(args.test_data) or '.', exist_ok=True)
        with open(args.test_data, 'wb') as f:
            pickle.dump(loaded_test_data, f)
        print(f'Saved test data to: {args.test_data} ({len(loaded_test_data)} samples)')
        
        os.makedirs(os.path.dirname(args.dataset_info) or '.', exist_ok=True)
        with open(args.dataset_info, 'wb') as f:
            pickle.dump(dataset_info, f)
        print(f'Saved dataset info to: {args.dataset_info}')
        
        # Create data configuration for next steps
        data_config = {
            'dataset_type': args.dataset_type,
            'dataset_name': args.dataset_name,
            'num_classes': len(unique_labels),
            'image_size': config.get('image_size', 64),
            'channels': config.get('channels', 1),
            'requires_preprocessing': True,
            'has_labels': len(unique_labels) > 1,
            'train_samples': len(loaded_train_data),
            'test_samples': len(loaded_test_data),
            'total_samples': len(loaded_train_data) + len(loaded_test_data),
            'dataset_format': 'base64_images',
            'normalized': False,
            'output_dim': len(unique_labels),
            'gan_compatible': True,
            'config_source': 'load_dataset_brick'
        }
        
        os.makedirs(os.path.dirname(args.data_config) or '.', exist_ok=True)
        with open(args.data_config, 'w') as f:
            json.dump(data_config, f, indent=2)
        print(f'Saved data config to: {args.data_config}')
        
        print('\\n' + '='*50)
        print('DATASET LOADING COMPLETE!')
        print('='*50)
        print('SUMMARY:')
        print(f'  Train samples: {len(loaded_train_data)}')
        print(f'  Test samples: {len(loaded_test_data)}')
        print(f'  Total samples: {len(loaded_train_data) + len(loaded_test_data)}')
        print(f'  Image size: {data_config["image_size"]}x{data_config["image_size"]}')
        print(f'  Channels: {data_config["channels"]}')
        
        # Special message for MNIST
        if args.dataset_name.lower() == 'mnist':
            print('\\nNOTE: For MNIST:')
            print('  - Expected: 60,000 training samples')
            print('  - Expected: 10,000 test samples')
            print('  - Expected total: 70,000 samples')
            if len(loaded_train_data) == 60000 and len(loaded_test_data) == 10000:
                print('  ✓ Correctly loaded MNIST dataset splits!')
            else:
                print(f'   Actual: Train={len(loaded_train_data)}, Test={len(loaded_test_data)}')
        
        print('='*50)

    args:
      - --dataset_type
      - {inputValue: dataset_type}
      - --dataset_path
      - {inputValue: dataset_path}
      - --dataset_name
      - {inputValue: dataset_name}
      - --config_json
      - {inputValue: config_json}
      - --train_split
      - {inputValue: train_split}
      - --shuffle_seed
      - {inputValue: shuffle_seed}
      - --train_data
      - {outputPath: train_data}
      - --test_data
      - {outputPath: test_data}
      - --dataset_info
      - {outputPath: dataset_info}
      - --data_config
      - {outputPath: data_config}
