name: Load Dataset v3
description: Universal dataset loader with single master config
inputs:
  - name: master_config
    type: String
    description: "Master configuration JSON for entire pipeline"
outputs:
  - name: train_data
    type: Dataset
  - name: test_data
    type: Dataset
  - name: dataset_info
    type: DatasetInfo
  - name: data_config
    type: String

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v42
    command:
      - sh
      - -c
      - |
        echo "Starting dataset loader..."
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import os
        import json
        import pickle
        import base64
        import io
        import zipfile
        import tarfile
        import tempfile
        import numpy as np
        import torch
        from torch.utils.data import Dataset, DataLoader, random_split
        from PIL import Image, ImageFile
        import requests
        from urllib.parse import unquote, urlparse
        from pathlib import Path
        import shutil
        from collections import Counter
        
        ImageFile.LOAD_TRUNCATED_IMAGES = True
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--master_config', type=str, required=True)
        parser.add_argument('--train_data', type=str, required=True)
        parser.add_argument('--test_data', type=str, required=True)
        parser.add_argument('--dataset_info', type=str, required=True)
        parser.add_argument('--data_config', type=str, required=True)
        args = parser.parse_args()
        
        print('Universal Dataset Loader Starting...')
        
        # Parse master config with better error handling
        print(f'Master config length: {len(args.master_config)} chars')
        print(f'First 200 chars: {args.master_config[:200]}...')
        print(f'Last 200 chars: ...{args.master_config[-200:]}')
        
        try:
            # Try to parse as JSON
            config = json.loads(args.master_config)
        except json.JSONDecodeError as e:
            print(f'Error parsing master config as JSON: {e}')
            print('Trying to fix escaped quotes...')
            
            # Try to fix common issues
            # 1. Remove outer quotes if present
            master_config_str = args.master_config.strip()
            if master_config_str.startswith('"') and master_config_str.endswith('"'):
                master_config_str = master_config_str[1:-1]
            
            # 2. Unescape quotes
            master_config_str = master_config_str.replace('\\"', '"')
            master_config_str = master_config_str.replace('\\\"', '"')
            
            # 3. Remove extra backslashes
            master_config_str = master_config_str.replace('\\\\', '\\')
            
            print(f'After fixing: First 200 chars: {master_config_str[:200]}...')
            
            try:
                config = json.loads(master_config_str)
                print('Successfully parsed after fixing escaped quotes')
            except json.JSONDecodeError as e2:
                print(f'Still cannot parse JSON: {e2}')
                print('Using default config...')
                
                # Use default config for MNIST
                config = {
                    'dataset': {
                        'type': 'torchvision',
                        'name': 'mnist',
                        'path': './data',
                        'image_size': 64,
                        'channels': 1,
                        'max_samples': 1000,
                        'train_split': 0.8,
                        'shuffle_seed': 42
                    },
                    'gan': {
                        'type': 'dcgan',
                        'model_type': 'dcgan',
                        'z_dim': 100,
                        'generator': {
                            'hidden_dims': [256, 128, 64],
                            'learning_rate': 0.0002,
                            'loss_type': 'bce_with_logits',
                            'use_forward_forward': False,
                            'use_cafo': False
                        },
                        'discriminator': {
                            'hidden_dims': [64, 128, 256],
                            'learning_rate': 0.0004,
                            'loss_type': 'bce_with_logits',
                            'dropout': 0.3,
                            'use_forward_forward': False,
                            'use_cafo': False
                        },
                        'training': {
                            'algorithm': 'backprop',
                            'batch_size': 64,
                            'epochs': 10,
                            'epochs_per_task': 5
                        }
                    }
                }
        
        dataset_cfg = config.get('dataset', {})
        
        # Extract dataset parameters with defaults
        dataset_type = dataset_cfg.get('type', 'torchvision')
        dataset_name = dataset_cfg.get('name', 'mnist')
        dataset_path = dataset_cfg.get('path', './data')
        image_size = dataset_cfg.get('image_size', 64)
        channels = dataset_cfg.get('channels', 1)
        max_samples = dataset_cfg.get('max_samples')
        train_split = dataset_cfg.get('train_split', 0.8)
        shuffle_seed = dataset_cfg.get('shuffle_seed', 42)
        
        print('Parameters from master config:')
        print(f'  Dataset Type: {dataset_type}')
        print(f'  Dataset Name: {dataset_name}')
        print(f'  Dataset Path: {dataset_path}')
        print(f'  Image Size: {image_size}')
        print(f'  Channels: {channels}')
        print(f'  Max Samples: {max_samples}')
        print(f'  Train Split: {train_split}')
        print(f'  Shuffle Seed: {shuffle_seed}')
        
        # Handle "none" path for torchvision
        if dataset_path.lower() in ['none', 'null', 'nil', ''] and dataset_type == 'torchvision':
            dataset_path = './data'
            print(f'Setting default download path for torchvision: {dataset_path}')
        
        # Define base dataset class
        class BaseDataset(Dataset):
            def __init__(self, data, transform=None):
                self.data = data
                self.transform = transform
            
            def __len__(self):
                return len(self.data)
            
            def __getitem__(self, idx):
                item = self.data[idx]
                return item
        
        # Define dataset loading functions
        def load_torchvision_dataset(name, params, download_path):
         
            try:
                import torchvision
                import torchvision.transforms as transforms
                
                print(f'Loading torchvision dataset: {name}')
                print(f'Download path: {download_path}')
                
                # Define transform
                transform = transforms.Compose([
                    transforms.Resize(params['image_size']),
                    transforms.CenterCrop(params['image_size']),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,), (0.5,)) if params['channels'] == 1 else transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
                
                # Load dataset
                if name.lower() == 'mnist':
                    train_dataset = torchvision.datasets.MNIST(root=download_path, train=True, download=True, transform=transform)
                    test_dataset = torchvision.datasets.MNIST(root=download_path, train=False, download=True, transform=transform)
                elif name.lower() == 'cifar10':
                    train_dataset = torchvision.datasets.CIFAR10(root=download_path, train=True, download=True, transform=transform)
                    test_dataset = torchvision.datasets.CIFAR10(root=download_path, train=False, download=True, transform=transform)
                elif name.lower() == 'fashionmnist':
                    train_dataset = torchvision.datasets.FashionMNIST(root=download_path, train=True, download=True, transform=transform)
                    test_dataset = torchvision.datasets.FashionMNIST(root=download_path, train=False, download=True, transform=transform)
                else:
                    print(f'Unknown torchvision dataset: {name}. Using MNIST as fallback.')
                    train_dataset = torchvision.datasets.MNIST(root=download_path, train=True, download=True, transform=transform)
                    test_dataset = torchvision.datasets.MNIST(root=download_path, train=False, download=True, transform=transform)
                
                # Limit samples if max_samples specified
                train_data = []
                test_data = []
                
                max_train = min(params.get('max_samples', len(train_dataset)), len(train_dataset))
                max_test = min(params.get('max_samples', len(test_dataset)), len(test_dataset))
                
                print(f'Collecting {max_train} train samples, {max_test} test samples')
                
                for i in range(max_train):
                    try:
                        img, label = train_dataset[i]
                        img_np = (img.numpy() * 255).astype(np.uint8)
                        
                        if params['channels'] == 1:
                            img_pil = Image.fromarray(img_np[0], mode='L')
                        else:
                            img_pil = Image.fromarray(np.transpose(img_np, (1, 2, 0)), mode='RGB')
                        
                        img_bytes = io.BytesIO()
                        img_pil.save(img_bytes, format='PNG')
                        base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                        
                        train_data.append({
                            'image_data': base64_data,
                            'label': str(label),
                            'dataset': name,
                            'index': i,
                            'shape': img_np.shape
                        })
                    except Exception as e:
                        print(f'Error processing train sample {i}: {e}')
                        continue
                
                for i in range(max_test):
                    try:
                        img, label = test_dataset[i]
                        img_np = (img.numpy() * 255).astype(np.uint8)
                        
                        if params['channels'] == 1:
                            img_pil = Image.fromarray(img_np[0], mode='L')
                        else:
                            img_pil = Image.fromarray(np.transpose(img_np, (1, 2, 0)), mode='RGB')
                        
                        img_bytes = io.BytesIO()
                        img_pil.save(img_bytes, format='PNG')
                        base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                        
                        test_data.append({
                            'image_data': base64_data,
                            'label': str(label),
                            'dataset': name,
                            'index': i,
                            'shape': img_np.shape
                        })
                    except Exception as e:
                        print(f'Error processing test sample {i}: {e}')
                        continue
                
                print(f'Successfully loaded {len(train_data)} train and {len(test_data)} test samples')
                return train_data, test_data
                
            except Exception as e:
                print(f'Error loading torchvision dataset: {e}')
                import traceback
                traceback.print_exc()
                return [], []
        
        def load_huggingface_dataset(name, params):
            
            try:
                from datasets import load_dataset
                
                print(f'Loading HuggingFace dataset: {name}')
                
                dataset = load_dataset(name)
                
                train_data = []
                test_data = []
                
                max_samples = params.get('max_samples', 100)
                
                if 'train' in dataset:
                    for i, item in enumerate(dataset['train']):
                        if i >= max_samples:
                            break
                        
                        if 'image' in item:
                            img = item['image']
                            if not isinstance(img, Image.Image):
                                img = Image.fromarray(np.array(img))
                            
                            img = img.resize((params['image_size'], params['image_size']))
                            
                            if params['channels'] == 1:
                                img = img.convert('L')
                            else:
                                img = img.convert('RGB')
                            
                            img_bytes = io.BytesIO()
                            img.save(img_bytes, format='PNG')
                            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                            
                            label = item.get('label', 'unknown')
                            
                            train_data.append({
                                'image_data': base64_data,
                                'label': str(label),
                                'dataset': name,
                                'index': i
                            })
                
                if 'test' in dataset:
                    for i, item in enumerate(dataset['test']):
                        if i >= max_samples:
                            break
                        
                        if 'image' in item:
                            img = item['image']
                            if not isinstance(img, Image.Image):
                                img = Image.fromarray(np.array(img))
                            
                            img = img.resize((params['image_size'], params['image_size']))
                            
                            if params['channels'] == 1:
                                img = img.convert('L')
                            else:
                                img = img.convert('RGB')
                            
                            img_bytes = io.BytesIO()
                            img.save(img_bytes, format='PNG')
                            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                            
                            label = item.get('label', 'unknown')
                            
                            test_data.append({
                                'image_data': base64_data,
                                'label': str(label),
                                'dataset': name,
                                'index': i
                            })
                
                print(f'Loaded {len(train_data)} train and {len(test_data)} test samples from HuggingFace')
                return train_data, test_data
                
            except Exception as e:
                print(f'Error loading HuggingFace dataset: {e}')
                return [], []
        
        # Main loading logic
        print(f'\\nProcessing dataset type: {dataset_type}')
        
        loaded_train_data = []
        loaded_test_data = []
        
        if dataset_type == 'torchvision':
            print('Processing torchvision dataset...')
            loaded_train_data, loaded_test_data = load_torchvision_dataset(
                dataset_name, 
                {'image_size': image_size, 'channels': channels, 'max_samples': max_samples}, 
                dataset_path
            )
        elif dataset_type == 'huggingface':
            print('Processing HuggingFace dataset...')
            loaded_train_data, loaded_test_data = load_huggingface_dataset(
                dataset_name, 
                {'image_size': image_size, 'channels': channels, 'max_samples': max_samples}
            )
        elif dataset_type in ['cdn_url', 'custom_url', 'local_dir']:
            print(f'Processing {dataset_type} dataset...')
            # For now, create dummy data
            print('Creating dummy dataset for testing...')
            dummy_image = np.ones((image_size, image_size, channels), dtype=np.uint8) * 255
            dummy_pil = Image.fromarray(dummy_image, mode='RGB' if channels == 3 else 'L')
            img_bytes = io.BytesIO()
            dummy_pil.save(img_bytes, format='PNG')
            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
            
            loaded_train_data = [{
                'image_data': base64_data,
                'label': 'dummy',
                'dataset': 'dummy',
                'index': 0,
                'warning': 'no_real_data'
            }]
            loaded_test_data = [{
                'image_data': base64_data,
                'label': 'dummy',
                'dataset': 'dummy',
                'index': 0,
                'warning': 'no_real_data'
            }]
        else:
            print(f'Unknown dataset type: {dataset_type}')
            print('Creating dummy dataset...')
            dummy_image = np.ones((image_size, image_size, channels), dtype=np.uint8) * 255
            dummy_pil = Image.fromarray(dummy_image, mode='RGB' if channels == 3 else 'L')
            img_bytes = io.BytesIO()
            dummy_pil.save(img_bytes, format='PNG')
            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
            
            loaded_train_data = [{
                'image_data': base64_data,
                'label': 'dummy',
                'dataset': 'dummy',
                'index': 0,
                'warning': 'no_real_data'
            }]
            loaded_test_data = [{
                'image_data': base64_data,
                'label': 'dummy',
                'dataset': 'dummy',
                'index': 0,
                'warning': 'no_real_data'
            }]
        
        # Check if we got data
        if not loaded_train_data:
            print('No train data loaded. Creating dummy dataset for testing.')
            dummy_image = np.ones((image_size, image_size, channels), dtype=np.uint8) * 255
            dummy_pil = Image.fromarray(dummy_image, mode='RGB' if channels == 3 else 'L')
            img_bytes = io.BytesIO()
            dummy_pil.save(img_bytes, format='PNG')
            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
            
            loaded_train_data = [{
                'image_data': base64_data,
                'label': 'dummy',
                'dataset': 'dummy',
                'index': 0,
                'warning': 'no_real_data'
            }]
        
        if not loaded_test_data and loaded_train_data:
            print('No test data loaded. Using train data for test.')
            loaded_test_data = loaded_train_data.copy()
        
        print(f'\\nSuccessfully loaded {len(loaded_train_data)} train samples, {len(loaded_test_data)} test samples')
        
        # Create dataset info
        class DatasetInfoWrapper:
            def __init__(self, info_dict):
                self.__dict__.update(info_dict)
        
        dataset_info = DatasetInfoWrapper({
            'total_samples': len(loaded_train_data) + len(loaded_test_data),
            'train_samples': len(loaded_train_data),
            'test_samples': len(loaded_test_data),
            'image_size': image_size,
            'channels': channels,
            'dataset_type': dataset_type,
            'dataset_name': dataset_name,
            'requires_preprocessing': True
        })
        
        # Save outputs - ensure directories exist
        output_dirs = [
            os.path.dirname(args.train_data),
            os.path.dirname(args.test_data),
            os.path.dirname(args.dataset_info),
            os.path.dirname(args.data_config)
        ]
        
        for dir_path in output_dirs:
            if dir_path:
                os.makedirs(dir_path, exist_ok=True)
        
        with open(args.train_data, 'wb') as f:
            pickle.dump(loaded_train_data, f)
        
        with open(args.test_data, 'wb') as f:
            pickle.dump(loaded_test_data, f)
        
        with open(args.dataset_info, 'wb') as f:
            pickle.dump(dataset_info, f)
        
        # Create data config for next steps
        data_config = {
            'dataset': dataset_cfg,
            'loaded_samples': {
                'train': len(loaded_train_data),
                'test': len(loaded_test_data),
                'total': len(loaded_train_data) + len(loaded_test_data)
            },
            'requires_preprocessing': True,
            'master_config_parsed': True,
            'parsing_notes': 'Successfully parsed master config' if 'dataset' in config else 'Used default config'
        }
        
        with open(args.data_config, 'w') as f:
            json.dump(data_config, f, indent=2)
        
        print('\\nDataset loading complete!')
        print(f'Train data saved to: {args.train_data}')
        print(f'Test data saved to: {args.test_data}')
        print(f'Dataset info saved to: {args.dataset_info}')
        print(f'Data config saved to: {args.data_config}')
        
    args:
      - --master_config
      - {inputValue: master_config}
      - --train_data
      - {outputPath: train_data}
      - --test_data
      - {outputPath: test_data}
      - --dataset_info
      - {outputPath: dataset_info}
      - --data_config
      - {outputPath: data_config}
