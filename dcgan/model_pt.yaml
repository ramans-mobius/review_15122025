name: Download and Re-upload PT Model v4
description: Downloads .pt file from CDN, fixes $ characters, verifies .pt format, and re-uploads
inputs:
  - name: cdn_url
    type: String
    description: "CDN URL of the model file (ensure $$ are properly escaped)"
  - name: bearer_token
    type: String
    description: "Bearer token for authentication"
  - name: domain
    type: String
    default: "https://ig.gov-cloud.ai"
    description: "API domain for upload"
  - name: get_cdn
    type: String
    default: "https://cdn-new.gov-cloud.ai"
    description: "CDN base URL"
    
outputs:
  - name: final_model_pt
    type: File
    description: "Final .pt file saved locally"
  - name: final_cdn_url
    type: String
    description: "Final CDN URL of the uploaded .pt file"
  - name: verification_status
    type: String
    description: "Verification status JSON"
  - name: upload_status
    type: String
    description: "Upload status JSON"
  
implementation:
  container:
    image: python:3.9-slim
    command:
      - sh
      - -ec
      - |
        apt-get update > /dev/null && apt-get install -y curl file > /dev/null
        pip install requests torch > /dev/null 2>&1 || pip install requests > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import sys
        import time
        import hashlib
        import re
        import subprocess
        import tempfile
        from pathlib import Path
        import requests
        
        parser = argparse.ArgumentParser(description='Download and re-upload .pt model')
        parser.add_argument('--cdn_url', type=str, required=True)
        parser.add_argument('--bearer_token', type=str, required=True)
        parser.add_argument('--domain', type=str, default="https://ig.gov-cloud.ai")
        parser.add_argument('--get_cdn', type=str, default="https://cdn-new.gov-cloud.ai")
        parser.add_argument('--final_model_pt', type=str, required=True)
        parser.add_argument('--final_cdn_url', type=str, required=True)
        parser.add_argument('--verification_status', type=str, required=True)
        parser.add_argument('--upload_status', type=str, required=True)
        
        args = parser.parse_args()
        
        # DEBUG: Print output paths
        print("DEBUG: Output paths:")
        print(f"  final_model_pt: {args.final_model_pt}")
        print(f"  final_cdn_url: {args.final_cdn_url}")
        print(f"  verification_status: {args.verification_status}")
        print(f"  upload_status: {args.upload_status}")
        
        # Create output directories
        for path in [args.final_model_pt, args.final_cdn_url, args.verification_status, args.upload_status]:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    print(f"DEBUG: Created directory: {dir_path}")
        
        print("=" * 80)
        print("DOWNLOAD AND RE-UPLOAD PT MODEL v3")
        print("=" * 80)
        
        # ============================
        # STEP 1: PROCESS CDN URL (FIX $ ISSUES)
        # ============================
        print("\\n" + "=" * 80)
        print("1. PROCESSING AND FIXING CDN URL")
        print("=" * 80)
        
        original_url = args.cdn_url.strip()
        print(f"Original URL received: {original_url}")
        
        # Count actual $ characters in the string
        dollar_count = original_url.count('$')
        print(f"Found {dollar_count} $ character(s) in received URL")
        
        # The actual URL should have _$$_ (two dollar signs)
        # Check if we have the correct pattern
        target_pattern = "_$$_V1_data"
        
        # First, restore proper $$ if they were lost
        if "_$_V1_data" in original_url:
            fixed_url = original_url.replace("_$_V1_data", "_$$_V1_data")
            print(f"Fixed: Changed _$_ to _$$_")
        elif "_V1_data" in original_url and "$$" not in original_url and "$" not in original_url:
            # If no $ at all but we need them
            parts = original_url.split("_V1_data")
            fixed_url = parts[0] + "_$$_V1_data" + parts[1] if len(parts) > 1 else parts[0] + "_$$_V1_data"
            print(f"Added missing $$ before V1_data")
        else:
            # Check for various patterns
            patterns_to_fix = [
                ("_$$$_", "_$$_"),  # Too many $
                ("_$$_$$_", "_$$_"),  # Duplicate $$
                ("_$", "_$$"),  # Missing one $
                ("$$_", "_$$_"),  # Wrong position
            ]
            
            fixed_url = original_url
            for old, new in patterns_to_fix:
                if old in fixed_url:
                    fixed_url = fixed_url.replace(old, new)
                    print(f"Fixed pattern: {old} → {new}")
        
        # Ensure we have exactly _$$_ before V1_data
        if "_$$_V1_data" not in fixed_url:
            # Try to insert it
            if "_V1_data" in fixed_url:
                fixed_url = fixed_url.replace("_V1_data", "_$$_V1_data")
                print(f"Inserted _$$_ before V1_data")
            elif "V1_data" in fixed_url:
                fixed_url = fixed_url.replace("V1_data", "_$$_V1_data")
                print(f"Added _$$_ before V1_data")
        
        # Final validation
        final_dollar_count = fixed_url.count('$')
        print(f"Final URL has {final_dollar_count} $ characters")
        
        if "_$$_V1_data" in fixed_url:
            print(f"✓ URL has correct _$$_V1_data pattern")
        else:
            print(f"⚠ URL doesn't have _$$_V1_data pattern")
            print(f"  Fixed URL: {fixed_url}")
        
        # ============================
        # STEP 2: DOWNLOAD FILE
        # ============================
        print("\\n" + "=" * 80)
        print("2. DOWNLOADING FILE")
        print("=" * 80)
        
        # Create temp file for download
        temp_dir = tempfile.mkdtemp()
        temp_download = os.path.join(temp_dir, "downloaded_model.pt")
        
        headers = {'Authorization': f'Bearer {args.bearer_token.strip()}'}
        
        download_success = False
        download_attempts = []
        
        # Try multiple URL variations
        url_variations = []
        
        # 1. The fixed URL (with _$$_)
        url_variations.append(("Fixed URL (with _$$_)", fixed_url))
        
        # 2. Original URL as-is
        url_variations.append(("Original URL", original_url))
        
        # 3. Try with triple $ (sometimes needed for escaping) - THIS IS THE KEY!
        if "_$$_V1_data" in fixed_url:
            triple_dollar_url = fixed_url.replace("_$$_V1_data", "_$$$_V1_data")
            url_variations.append(("Triple $ URL", triple_dollar_url))
        
        # 4. Try URL encoded $ signs
        encoded_dollar_url = fixed_url.replace("$", "%24")
        url_variations.append(("URL-encoded $", encoded_dollar_url))
        
        for attempt_name, attempt_url in url_variations:
            if download_success:
                break
                
            print(f"\\nAttempt: {attempt_name}")
            print(f"URL: {attempt_url}")
            
            try:
                response = requests.get(attempt_url, headers=headers, stream=True, timeout=300)
                response.raise_for_status()
                
                file_size = int(response.headers.get('content-length', 0))
                print(f"Response status: {response.status_code}")
                print(f"Content length: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
                
                # Download file
                start_time = time.time()
                downloaded = 0
                sha256_hash = hashlib.sha256()
                
                with open(temp_download, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            sha256_hash.update(chunk)
                            downloaded += len(chunk)
                            
                            if downloaded % (5 * 1024 * 1024) < 8192 and file_size > 0:
                                percent = (downloaded / file_size) * 100
                                print(f"  Progress: {downloaded/1024/1024:.1f} MB ({percent:.1f}%)")
                
                elapsed_time = time.time() - start_time
                actual_size = os.path.getsize(temp_download)
                checksum = sha256_hash.hexdigest()
                
                print(f"✓ Download successful: {actual_size:,} bytes in {elapsed_time:.1f}s")
                print(f"✓ Used URL pattern: {attempt_name}")
                download_success = True
                final_download_url = attempt_url
                
                download_attempts.append({
                    'attempt': attempt_name,
                    'url': attempt_url,
                    'success': True,
                    'size': actual_size,
                    'time': elapsed_time
                })
                
                break
                
            except Exception as e:
                print(f"✗ Failed: {str(e)}")
                download_attempts.append({
                    'attempt': attempt_name,
                    'url': attempt_url,
                    'success': False,
                    'error': str(e)
                })
                continue
        
        if not download_success:
            print("\\n✗ All download attempts failed")
            print("Download attempts summary:")
            for attempt in download_attempts:
                status = "✓" if attempt['success'] else "✗"
                print(f"  {status} {attempt['attempt']}: {attempt.get('error', 'Success')}")
            sys.exit(1)
        
        # ============================
        # STEP 3: VERIFY .PT FILE
        # ============================
        print("\\n" + "=" * 80)
        print("3. VERIFYING .PT FILE")
        print("=" * 80)
        
        verification = {
            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
            'original_url': original_url,
            'final_download_url': final_download_url,
            'download_attempts': download_attempts,
            'downloaded_file': temp_download,
            'file_size': actual_size,
            'sha256_checksum': checksum,
            'is_pt_file': False,
            'pt_verification_method': None,
            'file_type': None,
            'verification_details': {}
        }
        
        # Check 1: File extension
        if not temp_download.lower().endswith('.pt'):
            print("✗ File doesn't have .pt extension")
            
            # Rename to .pt extension
            pt_file = temp_download + '.pt'
            os.rename(temp_download, pt_file)
            temp_download = pt_file
            print(f"✓ Renamed to: {pt_file}")
        else:
            print("✓ File has .pt extension")
        
        # Check 2: File command verification
        try:
            file_result = subprocess.run(['file', temp_download], capture_output=True, text=True)
            file_output = file_result.stdout.strip()
            verification['file_type'] = file_output
            
            print(f"✓ File command output: {file_output}")
            
            # Check for PyTorch indicators
            pt_indicators = ['data', 'torch', 'pickle', 'python', 'zip']
            is_likely_pt = any(indicator.lower() in file_output.lower() for indicator in pt_indicators)
            
            if is_likely_pt:
                print("✓ File appears to be a PyTorch model (based on file command)")
                verification['is_pt_file'] = True
                verification['pt_verification_method'] = 'file_command'
                verification['verification_details']['file_command_match'] = True
            else:
                print(f"⚠ File type doesn't look like PyTorch: {file_output}")
        except Exception as e:
            print(f"⚠ Could not run file command: {str(e)}")
        
        # Check 3: Try PyTorch load verification
        if not verification['is_pt_file']:
            try:
                import torch
                model = torch.load(temp_download, map_location='cpu')
                print(f"✓ PyTorch successfully loaded the file")
                print(f"  Model type: {type(model)}")
                
                verification['is_pt_file'] = True
                verification['pt_verification_method'] = 'torch_load'
                verification['verification_details']['torch_load_success'] = True
                verification['verification_details']['model_type'] = str(type(model))
                
                # Check for common model attributes
                if isinstance(model, dict):
                    verification['verification_details']['is_dict'] = True
                    verification['verification_details']['dict_keys'] = list(model.keys())
                    print(f"  Loaded as dict with keys: {list(model.keys())[:5]}...")
                
                if hasattr(model, 'state_dict'):
                    verification['verification_details']['has_state_dict'] = True
                    verification['verification_details']['state_dict_keys'] = len(list(model.state_dict().keys()))
                    print(f"  Has state_dict with {verification['verification_details']['state_dict_keys']} keys")
                
            except Exception as e:
                print(f"✗ PyTorch failed to load file: {str(e)}")
                verification['verification_details']['torch_load_error'] = str(e)
        
        # Check 4: Magic number check
        try:
            with open(temp_download, 'rb') as f:
                first_bytes = f.read(4)
            
            verification['verification_details']['magic_bytes'] = first_bytes.hex()
            print(f"✓ Magic bytes: {first_bytes.hex()}")
            
            # Check for pickle protocol indicators
            if first_bytes.startswith(b'\\x80'):
                print("✓ File starts with pickle protocol marker")
                verification['verification_details']['is_pickle'] = True
                
                if not verification['is_pt_file']:
                    verification['is_pt_file'] = True
                    verification['pt_verification_method'] = 'pickle_magic_bytes'
            
            # Check for ZIP (PyTorch often packages as ZIP)
            elif first_bytes.startswith(b'PK\\x03\\x04'):
                print("✓ File is a ZIP archive (common for PyTorch models)")
                verification['verification_details']['is_zip'] = True
                
                if not verification['is_pt_file']:
                    verification['is_pt_file'] = True
                    verification['pt_verification_method'] = 'zip_magic_bytes'
                    
        except Exception as e:
            print(f"⚠ Could not read magic bytes: {str(e)}")
        
        # Final verification status
        if verification['is_pt_file']:
            print("\\n" + "=" * 40)
            print("✓ VERIFICATION PASSED: File is a valid .pt file")
            print(f"  Method: {verification['pt_verification_method']}")
            print(f"  Type: {verification['verification_details'].get('model_type', 'Unknown')}")
            print("=" * 40)
        else:
            print("\\n" + "=" * 40)
            print("✗ VERIFICATION FAILED: File may not be a valid .pt file")
            print("=" * 40)
        
        # Save verification status
        with open(args.verification_status, 'w') as f:
            json.dump(verification, f, indent=2)
        print(f"✓ Verification status saved: {args.verification_status}")
        
        # ============================
        # STEP 4: RE-UPLOAD TO CDN
        # ============================
        print("\\n" + "=" * 80)
        print("4. RE-UPLOADING .PT FILE TO CDN")
        print("=" * 80)
        
        # Prepare upload
        upload_url = f"{args.domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fdcgan%2Fmodels%2F"
        
        timestamp = int(time.time())
        unique_id = str(hashlib.md5(checksum.encode()).hexdigest())[:8]
        filename = f"verified_model_{timestamp}_{unique_id}.pt"
        
        print(f"Generated filename: {filename}")
        print(f"Source file: {temp_download} ({actual_size:,} bytes)")
        
        # Upload using curl - IMPORTANT: Use triple $ in upload URL
        # Replace $$ with $$$ to ensure they're preserved
        upload_url_encoded = upload_url.replace("$$", "$$$")
        curl_command = [
            "curl",
            "--location", upload_url_encoded,
            "--header", f"Authorization: Bearer {args.bearer_token.strip()}",
            "--form", f"file=@{temp_download}",
            "--form", f"filename={filename}",
            "--fail",
            "--show-error",
            "--connect-timeout", "60",
            "--max-time", "300"
        ]
        
        upload_response = None
        final_cdn_url = None
        
        try:
            print("Executing curl upload...")
            process = subprocess.run(
                curl_command,
                capture_output=True,
                text=True,
                check=False
            )
            
            print(f"Curl exit code: {process.returncode}")
            
            if process.returncode == 0:
                print("✓ Upload successful")
                upload_response = json.loads(process.stdout)
                
                # Extract CDN URL
                cdn_path = None
                if 'cdnUrl' in upload_response:
                    cdn_path = upload_response['cdnUrl']
                elif 'info' in upload_response and 'cdnUrl' in upload_response['info']:
                    cdn_path = upload_response['info']['cdnUrl']
                elif 'url' in upload_response:
                    cdn_path = upload_response['url']
                
                if cdn_path:
                    if cdn_path.startswith("http"):
                        final_cdn_url = cdn_path
                    else:
                        final_cdn_url = f"{args.get_cdn}{cdn_path}"
                    
                    print(f"✓ Final CDN URL: {final_cdn_url}")
                else:
                    print("✗ No CDN URL found in upload response")
                    
            else:
                print(f"✗ Upload failed: {process.stderr[:500]}")
                
        except Exception as e:
            print(f"✗ Upload error: {str(e)}")
        
        # ============================
        # STEP 5: SAVE FINAL OUTPUTS - FIXED SECTION
        # ============================
        print("\\n" + "=" * 80)
        print("5. SAVING FINAL OUTPUTS")
        print("=" * 80)
        
        # DEBUG: Show what we're saving
        print(f"DEBUG: temp_download path: {temp_download}")
        print(f"DEBUG: final_model_pt path: {args.final_model_pt}")
        print(f"DEBUG: File exists at temp_download: {os.path.exists(temp_download)}")
        print(f"DEBUG: File size: {os.path.getsize(temp_download) if os.path.exists(temp_download) else 'N/A'}")
        
        # Save the downloaded .pt file to final location
        final_model_path = args.final_model_pt
        
        # Ensure the directory exists
        os.makedirs(os.path.dirname(final_model_path), exist_ok=True)
        
        # Copy file to final location - Save it exactly where Argo expects it
        import shutil
        try:
            shutil.copy2(temp_download, final_model_path)
            print(f"✓ Model saved as: {final_model_path}")
            print(f"✓ Actual saved file size: {os.path.getsize(final_model_path):,} bytes")
            print(f"✓ File exists at final location: {os.path.exists(final_model_path)}")
        except Exception as e:
            print(f"✗ Error saving model file: {e}")
            # Try alternative approach
            try:
                with open(temp_download, 'rb') as src, open(final_model_path, 'wb') as dst:
                    dst.write(src.read())
                print(f"✓ Model saved using alternative method")
            except Exception as e2:
                print(f"✗ Alternative save also failed: {e2}")
                sys.exit(1)
        
        # Save final CDN URL
        with open(args.final_cdn_url, 'w') as f:
            f.write(final_cdn_url if final_cdn_url else "")
        print(f"✓ Final CDN URL saved: {args.final_cdn_url}")
        
        # Save upload status
        upload_status = {
            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
            'original_cdn_url': original_url,
            'final_cdn_url': final_cdn_url,
            'local_model_path': final_model_path,
            'filename': filename,
            'file_size': actual_size,
            'sha256_checksum': checksum,
            'upload_success': final_cdn_url is not None,
            'verification_passed': verification['is_pt_file'],
            'verification_method': verification['pt_verification_method'],
            'curl_response': upload_response,
            'download_attempts': download_attempts,
            'actual_file_saved': os.path.exists(final_model_path),
            'actual_file_size': os.path.getsize(final_model_path) if os.path.exists(final_model_path) else 0
        }
        
        with open(args.upload_status, 'w') as f:
            json.dump(upload_status, f, indent=2)
        print(f"✓ Upload status saved: {args.upload_status}")
        
        # Clean up temp files
        try:
            shutil.rmtree(temp_dir)
            print(f"✓ Cleaned up temp directory: {temp_dir}")
        except:
            print(f"⚠ Could not clean up temp directory: {temp_dir}")
        
        print("\\n" + "=" * 80)
        if final_cdn_url and verification['is_pt_file']:
            print("✓ SUCCESS: File downloaded, verified as .pt, and re-uploaded")
            print(f"  Final CDN URL: {final_cdn_url}")
        elif final_cdn_url:
            print("⚠ WARNING: File uploaded but .pt verification inconclusive")
            print(f"  Final CDN URL: {final_cdn_url}")
        elif verification['is_pt_file']:
            print("⚠ PARTIAL: File verified as .pt but upload failed")
        else:
            print("✗ FAILED: File not verified as .pt and upload failed")
        
        # Final verification that all outputs exist
        print("\\n" + "=" * 40)
        print("OUTPUT VERIFICATION")
        print("=" * 40)
        for path, name in [
            (args.final_model_pt, "final_model_pt"),
            (args.final_cdn_url, "final_cdn_url"),
            (args.verification_status, "verification_status"),
            (args.upload_status, "upload_status")
        ]:
            exists = os.path.exists(path)
            size = os.path.getsize(path) if exists else 0
            status = "✓" if exists and size > 0 else "✗"
            print(f"{status} {name}: {path} (exists: {exists}, size: {size:,} bytes)")
        
        if not all([
            os.path.exists(args.final_model_pt) and os.path.getsize(args.final_model_pt) > 0,
            os.path.exists(args.final_cdn_url),
            os.path.exists(args.verification_status),
            os.path.exists(args.upload_status)
        ]):
            print("\\n✗ SOME OUTPUTS ARE MISSING OR EMPTY")
            sys.exit(1)
        
        print("=" * 80)
        
    args:
      - --cdn_url
      - {inputValue: cdn_url}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
      - --final_model_pt
      - {outputPath: final_model_pt}
      - --final_cdn_url
      - {outputPath: final_cdn_url}
      - --verification_status
      - {outputPath: verification_status}
      - --upload_status
      - {outputPath: upload_status}
