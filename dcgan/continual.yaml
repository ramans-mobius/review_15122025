name: Continual Tasks Generator 
description: Creates continual learning tasks for DCGAN with consistent format
inputs:
  - name: data_pickle
    type: Dataset
  - name: splitting_strategy
    type: String
    description: "Strategy for splitting data: domain_split, class_split, temporal_split"
  - name: num_tasks
    type: Integer
    description: "Number of continual learning tasks to create"
  - name: config
    type: String
    description: "Configuration parameters"
outputs:
  - name: tasks_pickle
    type: Dataset
    description: "Pickle file containing list of continual learning tasks"
  - name: task_descriptions
    type: String

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v42
    command:
      - sh
      - -c
      - |
        echo "Checking for torchvision..."
        python3 -c "import torchvision; print(f'torchvision version: {torchvision.__version__}')" 2>/dev/null || {
          echo "torchvision not found, installing 0.17.0..."
          pip install torchvision==0.17.0 pillow
        }
        echo "Starting DCGAN Continual Tasks Generator"
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, os, pickle, json, sys
        import numpy as np
        import torch
        from torch.utils.data import Dataset, DataLoader
        from typing import Dict, List, Any
        
        # ============================================================================
        # CONSISTENT CLASSES (Match Preprocess brick)
        # ============================================================================
        
        class GANDataset(Dataset):
           
            def __init__(self, data_list, transform=None, image_size=64, channels=3):
                self.data_list = data_list
                self.transform = transform
                self.image_size = image_size
                self.channels = channels
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                return self.data_list[idx]
        
        class GANDataWrapper:
        
            def __init__(self, dataset, model_type='dcgan', image_size=64, channels=3, 
                        transform_params=None):
                self.dataset = dataset
                self.model_type = model_type
                self.image_size = image_size
                self.channels = channels
                self.transform_params = transform_params or {}
                self.num_samples = len(dataset)
            
            def __len__(self):
                return len(self.dataset)
            
            def __getitem__(self, idx):
                return self.dataset[idx]
        
        class TasksWrapper:
            
            def __init__(self, tasks):
                self.tasks = tasks
                self.num_tasks = len(tasks)
            
            def __len__(self):
                return len(self.tasks)
            
            def __getitem__(self, idx):
                return self.tasks[idx]
        
        # Safe unpickler for loading data
        class SafeUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                try:
                    return super().find_class(module, name)
                except:
                    if name == 'GANDataset':
                        return GANDataset
                    elif name == 'GANDataWrapper':
                        return GANDataWrapper
                    elif name == 'TasksWrapper':
                        return TasksWrapper
                    elif name == 'PreprocessMetadata':
                        # Define this class for compatibility
                        class PreprocessMetadata:
                            def __init__(self, image_size=64, channels=3, model_type='dcgan',
                                        mean=(0.5,), std=(0.5,), transform_params=None):
                                self.image_size = image_size
                                self.channels = channels
                                self.model_type = model_type
                                self.mean = mean
                                self.std = std
                                self.transform_params = transform_params or {}
                        return PreprocessMetadata
                    else:
                        class FallbackClass:
                            def __init__(self, *args, **kwargs):
                                pass
                        return FallbackClass
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--data_pickle', type=str, required=True, help='Input DCGAN data pickle path')
        parser.add_argument('--splitting_strategy', type=str, default='domain_split', help='Split strategy')
        parser.add_argument('--num_tasks', type=int, default=3, help='Number of tasks to create')
        parser.add_argument('--tasks_pickle', type=str, required=True, help='Output pickle for tasks')
        parser.add_argument('--task_descriptions', type=str, required=True, help='Output task descriptions')
        parser.add_argument('--config', type=str, required=True, help='Configuration JSON string')
        args = parser.parse_args()
        
        print("Starting DCGAN Continual Tasks Generator")
        print(f"Strategy: {args.splitting_strategy}, Num tasks: {args.num_tasks}")
        
        # Load data with safe unpickler
        try:
            with open(args.data_pickle, 'rb') as f:
                raw_data = f.read()
            import io
            data = SafeUnpickler(io.BytesIO(raw_data)).load()
            print("Data loaded successfully")
            
            # Extract dataset from wrapper
            if hasattr(data, 'dataset'):
                dataset = data.dataset
                image_size = data.image_size
                channels = data.channels
                print(f"Dataset: {len(dataset)} samples, {image_size}x{image_size}, {channels} channels")
            elif isinstance(data, dict) and 'dataset' in data:
                dataset = data['dataset']
                image_size = data.get('image_size', 64)
                channels = data.get('channels', 3)
                print(f"Dataset: {len(dataset)} samples (dict format)")
            else:
                dataset = data
                image_size = 64
                channels = 3
                print(f"Dataset: {len(dataset)} samples (raw format)")
                
        except Exception as e:
            print(f"Error loading data: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        
        # Parse config
        try:
            config = json.loads(args.config)
            print("Config loaded successfully")
        except Exception as e:
            print(f"Error loading config: {e}")
            sys.exit(1)
        
        # Get GAN config
        gan_config = config.get('gan_config', {})
        image_size = gan_config.get('dataset', {}).get('resize_size', image_size)
        channels = gan_config.get('generator', {}).get('image_channels', channels)
        
        print(f"Image size: {image_size}, Channels: {channels}")
        
        # Create DCGAN task dataset
        class DCGANTaskDataset(Dataset):
            def __init__(self, images, task_id=0, domain_factor=0.0, style='original'):
                self.images = images
                self.task_id = task_id
                self.domain_factor = domain_factor
                self.style = style
                
            def __len__(self):
                return len(self.images)
                
            def __getitem__(self, idx):
                img = self.images[idx]
                
                # Apply domain-specific transformations for GANs
                if self.domain_factor > 0:
                    img = self.apply_gan_domain_shift(img, self.domain_factor, self.style)
                
                return img
            
            def apply_gan_domain_shift(self, img, factor, style):
                img = img.clone()
                
                if style == 'noise':
                    noise_level = 0.1 + factor * 0.3
                    img = img + torch.randn_like(img) * noise_level
                    img = torch.clamp(img, -1, 1)
                
                elif style == 'blur':
                    from torch.nn.functional import avg_pool2d
                    kernel_size = int(3 + factor * 7)
                    if kernel_size % 2 == 0:
                        kernel_size += 1
                    
                    if img.dim() == 3:
                        img = avg_pool2d(img.unsqueeze(0), kernel_size=kernel_size, stride=1, padding=kernel_size//2).squeeze(0)
                
                elif style == 'contrast':
                    mean = img.mean()
                    contrast_factor = 1.0 + factor * 1.0
                    img = (img - mean) * contrast_factor + mean
                    img = torch.clamp(img, -1, 1)
                
                elif style == 'color_shift' and img.shape[0] == 3:
                    shift = torch.tensor([
                        factor * 0.4,   # Red
                        factor * 0.2,   # Green
                        -factor * 0.3   # Blue
                    ]).view(3, 1, 1)
                    img = img + shift
                    img = torch.clamp(img, -1, 1)
                
                return img
        
        # Split into continual tasks
        tasks = []
        task_descriptions_list = []
        
        data_size = len(dataset)
        if data_size == 0:
            print("Error: Empty dataset")
            sys.exit(1)
        
        task_size = max(1, data_size // args.num_tasks)
        
        print(f"\\nSplitting {data_size} samples into {args.num_tasks} tasks (~{task_size} samples each)")
        
        if args.splitting_strategy == 'domain_split':
            print(f"Using domain_split strategy...")
            
            styles = ['original', 'noise', 'blur', 'contrast', 'color_shift']
            
            for task_id in range(args.num_tasks):
                start_idx = task_id * task_size
                end_idx = min((task_id + 1) * task_size, data_size)
                
                # Get subset
                task_indices = list(range(start_idx, end_idx))
                task_data = [dataset[i] for i in task_indices if i < len(dataset)]
                
                if not task_data:
                    print(f"Warning: No data for task {task_id}")
                    continue
                
                # Create domain shift
                domain_factor = task_id * 0.25
                style = styles[task_id % len(styles)]
                
                # Create task dataset
                task_dataset = DCGANTaskDataset(
                    task_data, 
                    task_id=task_id,
                    domain_factor=domain_factor,
                    style=style
                )
                
                # Create data loader
                batch_size = config.get('train', {}).get('batch_size', 32)
                train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)
                
                tasks.append({
                    'task_id': task_id,
                    'dataset': task_dataset,
                    'train_loader': train_loader,
                    'domain_factor': domain_factor,
                    'style': style,
                    'size': len(task_dataset),
                    'description': f'Domain {task_id+1}: {style} (shift: {domain_factor:.2f})'
                })
                
                desc = f"Task {task_id+1}: {len(task_dataset)} samples, Style: {style}, Domain shift: {domain_factor:.2f}"
                task_descriptions_list.append(desc)
                
                print(f"  Task {task_id+1}: {len(task_dataset)} samples, Style: {style}, Domain factor: {domain_factor:.2f}")
        
        elif args.splitting_strategy == 'class_split':
            print(f"Using class_split strategy (simulated for GANs)...")
            
            # For GANs, simulate classes with different image characteristics
            class_types = ['sharp', 'smooth', 'textured', 'simple', 'complex']
            
            for task_id in range(args.num_tasks):
                start_idx = task_id * task_size
                end_idx = min((task_id + 1) * task_size, data_size)
                
                task_indices = list(range(start_idx, end_idx))
                task_data = [dataset[i] for i in task_indices if i < len(dataset)]
                
                if not task_data:
                    continue
                
                class_type = class_types[task_id % len(class_types)]
                class_factor = task_id * 0.2
                
                # Create class-specific dataset
                task_dataset = DCGANTaskDataset(
                    task_data,
                    task_id=task_id,
                    domain_factor=class_factor,
                    style=class_type
                )
                
                batch_size = config.get('train', {}).get('batch_size', 32)
                train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)
                
                tasks.append({
                    'task_id': task_id,
                    'dataset': task_dataset,
                    'train_loader': train_loader,
                    'class_type': class_type,
                    'class_factor': class_factor,
                    'size': len(task_dataset),
                    'description': f'Class {task_id+1}: {class_type} images'
                })
                
                desc = f"Task {task_id+1}: {len(task_dataset)} samples, Class: {class_type}, Factor: {class_factor:.2f}"
                task_descriptions_list.append(desc)
                
                print(f"  Task {task_id+1}: {len(task_dataset)} samples, Class: {class_type}, Factor: {class_factor:.2f}")
        
        elif args.splitting_strategy == 'temporal_split':
            print(f"Using temporal_split strategy...")
            
            for task_id in range(args.num_tasks):
                start_idx = task_id * task_size
                end_idx = min((task_id + 1) * task_size, data_size)
                
                task_indices = list(range(start_idx, end_idx))
                task_data = [dataset[i] for i in task_indices if i < len(dataset)]
                
                if not task_data:
                    continue
                
                # Simulate temporal evolution
                temporal_factor = task_id / (args.num_tasks - 1) if args.num_tasks > 1 else 0
                
                task_dataset = DCGANTaskDataset(
                    task_data,
                    task_id=task_id,
                    domain_factor=temporal_factor,
                    style='temporal'
                )
                
                batch_size = config.get('train', {}).get('batch_size', 32)
                train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)
                
                tasks.append({
                    'task_id': task_id,
                    'dataset': task_dataset,
                    'train_loader': train_loader,
                    'temporal_period': task_id,
                    'temporal_factor': temporal_factor,
                    'size': len(task_dataset),
                    'description': f'Temporal Period {task_id+1}/{args.num_tasks}'
                })
                
                desc = f"Task {task_id+1}: {len(task_dataset)} samples, Temporal period: {task_id+1}, Factor: {temporal_factor:.2f}"
                task_descriptions_list.append(desc)
                
                print(f"  Task {task_id+1}: {len(task_dataset)} samples, Temporal factor: {temporal_factor:.2f}")
        
        else:
            print(f" Unknown splitting strategy: {args.splitting_strategy}")
            sys.exit(1)
        
        tasks_wrapper = TasksWrapper(tasks)
        
        # Save tasks
        os.makedirs(os.path.dirname(args.tasks_pickle) or ".", exist_ok=True)
        with open(args.tasks_pickle, "wb") as f:
            pickle.dump(tasks_wrapper, f)
        
        # Save task descriptions
        os.makedirs(os.path.dirname(args.task_descriptions) or ".", exist_ok=True)
        with open(args.task_descriptions, "w") as f:
            json.dump({
                'num_tasks': len(tasks),
                'strategy': args.splitting_strategy,
                'descriptions': task_descriptions_list,
                'total_samples': sum(t['size'] for t in tasks)
            }, f, indent=2)
        
        print(f"\\n Saved {len(tasks)} continual learning tasks to {args.tasks_pickle}")
        print(f" Task descriptions saved to {args.task_descriptions}")
        for i, task in enumerate(tasks):
            print(f"Task {i}: {task['description']}")
    args:
      - --data_pickle
      - {inputPath: data_pickle}
      - --splitting_strategy
      - {inputValue: splitting_strategy}
      - --num_tasks
      - {inputValue: num_tasks}
      - --config
      - {inputValue: config}
      - --tasks_pickle
      - {outputPath: tasks_pickle}
      - --task_descriptions
      - {outputPath: task_descriptions}
