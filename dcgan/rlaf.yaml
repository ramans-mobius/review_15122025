name: DCGAN RLAF Loop - FIXED
description: Triggers the DCGAN RLAF pipeline in a loop to optimize GAN hyperparameters, controlled by a pierce_or_not flag.
inputs:
  - {name: trained_model, type: Model}
  - {name: init_metrics, type: Metrics}
  - {name: data_path, type: Dataset}
  - {name: config, type: String}
  - {name: domain, type: String}
  - {name: schema_id, type: String}
  - {name: model_id, type: String}
  - {name: dqn_pipeline_id, type: String}
  - {name: pipeline_domain, type: String}
  - {name: dqn_experiment_id, type: String}
  - {name: access_token, type: String}
  - {name: tasks, type: Dataset}
outputs:
  - {name: rlaf_output, type: Dataset}
  - {name: retrained_model, type: Model}
implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        echo "Installing required packages..."
        pip install requests urllib3 > /dev/null 2>&1
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import os
        import json
        import argparse
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        import time
        import pickle
        import numpy as np
        from torch.utils.data import DataLoader
        import traceback
        
        # ============================================================================
        # FIXED GAN RETRAINING FUNCTION
        # ============================================================================
        
        def gan_retraining(action_params, model_path, data_path, tasks_path, output_model_path, previous_metrics, dqn_params, base_config):
            print(f"Starting DCGAN retraining with action parameters: {action_params}")
            
            try:
                # Import DCGAN modules
                from nesy_factory.GANs.dcgan import (
                    DCGANConfig, TrainingAlgorithm, DCGANLayerConfig,
                    ActivationConfig, LossConfig, OptimizerConfig,
                    BlockTrainingConfig, BalancedTrainingConfig,
                    FullyConfigurableDCGANGenerator,
                    FullyConfigurableDCGANDiscriminator,
                    EnhancedDCGANTrainer,
                    validate_config,
                    DCGANDataset
                )
                print("✓ Successfully imported DCGAN modules")
                
            except ImportError as e:
                print(f" Error importing nesy_factory: {e}")
                traceback.print_exc()
                return {"metrics": {}, "model_path": output_model_path}
            
            # Load data
            try:
                with open(data_path, "rb") as f:
                    data = pickle.load(f)
                
                # Handle different data formats
                if hasattr(data, 'images'):
                    # PreprocessedDataset format
                    images = data.images
                    images_list = [images[i] for i in range(len(images))]
                    
                    if len(images.shape) == 4:
                        channels = images.shape[1]
                        image_size = images.shape[2]
                    else:
                        channels = 1
                        image_size = 64
                        
                elif hasattr(data, 'dataset'):
                    # Wrapper format
                    images_list = [data.dataset[i] for i in range(len(data.dataset))]
                    image_size = data.image_size
                    channels = data.channels
                    
                else:
                    # Direct list
                    images_list = [data[i] for i in range(len(data))]
                    image_size = images_list[0].shape[1] if len(images_list[0].shape) == 3 else 64
                    channels = images_list[0].shape[0] if len(images_list[0].shape) == 3 else 1
                
                print(f"✓ Loaded dataset: {len(images_list)} samples, {image_size}x{image_size}, {channels} channels")
                
            except Exception as e:
                print(f" Error loading data: {e}")
                return {"metrics": {}, "model_path": output_model_path}
            
            # Load tasks (if available)
            tasks = []
            if os.path.exists(tasks_path):
                try:
                    with open(tasks_path, "rb") as f:
                        tasks_wrapper = pickle.load(f)
                    
                    if hasattr(tasks_wrapper, 'tasks'):
                        tasks = tasks_wrapper.tasks
                    else:
                        tasks = tasks_wrapper
                    
                    print(f"✓ Loaded {len(tasks)} tasks")
                except Exception as e:
                    print(f" Could not load tasks: {e}")
            
            # Determine algorithm from action name
            action_name = action_params.get('name', '').lower()
            if 'forward' in action_name:
                algorithm = 'forward_forward'
            elif 'cafo' in action_name:
                algorithm = 'cafo'
            else:
                algorithm = 'backprop'
            
            print(f"Training algorithm: {algorithm}")
            
            # Load existing model checkpoint
            try:
                checkpoint = torch.load(model_path, map_location='cpu')
                print("✓ Loaded model checkpoint")
                
            except Exception as e:
                print(f" Error loading model: {e}")
                return {"metrics": {}, "model_path": output_model_path}
            
            # Create DCGAN config from base config and action parameters
            try:
                # Extract base config
                gan_cfg = base_config.get('gan', {})
                dataset_cfg = base_config.get('dataset', {})
                train_cfg = gan_cfg.get('training', {})
                gen_cfg = gan_cfg.get('generator', {})
                disc_cfg = gan_cfg.get('discriminator', {})
                
                # Override with action parameters
                learning_rate_g = action_params.get('learning_rate_g', train_cfg.get('learning_rate', 0.0002))
                learning_rate_d = action_params.get('learning_rate_d', train_cfg.get('learning_rate', 0.0001))
                batch_size = action_params.get('batch_size', train_cfg.get('batch_size', 32))
                dropout = action_params.get('dropout', disc_cfg.get('dropout', 0.3))
                
                # Create generator layers
                generator_layers = []
                for layer in gen_cfg.get('layers', []):
                    generator_layers.append(DCGANLayerConfig(
                        channels=layer['channels'],
                        kernel_size=layer['kernel_size'],
                        stride=layer['stride'],
                        padding=layer['padding']
                    ))
                
                # Create discriminator layers
                discriminator_layers = []
                for layer in disc_cfg.get('layers', []):
                    discriminator_layers.append(DCGANLayerConfig(
                        channels=layer['channels'],
                        kernel_size=layer['kernel_size'],
                        stride=layer['stride'],
                        padding=layer['padding']
                    ))
                
                # Map algorithm
                algorithm_map = {
                    'backprop': TrainingAlgorithm.BACKPROP,
                    'cafo': TrainingAlgorithm.CAFO,
                    'forward_forward': TrainingAlgorithm.FORWARD_FORWARD
                }
                training_algorithm = algorithm_map.get(algorithm, TrainingAlgorithm.BACKPROP)
                
                # Create DCGAN config
                dcgan_config = DCGANConfig(
                    image_size=image_size,
                    channels=channels,
                    latent_dim=gen_cfg.get('latent_dim', 100),
                    generator_layers=generator_layers,
                    discriminator_layers=discriminator_layers,
                    training_algorithm=training_algorithm,
                    use_cafo=(algorithm == 'cafo'),
                    use_forward_forward=(algorithm == 'forward_forward'),
                    use_hybrid=False,
                    block_training=BlockTrainingConfig(
                        enabled=(algorithm in ['cafo', 'forward_forward']),
                        num_blocks=min(3, len(generator_layers) - 1),
                        epochs_per_block=2,  # Reduced for RLAF
                        block_learning_rate=0.001
                    ),
                    balanced_training=BalancedTrainingConfig(
                        enabled=True,
                        discriminator_steps=1,
                        generator_steps=1,
                        label_smoothing=0.1
                    ),
                    generator_activation=ActivationConfig(
                        name=gen_cfg.get('activation', 'leaky_relu'),
                        negative_slope=0.2
                    ),
                    discriminator_activation=ActivationConfig(
                        name=disc_cfg.get('activation', 'leaky_relu'),
                        negative_slope=0.2
                    ),
                    generator_output_activation=ActivationConfig(
                        name=gen_cfg.get('output_activation', 'tanh')
                    ),
                    discriminator_output_activation=ActivationConfig(
                        name=disc_cfg.get('output_activation', 'sigmoid')
                    ),
                    generator_use_batchnorm=gen_cfg.get('use_batchnorm', True),
                    discriminator_use_batchnorm=disc_cfg.get('use_batchnorm', False),
                    generator_dropout=0.0,
                    discriminator_dropout=dropout,
                    generator_optimizer=OptimizerConfig(
                        name='adam',
                        learning_rate=learning_rate_g,
                        beta1=0.5,
                        beta2=0.999
                    ),
                    discriminator_optimizer=OptimizerConfig(
                        name='adam',
                        learning_rate=learning_rate_d,
                        beta1=0.5,
                        beta2=0.999
                    ),
                    batch_size=batch_size,
                    epochs=3,  # Reduced epochs for RLAF loop
                    device='cuda' if torch.cuda.is_available() else 'cpu',
                    seed=42
                )
                
                print(f"✓ Created DCGAN config for {algorithm} training")
                
            except Exception as e:
                print(f" Error creating DCGAN config: {e}")
                traceback.print_exc()
                return {"metrics": {}, "model_path": output_model_path}
            
            # Create trainer and models
            try:
                # Create EnhancedDCGANTrainer
                trainer = EnhancedDCGANTrainer(dcgan_config)
                
                # Load weights from checkpoint
                if 'generator_state_dict' in checkpoint:
                    trainer.generator.load_state_dict(checkpoint['generator_state_dict'])
                    print("✓ Loaded generator weights")
                
                if 'discriminator_state_dict' in checkpoint:
                    trainer.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                    print("✓ Loaded discriminator weights")
                
                print(f"✓ Trainer created for {algorithm} algorithm")
                
            except Exception as e:
                print(f" Error creating trainer: {e}")
                traceback.print_exc()
                return {"metrics": {}, "model_path": output_model_path}
            
            # Create data loader
            try:
                train_dataset = DCGANDataset(images_list, normalize=False)  # Already normalized
                actual_batch_size = min(batch_size, max(1, len(train_dataset)))
                dataloader = DataLoader(
                    train_dataset,
                    batch_size=actual_batch_size,
                    shuffle=True,
                    drop_last=True
                )
                
                print(f"✓ Data loader created: batch_size={actual_batch_size}, batches={len(dataloader)}")
                
            except Exception as e:
                print(f" Error creating data loader: {e}")
                return {"metrics": {}, "model_path": output_model_path}
            
            # Training loop
            print(f"\\nStarting training ({dcgan_config.epochs} epochs)...")
            
            try:
                # Phase 1: Block training if enabled
                if dcgan_config.block_training.enabled:
                    print(f" Phase 1: Block-wise training")
                    trainer.train_blocks_with_logging(dataloader)
                
                # Phase 2: Adversarial training
                print(f" Phase 2: Adversarial training")
                
                training_result = trainer.train_adversarial_with_logging(dataloader)
                
                print(f"✓ Training completed")
                
            except Exception as e:
                print(f" Error during training: {e}")
                traceback.print_exc()
                # Continue to evaluation even if training had issues
            
            # Evaluate on tasks (if available)
            evaluation_metrics = {}
            
            if tasks:
                print(f"\\nEvaluating on {len(tasks)} tasks...")
                
                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                trainer.generator.eval()
                trainer.discriminator.eval()
                
                for task_idx, task in enumerate(tasks[:3]):  # Limit to 3 tasks for speed
                    try:
                        # Get task data loader
                        if hasattr(task, 'train_loader'):
                            task_loader = task.train_loader
                        elif hasattr(task, 'dataset'):
                            task_dataset = task.dataset
                            task_loader = DataLoader(task_dataset, batch_size=32, shuffle=False)
                        else:
                            continue
                        
                        total_g_loss = 0.0
                        total_d_loss = 0.0
                        real_scores = []
                        fake_scores = []
                        batch_count = 0
                        
                        with torch.no_grad():
                            for batch in task_loader:
                                if isinstance(batch, (list, tuple)):
                                    real_images = batch[0]
                                else:
                                    real_images = batch
                                
                                real_images = real_images.to(device)
                                batch_size = real_images.size(0)
                                
                                # Generate fake images
                                z = torch.randn(batch_size, trainer.generator.latent_dim, device=device)
                                fake_images = trainer.generator(z)
                                
                                # Discriminator outputs
                                real_output = trainer.discriminator(real_images).view(-1)
                                fake_output = trainer.discriminator(fake_images).view(-1)
                                
                                # Calculate losses
                                g_loss = torch.nn.functional.binary_cross_entropy_with_logits(
                                    fake_output, torch.ones_like(fake_output)
                                )
                                
                                real_loss = torch.nn.functional.binary_cross_entropy_with_logits(
                                    real_output, torch.ones_like(real_output)
                                )
                                fake_loss = torch.nn.functional.binary_cross_entropy_with_logits(
                                    fake_output, torch.zeros_like(fake_output)
                                )
                                d_loss = (real_loss + fake_loss) / 2
                                
                                total_g_loss += g_loss.item()
                                total_d_loss += d_loss.item()
                                real_scores.append(real_output.mean().item())
                                fake_scores.append(fake_output.mean().item())
                                batch_count += 1
                        
                        if batch_count > 0:
                            task_metrics = {
                                f'task_{task_idx}_generator_loss': total_g_loss / batch_count,
                                f'task_{task_idx}_discriminator_loss': total_d_loss / batch_count,
                                f'task_{task_idx}_real_score': np.mean(real_scores) if real_scores else 0.0,
                                f'task_{task_idx}_fake_score': np.mean(fake_scores) if fake_scores else 0.0
                            }
                            evaluation_metrics.update(task_metrics)
                            
                            print(f"  Task {task_idx}: G={task_metrics[f'task_{task_idx}_generator_loss']:.4f}, "
                                  f"D={task_metrics[f'task_{task_idx}_discriminator_loss']:.4f}")
                            
                    except Exception as e:
                        print(f"   Error evaluating task {task_idx}: {e}")
            
            # Calculate average metrics
            avg_metrics = {}
            if evaluation_metrics:
                # Calculate averages
                generator_losses = [v for k, v in evaluation_metrics.items() if 'generator_loss' in k]
                discriminator_losses = [v for k, v in evaluation_metrics.items() if 'discriminator_loss' in k]
                real_scores = [v for k, v in evaluation_metrics.items() if 'real_score' in k]
                fake_scores = [v for k, v in evaluation_metrics.items() if 'fake_score' in k]
                
                avg_metrics = {
                    'generator_loss': np.mean(generator_losses) if generator_losses else 0.0,
                    'discriminator_loss': np.mean(discriminator_losses) if discriminator_losses else 0.0,
                    'real_score': np.mean(real_scores) if real_scores else 0.5,
                    'fake_score': np.mean(fake_scores) if fake_scores else 0.5,
                    'score_difference': abs(np.mean(real_scores) - np.mean(fake_scores)) if real_scores and fake_scores else 0.0
                }
                
                # Add individual task metrics
                avg_metrics.update(evaluation_metrics)
                
            else:
                # Use training history metrics if no task evaluation
                training_history = trainer.training_history
                if training_history and 'generator_losses' in training_history:
                    avg_metrics = {
                        'generator_loss': training_history['generator_losses'][-1] if training_history['generator_losses'] else 0.0,
                        'discriminator_loss': training_history['discriminator_losses'][-1] if training_history['discriminator_losses'] else 0.0,
                        'real_score': training_history['real_scores'][-1] if training_history['real_scores'] else 0.5,
                        'fake_score': training_history['fake_scores'][-1] if training_history['fake_scores'] else 0.5
                    }
            
            print(f"\\nEvaluation results:")
            for key, value in avg_metrics.items():
                if isinstance(value, (int, float)):
                    print(f"  {key}: {value:.4f}")
            
            # Calculate improvement score
            improvement_score = 0
            improvements = []
            
            if previous_metrics:
                for param in dqn_params:
                    key = param['key']
                    sign = 1 if param['sign'] == '+' else -1
                    
                    if key in avg_metrics and key in previous_metrics:
                        current_val = avg_metrics[key]
                        previous_val = previous_metrics[key]
                        
                        # Handle NaN values
                        if np.isnan(current_val) or np.isnan(previous_val):
                            continue
                        
                        improvement = (current_val - previous_val) * sign
                        improvement_score += improvement
                        improvements.append((key, previous_val, current_val, improvement))
            
            print(f"\\nImprovement analysis:")
            if improvements:
                for key, prev, curr, imp in improvements:
                    print(f"  {key}: {prev:.4f} → {curr:.4f} (Δ={imp:.4f})")
                
                print(f"  Total improvement score: {improvement_score:.4f}")
                
                if improvement_score > 0:
                    print(f"✓ Metrics improved. Saving retrained model.")
                    
                    # Save checkpoint
                    trained_checkpoint = {
                        'config': dcgan_config.to_dict(),
                        'generator_state_dict': trainer.generator.state_dict(),
                        'discriminator_state_dict': trainer.discriminator.state_dict(),
                        'trainer_state': {
                            'current_epoch': dcgan_config.epochs,
                            'current_step': trainer.current_step,
                            'training_history': trainer.training_history
                        },
                        'algorithm': algorithm,
                        'epochs_trained': dcgan_config.epochs,
                        'improvement_score': improvement_score,
                        'action_params': action_params
                    }
                    
                    os.makedirs(os.path.dirname(output_model_path), exist_ok=True)
                    torch.save(trained_checkpoint, output_model_path)
                    print(f"✓ Saved retrained model to {output_model_path}")
                    
                else:
                    print(f" No improvement in metrics. Keeping original model.")
                    # Copy original model
                    if os.path.exists(model_path):
                        os.makedirs(os.path.dirname(output_model_path), exist_ok=True)
                        torch.save(torch.load(model_path, map_location='cpu'), output_model_path)
                        print(f"✓ Copied original model to {output_model_path}")
            else:
                print(f" No previous metrics for comparison. Saving retrained model anyway.")
                
                # Save checkpoint
                trained_checkpoint = {
                    'config': dcgan_config.to_dict(),
                    'generator_state_dict': trainer.generator.state_dict(),
                    'discriminator_state_dict': trainer.discriminator.state_dict(),
                    'trainer_state': {
                        'current_epoch': dcgan_config.epochs,
                        'current_step': trainer.current_step,
                        'training_history': trainer.training_history
                    },
                    'algorithm': algorithm,
                    'epochs_trained': dcgan_config.epochs,
                    'action_params': action_params
                }
                
                os.makedirs(os.path.dirname(output_model_path), exist_ok=True)
                torch.save(trained_checkpoint, output_model_path)
                print(f"✓ Saved retrained model to {output_model_path}")
            
            return {"metrics": avg_metrics, "model_path": output_model_path}
        
        # ============================================================================
        # API FUNCTIONS (unchanged)
        # ============================================================================
        
        def get_retry_session():
            retry_strategy = Retry(
                total=5,
                status_forcelist=[500, 502, 503, 504],
                backoff_factor=1
            )
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session = requests.Session()
            session.mount("https://", adapter)
            session.mount("http://", adapter)
            return session
        
        def trigger_pipeline(config, pipeline_domain, model_id, dqn_params=None):
            http = get_retry_session()
            url = f"{pipeline_domain}/bob-service-test/v1.0/pipeline/trigger/ml?pipelineId={config['pipeline_id']}"
            pipeline_params = {"param_json": json.dumps(dqn_params), "model_id": model_id} if dqn_params else {"model_id": model_id}
            payload = json.dumps({
                "pipelineType": "ML", "containerResources": {}, "experimentId": config['experiment_id'],
                "enableCaching": True, "parameters": pipeline_params, "version": 1
            })
            headers = {
                'accept': 'application/json', 'Authorization': f"Bearer {config['access_token']}",
                'Content-Type': 'application/json'
            }
            response = http.post(url, headers=headers, data=payload, timeout=30)
            response.raise_for_status()
            return response.json()['runId']
        
        def get_pipeline_status(config, pipeline_domain):
            http = get_retry_session()
            url = f"{pipeline_domain}/bob-service-test/v1.0/pipeline/{config['pipeline_id']}/status/ml/{config['run_id']}"
            headers = {'accept': 'application/json', 'Authorization': f"Bearer {config['access_token']}"}
            response = http.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            pipeline_status = response.json()
            latest_state = pipeline_status['run_details']['state_history'][-1]
            return latest_state['state']
        
        def get_instance(access_token, domain, schema_id, model_id):
            http = get_retry_session()
            url = f"{domain}/pi-entity-instances-service/v3.0/schemas/{schema_id}/instances/list"
            headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
            payload = {"dbType": "TIDB", "ownedOnly": True, "filter": {"model_id": model_id}}
            response = http.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            return response.json()['content'][0]
        
        def update_instance_field(access_token, domain, schema_id, model_id, field, value):
            http = get_retry_session()
            url = f"{domain}/pi-entity-instances-service/v2.0/schemas/{schema_id}/instances"
            headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
            payload = {
                "dbType": "TIDB",
                "conditionalFilter": {"conditions": [{"field": "model_id", "operator": "EQUAL", "value": model_id}]},
                "partialUpdateRequests": [{"patch": [{"operation": "REPLACE", "path": f"{field}", "value": value}]}]
            }
            response = http.patch(url, headers=headers, data=json.dumps(payload), timeout=30)
            response.raise_for_status()
        
        def trigger_and_wait_for_dqn_pipeline(config, pipeline_domain, model_id, dqn_params):
            run_id = trigger_pipeline(config, pipeline_domain, model_id, dqn_params)
            config["run_id"] = run_id
            while True:
                status = get_pipeline_status(config, pipeline_domain)
                print(f"Current DQN pipeline status: {status}")
                if status == 'SUCCEEDED':
                    print("DQN Pipeline execution completed.")
                    break
                elif status in ['FAILED', 'ERROR']:
                    raise RuntimeError(f"DQN Pipeline failed with status {status}")
                time.sleep(60)
        
        # ============================================================================
        # MAIN FUNCTION
        # ============================================================================
        
        def main():
            parser = argparse.ArgumentParser()
            parser.add_argument('--trained_model', type=str, required=True)
            parser.add_argument('--init_metrics', type=str, required=True)
            parser.add_argument('--rlaf_output', type=str, required=True)
            parser.add_argument('--data_path', type=str, required=True)
            parser.add_argument('--config', type=str, required=True)
            parser.add_argument('--domain', type=str, required=True)
            parser.add_argument('--schema_id', type=str, required=True)
            parser.add_argument('--model_id', type=str, required=True)
            parser.add_argument('--dqn_pipeline_id', type=str, required=True)
            parser.add_argument('--dqn_experiment_id', type=str, required=True)
            parser.add_argument('--access_token', type=str, required=True)
            parser.add_argument('--tasks', type=str, required=True)
            parser.add_argument('--pipeline_domain', type=str, required=True)
            parser.add_argument('--retrained_model', type=str, required=True)
            args = parser.parse_args()
            
            print("\\n" + "="*60)
            print("DCGAN RLAF LOOP STARTING - FIXED")
            print("="*60)
            
            # Load access token
            with open(args.access_token, 'r') as f:
                access_token = f.read().strip()
            
            # Load initial metrics
            with open(args.init_metrics, 'r') as f:
                current_metrics = json.load(f)
            
            # Load base config
            base_config = json.loads(args.config)
            
            action_id_for_next_pierce = -1
            
            # Run RLAF loop (max 2 iterations)
            for i in range(2):
                print(f"\\n{'='*60}")
                print(f"RLAF Loop Iteration {i+1}")
                print(f"{'='*60}")
                
                # Prepare metrics for DQN
                cleaned_metrics = {}
                dqn_params = []
                
                # Extract numeric metrics
                for key, value in current_metrics.items():
                    if isinstance(value, (int, float)):
                        cleaned_metrics[key] = float(value)
                        
                        # GAN-specific metrics mapping
                        if any(term in key.lower() for term in ['loss', 'mse', 'mae', 'fid']):
                            sign = "-"  # Lower is better
                        elif any(term in key.lower() for term in ['accuracy', 'score', 'psnr', 'ssim', 'diversity']):
                            sign = "+"  # Higher is better
                        else:
                            sign = "+"  # Default: higher is better
                        
                        dqn_params.append({"key": key, "sign": sign, "mul": 1.0})
                    elif isinstance(value, dict):
                        # Handle nested metrics
                        for sub_key, sub_value in value.items():
                            if isinstance(sub_value, (int, float)):
                                full_key = f"{key}_{sub_key}"
                                cleaned_metrics[full_key] = float(sub_value)
                                
                                # Determine sign
                                if 'loss' in sub_key.lower():
                                    sign = "-"
                                elif 'score' in sub_key.lower():
                                    sign = "+"
                                else:
                                    sign = "+"
                                
                                dqn_params.append({"key": full_key, "sign": sign, "mul": 1.0})
                
                print(f"Prepared {len(cleaned_metrics)} metrics for DQN")
                
                # Get current instance
                try:
                    instance = get_instance(access_token, args.domain, args.schema_id, args.model_id)
                    
                    # Update pierce2rlaf history
                    if instance.get('pierce2rlaf'):
                        latest_pierce2rlaf = instance['pierce2rlaf'][-1]
                        previous_state = latest_pierce2rlaf['current_state']
                        episode = latest_pierce2rlaf['episode']
                    else:
                        previous_state = {key: 0.0 for key in cleaned_metrics.keys()}
                        episode = 0
                    
                    new_pierce2rlaf_entry = {
                        "action_id": action_id_for_next_pierce,
                        "previous_state": previous_state,
                        "current_state": cleaned_metrics,
                        "episode": episode,
                        "timestamp": int(time.time())
                    }
                    
                    pierce2rlaf_history = instance.get("pierce2rlaf", [])
                    pierce2rlaf_history.append(new_pierce2rlaf_entry)
                    update_instance_field(access_token, args.domain, args.schema_id, args.model_id, "pierce2rlaf", pierce2rlaf_history)
                    
                except Exception as e:
                    print(f" Error updating instance: {e}")
                    previous_state = {}
                
                # Trigger DQN pipeline
                dqn_config = {
                    "pipeline_id": args.dqn_pipeline_id,
                    "experiment_id": args.dqn_experiment_id,
                    "access_token": access_token
                }
                
                try:
                    print(f"Triggering DQN pipeline with {len(dqn_params)} parameters...")
                    trigger_and_wait_for_dqn_pipeline(dqn_config, args.pipeline_domain, args.model_id, dqn_params)
                    
                except Exception as e:
                    print(f" Error triggering DQN pipeline: {e}")
                    break
                
                # Get updated instance with RLAF action
                try:
                    updated_instance = get_instance(access_token, args.domain, args.schema_id, args.model_id)
                    
                    # Check if there are any rlaf2pierce entries
                    if not updated_instance.get('rlaf2pierce'):
                        print("No rlaf2pierce entries found. Exiting loop.")
                        break
                    
                    latest_rlaf2pierce = updated_instance['rlaf2pierce'][-1]
                    
                    # Check pierce_or_not flag
                    if not latest_rlaf2pierce.get("pierce_or_not", True):
                        print("pierce_or_not is false. Exiting loop.")
                        break
                    
                    # Get action details
                    rlaf_actions = updated_instance.get('rlaf_actions', {}).get('actions', [])
                    action_id_for_next_pierce = latest_rlaf2pierce['action_id']
                    action_details = next((a for a in rlaf_actions if a["id"] == action_id_for_next_pierce), None)
                    
                    if not action_details:
                        print(f"Action with ID {action_id_for_next_pierce} not found in rlaf_actions")
                        break
                    
                    print(f"\\nDQN pipeline recommended action: {action_details['name']}")
                    print(f"Action parameters: {action_details['params']}")
                    print(f"Retraining DCGAN model with new hyperparameters...")
                    
                    # Retrain with action parameters
                    retraining_results = gan_retraining(
                        action_details['params'], 
                        args.trained_model, 
                        args.data_path, 
                        args.tasks,
                        args.retrained_model, 
                        previous_state, 
                        dqn_params,
                        base_config
                    )
                    
                    # Update metrics for next iteration
                    current_metrics = retraining_results["metrics"]
                    
                    # Update the trained_model path for next iteration
                    args.trained_model = retraining_results["model_path"]
                    
                except Exception as e:
                    print(f" Error in RLAF iteration: {e}")
                    traceback.print_exc()
                    break
            
            # Save final results
            os.makedirs(os.path.dirname(args.rlaf_output), exist_ok=True)
            with open(args.rlaf_output, 'w') as f:
                json.dump({
                    "final_metrics": current_metrics,
                    "iterations_completed": min(i + 1, 2),
                    "timestamp": time.strftime('%Y-%m-%d %H:%M:%S')
                }, f, indent=4)
            
            print(f"\\n{'='*60}")
            print("RLAF LOOP COMPLETED")
            print(f"Final metrics saved to: {args.rlaf_output}")
            print(f"Retrained model saved to: {args.retrained_model}")
            print(f"{'='*60}")
        
        if __name__ == '__main__':
            main()
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --init_metrics
      - {inputPath: init_metrics}
      - --rlaf_output
      - {outputPath: rlaf_output}
      - --data_path
      - {inputPath: data_path}
      - --config
      - {inputValue: config}
      - --domain
      - {inputValue: domain}
      - --schema_id
      - {inputValue: schema_id}
      - --model_id
      - {inputValue: model_id}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --dqn_experiment_id
      - {inputValue: dqn_experiment_id}
      - --access_token
      - {inputPath: access_token}
      - --tasks
      - {inputPath: tasks}
      - --pipeline_domain
      - {inputValue: pipeline_domain}
      - --retrained_model
      - {outputPath: retrained_model}
