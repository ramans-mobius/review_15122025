name: DCGAN RLAF Loop v23
description: DCGAN RLAF with PreprocessedDataset, CAFO, and Forward-Forward support
inputs:
  - name: trained_model
    type: Model
  - name: init_metrics
    type: Metrics
  - name: data_path
    type: Dataset
  - name: config
    type: String
  - name: domain
    type: String
  - name: schema_id
    type: String
  - name: model_id
    type: String
  - name: dqn_pipeline_id
    type: String
  name: pipeline_domain
    type: String
  - name: dqn_experiment_id
    type: String
  - name: access_token
    type: String
  - name: tasks
    type: Dataset
outputs:
  - name: rlaf_output
    type: Dataset
  - name: retrained_model
    type: Model

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        echo "Installing packages..."
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        pip install requests pillow scikit-image scipy > /dev/null 2>&1
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import os
        import json
        import argparse
        import requests
        import pickle
        import time
        import numpy as np
        import sys
        import traceback
        import warnings
        from typing import Dict, List, Any
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        from torch.utils.data import DataLoader, Dataset, TensorDataset
        import torch.nn as nn
        import torch.optim as optim
        import torch.nn.functional as F
        warnings.filterwarnings('ignore')
        
        print("=" * 80)
        print("DCGAN RLAF LOOP - WITH CAFO/FF SUPPORT")
        print("=" * 80)
        
        try:
            import nesy_factory.GANs.dcgan as dcgan_module
            print("SUCCESS: Imported nesy_factory.GANs.dcgan")
            
            from nesy_factory.GANs.dcgan import (
                DCGANConfig, TrainingAlgorithm,
                FullyConfigurableDCGANGenerator,
                FullyConfigurableDCGANDiscriminator,
                EnhancedDCGANTrainer,
                ActivationConfig, OptimizerConfig,
                BalancedTrainingConfig,
                BlockTrainingConfig,
                CAFODCGANBlock,
                ForwardForwardDCGANBlock,
                StandardDCGANBlock
            )
            print("SUCCESS: All DCGAN classes imported")
            
        except ImportError as e:
            print(f"FATAL ERROR: Failed to import nesy_factory.GANs.dcgan: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        class PreprocessedDataset:
            def __init__(self, images, labels, dataset_name, preprocessor_params):
                self.images = images
                self.labels = labels
                self.dataset_name = dataset_name
                self.preprocessed = True
                self.preprocessor_params = preprocessor_params
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx],
                    'index': idx,
                    'dataset': self.dataset_name,
                    'preprocessed': True,
                    'preprocessor_params': self.preprocessor_params
                }
        
        class RawDatasetWrapper:
            def __init__(self, images, labels, dataset_name='mnist'):
                self.images = images
                self.labels = labels
                self.dataset_name = dataset_name
                self.preprocessed = False
                self._num_samples = len(images)
            
            def __len__(self):
                return self._num_samples
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx],
                    'index': idx,
                    'dataset': self.dataset_name,
                    'preprocessed': self.preprocessed
                }
        
        class DCGANTaskDataset(Dataset):
            def __init__(self, images, task_id=0, domain_factor=0.0, style='original'):
                self.images = images
                self.task_id = task_id
                self.domain_factor = domain_factor
                self.style = style
                
            def __len__(self):
                return len(self.images)
                
            def __getitem__(self, idx):
                img = self.images[idx]
                
                if self.domain_factor > 0:
                    img = self.apply_gan_domain_shift(img, self.domain_factor, self.style)
                
                return img
            
            def apply_gan_domain_shift(self, img, factor, style):
                img = img.clone()
                
                if style == 'noise':
                    noise_level = 0.1 + factor * 0.3
                    noise = torch.randn_like(img) * noise_level
                    img = img + noise
                    img = torch.clamp(img, -1, 1)
                    
                elif style == 'blur':
                    kernel_size = int(3 + factor * 5)
                    if kernel_size % 2 == 0:
                        kernel_size += 1
                    
                    if img.dim() == 3:
                        img = F.avg_pool2d(img.unsqueeze(0), 
                                          kernel_size=kernel_size, 
                                          stride=1, 
                                          padding=kernel_size//2).squeeze(0)
                
                elif style == 'contrast':
                    mean = img.mean()
                    contrast_factor = 1.0 + factor * 1.5
                    img = (img - mean) * contrast_factor + mean
                    img = torch.clamp(img, -1, 1)
                
                elif style == 'brightness':
                    brightness_shift = factor * 0.4
                    img = img + brightness_shift
                    img = torch.clamp(img, -1, 1)
                
                elif style == 'color_shift' and img.shape[0] == 3:
                    shift = torch.tensor([
                        factor * 0.3,
                        factor * 0.2,
                        -factor * 0.25
                    ]).view(3, 1, 1).to(img.device)
                    img = img + shift
                    img = torch.clamp(img, -1, 1)
                
                return img
        
        class TasksWrapper:
            def __init__(self, tasks):
                self.tasks = tasks
                self.num_tasks = len(tasks)
            
            def __len__(self):
                return len(self.tasks)
            
            def __getitem__(self, idx):
                return self.tasks[idx]
            
            def get_task(self, task_id):
                for task in self.tasks:
                    if task['task_id'] == task_id:
                        return task
                return None
        
        class SimpleDCGANDataset(Dataset):
            def __init__(self, images, normalize=False):
                self.images = images
                self.normalize = normalize
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                img = self.images[idx]
                if self.normalize:
                    return img
                return img
        
        class SafeUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                try:
                    return super().find_class(module, name)
                except:
                    if name == 'RawDatasetWrapper':
                        return RawDatasetWrapper
                    elif name == 'PreprocessedDataset':
                        return PreprocessedDataset
                    elif name == 'DCGANTaskDataset':
                        return DCGANTaskDataset
                    elif name == 'TasksWrapper':
                        return TasksWrapper
                    elif name == 'GANDataset':
                        return DCGANTaskDataset
                    elif name == 'DCGANDataset':
                        return DCGANTaskDataset
                    else:
                        class GenericClass:
                            def __init__(self, *args, **kwargs):
                                self.data = args[0] if args else kwargs
                            def __len__(self):
                                if hasattr(self.data, '__len__'):
                                    return len(self.data)
                                return 0
                            def __getitem__(self, idx):
                                if hasattr(self.data, '__getitem__'):
                                    return self.data[idx]
                                return None
                        return GenericClass
        
        def calculate_gan_metrics(real_images, fake_images):
            metrics = {
                'fid_score': 100.0,
                'ssim_mean': 0.0,
                'psnr_mean': 0.0,
                'diversity_score': 0.0
            }
            
            try:
                from skimage.metrics import structural_similarity as ssim
                from skimage.metrics import peak_signal_noise_ratio as psnr
                
                real_np = real_images.cpu().numpy()
                fake_np = fake_images.cpu().numpy()
                
                ssim_scores = []
                psnr_scores = []
                
                num_samples = min(len(real_np), len(fake_np), 20)
                
                for i in range(num_samples):
                    if len(real_np[i].shape) == 3 and real_np[i].shape[0] == 1:
                        real_img = real_np[i][0]
                        fake_img = fake_np[i][0]
                    elif len(real_np[i].shape) == 3:
                        real_img = real_np[i].transpose(1, 2, 0)
                        fake_img = fake_np[i].transpose(1, 2, 0)
                    else:
                        real_img = real_np[i]
                        fake_img = fake_np[i]
                    
                    real_img = (real_img + 1) / 2
                    fake_img = (fake_img + 1) / 2
                    
                    try:
                        ssim_score = ssim(real_img, fake_img, data_range=1.0, 
                                          channel_axis=-1 if real_img.ndim == 3 else None)
                        ssim_scores.append(ssim_score)
                    except:
                        ssim_scores.append(0.0)
                    
                    try:
                        psnr_score = psnr(real_img, fake_img, data_range=1.0)
                        psnr_scores.append(psnr_score)
                    except:
                        psnr_scores.append(0.0)
                
                metrics['ssim_mean'] = float(np.mean(ssim_scores)) if ssim_scores else 0.0
                metrics['psnr_mean'] = float(np.mean(psnr_scores)) if psnr_scores else 0.0
                    
            except Exception as e:
                print(f"WARNING: SSIM/PSNR calculation failed: {e}")
            
            try:
                images_np = fake_images.cpu().numpy().reshape(fake_images.shape[0], -1)
                if len(images_np) > 1:
                    n_samples = min(20, len(images_np))
                    subset = images_np[:n_samples]
                    distances = []
                    for i in range(n_samples):
                        for j in range(i + 1, n_samples):
                            dist = np.linalg.norm(subset[i] - subset[j])
                            distances.append(dist)
                    if distances:
                        metrics['diversity_score'] = float(np.mean(distances))
            except Exception as e:
                print(f"WARNING: Diversity score calculation failed: {e}")
            
            try:
                real_np = real_images.cpu().numpy().reshape(real_images.shape[0], -1)
                fake_np = fake_images.cpu().numpy().reshape(fake_images.shape[0], -1)
                
                mu_real = np.mean(real_np, axis=0)
                sigma_real = np.cov(real_np, rowvar=False)
                mu_fake = np.mean(fake_np, axis=0)
                sigma_fake = np.cov(fake_np, rowvar=False)
                
                from scipy import linalg
                diff = mu_real - mu_fake
                eps = 1e-6
                sigma_real = sigma_real + eps * np.eye(sigma_real.shape[0])
                sigma_fake = sigma_fake + eps * np.eye(sigma_fake.shape[0])
                
                covmean = linalg.sqrtm(sigma_real.dot(sigma_fake))
                if np.iscomplexobj(covmean):
                    covmean = covmean.real
                
                fid = diff.dot(diff) + np.trace(sigma_real + sigma_fake - 2*covmean)
                metrics['fid_score'] = float(fid)
                
            except Exception as e:
                print(f"WARNING: FID calculation failed: {e}")
            
            return metrics
        
        def get_retry_session():
            retry_strategy = Retry(total=5, status_forcelist=[500, 502, 503, 504])
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session = requests.Session()
            session.mount("https://", adapter)
            session.mount("http://", adapter)
            return session
        
        def get_instance(access_token, domain, schema_id, model_id):
            http = get_retry_session()
            url = f"{domain}/pi-entity-instances-service/v3.0/schemas/{schema_id}/instances/list"
            headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
            payload = {"dbType": "TIDB", "ownedOnly": True, "filter": {"model_id": model_id}}
            response = http.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            data = response.json()
            if not data['content']:
                raise ValueError(f"No instance found for model_id: {model_id}")
            return data['content'][0]
        
        def update_instance_field(access_token, domain, schema_id, model_id, field, value):
            http = get_retry_session()
            url = f"{domain}/pi-entity-instances-service/v2.0/schemas/{schema_id}/instances"
            headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
            payload = {
                "dbType": "TIDB",
                "conditionalFilter": {"conditions": [{"field": "model_id", "operator": "EQUAL", "value": model_id}]},
                "partialUpdateRequests": [{"patch": [{"operation": "REPLACE", "path": f"{field}", "value": value}]}]
            }
            response = http.patch(url, headers=headers, data=json.dumps(payload), timeout=30)
            response.raise_for_status()
        
        def trigger_pipeline(config, pipeline_domain, dqn_params=None, model_id=None):
            http = get_retry_session()
            url = f"{pipeline_domain}/bob-service-test/v1.0/pipeline/trigger/ml?pipelineId={config['pipeline_id']}"
            pipeline_params = {}
            if dqn_params: pipeline_params["param_json"] = json.dumps(dqn_params)
            if model_id: pipeline_params["model_id"] = model_id
            payload = json.dumps({
                "pipelineType": "ML", "containerResources": {}, 
                "experimentId": config['experiment_id'], "enableCaching": True, 
                "parameters": pipeline_params, "version": 1
            })
            headers = {'accept': 'application/json', 'Authorization': f"Bearer {config['access_token']}", 'Content-Type': 'application/json'}
            response = http.post(url, headers=headers, data=payload, timeout=30)
            response.raise_for_status()
            return response.json()['runId']
        
        def get_pipeline_status(config, pipeline_domain):
            http = get_retry_session()
            url = f"{pipeline_domain}/bob-service-test/v1.0/pipeline/{config['pipeline_id']}/status/ml/{config['run_id']}"
            headers = {'accept': 'application/json', 'Authorization': f"Bearer {config['access_token']}"}
            response = http.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            return response.json()['run_details']['state_history'][-1]['state']
        
        def trigger_and_wait_for_dqn_pipeline(config, pipeline_domain, dqn_params, model_id):
            run_id = trigger_pipeline(config, pipeline_domain, dqn_params, model_id)
            config["run_id"] = run_id
            max_wait_time = 1800
            start_time = time.time()
            while time.time() - start_time < max_wait_time:
                status = get_pipeline_status(config, pipeline_domain)
                if status == 'SUCCEEDED': return True
                elif status in ['FAILED', 'ERROR', 'CANCELLED']:
                    raise RuntimeError(f"DQN pipeline failed with status: {status}")
                time.sleep(30)
            raise RuntimeError("DQN pipeline timeout after 30 minutes")
        
        def train_dcgan_with_action(action, model_path, config_str, tasks_path, output_model_path):
            print(f"DEBUG: Starting DCGAN training with action: {action}")
            
            config = json.loads(config_str)
            gan_cfg = config['gan']
            dataset_cfg = config['dataset']
            
            training_cfg = gan_cfg['training']
            generator_cfg = gan_cfg['generator']
            discriminator_cfg = gan_cfg['discriminator']
            
            batch_size = action.get('batch_size', training_cfg.get('batch_size', 16))
            epochs = action.get('epochs', training_cfg.get('epochs', 2))
            gen_lr = action.get('learning_rate_g', generator_cfg.get('learning_rate', 0.0002))
            disc_lr = action.get('learning_rate_d', discriminator_cfg.get('learning_rate', 0.0002))
            dropout = action.get('dropout', discriminator_cfg.get('dropout', 0.3))
            algorithm = action.get('algorithm', training_cfg.get('algorithm', 'backprop'))
            
            print(f"DEBUG: Training parameters:")
            print(f"  Algorithm: {algorithm}")
            print(f"  Batch size: {batch_size}")
            print(f"  Epochs: {epochs}")
            print(f"  Generator LR: {gen_lr}")
            print(f"  Discriminator LR: {disc_lr}")
            print(f"  Dropout: {dropout}")
            
            checkpoint = torch.load(model_path, map_location='cpu')
            
            dcgan_config = checkpoint.get('config', {})
            
            algorithm_map = {
                'backprop': TrainingAlgorithm.BACKPROP,
                'cafo': TrainingAlgorithm.CAFO,
                'forward_forward': TrainingAlgorithm.FORWARD_FORWARD,
                'hybrid': TrainingAlgorithm.HYBRID
            }
            training_algorithm = algorithm_map.get(algorithm, TrainingAlgorithm.BACKPROP)
            
            if isinstance(dcgan_config, dict):
                dcgan_config.update({
                    'batch_size': batch_size,
                    'epochs': epochs,
                    'generator_learning_rate': gen_lr,
                    'discriminator_learning_rate': disc_lr,
                    'dropout': dropout,
                    'training_algorithm': training_algorithm,
                    'use_cafo': (algorithm == 'cafo'),
                    'use_forward_forward': (algorithm == 'forward_forward'),
                    'use_hybrid': (algorithm == 'hybrid')
                })
                
                if hasattr(DCGANConfig, 'from_dict'):
                    dcgan_config_obj = DCGANConfig.from_dict(dcgan_config)
                else:
                    dcgan_config_obj = DCGANConfig(
                        image_size=dataset_cfg.get('image_size', 64),
                        channels=dataset_cfg.get('channels', 1),
                        latent_dim=generator_cfg.get('latent_dim', 100),
                        training_algorithm=training_algorithm,
                        use_cafo=(algorithm == 'cafo'),
                        use_forward_forward=(algorithm == 'forward_forward'),
                        use_hybrid=(algorithm == 'hybrid'),
                        batch_size=batch_size,
                        epochs=epochs,
                        device='cpu'
                    )
            else:
                dcgan_config_obj = dcgan_config
                if hasattr(dcgan_config_obj, 'training_algorithm'):
                    dcgan_config_obj.training_algorithm = training_algorithm
                    dcgan_config_obj.use_cafo = (algorithm == 'cafo')
                    dcgan_config_obj.use_forward_forward = (algorithm == 'forward_forward')
                    dcgan_config_obj.use_hybrid = (algorithm == 'hybrid')
            
            generator = FullyConfigurableDCGANGenerator(dcgan_config_obj)
            discriminator = FullyConfigurableDCGANDiscriminator(dcgan_config_obj)
            
            if 'generator_state_dict' in checkpoint:
                generator.load_state_dict(checkpoint['generator_state_dict'])
                print("DEBUG: Loaded generator weights")
            if 'discriminator_state_dict' in checkpoint:
                discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                print("DEBUG: Loaded discriminator weights")
            
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            print(f"DEBUG: Using device: {device}")
            
            generator = generator.to(device)
            discriminator = discriminator.to(device)
            
            print(f"DEBUG: Loading tasks data from {tasks_path}")
            
            try:
                with open(tasks_path, 'rb') as f:
                    raw_data = f.read()
                
                import io
                data = SafeUnpickler(io.BytesIO(raw_data)).load()
                print(f"Tasks data loaded successfully")
                print(f"  Data type: {type(data)}")
                
            except Exception as e:
                print(f"ERROR: Failed to load tasks data: {e}")
                traceback.print_exc()
                raise
            
            all_images = []
            if isinstance(data, TasksWrapper):
                print("DEBUG: Loading TasksWrapper")
                tasks = data.tasks
                for task in tasks:
                    if 'train_loader' in task:
                        dataloader = task['train_loader']
                        for batch in dataloader:
                            if isinstance(batch, torch.Tensor):
                                all_images.append(batch)
                            elif isinstance(batch, (list, tuple)):
                                all_images.append(batch[0])
                    elif 'dataset' in task:
                        dataset = task['dataset']
                        if hasattr(dataset, '__len__'):
                            for i in range(min(len(dataset), 50)):
                                try:
                                    all_images.append(dataset[i])
                                except:
                                    pass
            elif isinstance(data, PreprocessedDataset):
                print("DEBUG: Loading PreprocessedDataset")
                if hasattr(data, 'images'):
                    images = data.images
                    if torch.is_tensor(images):
                        all_images = [images[i] for i in range(min(len(images), 100))]
                    elif isinstance(images, list):
                        all_images = images[:100]
            elif isinstance(data, RawDatasetWrapper):
                print("DEBUG: Loading RawDatasetWrapper")
                if hasattr(data, 'images'):
                    images = data.images
                    if torch.is_tensor(images):
                        all_images = [images[i] for i in range(min(len(images), 100))]
                    elif isinstance(images, list):
                        all_images = images[:100]
            elif isinstance(data, list):
                print("DEBUG: Loading list of tasks")
                for task in data:
                    if isinstance(task, dict) and 'train_loader' in task:
                        dataloader = task['train_loader']
                        for batch in dataloader:
                            if isinstance(batch, torch.Tensor):
                                all_images.append(batch)
                            elif isinstance(batch, (list, tuple)):
                                all_images.append(batch[0])
                    elif hasattr(task, '__len__'):
                        try:
                            for i in range(min(len(task), 20)):
                                all_images.append(task[i])
                        except:
                            pass
            elif hasattr(data, 'images'):
                print("DEBUG: Loading object with images attribute")
                if isinstance(data.images, torch.Tensor):
                    all_images = [data.images[i] for i in range(min(len(data.images), 100))]
                elif isinstance(data.images, list):
                    all_images = data.images[:100]
            elif hasattr(data, '__len__'):
                print("DEBUG: Loading direct dataset")
                try:
                    for i in range(min(len(data), 100)):
                        all_images.append(data[i])
                except:
                    pass
            
            if not all_images:
                print("WARNING: No training data found in tasks, creating dummy data")
                image_size = dataset_cfg.get('image_size', 64)
                channels = dataset_cfg.get('channels', 1)
                all_images = [torch.randn(32, channels, image_size, image_size) * 2 - 1]
            
            print(f"DEBUG: Collected {len(all_images)} image batches/samples")
            
            if all_images and isinstance(all_images[0], torch.Tensor) and all_images[0].dim() == 4:
                images_tensor = torch.cat(all_images, dim=0)
            elif all_images and isinstance(all_images[0], torch.Tensor):
                images_tensor = torch.stack(all_images)
            elif all_images:
                try:
                    images_tensor = torch.tensor(np.stack(all_images))
                except:
                    print("WARNING: Could not stack images, using first batch")
                    images_tensor = all_images[0] if isinstance(all_images[0], torch.Tensor) else torch.tensor(all_images[0])
            
            if images_tensor.max() > 1.0 or images_tensor.min() < -1.0:
                images_tensor = (images_tensor - images_tensor.min()) / (images_tensor.max() - images_tensor.min()) * 2 - 1
            
            dataset = SimpleDCGANDataset(images_tensor, normalize=False)
            actual_batch_size = min(batch_size, max(1, len(dataset)))
            dataloader = DataLoader(dataset, batch_size=actual_batch_size, shuffle=True, drop_last=True)
            
            print(f"DEBUG: Training dataset: {len(dataset)} samples")
            print(f"DEBUG: Batch size: {actual_batch_size}")
            print(f"DEBUG: Batches per epoch: {len(dataloader)}")
            
            latent_dim = generator.latent_dim if hasattr(generator, 'latent_dim') else 100
            gen_optimizer = optim.Adam(generator.parameters(), lr=gen_lr, betas=(0.5, 0.999))
            disc_optimizer = optim.Adam(discriminator.parameters(), lr=disc_lr, betas=(0.5, 0.999))
            
            generator.train()
            discriminator.train()
            
            training_history = {
                'generator_losses': [],
                'discriminator_losses': [],
                'algorithm': algorithm
            }
            
            start_time = time.time()
            
            for epoch in range(epochs):
                print(f"DEBUG: Epoch {epoch+1}/{epochs} (Algorithm: {algorithm})")
                
                epoch_g_loss = []
                epoch_d_loss = []
                
                for batch_idx, real_data in enumerate(dataloader):
                    real_data = real_data.to(device)
                    batch_size_real = real_data.size(0)
                    
                    if algorithm == 'cafo':
                        disc_optimizer.zero_grad()
                        
                        real_output = discriminator(real_data)
                        if real_output.dim() > 1:
                            real_output = real_output.view(-1)
                        
                        if hasattr(discriminator, 'compute_cafo_loss'):
                            d_loss_real = discriminator.compute_cafo_loss(real_output, is_real=True)
                        else:
                            real_labels = torch.ones(batch_size_real, device=device)
                            d_loss_real = nn.functional.binary_cross_entropy_with_logits(real_output, real_labels)
                        
                        z = torch.randn(batch_size_real, latent_dim, device=device)
                        fake_data = generator(z).detach()
                        fake_output = discriminator(fake_data)
                        if fake_output.dim() > 1:
                            fake_output = fake_output.view(-1)
                        
                        if hasattr(discriminator, 'compute_cafo_loss'):
                            d_loss_fake = discriminator.compute_cafo_loss(fake_output, is_real=False)
                        else:
                            fake_labels = torch.zeros(batch_size_real, device=device)
                            d_loss_fake = nn.functional.binary_cross_entropy_with_logits(fake_output, fake_labels)
                        
                        d_loss = (d_loss_real + d_loss_fake) / 2
                        d_loss.backward()
                        disc_optimizer.step()
                        
                        gen_optimizer.zero_grad()
                        z = torch.randn(batch_size_real, latent_dim, device=device)
                        fake_data = generator(z)
                        fake_output = discriminator(fake_data)
                        if fake_output.dim() > 1:
                            fake_output = fake_output.view(-1)
                        
                        if hasattr(generator, 'compute_cafo_loss'):
                            g_loss = generator.compute_cafo_loss(fake_output)
                        else:
                            g_loss = -torch.mean(fake_output)
                        
                        g_loss.backward()
                        gen_optimizer.step()
                        
                    elif algorithm == 'forward_forward':
                        disc_optimizer.zero_grad()
                        
                        real_output = discriminator(real_data)
                        if real_output.dim() > 1:
                            real_output = real_output.view(-1)
                        
                        if hasattr(discriminator, 'compute_goodness'):
                            real_goodness = discriminator.compute_goodness(real_output)
                            d_loss_real = -torch.mean(real_goodness)
                        else:
                            d_loss_real = -torch.mean(real_output)
                        
                        z = torch.randn(batch_size_real, latent_dim, device=device)
                        fake_data = generator(z).detach()
                        fake_output = discriminator(fake_data)
                        if fake_output.dim() > 1:
                            fake_output = fake_output.view(-1)
                        
                        if hasattr(discriminator, 'compute_goodness'):
                            fake_goodness = discriminator.compute_goodness(fake_output)
                            d_loss_fake = torch.mean(fake_goodness)
                        else:
                            d_loss_fake = torch.mean(fake_output)
                        
                        d_loss = d_loss_real + d_loss_fake
                        d_loss.backward()
                        disc_optimizer.step()
                        
                        gen_optimizer.zero_grad()
                        z = torch.randn(batch_size_real, latent_dim, device=device)
                        fake_data = generator(z)
                        fake_output = discriminator(fake_data)
                        if fake_output.dim() > 1:
                            fake_output = fake_output.view(-1)
                        
                        if hasattr(generator, 'compute_goodness'):
                            fake_goodness = generator.compute_goodness(fake_output)
                            g_loss = -torch.mean(fake_goodness)
                        else:
                            g_loss = -torch.mean(fake_output)
                        
                        g_loss.backward()
                        gen_optimizer.step()
                        
                    else:
                        disc_optimizer.zero_grad()
                        
                        real_output = discriminator(real_data)
                        if real_output.dim() > 1:
                            real_output = real_output.view(-1)
                        
                        real_labels = torch.ones(batch_size_real, device=device)
                        d_loss_real = nn.functional.binary_cross_entropy_with_logits(real_output, real_labels)
                        
                        z = torch.randn(batch_size_real, latent_dim, device=device)
                        fake_data = generator(z).detach()
                        fake_output = discriminator(fake_data)
                        if fake_output.dim() > 1:
                            fake_output = fake_output.view(-1)
                        
                        fake_labels = torch.zeros(batch_size_real, device=device)
                        d_loss_fake = nn.functional.binary_cross_entropy_with_logits(fake_output, fake_labels)
                        
                        d_loss = (d_loss_real + d_loss_fake) / 2
                        d_loss.backward()
                        disc_optimizer.step()
                        
                        gen_optimizer.zero_grad()
                        z = torch.randn(batch_size_real, latent_dim, device=device)
                        fake_data = generator(z)
                        fake_output = discriminator(fake_data)
                        if fake_output.dim() > 1:
                            fake_output = fake_output.view(-1)
                        
                        g_loss = nn.functional.binary_cross_entropy_with_logits(fake_output, real_labels)
                        g_loss.backward()
                        gen_optimizer.step()
                    
                    epoch_g_loss.append(g_loss.item())
                    epoch_d_loss.append(d_loss.item())
                    
                    if batch_idx % 5 == 0:
                        print(f"  Batch {batch_idx}: G={g_loss.item():.4f}, D={d_loss.item():.4f}")
                
                avg_g_loss = np.mean(epoch_g_loss) if epoch_g_loss else 0
                avg_d_loss = np.mean(epoch_d_loss) if epoch_d_loss else 0
                
                training_history['generator_losses'].append(avg_g_loss)
                training_history['discriminator_losses'].append(avg_d_loss)
                
                print(f"  Epoch {epoch+1} summary: G={avg_g_loss:.4f}, D={avg_d_loss:.4f}")
            
            training_time = time.time() - start_time
            print(f"DEBUG: Training completed in {training_time:.2f}s")
            
            generator.eval()
            discriminator.eval()
            
            with torch.no_grad():
                num_eval_samples = min(20, len(dataset))
                real_images = []
                fake_images = []
                
                dataloader_iter = iter(dataloader)
                for i in range(min(2, len(dataloader))):
                    try:
                        real_batch = next(dataloader_iter).to(device)
                        real_images.append(real_batch)
                        
                        z = torch.randn(real_batch.size(0), latent_dim, device=device)
                        fake_batch = generator(z)
                        fake_images.append(fake_batch)
                    except StopIteration:
                        break
                
                if real_images and fake_images:
                    real_images = torch.cat(real_images, dim=0)
                    fake_images = torch.cat(fake_images, dim=0)
                    
                    metrics = calculate_gan_metrics(real_images, fake_images)
                    
                    real_output = discriminator(real_images).mean().item()
                    fake_output = discriminator(fake_images).mean().item()
                    
                    metrics['real_score'] = real_output
                    metrics['fake_score'] = fake_output
                    metrics['score_difference'] = real_output - fake_output
                    metrics['generator_loss'] = training_history['generator_losses'][-1]
                    metrics['discriminator_loss'] = training_history['discriminator_losses'][-1]
                    metrics['algorithm'] = algorithm
                    
                    print(f"DEBUG: Evaluation metrics: {metrics}")
                else:
                    metrics = {
                        'fid_score': 100.0,
                        'ssim_mean': 0.0,
                        'psnr_mean': 0.0,
                        'diversity_score': 0.0,
                        'real_score': 0.0,
                        'fake_score': 0.0,
                        'score_difference': 0.0,
                        'generator_loss': training_history['generator_losses'][-1],
                        'discriminator_loss': training_history['discriminator_losses'][-1],
                        'algorithm': algorithm
                    }
            
            os.makedirs(os.path.dirname(output_model_path), exist_ok=True)
            
            checkpoint = {
                'model_source': 'rlaf_trained',
                'model_type': 'dcgan',
                'algorithm': algorithm,
                'generator_state_dict': generator.state_dict(),
                'discriminator_state_dict': discriminator.state_dict(),
                'config': dcgan_config_obj,
                'training_history': training_history,
                'epochs': epochs,
                'batch_size': batch_size,
                'action_applied': action,
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'latent_dim': latent_dim,
                'metrics': metrics
            }
            
            torch.save(checkpoint, output_model_path)
            print(f"DEBUG: Model saved to: {output_model_path}")
            
            return metrics
        
        def main():
            parser = argparse.ArgumentParser()
            parser.add_argument('--trained_model', type=str, required=True)
            parser.add_argument('--init_metrics', type=str, required=True)
            parser.add_argument('--rlaf_output', type=str, required=True)
            parser.add_argument('--data_path', type=str, required=True)
            parser.add_argument('--config', type=str, required=True)
            parser.add_argument('--domain', type=str, required=True)
            parser.add_argument('--schema_id', type=str, required=True)
            parser.add_argument('--model_id', type=str, required=True)
            parser.add_argument('--dqn_pipeline_id', type=str, required=True)
            parser.add_argument('--dqn_experiment_id', type=str, required=True)
            parser.add_argument('--access_token', type=str, required=True)
            parser.add_argument('--tasks', type=str, required=True)
            parser.add_argument('--pipeline_domain', type=str, required=True)
            parser.add_argument('--retrained_model', type=str, required=True)
            args = parser.parse_args()
            
            print("=" * 80)
            print("DCGAN RLAF LOOP - WITH CAFO/FF SUPPORT")
            print("=" * 80)
            
            with open(args.access_token, 'r') as f: 
                access_token = f.read().strip()
            
            print("\\n[STEP 1] Loading initial metrics...")
            current_metrics = {}
            try:
                with open(args.init_metrics, 'r') as f: 
                    metrics_data = json.load(f)
                if 'primary_metrics' in metrics_data: 
                    current_metrics = metrics_data['primary_metrics']
                elif 'key_metrics' in metrics_data: 
                    current_metrics = metrics_data['key_metrics']
                else: 
                    current_metrics = metrics_data
            except: 
                current_metrics = {'fid_score': 100.0, 'ssim_mean': 0.0, 'psnr_mean': 0.0, 'diversity_score': 0.0}
            
            print(f"Initial metrics: {current_metrics}")
            
            dcgan_dqn_params = [
                {"key": "fid_score", "sign": "-", "mul": 0.3},
                {"key": "ssim_mean", "sign": "+", "mul": 0.3},
                {"key": "psnr_mean", "sign": "+", "mul": 0.2},
                {"key": "diversity_score", "sign": "+", "mul": 0.2}
            ]
            
            action_to_use = None
            
            print(f"\\n[STEP 2] Starting RLAF loop (2 iterations)")
            
            for i in range(2):
                print(f"\\n{'='*60}")
                print(f"RLAF ITERATION {i+1}/2")
                print(f"{'='*60}")
                
                state_for_dqn = {
                    'fid_score': float(current_metrics.get('fid_score', 100.0)),
                    'ssim_mean': float(current_metrics.get('ssim_mean', 0.0)),
                    'psnr_mean': float(current_metrics.get('psnr_mean', 0.0)),
                    'diversity_score': float(current_metrics.get('diversity_score', 0.0))
                }
                
                for key in state_for_dqn:
                    if np.isnan(state_for_dqn[key]): 
                        state_for_dqn[key] = 0.0
                
                print(f"State for DQN: {state_for_dqn}")
                
                try:
                    instance = get_instance(access_token, args.domain, args.schema_id, args.model_id)
                    
                    if instance.get('pierce2rlaf'):
                        latest_entry = instance['pierce2rlaf'][-1]
                        previous_state = latest_entry['current_state']
                    else:
                        previous_state = {key: 0.0 for key in state_for_dqn.keys()}
                    
                    new_entry = {
                        "action_id": -1,
                        "previous_state": previous_state,
                        "current_state": state_for_dqn,
                        "episode": i,
                        "timestamp": int(time.time())
                    }
                    
                    pierce2rlaf_history = instance.get("pierce2rlaf", [])
                    pierce2rlaf_history.append(new_entry)
                    
                    update_instance_field(access_token, args.domain, args.schema_id, args.model_id,
                                        "pierce2rlaf", pierce2rlaf_history)
                    
                    print(f"Updated pierce2rlaf (size: {len(pierce2rlaf_history)})")
                    
                except Exception as e:
                    print(f"ERROR: Database update failed: {str(e)}")
                    raise
                
                print("\\n[STEP 3] Triggering DQN pipeline...")
                try:
                    dqn_config = {
                        "pipeline_id": args.dqn_pipeline_id,
                        "experiment_id": args.dqn_experiment_id,
                        "access_token": access_token
                    }
                    
                    dqn_success = trigger_and_wait_for_dqn_pipeline(
                        dqn_config, args.pipeline_domain, dcgan_dqn_params, args.model_id
                    )
                    
                    if dqn_success:
                        instance = get_instance(access_token, args.domain, args.schema_id, args.model_id)
                        
                        if instance.get('rlaf2pierce'):
                            latest_rlaf2pierce = instance['rlaf2pierce'][-1]
                            
                            if latest_rlaf2pierce.get("pierce_or_not", True):
                                rlaf_actions = instance.get('rlaf_actions', {}).get('actions', [])
                                action_id = latest_rlaf2pierce['action_id']
                                action_details = next((a for a in rlaf_actions if a["id"] == action_id), None)
                                
                                if action_details:
                                    action_to_use = action_details['params']
                                    
                                    if 'algorithm' in action_details:
                                        action_to_use['algorithm'] = action_details['algorithm']
                                    
                                    print(f"DQN selected action: {action_details['name']}")
                                    print(f"Action parameters: {action_to_use}")
                                    
                                    print("\\n[STEP 4] Starting full DCGAN training with CAFO/FF support...")
                                    new_metrics = train_dcgan_with_action(
                                        action_to_use, 
                                        args.trained_model, 
                                        args.config, 
                                        args.tasks,
                                        args.retrained_model
                                    )
                                    
                                    current_metrics = {
                                        'fid_score': new_metrics.get('fid_score', 100.0),
                                        'ssim_mean': new_metrics.get('ssim_mean', 0.0),
                                        'psnr_mean': new_metrics.get('psnr_mean', 0.0),
                                        'diversity_score': new_metrics.get('diversity_score', 0.0),
                                        'real_score': new_metrics.get('real_score', 0.0),
                                        'fake_score': new_metrics.get('fake_score', 0.0),
                                        'score_difference': new_metrics.get('score_difference', 0.0),
                                        'generator_loss': new_metrics.get('generator_loss', 0.0),
                                        'discriminator_loss': new_metrics.get('discriminator_loss', 0.0),
                                        'algorithm': new_metrics.get('algorithm', 'backprop')
                                    }
                                    print(f"Training completed. New metrics: {current_metrics}")
                                    
                                    rlaf2pierce_history = instance.get("rlaf2pierce", [])
                                    if rlaf2pierce_history:
                                        latest_entry = rlaf2pierce_history[-1]
                                        latest_entry['training_results'] = {
                                            'metrics': current_metrics,
                                            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ')
                                        }
                                        update_instance_field(access_token, args.domain, args.schema_id, args.model_id,
                                                            "rlaf2pierce", rlaf2pierce_history)
                                    
                                    args.trained_model = args.retrained_model
                                    
                                else:
                                    print(f"ERROR: Action ID {action_id} not found")
                                    raise ValueError("Action not found")
                            else:
                                print("pierce_or_not is false. Stopping RLAF loop.")
                                break
                        else:
                            print("ERROR: No rlaf2pierce data")
                            raise ValueError("No rlaf2pierce recommendations")
                    else:
                        print("ERROR: DQN pipeline failed")
                        raise RuntimeError("DQN pipeline failed")
                        
                except Exception as e:
                    print(f"ERROR: DQN pipeline error: {e}")
                    traceback.print_exc()
                    raise
            
            print("\\n[STEP 5] Saving final results...")
            os.makedirs(os.path.dirname(args.rlaf_output), exist_ok=True)
            
            final_metrics = {}
            for k, v in current_metrics.items():
                try:
                    if isinstance(v, (int, float, np.integer, np.floating)):
                        final_metrics[k] = float(v)
                    elif isinstance(v, str) and k != 'algorithm':
                        try:
                            final_metrics[k] = float(v)
                        except ValueError:
                            final_metrics[k] = v
                    else:
                        final_metrics[k] = v
                except:
                    final_metrics[k] = v
            
            final_output = {
                "final_metrics": final_metrics,
                "model_type": "DCGAN",
                "iterations_completed": i + 1,
                "timestamp": time.time(),
                "features_used": 4,
                "feature_names": ["fid_score", "ssim_mean", "psnr_mean", "diversity_score"],
                "training_algorithm": current_metrics.get('algorithm', 'backprop'),
                "supported_algorithms": ["backprop", "cafo", "forward_forward", "hybrid"],
                "cafo_support": True,
                "forward_forward_support": True
            }
            
            with open(args.rlaf_output, 'w') as f:
                json.dump(final_output, f, indent=2)
            
            print(f"\\nFinal results saved to: {args.rlaf_output}")
            print(f"Final model saved to: {args.retrained_model}")
            print(f"Final metrics: {current_metrics}")
            print(f"Training algorithm used: {current_metrics.get('algorithm', 'backprop')}")
            print("\\n" + "=" * 80)
            print("DCGAN RLAF LOOP WITH CAFO/FF SUPPORT COMPLETED SUCCESSFULLY")
            print("=" * 80)
        
        if __name__ == '__main__':
            try:
                main()
                print("\\nRLAF loop completed successfully")
                sys.exit(0)
            except Exception as e:
                print(f"\\nRLAF loop failed: {e}")
                traceback.print_exc()
                sys.exit(1)
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --init_metrics
      - {inputPath: init_metrics}
      - --rlaf_output
      - {outputPath: rlaf_output}
      - --data_path
      - {inputPath: data_path}
      - --config
      - {inputValue: config}
      - --domain
      - {inputValue: domain}
      - --schema_id
      - {inputValue: schema_id}
      - --model_id
      - {inputValue: model_id}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --dqn_experiment_id
      - {inputValue: dqn_experiment_id}
      - --access_token
      - {inputPath: access_token}
      - --tasks
      - {inputPath: tasks}
      - --pipeline_domain
      - {inputValue: pipeline_domain}
      - --retrained_model
      - {outputPath: retrained_model}
