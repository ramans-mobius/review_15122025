name: DCGAN RLAF Loop v7
description: Triggers the DCGAN RLAF pipeline with proper training and domain handling
inputs:
  - {name: trained_model, type: Model}
  - {name: init_metrics, type: Metrics}
  - {name: data_path, type: Dataset}
  - {name: config, type: String}
  - {name: domain, type: String}
  - {name: schema_id, type: String}
  - {name: model_id, type: String}
  - {name: dqn_pipeline_id, type: String}
  - {name: pipeline_domain, type: String}
  - {name: dqn_experiment_id, type: String}
  - {name: access_token, type: String}
  - {name: tasks, type: Dataset}
outputs:
  - {name: rlaf_output, type: Dataset}
  - {name: retrained_model, type: Model}
implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        echo "Installing required packages..."
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        pip install requests urllib3 pillow matplotlib > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import os
        import json
        import argparse
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        import time
        import pickle
        import numpy as np
        import torch.nn as nn
        import traceback
        import sys
        import warnings
        warnings.filterwarnings('ignore')
        
        # ============================================================================
        # DEBUG: PRINT ALL INPUTS FUNCTION
        # ============================================================================
        
        def print_all_inputs(args):
            print("\\n" + "="*80)
            print("DEBUG: ALL INPUT VALUES")
            print("="*80)
            
            print("\\n1. FILE PATHS (checking existence):")
            print("-" * 60)
            file_args = ['trained_model', 'init_metrics', 'data_path', 'access_token', 'tasks']
            for arg_name in file_args:
                arg_value = getattr(args, arg_name, None)
                exists = os.path.exists(arg_value) if arg_value else False
                print(f"  {arg_name}:")
                print(f"    Value: '{arg_value}'")
                print(f"    Exists: {exists}")
                if exists and os.path.isfile(arg_value):
                    size = os.path.getsize(arg_value)
                    print(f"    Size: {size:,} bytes ({size/1024**2:.2f} MB)")
            
            print("\\n2. STRING PARAMETERS (raw values with whitespace):")
            print("-" * 60)
            string_args = ['config', 'domain', 'schema_id', 'model_id', 'dqn_pipeline_id', 
                          'pipeline_domain', 'dqn_experiment_id']
            for arg_name in string_args:
                arg_value = getattr(args, arg_name, None)
                print(f"  {arg_name}:")
                if arg_value:
                    # Show raw string with special characters visible
                    raw_display = repr(arg_value)
                    if len(raw_display) > 100:
                        print(f"    Raw (repr): {raw_display[:100]}...")
                    else:
                        print(f"    Raw (repr): {raw_display}")
                    print(f"    Length: {len(arg_value)}")
                    
                    # Show cleaned version
                    cleaned = arg_value.strip().replace('\\n', '').replace('\\r', '')
                    if cleaned != arg_value:
                        print(f"    Cleaned: '{cleaned}'")
                else:
                    print(f"    Value: None")
            
            print("\\n3. OUTPUT PATHS:")
            print("-" * 60)
            output_args = ['rlaf_output', 'retrained_model']
            for arg_name in output_args:
                arg_value = getattr(args, arg_name, None)
                print(f"  {arg_name}: '{arg_value}'")
                if arg_value:
                    dir_path = os.path.dirname(arg_value)
                    print(f"    Directory: '{dir_path}'")
                    print(f"    Directory exists: {os.path.exists(dir_path) if dir_path else 'N/A'}")
            
            print("="*80)
        
        # ============================================================================
        # DOMAIN CLEANING AND VALIDATION
        # ============================================================================
        
        def clean_domain(domain_str):
           
            if not domain_str:
                return ""
            
            # Remove all whitespace including newlines
            cleaned = ''.join(domain_str.split())
            
            # Ensure it starts with http:// or https://
            if not cleaned.startswith(('http://', 'https://')):
                cleaned = 'https://' + cleaned
            
            # Remove trailing slash
            cleaned = cleaned.rstrip('/')
            
            return cleaned
        
        def test_domain_connectivity(domain):
          
            try:
                session = requests.Session()
                # Short timeout for quick test
                response = session.get(f"{domain}/", timeout=5)
                return response.status_code < 500  # Accept any non-server-error
            except (requests.exceptions.Timeout, 
                   requests.exceptions.ConnectionError,
                   requests.exceptions.RequestException):
                return False
            except Exception:
                return False
        
        # ============================================================================
        # GAN RETRAINING FUNCTION - USING ACTUAL TRAINING LOGIC
        # ============================================================================
        
        def gan_retraining(action_params, model_path, data_path, tasks_path, output_model_path, 
                          previous_metrics, dqn_params, base_config):
        
            
            print(f"\\n" + "="*60)
            print(f"STARTING GAN RETRAINING")
            print("="*60)
            print(f"Action: {action_params.get('name', 'unknown')}")
            print(f"Model input: {model_path}")
            print(f"Data path: {data_path}")
            
            # Check inputs exist
            if not os.path.exists(model_path):
                print(f"ERROR: Model file doesn't exist: {model_path}")
                return {"metrics": {}, "model_path": output_model_path}
            
            if not os.path.exists(data_path):
                print(f"ERROR: Data file doesn't exist: {data_path}")
                return {"metrics": {}, "model_path": output_model_path}
            
            # Import DCGAN modules
            try:
                from nesy_factory.GANs.dcgan import (
                    EnhancedDCGANTrainer,
                    DCGANDataset
                )
                print("✓ Imported DCGAN modules")
            except ImportError as e:
                print(f"ERROR importing nesy_factory: {e}")
                traceback.print_exc()
                return {"metrics": {}, "model_path": output_model_path}
            
            # Load data
            try:
                print(f"\\nLOADING DATA...")
                with open(data_path, "rb") as f:
                    data_wrapper = pickle.load(f)
                
                # Extract images from data wrapper (similar to training brick)
                if hasattr(data_wrapper, 'images'):
                    images = data_wrapper.images
                else:
                    # Try to get images directly
                    images = data_wrapper
                
                # Convert to proper tensor format
                if isinstance(images, torch.Tensor):
                    if images.dim() == 4:
                        images_list = [images[i] for i in range(len(images))]
                        channels = images.shape[1]
                        image_size = images.shape[2]
                    elif images.dim() == 3:
                        images_list = [images[i].unsqueeze(0) for i in range(len(images))]
                        channels = 1
                        image_size = images.shape[1]
                    else:
                        print(f"ERROR: Unexpected tensor shape: {images.shape}")
                        return {"metrics": {}, "model_path": output_model_path}
                else:
                    # Convert list to tensor
                    images_list = []
                    for img in images[:100]:  # Limit for speed
                        if isinstance(img, torch.Tensor):
                            images_list.append(img)
                        elif isinstance(img, (list, np.ndarray)):
                            images_list.append(torch.tensor(img))
                    if not images_list:
                        print(f"ERROR: Could not convert images to tensor")
                        return {"metrics": {}, "model_path": output_model_path}
                    
                    # Stack images
                    if len(images_list) > 1:
                        images_tensor = torch.stack(images_list)
                    else:
                        images_tensor = images_list[0].unsqueeze(0)
                    
                    if images_tensor.dim() == 4:
                        images_list = [images_tensor[i] for i in range(len(images_tensor))]
                        channels = images_tensor.shape[1]
                        image_size = images_tensor.shape[2]
                    else:
                        channels = 1
                        image_size = 64
                
                print(f"✓ Loaded {len(images_list)} images")
                print(f"  Image size: {image_size}x{image_size}")
                print(f"  Channels: {channels}")
                
            except Exception as e:
                print(f"ERROR loading data: {e}")
                traceback.print_exc()
                return {"metrics": {}, "model_path": output_model_path}
            
            # Load model
            try:
                print(f"\\nLOADING MODEL...")
                checkpoint = torch.load(model_path, map_location='cpu')
                
                # Extract config
                if 'config' in checkpoint and checkpoint['config'] is not None:
                    dcgan_config = checkpoint['config']
                    print(f"✓ Loaded model config")
                else:
                    print(f"WARNING: No config in checkpoint, using defaults")
                    dcgan_config = None
                
                # Create trainer
                trainer = EnhancedDCGANTrainer(dcgan_config) if dcgan_config else EnhancedDCGANTrainer()
                
                # Load weights
                if 'generator_state_dict' in checkpoint:
                    trainer.generator.load_state_dict(checkpoint['generator_state_dict'])
                    print(f"✓ Loaded generator weights")
                
                if 'discriminator_state_dict' in checkpoint:
                    trainer.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                    print(f"✓ Loaded discriminator weights")
                
                # Get latent dim
                latent_dim = trainer.generator.latent_dim if hasattr(trainer.generator, 'latent_dim') else 100
                
                # Move to device
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                trainer.generator = trainer.generator.to(device)
                trainer.discriminator = trainer.discriminator.to(device)
                
                print(f"✓ Model loaded on {device}")
                print(f"  Latent dim: {latent_dim}")
                print(f"  Generator params: {sum(p.numel() for p in trainer.generator.parameters()):,}")
                print(f"  Discriminator params: {sum(p.numel() for p in trainer.discriminator.parameters()):,}")
                
            except Exception as e:
                print(f"ERROR loading model: {e}")
                traceback.print_exc()
                return {"metrics": {}, "model_path": output_model_path}
            
            # Update training parameters from action
            try:
                print(f"\\nUPDATING TRAINING PARAMETERS...")
                
                # Get action parameters
                learning_rate_g = action_params.get('learning_rate_g', 0.0002)
                learning_rate_d = action_params.get('learning_rate_d', 0.0001)
                batch_size = action_params.get('batch_size', 32)
                dropout = action_params.get('dropout', 0.3)
                epochs = action_params.get('epochs', 3)  # Small for RLAF
                
                # Determine algorithm from action name
                action_name = action_params.get('name', '').lower()
                if 'forward' in action_name:
                    algorithm = 'forward_forward'
                elif 'cafo' in action_name:
                    algorithm = 'cafo'
                else:
                    algorithm = 'backprop'
                
                print(f"Algorithm: {algorithm}")
                print(f"Learning rates: G={learning_rate_g}, D={learning_rate_d}")
                print(f"Batch size: {batch_size}")
                print(f"Epochs: {epochs}")
                print(f"Dropout: {dropout}")
                
                # Update trainer config if possible
                if hasattr(trainer, 'config'):
                    if hasattr(trainer.config, 'training_algorithm'):
                        trainer.config.training_algorithm = algorithm
                    
                    if hasattr(trainer.config, 'batch_size'):
                        trainer.config.batch_size = batch_size
                    
                    if hasattr(trainer.config, 'epochs'):
                        trainer.config.epochs = epochs
                
                # Update optimizers
                if hasattr(trainer, 'g_optimizer'):
                    for param_group in trainer.g_optimizer.param_groups:
                        param_group['lr'] = learning_rate_g
                
                if hasattr(trainer, 'd_optimizer'):
                    for param_group in trainer.d_optimizer.param_groups:
                        param_group['lr'] = learning_rate_d
                
            except Exception as e:
                print(f"WARNING updating parameters: {e}")
                # Continue with defaults
            
            # Create dataloader
            try:
                print(f"\\nCREATING DATALOADER...")
                train_dataset = DCGANDataset(images_list, normalize=False)
                actual_batch_size = min(batch_size, max(1, len(train_dataset)))
                dataloader = torch.utils.data.DataLoader(
                    train_dataset,
                    batch_size=actual_batch_size,
                    shuffle=True,
                    drop_last=True
                )
                
                print(f"✓ Dataloader created")
                print(f"  Dataset size: {len(train_dataset)}")
                print(f"  Batch size: {actual_batch_size}")
                print(f"  Batches per epoch: {len(dataloader)}")
                
            except Exception as e:
                print(f"ERROR creating dataloader: {e}")
                traceback.print_exc()
                return {"metrics": {}, "model_path": output_model_path}
            
            # Training loop
            print(f"\\n" + "="*60)
            print(f"TRAINING - {epochs} EPOCHS")
            print("="*60)
            
            try:
                training_history = {
                    'generator_losses': [],
                    'discriminator_losses': [],
                    'real_scores': [],
                    'fake_scores': []
                }
                
                for epoch in range(epochs):
                    print(f"\\nEPOCH {epoch+1}/{epochs}:")
                    
                    epoch_g_loss = []
                    epoch_d_loss = []
                    epoch_real_scores = []
                    epoch_fake_scores = []
                    
                    for batch_idx, batch_data in enumerate(dataloader):
                        # Limit batches for speed in RLAF
                        if batch_idx > 5:  # Small for RLAF
                            break
                        
                        # Get real data
                        real_data = batch_data.to(device)
                        batch_size_real = real_data.size(0)
                        
                        # Train discriminator
                        trainer.d_optimizer.zero_grad()
                        
                        # Real data
                        real_output = trainer.discriminator(real_data)
                        if real_output.dim() > 1:
                            real_output = real_output.view(-1)
                        
                        real_labels = torch.ones(batch_size_real, device=device)
                        d_loss_real = nn.functional.binary_cross_entropy_with_logits(real_output, real_labels)
                        
                        # Fake data
                        z = torch.randn(batch_size_real, latent_dim, device=device)
                        fake_data = trainer.generator(z).detach()
                        fake_output = trainer.discriminator(fake_data)
                        if fake_output.dim() > 1:
                            fake_output = fake_output.view(-1)
                        
                        fake_labels = torch.zeros(batch_size_real, device=device)
                        d_loss_fake = nn.functional.binary_cross_entropy_with_logits(fake_output, fake_labels)
                        
                        d_loss = (d_loss_real + d_loss_fake) / 2
                        d_loss.backward()
                        trainer.d_optimizer.step()
                        
                        # Train generator
                        trainer.g_optimizer.zero_grad()
                        
                        z = torch.randn(batch_size_real, latent_dim, device=device)
                        fake_data = trainer.generator(z)
                        fake_output = trainer.discriminator(fake_data)
                        if fake_output.dim() > 1:
                            fake_output = fake_output.view(-1)
                        
                        g_loss = nn.functional.binary_cross_entropy_with_logits(fake_output, real_labels)
                        g_loss.backward()
                        trainer.g_optimizer.step()
                        
                        # Record metrics
                        epoch_g_loss.append(g_loss.item())
                        epoch_d_loss.append(d_loss.item())
                        epoch_real_scores.append(real_output.mean().item())
                        epoch_fake_scores.append(fake_output.mean().item())
                        
                        if batch_idx % 2 == 0:
                            print(f"  BATCH {batch_idx}: G={g_loss.item():.4f}, D={d_loss.item():.4f}")
                    
                    avg_g_loss = np.mean(epoch_g_loss) if epoch_g_loss else 0
                    avg_d_loss = np.mean(epoch_d_loss) if epoch_d_loss else 0
                    avg_real_score = np.mean(epoch_real_scores) if epoch_real_scores else 0.5
                    avg_fake_score = np.mean(epoch_fake_scores) if epoch_fake_scores else 0.5
                    
                    training_history['generator_losses'].append(avg_g_loss)
                    training_history['discriminator_losses'].append(avg_d_loss)
                    training_history['real_scores'].append(avg_real_score)
                    training_history['fake_scores'].append(avg_fake_score)
                    
                    print(f"  EPOCH SUMMARY: G={avg_g_loss:.4f}, D={avg_d_loss:.4f}, "
                          f"Real={avg_real_score:.3f}, Fake={avg_fake_score:.3f}")
                
                print(f"\\n✓ Training completed")
                
            except Exception as e:
                print(f"ERROR during training: {e}")
                traceback.print_exc()
                # Continue to save model anyway
            
            # Calculate final metrics
            final_metrics = {}
            if training_history['generator_losses']:
                final_metrics = {
                    'generator_loss': training_history['generator_losses'][-1],
                    'discriminator_loss': training_history['discriminator_losses'][-1] if training_history['discriminator_losses'] else 0.0,
                    'real_score': training_history['real_scores'][-1] if training_history['real_scores'] else 0.5,
                    'fake_score': training_history['fake_scores'][-1] if training_history['fake_scores'] else 0.5,
                    'score_difference': abs((training_history['real_scores'][-1] if training_history['real_scores'] else 0.5) - 
                                          (training_history['fake_scores'][-1] if training_history['fake_scores'] else 0.5))
                }
            
            print(f"\\nFINAL METRICS:")
            for key, value in final_metrics.items():
                print(f"  {key}: {value:.4f}")
            
            # Calculate improvement score
            improvement_score = 0
            if previous_metrics:
                print(f"\\nCALCULATING IMPROVEMENT...")
                for param in dqn_params:
                    key = param['key']
                    sign = 1 if param['sign'] == '+' else -1
                    
                    if key in final_metrics and key in previous_metrics:
                        current_val = final_metrics[key]
                        previous_val = previous_metrics[key]
                        
                        if not (np.isnan(current_val) or np.isnan(previous_val)):
                            improvement = (current_val - previous_val) * sign
                            improvement_score += improvement
                            print(f"  {key}: {previous_val:.4f} → {current_val:.4f} (Δ={improvement:.4f})")
            
            print(f"  Total improvement score: {improvement_score:.4f}")
            
            # Save retrained model
            try:
                print(f"\\nSAVING RETRAINED MODEL...")
                
                checkpoint_to_save = {
                    'model_source': 'rlaf_trained',
                    'model_type': 'dcgan',
                    'algorithm': algorithm,
                    'config': dcgan_config if 'dcgan_config' in locals() else {},
                    'generator_state_dict': trainer.generator.state_dict(),
                    'discriminator_state_dict': trainer.discriminator.state_dict(),
                    'generator_optimizer_state': trainer.g_optimizer.state_dict() if hasattr(trainer, 'g_optimizer') else None,
                    'discriminator_optimizer_state': trainer.d_optimizer.state_dict() if hasattr(trainer, 'd_optimizer') else None,
                    'training_history': training_history,
                    'epoch': epochs,
                    'batch_size': batch_size,
                    'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                    'latent_dim': latent_dim,
                    'image_size': image_size,
                    'channels': channels,
                    'improvement_score': improvement_score,
                    'action_params': action_params
                }
                
                os.makedirs(os.path.dirname(output_model_path), exist_ok=True)
                torch.save(checkpoint_to_save, output_model_path)
                print(f"✓ Model saved to: {output_model_path}")
                
            except Exception as e:
                print(f"ERROR saving model: {e}")
                traceback.print_exc()
                return {"metrics": final_metrics, "model_path": output_model_path}
            
            return {"metrics": final_metrics, "model_path": output_model_path}
        
        # ============================================================================
        # API FUNCTIONS
        # ============================================================================
        
        def get_retry_session():
            retry_strategy = Retry(
                total=3,
                backoff_factor=1,
                status_forcelist=[500, 502, 503, 504]
            )
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session = requests.Session()
            session.mount("https://", adapter)
            session.mount("http://", adapter)
            return session
        
        def get_instance(access_token, domain, schema_id, model_id):
            print(f"\\nGETTING INSTANCE...")
            print(f"  Domain: {domain}")
            print(f"  Schema ID: {schema_id}")
            print(f"  Model ID: {model_id}")
            
            try:
                http = get_retry_session()
                url = f"{domain}/pi-entity-instances-service/v3.0/schemas/{schema_id}/instances/list"
                
                headers = {
                    "Authorization": f"Bearer {access_token}",
                    "Content-Type": "application/json"
                }
                payload = {
                    "dbType": "TIDB",
                    "ownedOnly": True,
                    "filter": {"model_id": model_id}
                }
                
                print(f"  Request URL: {url}")
                response = http.post(url, headers=headers, json=payload, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if not data['content']:
                    print(f"  WARNING: No instance found for model_id: {model_id}")
                    return None
                
                instance = data['content'][0]
                print(f"✓ Instance retrieved")
                return instance
                
            except Exception as e:
                print(f"ERROR getting instance: {e}")
                return None
        
        # ============================================================================
        # MAIN FUNCTION
        # ============================================================================
        
        def main():
            parser = argparse.ArgumentParser()
            parser.add_argument('--trained_model', type=str, required=True)
            parser.add_argument('--init_metrics', type=str, required=True)
            parser.add_argument('--rlaf_output', type=str, required=True)
            parser.add_argument('--data_path', type=str, required=True)
            parser.add_argument('--config', type=str, required=True)
            parser.add_argument('--domain', type=str, required=True)
            parser.add_argument('--schema_id', type=str, required=True)
            parser.add_argument('--model_id', type=str, required=True)
            parser.add_argument('--dqn_pipeline_id', type=str, required=True)
            parser.add_argument('--dqn_experiment_id', type=str, required=True)
            parser.add_argument('--access_token', type=str, required=True)
            parser.add_argument('--tasks', type=str, required=True)
            parser.add_argument('--pipeline_domain', type=str, required=True)
            parser.add_argument('--retrained_model', type=str, required=True)
            args = parser.parse_args()
            
            # Print all inputs for debugging
            print_all_inputs(args)
            
            print("\\n" + "="*80)
            print("DCGAN RLAF LOOP v7 - WITH ACTUAL TRAINING")
            print("="*80)
            
            # Clean domains
            print("\\nCLEANING DOMAINS...")
            original_domain = args.domain
            original_pipeline_domain = args.pipeline_domain
            
            clean_domain_str = clean_domain(args.domain)
            clean_pipeline_domain = clean_domain(args.pipeline_domain)
            
            print(f"Original domain: '{original_domain}'")
            print(f"Cleaned domain: '{clean_domain_str}'")
            print(f"Original pipeline domain: '{original_pipeline_domain}'")
            print(f"Cleaned pipeline domain: '{clean_pipeline_domain}'")
            
            # Test domain connectivity
            print("\\nTESTING DOMAIN CONNECTIVITY...")
            domains_to_test = [
                clean_domain_str,
                clean_pipeline_domain,
                "https://igs.gov-cloud.ai",
                "https://ig.gov-cloud.ai",
                "https://ig.mobiusdtaas.ai"
            ]
            
            working_domains = []
            for domain in domains_to_test:
                if not domain:
                    continue
                print(f"  Testing {domain}...")
                if test_domain_connectivity(domain):
                    working_domains.append(domain)
                    print(f"    ✓ Reachable")
                else:
                    print(f"    ✗ Not reachable")
            
            if not working_domains:
                print("\\n✗ CRITICAL ERROR: No domains are reachable!")
                print("\\nTROUBLESHOOTING:")
                print("1. Check network connectivity from container")
                print("2. Verify domains are correct and running")
                print("3. Check if there are firewall restrictions")
                print("4. Try pinging the domains manually")
                
                # Still try to create outputs
                print("\\nCreating minimal outputs to continue pipeline...")
                create_minimal_outputs(args)
                sys.exit(1)
            
            print(f"\\n✓ Working domains: {working_domains}")
            selected_domain = working_domains[0]  # Use first working domain
            
            # Load access token
            try:
                with open(args.access_token, 'r') as f:
                    access_token = f.read().strip()
                print(f"\\nAccess token loaded ({len(access_token)} chars)")
            except Exception as e:
                print(f"ERROR loading access token: {e}")
                create_minimal_outputs(args)
                sys.exit(1)
            
            # Load initial metrics
            try:
                with open(args.init_metrics, 'r') as f:
                    current_metrics = json.load(f)
                print(f"\\nInitial metrics loaded: {list(current_metrics.keys())}")
            except Exception as e:
                print(f"ERROR loading metrics: {e}")
                current_metrics = {}
            
            # Try to get instance
            print("\\nATTEMPTING TO GET INSTANCE FROM SCHEMA...")
            instance = None
            for domain in working_domains:
                instance = get_instance(access_token, domain, args.schema_id, args.model_id)
                if instance:
                    print(f"✓ Found instance in domain: {domain}")
                    selected_domain = domain
                    break
            
            if not instance:
                print("\\nWARNING: Could not find instance in any domain")
                print("Continuing with local RLAF simulation...")
                instance = {'rlaf_actions': {'actions': []}, 'rlaf2pierce': []}
            
            # ============================================================================
            # RLAF LOOP
            # ============================================================================
            
            print("\\n" + "="*80)
            print("STARTING RLAF LOOP")
            print("="*80)
            
            max_iterations = 2
            all_metrics = []
            iteration_results = []
            
            # Load base config
            try:
                base_config = json.loads(args.config)
            except:
                base_config = {}
            
            for iteration in range(max_iterations):
                print(f"\\nITERATION {iteration + 1}/{max_iterations}")
                print("-" * 60)
                
                # Prepare metrics for DQN (simplified for now)
                dqn_params = []
                for key, value in current_metrics.items():
                    if isinstance(value, (int, float)):
                        # Determine if higher or lower is better
                        if any(term in key.lower() for term in ['loss', 'error', 'mse', 'mae']):
                            sign = "-"
                        else:
                            sign = "+"
                        dqn_params.append({"key": key, "sign": sign, "mul": 1.0})
                
                print(f"Prepared {len(dqn_params)} metrics for DQN")
                
                # Try to get RLAF actions from instance
                rlaf_actions = instance.get('rlaf_actions', {}).get('actions', [])
                rlaf2pierce = instance.get('rlaf2pierce', [])
                
                if not rlaf_actions or not rlaf2pierce:
                    print("No RLAF actions available. Simulating...")
                    # Simulate an action
                    simulated_action = {
                        "id": 1,
                        "name": "backprop_optimized",
                        "params": {
                            "learning_rate_g": 0.0002,
                            "learning_rate_d": 0.0001,
                            "batch_size": 32,
                            "dropout": 0.3,
                            "epochs": 3
                        }
                    }
                    
                    # Run retraining with simulated action
                    print("Running retraining with simulated action...")
                    retraining_results = gan_retraining(
                        simulated_action['params'],
                        args.trained_model,
                        args.data_path,
                        args.tasks,
                        args.retrained_model,
                        current_metrics,
                        dqn_params,
                        base_config
                    )
                    
                    # Update metrics
                    current_metrics = retraining_results["metrics"]
                    all_metrics.append(current_metrics)
                    iteration_results.append({
                        'iteration': iteration + 1,
                        'action': simulated_action,
                        'metrics': current_metrics
                    })
                    
                    # Update model path for next iteration
                    args.trained_model = retraining_results["model_path"]
                    
                    print(f"✓ Iteration {iteration + 1} completed")
                    continue
                
                # Use actual RLAF logic if available
                latest_rlaf2pierce = rlaf2pierce[-1]
                action_id = latest_rlaf2pierce.get('action_id', -1)
                
                if action_id < 0 or action_id >= len(rlaf_actions):
                    print(f"Invalid action ID: {action_id}")
                    break
                
                action_details = rlaf_actions[action_id]
                print(f"Action: {action_details.get('name', 'unknown')}")
                print(f"Params: {action_details.get('params', {})}")
                
                # Run retraining
                retraining_results = gan_retraining(
                    action_details.get('params', {}),
                    args.trained_model,
                    args.data_path,
                    args.tasks,
                    args.retrained_model,
                    current_metrics,
                    dqn_params,
                    base_config
                )
                
                # Update metrics
                current_metrics = retraining_results["metrics"]
                all_metrics.append(current_metrics)
                iteration_results.append({
                    'iteration': iteration + 1,
                    'action': action_details,
                    'metrics': current_metrics,
                    'improvement': retraining_results.get("improvement_score", 0)
                })
                
                # Update model path for next iteration
                args.trained_model = retraining_results["model_path"]
                
                print(f"✓ Iteration {iteration + 1} completed")
            
            # ============================================================================
            # SAVE FINAL RESULTS
            # ============================================================================
            
            print("\\n" + "="*80)
            print("SAVING RESULTS")
            print("="*80)
            
            try:
                os.makedirs(os.path.dirname(args.rlaf_output), exist_ok=True)
                
                final_results = {
                    "iterations_completed": len(iteration_results),
                    "final_metrics": current_metrics,
                    "all_iterations": iteration_results,
                    "domain_info": {
                        "original_domain": original_domain,
                        "original_pipeline_domain": original_pipeline_domain,
                        "cleaned_domain": clean_domain_str,
                        "cleaned_pipeline_domain": clean_pipeline_domain,
                        "working_domains_found": working_domains,
                        "selected_domain": selected_domain
                    },
                    "model_info": {
                        "initial_model": args.trained_model,
                        "final_model": args.retrained_model,
                        "model_id": args.model_id,
                        "schema_id": args.schema_id
                    },
                    "timestamp": time.strftime('%Y-%m-%d %H:%M:%S')
                }
                
                with open(args.rlaf_output, 'w') as f:
                    json.dump(final_results, f, indent=4)
                
                print(f"✓ RLAF results saved to: {args.rlaf_output}")
                print(f"✓ Retrained model saved to: {args.retrained_model}")
                
            except Exception as e:
                print(f"ERROR saving results: {e}")
                create_minimal_outputs(args)
            
            print("\\n" + "="*80)
            print("RLAF LOOP COMPLETED")
            print("="*80)
            print(f"Iterations: {len(iteration_results)}/{max_iterations}")
            if current_metrics:
                print("Final metrics:")
                for key, value in current_metrics.items():
                    if isinstance(value, (int, float)):
                        print(f"  {key}: {value:.4f}")
            print("="*80)
        
        def create_minimal_outputs(args):
            
            print("Creating minimal outputs...")
            
            try:
                # Create rlaf_output
                os.makedirs(os.path.dirname(args.rlaf_output), exist_ok=True)
                with open(args.rlaf_output, 'w') as f:
                    json.dump({
                        "error": "RLAF failed due to domain connectivity issues",
                        "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
                        "note": "Continuing pipeline with original model"
                    }, f, indent=4)
                
                # Copy trained model to retrained_model
                import shutil
                os.makedirs(os.path.dirname(args.retrained_model), exist_ok=True)
                shutil.copy2(args.trained_model, args.retrained_model)
                
                print("✓ Minimal outputs created")
                
            except Exception as e:
                print(f"ERROR creating minimal outputs: {e}")
        
        if __name__ == '__main__':
            main()
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --init_metrics
      - {inputPath: init_metrics}
      - --rlaf_output
      - {outputPath: rlaf_output}
      - --data_path
      - {inputPath: data_path}
      - --config
      - {inputValue: config}
      - --domain
      - {inputValue: domain}
      - --schema_id
      - {inputValue: schema_id}
      - --model_id
      - {inputValue: model_id}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --dqn_experiment_id
      - {inputValue: dqn_experiment_id}
      - --access_token
      - {inputPath: access_token}
      - --tasks
      - {inputPath: tasks}
      - --pipeline_domain
      - {inputValue: pipeline_domain}
      - --retrained_model
      - {outputPath: retrained_model}
