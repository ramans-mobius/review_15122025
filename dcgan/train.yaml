name: Train DCGAN v29
description: Trains DCGAN using block-by-block training similar to LSTM approach
inputs:
  - name: data_path
    type: Dataset
    description: "Preprocessed dataset (GANDataWrapper)"
  - name: master_config
    type: String
    description: "Master configuration JSON"
  - name: model_input
    type: Model
    description: "Model checkpoint from Build brick"
  - name: bearer_token
    type: String
    description: "Bearer token for CDN uploads"
  - name: domain
    type: String
    description: "CDN domain"
  - name: get_cdn
    type: String
    description: "CDN download prefix"
  
outputs:
  - name: trained_model
    type: Model
    description: "Trained model checkpoint"
  - name: training_history
    type: String
    description: "Complete training history JSON"
  - name: layer_training_logs
    type: String
    description: "Detailed per-layer training logs"
  - name: generated_images_urls
    type: String
    description: "CDN URLs for generated images"
  - name: training_summary
    type: String
    description: "Training summary JSON"

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -c
      - |
        # Install dependencies
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        pip install torchvision==0.17.0 pillow > /dev/null
        
        echo "Starting DCGAN training with block-by-block approach..."
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import torch.optim as optim
        import torch.nn.functional as F
        import argparse
        import pickle
        import json
        import os
        import sys
        import time
        import uuid
        import base64
        import subprocess
        from pathlib import Path
        from io import BytesIO
        import numpy as np
        from PIL import Image
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader
        
        # Set matplotlib backend
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        
        print("=" * 80)
        print("DCGAN TRAINING v28 - BLOCK-BY-BLOCK APPROACH")
        print("=" * 80)
        
        # ============================================================================
        # BLOCK CLASSES (Like LSTM)
        # ============================================================================
        
        class DCGANGeneratorBlock(nn.Module):
          
            
            def __init__(self, layer_type, layer_config, block_idx, total_blocks):
                super().__init__()
                self.layer_type = layer_type
                self.block_idx = block_idx
                self.total_blocks = total_blocks
                
                if layer_type == 'Linear':
                    self.layer = nn.Linear(
                        in_features=layer_config['in_features'],
                        out_features=layer_config['out_features']
                    )
                    self.bn = nn.BatchNorm1d(layer_config['out_features']) if layer_config.get('use_batchnorm', True) else nn.Identity()
                    self.act = nn.ReLU(inplace=True) if not layer_config.get('is_output', False) else nn.Tanh()
                    
                elif layer_type == 'ConvTranspose2d':
                    self.layer = nn.ConvTranspose2d(
                        in_channels=layer_config['in_channels'],
                        out_channels=layer_config['out_channels'],
                        kernel_size=layer_config['kernel_size'],
                        stride=layer_config['stride'],
                        padding=layer_config['padding'],
                        output_padding=layer_config.get('output_padding', 0),
                        bias=False
                    )
                    if not layer_config.get('is_output', False):
                        self.bn = nn.BatchNorm2d(layer_config['out_channels']) if layer_config.get('use_batchnorm', True) else nn.Identity()
                        self.act = nn.ReLU(inplace=True)
                    else:
                        self.bn = nn.Identity()
                        self.act = nn.Tanh()
                
                # For Forward-Forward training
                self.ff_threshold = layer_config.get('ff_threshold', 2.0)
                
                # Initialize weights
                self._init_weights()
            
            def _init_weights(self):
              
                if isinstance(self.layer, (nn.Linear, nn.ConvTranspose2d)):
                    nn.init.normal_(self.layer.weight, 0.0, 0.02)
                    if hasattr(self.layer, 'bias') and self.layer.bias is not None:
                        nn.init.constant_(self.layer.bias, 0.0)
            
            def forward(self, x):
               
                x = self.layer(x)
                x = self.bn(x)
                x = self.act(x)
                return x
            
            def compute_goodness(self, x):
              
                if x.numel() == 0:
                    return torch.zeros(x.size(0), device=x.device)
                
                # Flatten all dimensions except batch
                if x.dim() >= 2:
                    return (x ** 2).mean(dim=list(range(1, x.dim())))
                else:
                    return x ** 2
            
            def forward_forward_loss(self, pos_goodness, neg_goodness):
               
                if pos_goodness.numel() == 0 or neg_goodness.numel() == 0:
                    return torch.tensor(0.0, device=pos_goodness.device)
                
                pos_term = torch.log1p(torch.exp(-(pos_goodness - self.ff_threshold)))
                neg_term = torch.log1p(torch.exp(+(neg_goodness - self.ff_threshold)))
                return (pos_term + neg_term).mean()
        
        class DCGANDiscriminatorBlock(nn.Module):
          
            
            def __init__(self, layer_type, layer_config, block_idx, total_blocks):
                super().__init__()
                self.layer_type = layer_type
                self.block_idx = block_idx
                self.total_blocks = total_blocks
                
                if layer_type == 'Conv2d':
                    self.layer = nn.Conv2d(
                        in_channels=layer_config['in_channels'],
                        out_channels=layer_config['out_channels'],
                        kernel_size=layer_config['kernel_size'],
                        stride=layer_config['stride'],
                        padding=layer_config['padding'],
                        bias=False
                    )
                    self.bn = nn.BatchNorm2d(layer_config['out_channels']) if layer_config.get('use_batchnorm', False) else nn.Identity()
                    self.act = nn.LeakyReLU(0.2, inplace=True)
                    self.dropout = nn.Dropout2d(layer_config.get('dropout', 0.3)) if layer_config.get('dropout', 0.3) > 0 else nn.Identity()
                    
                elif layer_type == 'Linear':
                    self.layer = nn.Linear(
                        in_features=layer_config['in_features'],
                        out_features=layer_config['out_features']
                    )
                    self.bn = nn.Identity()  # Usually no BN for final linear in discriminator
                    self.act = nn.Sigmoid() if layer_config.get('is_output', False) else nn.Identity()
                    self.dropout = nn.Dropout(layer_config.get('dropout', 0.3)) if layer_config.get('dropout', 0.3) > 0 else nn.Identity()
                
                # For Forward-Forward training
                self.ff_threshold = layer_config.get('ff_threshold', 2.0)
                
                # Initialize weights
                self._init_weights()
            
            def _init_weights(self):
              
                if isinstance(self.layer, (nn.Linear, nn.Conv2d)):
                    nn.init.normal_(self.layer.weight, 0.0, 0.02)
                    if hasattr(self.layer, 'bias') and self.layer.bias is not None:
                        nn.init.constant_(self.layer.bias, 0.0)
            
            def forward(self, x):
            
                x = self.layer(x)
                x = self.bn(x)
                x = self.act(x)
                x = self.dropout(x)
                return x
            
            def compute_goodness(self, x):
              
                if x.numel() == 0:
                    return torch.zeros(x.size(0), device=x.device)
                
                # Flatten all dimensions except batch
                if x.dim() >= 2:
                    return (x ** 2).mean(dim=list(range(1, x.dim())))
                else:
                    return x ** 2
            
            def forward_forward_loss(self, pos_goodness, neg_goodness):
               
                if pos_goodness.numel() == 0 or neg_goodness.numel() == 0:
                    return torch.tensor(0.0, device=pos_goodness.device)
                
                pos_term = torch.log1p(torch.exp(-(pos_goodness - self.ff_threshold)))
                neg_term = torch.log1p(torch.exp(+(neg_goodness - self.ff_threshold)))
                return (pos_term + neg_term).mean()
        
        # ============================================================================
        # DIMENSIONAL CALCULATION FUNCTIONS
        # ============================================================================
        
        def calculate_generator_dimensions(config):
          
            gen_config = config['generator']
            dataset_config = config['dataset']
            
            # Image size (assume square)
            image_size = dataset_config.get('resize_size', 64)
            
            # Get layer configurations
            hidden_dims = gen_config['hidden_dims']
            kernel_sizes = gen_config.get('kernel_sizes', [4] * (len(hidden_dims) + 1))
            strides = gen_config.get('strides', [1] + [2] * len(hidden_dims))
            paddings = gen_config.get('paddings', [0] * (len(hidden_dims) + 1))
            output_paddings = gen_config.get('output_paddings', [0] * (len(hidden_dims) + 1))
            
            # Calculate initial size (going backwards from output)
            current_size = image_size
            print(f"Calculating generator dimensions:")
            print(f"  Target image size: {image_size}")
            print(f"  Hidden dims: {hidden_dims}")
            
            # Work backwards through conv layers
            for i in reversed(range(len(hidden_dims))):
                numerator = current_size + 2 * paddings[i+1] - kernel_sizes[i+1] - output_paddings[i+1]
                if numerator % strides[i+1] != 0:
                    needed_padding = strides[i+1] - (numerator % strides[i+1])
                    output_paddings[i+1] += needed_padding
                    numerator = current_size + 2 * paddings[i+1] - kernel_sizes[i+1] - output_paddings[i+1]
                
                current_size = numerator // strides[i+1] + 1
                print(f"  After layer {i}: size = {current_size}, out_channels = {hidden_dims[i]}")
            
            initial_size = max(1, current_size)
            
            # Calculate Linear layer output size
            fc_output_size = hidden_dims[0] * initial_size * initial_size
            
            print(f"  Initial size after linear: {initial_size}")
            print(f"  Linear output size: {fc_output_size}")
            print(f"  First conv layer dims: {hidden_dims[0]}x{initial_size}x{initial_size}")
            
            return {
                'initial_size': initial_size,
                'fc_output_size': fc_output_size,
                'layer_dims': hidden_dims,
                'image_size': image_size,
                'channels': dataset_config.get('channels', 1)
            }
        
        def verify_generator_dimensions(generator, dim_info):
         
            print(f"Verifying generator dimensions:")
            print(f"  Expected initial_size: {dim_info['initial_size']}")
            print(f"  Expected fc_output_size: {dim_info['fc_output_size']}")
            
            # Check Linear layer
            if hasattr(generator, 'fc'):
                actual_fc_out = generator.fc.out_features
                print(f"  Actual fc.out_features: {actual_fc_out}")
                
                if actual_fc_out != dim_info['fc_output_size']:
                    print(f"  WARNING: Mismatch! Expected {dim_info['fc_output_size']}, got {actual_fc_out}")
                    return False
            
            # Check if we can reshape properly
            try:
                # Test forward pass with dummy input
                z = torch.randn(2, generator.z_dim)
                output = generator(z)
                expected_shape = (2, dim_info['channels'], dim_info['image_size'], dim_info['image_size'])
                
                print(f"  Output shape: {output.shape}")
                print(f"  Expected shape: {expected_shape}")
                
                if output.shape != expected_shape:
                    print(f"  WARNING: Output shape mismatch!")
                    return False
                
                return True
                
            except Exception as e:
                print(f"  ERROR during forward pass: {e}")
                return False
        
        # ============================================================================
        # TRAINING FUNCTIONS
        # ============================================================================
        
        def train_forward_forward_blocks(model, train_loader, epochs_per_block, threshold, lr, device, component='discriminator'):
           
            print(f"Training {component} with Forward-Forward (block-by-block)...")
            
            # Extract trainable blocks
            blocks = []
            if component == 'discriminator':
                if hasattr(model, 'disc_blocks'):
                    blocks = model.disc_blocks
                else:
                    # Extract from discriminator
                    blocks = []
                    for module in model.modules():
                        if isinstance(module, DCGANDiscriminatorBlock):
                            blocks.append(module)
            else:  # generator
                if hasattr(model, 'gen_blocks'):
                    blocks = model.gen_blocks
                else:
                    # Extract from generator
                    blocks = []
                    for module in model.modules():
                        if isinstance(module, DCGANGeneratorBlock):
                            blocks.append(module)
            
            if not blocks:
                print(f"  No trainable blocks found in {component}")
                return {'block_results': [], 'loss_entries': []}
            
            print(f"  Found {len(blocks)} trainable blocks in {component}")
            
            results = []
            loss_entries = []
            
            # Get real and fake data for training
            real_batch = next(iter(train_loader))[0].to(device)
            batch_size = real_batch.size(0)
            
            if component == 'discriminator':
                # For discriminator: positive = real, negative = fake
                # Generate fake images
                with torch.no_grad():
                    z = torch.randn(batch_size, model.z_dim, device=device)
                    fake_batch = model(z) if component == 'discriminator' else torch.randn_like(real_batch)
                
                current_pos = real_batch
                current_neg = fake_batch
                
            else:  # generator
                # For generator: positive = noise, negative = corrupted noise
                noise = torch.randn(batch_size, model.z_dim, device=device)
                neg_noise = noise.clone()
                for b in range(batch_size):
                    perm = torch.randperm(noise.size(1), device=device)
                    neg_noise[b] = neg_noise[b, perm]
                
                current_pos = noise
                current_neg = neg_noise
            
            # Train each block sequentially
            for block_idx, block in enumerate(blocks):
                print(f"  Training Block {block_idx + 1}/{len(blocks)}: {block.layer_type}")
                print(f"    Input shape: {current_pos.shape}")
                
                # Create optimizer for this block only
                optimizer = optim.Adam(block.parameters(), lr=lr)
                block.train()
                
                block_losses = []
                
                for epoch in range(epochs_per_block):
                    optimizer.zero_grad()
                    
                    # Forward pass for positive samples
                    pos_output = block(current_pos)
                    pos_goodness = block.compute_goodness(pos_output)
                    
                    # Forward pass for negative samples
                    neg_output = block(current_neg)
                    neg_goodness = block.compute_goodness(neg_output)
                    
                    # Compute loss
                    loss = block.forward_forward_loss(pos_goodness, neg_goodness)
                    
                    # Backward pass
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss = loss.item()
                    block_losses.append(epoch_loss)
                    
                    # Calculate success rates
                    pos_above = (pos_goodness > threshold).float().mean().item()
                    neg_below = (neg_goodness < threshold).float().mean().item()
                    
                    # Create loss entry
                    loss_entry = {
                        'block': block_idx + 1,
                        'epoch': epoch + 1,
                        'loss': epoch_loss,
                        'component': component,
                        'training_mode': 'forward_forward',
                        'layer_type': block.layer_type,
                        'uid': str(uuid.uuid4()),
                        'pos_above_threshold': pos_above,
                        'neg_below_threshold': neg_below,
                        'input_shape': list(current_pos.shape)
                    }
                    loss_entries.append(loss_entry)
                    
                    if epoch == 0 or epoch == epochs_per_block - 1:
                        print(f"    Epoch {epoch + 1}/{epochs_per_block}: Loss = {epoch_loss:.6f}, "
                              f"Pos>Th: {pos_above:.3f}, Neg<Th: {neg_below:.3f}")
                
                results.append({
                    'block': block_idx + 1,
                    'losses': block_losses,
                    'final_loss': block_losses[-1] if block_losses else 0.0,
                    'layer_type': block.layer_type
                })
                
                # Prepare input for next block
                with torch.no_grad():
                    current_pos = block(current_pos).detach()
                    current_neg = block(current_neg).detach()
            
            return {
                'block_results': results,
                'loss_entries': loss_entries,
                'total_blocks': len(blocks)
            }
        
        def train_cafo_blocks(model, train_loader, epochs_per_block, lr, device, component='discriminator'):
        
            print(f"Training {component} with CAFO (block-by-block)...")
            
            # Extract trainable blocks
            blocks = []
            if component == 'discriminator':
                if hasattr(model, 'disc_blocks'):
                    blocks = model.disc_blocks
                else:
                    # Extract from discriminator
                    blocks = []
                    for module in model.modules():
                        if isinstance(module, DCGANDiscriminatorBlock):
                            blocks.append(module)
            else:  # generator
                if hasattr(model, 'gen_blocks'):
                    blocks = model.gen_blocks
                else:
                    # Extract from generator
                    blocks = []
                    for module in model.modules():
                        if isinstance(module, DCGANGeneratorBlock):
                            blocks.append(module)
            
            if not blocks:
                print(f"  No trainable blocks found in {component}")
                return {'block_results': [], 'loss_entries': []}
            
            print(f"  Found {len(blocks)} trainable blocks in {component}")
            
            results = []
            loss_entries = []
            
            # Get data for training
            real_batch = next(iter(train_loader))[0].to(device)
            batch_size = real_batch.size(0)
            
            if component == 'discriminator':
                # For discriminator: combine real and fake
                with torch.no_grad():
                    z = torch.randn(batch_size, model.z_dim, device=device)
                    fake_batch = model(z) if hasattr(model, 'z_dim') else torch.randn_like(real_batch)
                
                all_data = torch.cat([real_batch, fake_batch])
                all_labels = torch.cat([
                    torch.ones(batch_size, device=device),  # Real = 1
                    torch.zeros(batch_size, device=device)  # Fake = 0
                ]).float()
                
                current_data = all_data
                current_labels = all_labels
                
            else:  # generator
                # For generator: use noise, target high quality
                noise = torch.randn(batch_size, model.z_dim, device=device)
                current_data = noise
                current_labels = torch.ones(batch_size, device=device).float()
            
            # Train each block sequentially
            for block_idx, block in enumerate(blocks):
                print(f"  Training Block {block_idx + 1}/{len(blocks)}: {block.layer_type}")
                print(f"    Input shape: {current_data.shape}")
                
                # Create optimizer for this block only
                optimizer = optim.Adam(block.parameters(), lr=lr, weight_decay=1e-4)
                block.train()
                
                block_losses = []
                
                for epoch in range(epochs_per_block):
                    optimizer.zero_grad()
                    
                    # Forward pass
                    features = block(current_data)
                    
                    # Flatten features for predictor
                    features_flat = features.view(features.size(0), -1)
                    predictor_input_dim = features_flat.size(1)
                    
                    # Create predictor
                    predictor = nn.Linear(predictor_input_dim, 1).to(device)
                    nn.init.normal_(predictor.weight, 0.0, 0.02)
                    if predictor.bias is not None:
                        nn.init.constant_(predictor.bias, 0.0)
                    
                    # Make predictions
                    predictions = predictor(features_flat).squeeze()
                    
                    # Compute loss
                    if component == 'discriminator':
                        loss = F.binary_cross_entropy_with_logits(predictions, current_labels)
                    else:  # generator
                        target_quality = torch.ones_like(predictions)
                        loss = F.mse_loss(predictions, target_quality)
                    
                    # Backward pass (both block and predictor)
                    predictor_optimizer = optim.Adam(predictor.parameters(), lr=lr)
                    predictor_optimizer.zero_grad()
                    
                    loss.backward()
                    optimizer.step()
                    predictor_optimizer.step()
                    
                    epoch_loss = loss.item()
                    block_losses.append(epoch_loss)
                    
                    # Create loss entry
                    loss_entry = {
                        'block': block_idx + 1,
                        'epoch': epoch + 1,
                        'loss': epoch_loss,
                        'component': component,
                        'training_mode': 'cafo',
                        'layer_type': block.layer_type,
                        'uid': str(uuid.uuid4()),
                        'input_shape': list(current_data.shape)
                    }
                    loss_entries.append(loss_entry)
                    
                    if epoch == 0 or epoch == epochs_per_block - 1:
                        print(f"    Epoch {epoch + 1}/{epochs_per_block}: Loss = {epoch_loss:.6f}")
                
                results.append({
                    'block': block_idx + 1,
                    'losses': block_losses,
                    'final_loss': block_losses[-1] if block_losses else 0.0,
                    'layer_type': block.layer_type
                })
                
                # Prepare input for next block
                with torch.no_grad():
                    current_data = block(current_data).detach()
            
            return {
                'block_results': results,
                'loss_entries': loss_entries,
                'total_blocks': len(blocks)
            }
        
        # ============================================================================
        # MAIN TRAINING LOGIC
        # ============================================================================
        
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--model_input", required=True)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        parser.add_argument("--layer_training_logs", required=True)
        parser.add_argument("--generated_images_urls", required=True)
        parser.add_argument("--training_summary", required=True)
        parser.add_argument("--bearer_token", required=True)
        parser.add_argument("--domain", required=True)
        parser.add_argument("--get_cdn", required=True)
        args = parser.parse_args()
        
        # Parse master config
        config = json.loads(args.master_config)
        gan_cfg = config['gan']
        training_cfg = gan_cfg['training']
        
        # Determine training algorithm
        algorithm = training_cfg.get('algorithm', 'backprop')
        print(f"Training Algorithm: {algorithm}")
        
        # Load model
        checkpoint = torch.load(args.model_input, map_location='cpu')
        
        # Load dataset
        class SafeUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                if name in ['GANDataWrapper', 'GANDataset', 'DatasetInfoWrapper', 'PreprocessMetadata']:
                    return type(name, (), {})
                return super().find_class(module, name)
        
        with open(args.data_path, "rb") as f:
            data_wrapper = SafeUnpickler(f).load()
        
        # Create data loader
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {device}")
        
        batch_size = training_cfg.get('batch_size', 32)
        train_loader = DataLoader(data_wrapper.dataset, batch_size=batch_size, shuffle=True)
        
        # Dimensional verification
        print("\\n" + "="*60)
        print("DIMENSIONAL VERIFICATION")
        print("="*60)
        
        dim_info = calculate_generator_dimensions(config)
        
        # Verify generator dimensions if possible
        if 'generator_state_dict' in checkpoint:
            # Create a dummy generator for verification
            from nesy_factory.GANs.dcgan import Generator
            dummy_gen = Generator(config)
            dummy_gen.load_state_dict(checkpoint['generator_state_dict'])
            dummy_gen.to(device)
            
            verified = verify_generator_dimensions(dummy_gen, dim_info)
            print(f"Generator verification: {'PASS' if verified else 'FAIL'}")
        
        # Training results
        training_history = {
            'training_mode': algorithm,
            'algorithm': algorithm,
            'model_type': 'dcgan',
            'block_results': [],
            'layer_logs': [],
            'generated_images': []
        }
        
        # Training based on algorithm
        if algorithm == 'forward_forward':
            print(f"\\n{'='*60}")
            print(f"FORWARD-FORWARD BLOCK TRAINING")
            print(f"{'='*60}")
            
            # Train generator blocks
            if gan_cfg['generator'].get('use_forward_forward', False):
                ff_epochs_per_block = training_cfg.get('ff_epochs_per_block', 2)
                ff_threshold = training_cfg.get('ff_threshold', 2.0)
                
                gen_results = train_forward_forward_blocks(
                    dummy_gen, train_loader, ff_epochs_per_block, 
                    ff_threshold, 0.01, device, 'generator'
                )
                training_history['block_results'].append({
                    'component': 'generator',
                    'results': gen_results
                })
                training_history['layer_logs'].extend(gen_results['loss_entries'])
            
            # Train discriminator blocks
            if gan_cfg['discriminator'].get('use_forward_forward', False):
                ff_epochs_per_block = training_cfg.get('ff_epochs_per_block', 2)
                ff_threshold = training_cfg.get('ff_threshold', 2.0)
                
                # Load discriminator
                from nesy_factory.GANs.dcgan import Discriminator
                dummy_disc = Discriminator(config)
                if 'discriminator_state_dict' in checkpoint:
                    dummy_disc.load_state_dict(checkpoint['discriminator_state_dict'])
                dummy_disc.to(device)
                
                disc_results = train_forward_forward_blocks(
                    dummy_disc, train_loader, ff_epochs_per_block, 
                    ff_threshold, 0.01, device, 'discriminator'
                )
                training_history['block_results'].append({
                    'component': 'discriminator',
                    'results': disc_results
                })
                training_history['layer_logs'].extend(disc_results['loss_entries'])
            
        elif algorithm == 'cafo':
            print(f"\\n{'='*60}")
            print(f"CAFO BLOCK TRAINING")
            print(f"{'='*60}")
            
            # Train generator blocks
            if gan_cfg['generator'].get('use_cafo', False):
                cafo_epochs_per_block = training_cfg.get('cafo_epochs_per_block', 2)
                
                gen_results = train_cafo_blocks(
                    dummy_gen, train_loader, cafo_epochs_per_block, 
                    0.001, device, 'generator'
                )
                training_history['block_results'].append({
                    'component': 'generator',
                    'results': gen_results
                })
                training_history['layer_logs'].extend(gen_results['loss_entries'])
            
            # Train discriminator blocks
            if gan_cfg['discriminator'].get('use_cafo', False):
                cafo_epochs_per_block = training_cfg.get('cafo_epochs_per_block', 2)
                
                # Load discriminator
                from nesy_factory.GANs.dcgan import Discriminator
                dummy_disc = Discriminator(config)
                if 'discriminator_state_dict' in checkpoint:
                    dummy_disc.load_state_dict(checkpoint['discriminator_state_dict'])
                dummy_disc.to(device)
                
                disc_results = train_cafo_blocks(
                    dummy_disc, train_loader, cafo_epochs_per_block, 
                    0.001, device, 'discriminator'
                )
                training_history['block_results'].append({
                    'component': 'discriminator',
                    'results': disc_results
                })
                training_history['layer_logs'].extend(disc_results['loss_entries'])
        
        else:  # backprop
            print(f"\\n{'='*60}")
            print(f"BACKPROPAGATION TRAINING")
            print(f"{'='*60}")
            
            # Use the BackpropTrainer from dcgan.py
            try:
                from nesy_factory.GANs.dcgan import BackpropTrainer
                
                # Load both models
                from nesy_factory.GANs.dcgan import Generator, Discriminator
                generator = Generator(config)
                discriminator = Discriminator(config)
                
                if 'generator_state_dict' in checkpoint:
                    generator.load_state_dict(checkpoint['generator_state_dict'])
                if 'discriminator_state_dict' in checkpoint:
                    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                
                generator.to(device)
                discriminator.to(device)
                
                # Create optimizers
                optimizer_g = optim.Adam(generator.parameters(), lr=gan_cfg['generator']['learning_rate'], betas=(0.5, 0.999))
                optimizer_d = optim.Adam(discriminator.parameters(), lr=gan_cfg['discriminator']['learning_rate'], betas=(0.5, 0.999))
                
                # Create trainer
                trainer = BackpropTrainer(config, device)
                epochs = training_cfg.get('epochs', 10)
                
                for epoch in range(epochs):
                    print(f"Epoch {epoch + 1}/{epochs}")
                    
                    metrics = trainer.train_epoch(
                        generator, discriminator, train_loader,
                        optimizer_g, optimizer_d, epoch
                    )
                    
                    # Log metrics
                    training_history['layer_logs'].append({
                        'epoch': epoch + 1,
                        'g_loss': metrics['g_loss'],
                        'd_loss': metrics['d_loss'],
                        'real_score': metrics['real_score'],
                        'fake_score': metrics['fake_score'],
                        'training_mode': 'backprop',
                        'uid': str(uuid.uuid4())
                    })
                    
                    print(f"  Generator Loss: {metrics['g_loss']:.4f}")
                    print(f"  Discriminator Loss: {metrics['d_loss']:.4f}")
                
                # Update checkpoint with trained models
                checkpoint['generator_state_dict'] = generator.state_dict()
                checkpoint['discriminator_state_dict'] = discriminator.state_dict()
                checkpoint['optimizer_g_state_dict'] = optimizer_g.state_dict()
                checkpoint['optimizer_d_state_dict'] = optimizer_d.state_dict()
                
            except ImportError:
                print("WARNING: Could not import BackpropTrainer, using manual training")
                # Fallback to manual training
        
        # Generate final images
        print(f"\\n{'='*60}")
        print(f"GENERATING FINAL IMAGES")
        print(f"{'='*60}")
        
        # Simple image generation function
        def generate_images(generator, num_images=16):
            generator.eval()
            with torch.no_grad():
                z = torch.randn(num_images, generator.z_dim, device=device)
                generated = generator(z).cpu()
                # Convert from [-1, 1] to [0, 1]
                generated = (generated + 1) / 2
            return generated
        
        # Save generated images
        os.makedirs('/tmp/generated_images', exist_ok=True)
        try:
            if 'generator' in locals():
                images = generate_images(generator)
                
                # Save grid image
                n_cols = 4
                n_rows = 4
                fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 12))
                
                for i in range(16):
                    ax = axes[i // n_cols, i % n_cols]
                    if images.shape[1] == 1:
                        ax.imshow(images[i, 0], cmap='gray', vmin=0, vmax=1)
                    else:
                        ax.imshow(images[i].permute(1, 2, 0))
                    ax.axis('off')
                
                plt.tight_layout()
                grid_path = '/tmp/generated_images/final_grid.png'
                plt.savefig(grid_path, dpi=150, bbox_inches='tight')
                plt.close()
                
                print(f"Generated images saved to {grid_path}")
                
                # CDN upload function
                def upload_to_cdn(file_path, description, bearer_token, domain, get_cdn_prefix):
                    if not os.path.exists(file_path):
                        return None
                    
                    upload_url = f"{domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fbottle%2Flimka%2Fsoda%2F"
                    
                    curl_command = [
                        "curl",
                        "--location", upload_url,
                        "--header", f"Authorization: Bearer {bearer_token}",
                        "--form", f"file=@{file_path}",
                        "--fail",
                        "--show-error",
                        "--connect-timeout", "30",
                        "--max-time", "120"
                    ]
                    
                    try:
                        process = subprocess.run(curl_command, capture_output=True, text=True, check=True)
                        response_json = json.loads(process.stdout)
                        relative_cdn_url = response_json.get("cdnUrl", "")
                        return f"{get_cdn_prefix}{relative_cdn_url}"
                    except:
                        return None
                
                # Upload to CDN
                bearer_token = args.bearer_token
                image_url = upload_to_cdn(grid_path, "Generated images", bearer_token, args.domain, args.get_cdn)
                
                if image_url:
                    training_history['generated_images'].append({
                        'url': image_url,
                        'description': 'Final generated images',
                        'uid': str(uuid.uuid4())
                    })
                    print(f"Images uploaded to CDN: {image_url[:100]}...")
        
        except Exception as e:
            print(f"Warning: Could not generate images: {e}")
        
        # Save outputs
        print(f"\\n{'='*60}")
        print(f"SAVING OUTPUTS")
        print(f"{'='*60}")
        
        # Save trained model
        os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
        torch.save(checkpoint, args.trained_model)
        print(f"✓ Model saved to: {args.trained_model}")
        
        # Save training history
        os.makedirs(os.path.dirname(args.training_history), exist_ok=True)
        with open(args.training_history, 'w') as f:
            json.dump(training_history, f, indent=2)
        print(f"✓ Training history saved to: {args.training_history}")
        
        # Save layer training logs
        os.makedirs(os.path.dirname(args.layer_training_logs), exist_ok=True)
        with open(args.layer_training_logs, 'w') as f:
            json.dump(training_history['layer_logs'], f, indent=2)
        print(f"✓ Layer training logs saved to: {args.layer_training_logs}")
        
        # Save generated images URLs
        os.makedirs(os.path.dirname(args.generated_images_urls), exist_ok=True)
        with open(args.generated_images_urls, 'w') as f:
            json.dump(training_history['generated_images'], f, indent=2)
        print(f"✓ Generated images URLs saved to: {args.generated_images_urls}")
        
        # Create training summary
        summary = {
            'training_completed': True,
            'model_type': 'dcgan',
            'training_mode': algorithm,
            'algorithm': algorithm,
            'total_blocks_trained': len(training_history['block_results']),
            'total_layer_logs': len(training_history['layer_logs']),
            'dimensional_verification': 'verified' if 'verified' in locals() else 'skipped',
            'image_generation': 'success' if training_history['generated_images'] else 'failed',
            'output_files': {
                'trained_model': args.trained_model,
                'training_history': args.training_history,
                'layer_training_logs': args.layer_training_logs,
                'generated_images_urls': args.generated_images_urls
            }
        }
        
        os.makedirs(os.path.dirname(args.training_summary), exist_ok=True)
        with open(args.training_summary, 'w') as f:
            json.dump(summary, f, indent=2)
        print(f"✓ Training summary saved to: {args.training_summary}")
        
        print(f"\\n{'='*80}")
        print(f"TRAINING COMPLETE - {algorithm.upper()} MODE")
        print(f"{'='*80}")
        print(f"✓ Training mode: {algorithm}")
        print(f"✓ Blocks trained: {len(training_history['block_results'])}")
        print(f"✓ Layer logs: {len(training_history['layer_logs'])}")
        print(f"✓ Images generated: {len(training_history['generated_images'])}")
        print(f"✓ Model saved: {args.trained_model}")
        
    args:
      - --data_path
      - {inputPath: data_path}
      - --master_config
      - {inputValue: master_config}
      - --model_input
      - {inputPath: model_input}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
      - --layer_training_logs
      - {outputPath: layer_training_logs}
      - --generated_images_urls
      - {outputPath: generated_images_urls}
      - --training_summary
      - {outputPath: training_summary}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
