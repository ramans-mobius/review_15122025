name: Train DCGAN v28 - FIXED
description: Trains DCGAN with Backprop, CAFO, or Forward-Forward using EnhancedDCGANTrainer
inputs:
  - name: data_path
    type: Dataset
    description: "Processed data from CDN (Pickle file)"
  - name: master_config
    type: String
    description: "Master configuration JSON"
  - name: model_input
    type: Model
    description: "Built DCGAN model from Build brick"
  - name: bearer_token
    type: String
    description: "Bearer token for CDN upload"
  - name: domain
    type: String
    description: "CDN upload domain"
  - name: get_cdn
    type: String
    description: "CDN download prefix"
  
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String
  - name: training_metrics
    type: String
  - name: generated_samples
    type: Dataset
  - name: generated_images_urls
    type: String
  - name: training_images_summary
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        echo "Installing required packages..."
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        pip install pillow matplotlib > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import argparse, pickle, os, json, sys, time, uuid
        import numpy as np
        import base64
        import subprocess
        from PIL import Image
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader, Dataset
        from io import BytesIO
        import matplotlib.pyplot as plt
        import warnings
        import traceback
        
        warnings.filterwarnings('ignore')
        
        # Set matplotlib backend
        import matplotlib
        matplotlib.use('Agg')
        
        # Import DCGAN
        print("Importing DCGAN modules...")
        try:
            from nesy_factory.GANs.dcgan import (
                DCGANConfig, TrainingAlgorithm,
                FullyConfigurableDCGANGenerator,
                FullyConfigurableDCGANDiscriminator,
                EnhancedDCGANTrainer,
                validate_config,
                DCGANDataset,
                create_dataloader,
                DCGANConfig
            )
            print(" Successfully imported DCGAN modules")
        except ImportError as e:
            print(f" ERROR importing DCGAN: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--model_input", required=True)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        parser.add_argument("--training_metrics", required=True)
        parser.add_argument("--generated_samples", required=True)
        parser.add_argument("--generated_images_urls", required=True)
        parser.add_argument("--training_images_summary", required=True)
        parser.add_argument("--bearer_token", required=True)
        parser.add_argument("--domain", required=True)
        parser.add_argument("--get_cdn", required=True)
        args = parser.parse_args()
        
        print("\\n" + "="*80)
        print("DCGAN TRAINING WITH ENHANCED TRAINER - FIXED")
        print("="*80)
        
        # ============================================================================
        # PARSE CONFIG AND SETUP
        # ============================================================================
        
        try:
            config = json.loads(args.master_config)
            gan_cfg = config['gan']
            dataset_cfg = config['dataset']
            
            # Determine training algorithm
            algorithm = gan_cfg['training'].get('algorithm', 'backprop')
            epochs = gan_cfg['training'].get('epochs', 2)
            batch_size = gan_cfg['training'].get('batch_size', 16)
            
            print(f"Training Algorithm: {algorithm.upper()}")
            print(f"Epochs: {epochs}")
            print(f"Batch size: {batch_size}")
            
        except Exception as e:
            print(f"ERROR parsing master_config: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # LOAD DATASET
        # ============================================================================
        
        try:
            # Load processed data from Preprocess v1
            with open(args.data_path, 'rb') as f:
                data_wrapper = pickle.load(f)
            
            # Handle different data wrapper types
            if hasattr(data_wrapper, 'images'):
                # This is a PreprocessedDataset from Preprocess v1
                images = data_wrapper.images
                labels = data_wrapper.labels if hasattr(data_wrapper, 'labels') else None
                
                # Convert to list of tensors for DCGANDataset
                images_list = [images[i] for i in range(len(images))]
                
                # Determine image properties
                if len(images.shape) == 4:
                    channels = images.shape[1]
                    image_size = images.shape[2]
                else:
                    channels = 1
                    image_size = 64
                
                print(f"Loaded PreprocessedDataset:")
                print(f"  Samples: {len(images_list)}")
                print(f"  Image size: {image_size}")
                print(f"  Channels: {channels}")
                
                # Create DCGANDataset
                train_dataset = DCGANDataset(images_list, normalize=False)  # Already normalized in Preprocess v1
                
            elif hasattr(data_wrapper, '__len__'):
                # Direct list of tensors
                images_list = [data_wrapper[i] for i in range(len(data_wrapper))]
                image_size = images_list[0].shape[1] if len(images_list[0].shape) == 3 else 64
                channels = images_list[0].shape[0] if len(images_list[0].shape) == 3 else 1
                
                print(f"Loaded tensor list:")
                print(f"  Samples: {len(images_list)}")
                print(f"  Image size: {image_size}")
                print(f"  Channels: {channels}")
                
                train_dataset = DCGANDataset(images_list, normalize=True)
                
            else:
                raise ValueError("Unsupported data format")
            
        except Exception as e:
            print(f"ERROR loading dataset: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Create dataloader
        actual_batch_size = min(batch_size, max(1, len(train_dataset)))
        dataloader = DataLoader(
            train_dataset, 
            batch_size=actual_batch_size, 
            shuffle=True, 
            drop_last=True
        )
        
        print(f"\\nData loader created:")
        print(f"  Dataset size: {len(train_dataset)}")
        print(f"  Batch size: {actual_batch_size}")
        print(f"  Batches per epoch: {len(dataloader)}")
        
        # ============================================================================
        # LOAD MODEL AND CREATE TRAINER
        # ============================================================================
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Device: {device}")
        
        try:
            # Load checkpoint
            checkpoint = torch.load(args.model_input, map_location='cpu')
            
            # Extract DCGAN config
            if 'config' in checkpoint:
                config_dict = checkpoint['config']
                # Convert dict back to DCGANConfig
                dcgan_config = DCGANConfig.from_dict(config_dict)
            else:
                # Create from master config
                dcgan_config = DCGANConfig(
                    image_size=image_size,
                    channels=channels,
                    latent_dim=gan_cfg.get('generator', {}).get('latent_dim', 100),
                    batch_size=actual_batch_size,
                    epochs=epochs,
                    device=device,
                )
            
            # Set algorithm
            algorithm_map = {
                'backprop': TrainingAlgorithm.BACKPROP,
                'cafo': TrainingAlgorithm.CAFO,
                'forward_forward': TrainingAlgorithm.FORWARD_FORWARD
            }
            dcgan_config.training_algorithm = algorithm_map.get(algorithm, TrainingAlgorithm.BACKPROP)
            
            # Enable block training for CAFO/Forward-Forward
            if algorithm in ['cafo', 'forward_forward']:
                dcgan_config.block_training.enabled = True
            
            # Validate config
            is_valid, errors = validate_config(dcgan_config)
            if not is_valid:
                print("Config validation errors:")
                for error in errors:
                    print(f"  - {error}")
                sys.exit(1)
            
            # Create EnhancedDCGANTrainer
            print(f"\\nCreating EnhancedDCGANTrainer...")
            trainer = EnhancedDCGANTrainer(dcgan_config)
            
            # Load weights if available
            if 'generator_state_dict' in checkpoint:
                trainer.generator.load_state_dict(checkpoint['generator_state_dict'])
                print("✓ Generator weights loaded")
            if 'discriminator_state_dict' in checkpoint:
                trainer.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                print("✓ Discriminator weights loaded")
            
            print(f"✓ Trainer created for {algorithm.upper()} algorithm")
            print(f"  Block training: {'Enabled' if dcgan_config.block_training.enabled else 'Disabled'}")
            
        except Exception as e:
            print(f"ERROR creating trainer: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # TRAINING
        # ============================================================================
        
        print(f"\\n" + "="*60)
        print(f"STARTING TRAINING")
        print(f"="*60)
        
        start_time = time.time()
        
        try:
            # Phase 1: Block training if enabled
            if dcgan_config.block_training.enabled:
                print(f"\\n PHASE 1: BLOCK-WISE PRE-TRAINING")
                print("-" * 40)
                
                block_start = time.time()
                block_results = trainer.train_blocks_with_logging(dataloader)
                block_time = time.time() - block_start
                
                print(f"Block training completed in {block_time:.2f}s")
            
            # Phase 2: Adversarial training
            print(f"\\n PHASE 2: ADVERSARIAL TRAINING")
            print("=" * 40)
            
            # Train for configured epochs
            training_result = trainer.train_adversarial_with_logging(dataloader)
            
            training_time = time.time() - start_time
            print(f"\\nTraining completed in {training_time:.2f}s")
            
        except Exception as e:
            print(f"ERROR during training: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # GENERATE SAMPLES
        # ============================================================================
        
        print(f"\\nGenerating samples...")
        
        def generate_and_save_samples(generator, num_samples=16, save_dir="/tmp/samples"):
            os.makedirs(save_dir, exist_ok=True)
            
            generator.eval()
            with torch.no_grad():
                z = torch.randn(num_samples, generator.latent_dim, device=device)
                samples = generator(z).cpu()
            
            # Convert from [-1, 1] to [0, 1]
            samples = (samples + 1) / 2
            
            # Save images
            image_paths = []
            for i in range(num_samples):
                img_tensor = samples[i]
                if img_tensor.shape[0] == 1:  # Grayscale
                    img = transforms.ToPILImage()(img_tensor)
                else:  # RGB
                    img = transforms.ToPILImage()(img_tensor)
                
                img_path = os.path.join(save_dir, f"sample_{i:02d}.png")
                img.save(img_path)
                image_paths.append(img_path)
            
            return image_paths, samples
        
        # Generate initial samples (before training)
        print("Generating initial samples...")
        init_samples_path, init_samples = generate_and_save_samples(
            trainer.generator, num_samples=16, save_dir="/tmp/init_samples"
        )
        
        # Generate final samples (after training)
        print("Generating final samples...")
        final_samples_path, final_samples = generate_and_save_samples(
            trainer.generator, num_samples=16, save_dir="/tmp/final_samples"
        )
        
        # ============================================================================
        # CDN UPLOAD FUNCTION
        # ============================================================================
        
        def upload_to_cdn(file_path, description, bearer_token, domain, get_cdn_prefix):
            if not os.path.exists(file_path):
                return None
            
            file_size = os.path.getsize(file_path)
            print(f"  Uploading {description} ({file_size:,} bytes)...")
            
            # Generate unique filename
            unique_id = str(uuid.uuid4())[:8]
            cdn_filename = f"dcgan_{description.replace(' ', '_')}_{unique_id}.png"
            
            upload_url = f"{domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fdcgan%2F"
            
            curl_command = [
                "curl",
                "--location", upload_url,
                "--header", f"Authorization: Bearer {bearer_token}",
                "--form", f"file=@{file_path}",
                "--form", f"filename={cdn_filename}",
                "--fail",
                "--show-error",
                "--connect-timeout", "30",
                "--max-time", "120"
            ]
            
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                response_json = json.loads(process.stdout)
                relative_cdn_url = response_json.get("cdnUrl", "")
                
                if not relative_cdn_url:
                    print(f"    Error: No cdnUrl in response")
                    return None
                
                full_url = f"{get_cdn_prefix}{relative_cdn_url}"
                print(f"    Uploaded: {full_url}")
                return full_url
                
            except subprocess.CalledProcessError as e:
                print(f"    Upload error: {e.stderr[:200]}")
                return None
            except json.JSONDecodeError:
                return None
        
        # Read bearer token
        with open(args.bearer_token, 'r') as f:
            bearer_token = f.read().strip()
        
        # Create sample grid
        def create_sample_grid(samples, title, save_path):
            n_cols = 4
            n_rows = 4
            fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 12))
            axes = axes.flatten()
            
            for i in range(min(16, len(samples))):
                ax = axes[i]
                sample = samples[i]
                if len(sample.shape) == 3 and sample.shape[0] == 1:
                    ax.imshow(sample[0], cmap='gray', vmin=0, vmax=1)
                elif len(sample.shape) == 3:
                    ax.imshow(sample.permute(1, 2, 0))
                else:
                    ax.imshow(sample, cmap='gray', vmin=0, vmax=1)
                ax.axis('off')
                ax.set_title(f"Sample {i+1}")
            
            for i in range(min(16, len(samples)), len(axes)):
                axes[i].axis('off')
            
            plt.suptitle(title, fontsize=16)
            plt.tight_layout()
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
        
        # Create and upload sample grids
        init_grid_path = "/tmp/init_grid.png"
        create_sample_grid(init_samples, "Initial Samples (Before Training)", init_grid_path)
        init_grid_url = upload_to_cdn(
            init_grid_path, "initial_samples_grid", 
            bearer_token, args.domain, args.get_cdn
        )
        
        final_grid_path = "/tmp/final_grid.png"
        create_sample_grid(final_samples, "Final Samples (After Training)", final_grid_path)
        final_grid_url = upload_to_cdn(
            final_grid_path, "final_samples_grid", 
            bearer_token, args.domain, args.get_cdn
        )
        
        # ============================================================================
        # CREATE OUTPUTS
        # ============================================================================
        
        print(f"\\nCreating outputs...")
        
        # Get metrics from trainer
        metrics_history = trainer.training_history
        
        # Create training history
        training_history_data = {
            'algorithm': algorithm,
            'epochs_completed': dcgan_config.epochs,
            'total_training_time': training_time,
            'generator_losses': metrics_history.get('generator_losses', []),
            'discriminator_losses': metrics_history.get('discriminator_losses', []),
            'real_scores': metrics_history.get('real_scores', []),
            'fake_scores': metrics_history.get('fake_scores', []),
            'block_training_results': metrics_history.get('block_training_results', {}),
            'final_metrics': {
                'generator_loss': metrics_history.get('generator_losses', [-1])[-1] if metrics_history.get('generator_losses') else 0,
                'discriminator_loss': metrics_history.get('discriminator_losses', [-1])[-1] if metrics_history.get('discriminator_losses') else 0,
                'real_score': metrics_history.get('real_scores', [-1])[-1] if metrics_history.get('real_scores') else 0.5,
                'fake_score': metrics_history.get('fake_scores', [-1])[-1] if metrics_history.get('fake_scores') else 0.5
            }
        }
        
        # Create training metrics
        training_metrics_data = {
            'model_type': 'dcgan',
            'training_algorithm': algorithm,
            'architecture': 'fully_configurable',
            'epochs_completed': dcgan_config.epochs,
            'final_generator_loss': training_history_data['final_metrics']['generator_loss'],
            'final_discriminator_loss': training_history_data['final_metrics']['discriminator_loss'],
            'final_real_score': training_history_data['final_metrics']['real_score'],
            'final_fake_score': training_history_data['final_metrics']['fake_score'],
            'total_training_time': training_time,
            'samples_generated': 16,
            'training_success': True,
            'image_size': image_size,
            'channels': channels,
            'latent_dim': trainer.generator.latent_dim,
            'batch_size': actual_batch_size,
            'device': str(device),
            'block_training_enabled': dcgan_config.block_training.enabled,
            'algorithm_specific': {
                'use_cafo': algorithm == 'cafo',
                'use_forward_forward': algorithm == 'forward_forward'
            }
        }
        
        # Prepare generated samples for output
        generated_samples_data = []
        for i, (img_path, sample) in enumerate(zip(final_samples_path, final_samples)):
            with open(img_path, 'rb') as f:
                img_data = f.read()
            
            generated_samples_data.append({
                'sample_id': i,
                'image_data': base64.b64encode(img_data).decode('utf-8'),
                'image_tensor': sample.numpy().tolist(),
                'filename': f'dcgan_{algorithm}_sample_{i}.png'
            })
        
        # Generated images URLs
        generated_images_urls_data = {
            'algorithm': algorithm,
            'model_type': 'dcgan',
            'image_grids': [
                {
                    'phase': 'initial',
                    'url': init_grid_url if init_grid_url else '',
                    'description': 'Initial samples before training'
                },
                {
                    'phase': 'final',
                    'url': final_grid_url if final_grid_url else '',
                    'description': 'Final samples after training'
                }
            ]
        }
        
        # Training images summary
        training_images_summary_data = {
            'training_completed': True,
            'algorithm': algorithm,
            'epochs_trained': dcgan_config.epochs,
            'final_metrics': training_history_data['final_metrics'],
            'image_grid_urls': generated_images_urls_data['image_grids'],
            'training_time': training_time,
            'block_training_used': dcgan_config.block_training.enabled
        }
        
        # Create trained model checkpoint
        trained_checkpoint = {
            'config': dcgan_config.to_dict(),
            'generator_state_dict': trainer.generator.state_dict(),
            'discriminator_state_dict': trainer.discriminator.state_dict(),
            'trainer_state': {
                'current_epoch': dcgan_config.epochs,
                'current_step': trainer.current_step,
                'training_history': trainer.training_history
            },
            'training_history': training_history_data,
            'training_metrics': training_metrics_data,
            'algorithm': algorithm,
            'epochs_trained': dcgan_config.epochs,
            'master_config': config,
            'model_info': checkpoint.get('model_info', {})
        }
        
        # ============================================================================
        # SAVE OUTPUTS
        # ============================================================================
        
        try:
            # Save trained model
            os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
            torch.save(trained_checkpoint, args.trained_model)
            print(f"✓ Trained model saved: {args.trained_model}")
            
            # Save training history
            with open(args.training_history, 'w') as f:
                json.dump(training_history_data, f, indent=2)
            print(f"✓ Training history saved: {args.training_history}")
            
            # Save training metrics
            with open(args.training_metrics, 'w') as f:
                json.dump(training_metrics_data, f, indent=2)
            print(f"✓ Training metrics saved: {args.training_metrics}")
            
            # Save generated samples
            with open(args.generated_samples, 'wb') as f:
                pickle.dump(generated_samples_data, f)
            print(f"✓ Generated samples saved: {args.generated_samples}")
            
            # Save generated images URLs
            with open(args.generated_images_urls, 'w') as f:
                json.dump(generated_images_urls_data, f, indent=2)
            print(f"✓ Generated images URLs saved: {args.generated_images_urls}")
            
            # Save training images summary
            with open(args.training_images_summary, 'w') as f:
                json.dump(training_images_summary_data, f, indent=2)
            print(f"✓ Training images summary saved: {args.training_images_summary}")
            
        except Exception as e:
            print(f"ERROR saving outputs: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # FINAL SUMMARY
        # ============================================================================
        
        print(f"\\n" + "="*80)
        print(f"TRAINING COMPLETED SUCCESSFULLY!")
        print("="*80)
        print(f"Algorithm: {algorithm.upper()}")
        print(f"Epochs: {dcgan_config.epochs}")
        print(f"Total time: {training_time:.2f}s")
        print(f"Final Generator Loss: {training_history_data['final_metrics']['generator_loss']:.4f}")
        print(f"Final Discriminator Loss: {training_history_data['final_metrics']['discriminator_loss']:.4f}")
        print(f"Final Real Score: {training_history_data['final_metrics']['real_score']:.3f}")
        print(f"Final Fake Score: {training_history_data['final_metrics']['fake_score']:.3f}")
        print(f"Samples generated: {len(generated_samples_data)}")
        print(f"Block training: {'Yes' if dcgan_config.block_training.enabled else 'No'}")
        print(f"Initial images URL: {init_grid_url if init_grid_url else 'Not uploaded'}")
        print(f"Final images URL: {final_grid_url if final_grid_url else 'Not uploaded'}")
        print("="*80)

    args:
      - --data_path
      - {inputPath: data_path}
      - --master_config
      - {inputValue: master_config}
      - --model_input
      - {inputPath: model_input}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
      - --training_metrics
      - {outputPath: training_metrics}
      - --generated_samples
      - {outputPath: generated_samples}
      - --generated_images_urls
      - {outputPath: generated_images_urls}
      - --training_images_summary
      - {outputPath: training_images_summary}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
