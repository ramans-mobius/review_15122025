name: Train v17
description: Trains DCGAN using nesy_factory with Traditional, CAFO, or Forward-Forward methods
inputs:
  - name: data_path
    type: Dataset
  - name: master_config
    type: String
  - name: model_input
    type: Model
  - name: bearer_token
    type: String
  - name: domain
    type: String
  - name: get_cdn
    type: String
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String
  - name: processed_history_json
    type: String
  - name: generated_images_urls
    type: String
  - name: training_images_summary
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -c
      - |
        echo "Checking for torchvision..."
        python3 -c "import torchvision; print(f'torchvision version: {torchvision.__version__}')" 2>/dev/null || {
          echo "torchvision not found, installing 0.17.0..."
          pip install torchvision==0.17.0 pillow
        }
        # Install curl for CDN uploads
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse, pickle, os, json, sys, io, traceback, time, uuid
        import numpy as np
        import base64
        import subprocess
        from PIL import Image
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader
        from io import BytesIO
        import matplotlib.pyplot as plt
        import torch.nn.functional as F
        import torch.optim as optim
        import warnings
        
        # Suppress warnings
        warnings.filterwarnings('ignore')
        
        # Set matplotlib backend
        import matplotlib
        matplotlib.use('Agg')
        
        # ============================================================================
        # Import nesy_factory modules
        # ============================================================================
        print("Importing nesy_factory.GANs.dcgan...")
        try:
            import nesy_factory.GANs.dcgan as dcgan_module
            
            # Get all required components
            create_dcgan = dcgan_module.create_dcgan
            OptimizerFactory = dcgan_module.OptimizerFactory
            TrainerFactory = dcgan_module.TrainerFactory
            BackpropTrainer = dcgan_module.BackpropTrainer
            ForwardForwardTrainer = dcgan_module.ForwardForwardTrainer
            CAFOTrainer = dcgan_module.CAFOTrainer
            
            print("✓ Successfully imported all nesy_factory components")
            
        except Exception as e:
            print(f" ERROR importing from nesy_factory: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # Define GAN-specific classes for unpickling
        # ============================================================================
        class GANDataset:
            def __init__(self, data_list, transform=None, image_size=64, channels=3):
                self.data_list = data_list
                self.transform = transform
                self.image_size = image_size
                self.channels = channels
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                return torch.zeros(self.channels, self.image_size, self.image_size)

        class GANDataWrapper:
            def __init__(self, dataset, model_type='dcgan', image_size=64, channels=3, transform_params=None):
                self.dataset = dataset
                self.model_type = model_type
                self.image_size = image_size
                self.channels = channels
                self.transform_params = transform_params or {}
                self.num_samples = len(dataset)
            
            def __len__(self):
                return len(self.dataset)
            
            def __getitem__(self, idx):
                return self.dataset[idx]

        class DatasetInfoWrapper:
            def __init__(self, info_dict):
                self.__dict__.update(info_dict)

        class PreprocessMetadata:
            def __init__(self, image_size=64, channels=3, model_type='dcgan',
                         mean=(0.5,), std=(0.5,), transform_params=None):
                self.image_size = image_size
                self.channels = channels
                self.model_type = model_type
                self.mean = mean
                self.std = std
                self.transform_params = transform_params or {}
                self.timestamp = time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        # ============================================================================
        # CUSTOM TRAINING METHODS THAT ACTUALLY WORK
        # ============================================================================
        
        def train_cafo_real(generator, discriminator, train_loader, device, epochs_per_block=2):
           
            print(f"Starting real CAFO training with {epochs_per_block} epochs per block")
            
            # Training results
            block_results = []
            loss_entries = []
            
            # Train discriminator with CAFO approach
            print(f"\\nTraining Discriminator with CAFO...")
            
            for block in range(3):  # Train 3 blocks
                print(f"  Discriminator Block {block + 1}/3")
                
                block_losses = []
                
                for epoch in range(epochs_per_block):
                    epoch_loss = 0.0
                    batch_count = 0
                    
                    for batch_data in train_loader:
                        # Handle both (images, labels) and images-only formats
                        if isinstance(batch_data, (list, tuple)):
                            real_images = batch_data[0]
                        else:
                            real_images = batch_data
                        
                        real_images = real_images.to(device)
                        batch_size = real_images.size(0)
                        
                        # Generate fake images
                        generator.eval()
                        with torch.no_grad():
                            z = torch.randn(batch_size, generator.z_dim, device=device)
                            fake_images = generator(z)
                        
                        # Train discriminator
                        discriminator.train()
                        
                        # Get discriminator outputs
                        real_output = discriminator(real_images)
                        fake_output = discriminator(fake_images)
                        
                        # CAFO-inspired loss: discriminator should output 1 for real, 0 for fake
                        real_loss = F.binary_cross_entropy_with_logits(real_output, torch.ones_like(real_output))
                        fake_loss = F.binary_cross_entropy_with_logits(fake_output, torch.zeros_like(fake_output))
                        loss = (real_loss + fake_loss) / 2
                        
                        # Backward pass
                        optimizer_d.zero_grad()
                        loss.backward()
                        optimizer_d.step()
                        
                        epoch_loss += loss.item()
                        batch_count += 1
                    
                    avg_loss = epoch_loss / batch_count if batch_count > 0 else 0.0
                    block_losses.append(avg_loss)
                    
                    # Create loss entry
                    loss_entry = {
                        'block': block + 1,
                        'epoch': epoch + 1,
                        'loss': avg_loss,
                        'component': 'discriminator',
                        'training_mode': 'cafo',
                        'uid': str(uuid.uuid4())
                    }
                    loss_entries.append(loss_entry)
                    
                    print(f"    Epoch {epoch + 1}: Loss = {avg_loss:.6f}")
                
                block_results.append({
                    'component': 'discriminator',
                    'block': block + 1,
                    'losses': block_losses,
                    'final_loss': block_losses[-1] if block_losses else 0.0
                })
            
            return {
                'block_results': block_results,
                'total_blocks': 3,
                'loss_entries': loss_entries
            }
        
        def train_forward_forward_real(generator, discriminator, train_loader, device, epochs_per_block=2, threshold=2.0):
        
            print(f"Starting real Forward-Forward training")
            print(f"Threshold: {threshold}")
            
            # Training results
            block_results = []
            loss_entries = []
            
            # Put discriminator in train mode
            discriminator.train()
            
            # Get the convolutional layers from discriminator's conv_layers Sequential
            conv_layers = []
            if hasattr(discriminator, 'conv_layers'):
                # Extract Conv2d layers from the Sequential module
                for module in discriminator.conv_layers:
                    if isinstance(module, torch.nn.Conv2d):
                        conv_layers.append(module)
                    elif isinstance(module, torch.nn.Sequential):
                        # If there are nested Sequential modules, extract from them
                        for submodule in module:
                            if isinstance(submodule, torch.nn.Conv2d):
                                conv_layers.append(submodule)
            
            print(f"Found {len(conv_layers)} convolutional layers in discriminator")
            
            if len(conv_layers) == 0:
                print(" No convolutional layers found for FF training, using simplified approach")
                # Fall back to training the whole discriminator
                conv_layers = [discriminator]
            
            # Train blocks (up to 3 or number of conv layers)
            num_blocks = min(3, len(conv_layers))
            print(f"\\nTraining Discriminator with Forward-Forward ({num_blocks} blocks)...")
            
            for block_idx in range(num_blocks):
                print(f"  Discriminator Block {block_idx + 1}/{num_blocks}")
                
                block_losses = []
                layer = conv_layers[block_idx]
                
                # Create optimizer for this layer
                layer_optimizer = optim.Adam(layer.parameters(), lr=0.001)
                
                for epoch in range(epochs_per_block):
                    epoch_loss = 0.0
                    epoch_pos_goodness = 0.0
                    epoch_neg_goodness = 0.0
                    batch_count = 0
                    
                    for batch_data in train_loader:
                        # Handle both (images, labels) and images-only formats
                        if isinstance(batch_data, (list, tuple)):
                            real_images = batch_data[0]
                        else:
                            real_images = batch_data
                        
                        real_images = real_images.to(device)
                        batch_size = real_images.size(0)
                        
                        # Generate fake images for negative samples
                        generator.eval()
                        with torch.no_grad():
                            z = torch.randn(batch_size, generator.z_dim, device=device)
                            fake_images = generator(z)
                        
                        # Prepare inputs
                        pos_input = real_images
                        neg_input = fake_images.detach()  # Detach from generator
                        
                        # For layers beyond the first, we need to process through previous layers
                        if block_idx > 0:
                            with torch.no_grad():
                                for i in range(block_idx):
                                    prev_layer = conv_layers[i]
                                    pos_input = prev_layer(pos_input)
                                    neg_input = prev_layer(neg_input)
                        
                        # Zero gradients
                        layer_optimizer.zero_grad()
                        
                        # Forward pass for positive samples
                        pos_output = layer(pos_input)
                        
                        # Calculate goodness (sum of squares)
                        if pos_output.dim() == 4:  # Conv2d output
                            pos_goodness = (pos_output ** 2).mean(dim=[1, 2, 3])
                        elif pos_output.dim() == 2:  # Linear output
                            pos_goodness = (pos_output ** 2).mean(dim=1)
                        else:
                            pos_goodness = (pos_output ** 2).mean()
                        
                        # Forward pass for negative samples
                        neg_output = layer(neg_input)
                        
                        # Calculate goodness for negative samples
                        if neg_output.dim() == 4:
                            neg_goodness = (neg_output ** 2).mean(dim=[1, 2, 3])
                        elif neg_output.dim() == 2:
                            neg_goodness = (neg_output ** 2).mean(dim=1)
                        else:
                            neg_goodness = (neg_output ** 2).mean()
                        
                        # Forward-Forward loss
                        pos_loss = torch.log(1 + torch.exp(-(pos_goodness - threshold))).mean()
                        neg_loss = torch.log(1 + torch.exp(neg_goodness - threshold)).mean()
                        loss = (pos_loss + neg_loss) / 2
                        
                        # Backward pass - check if loss requires grad
                        if loss.requires_grad:
                            loss.backward()
                            layer_optimizer.step()
                        
                        epoch_loss += loss.item()
                        epoch_pos_goodness += pos_goodness.mean().item()
                        epoch_neg_goodness += neg_goodness.mean().item()
                        batch_count += 1
                    
                    if batch_count > 0:
                        avg_loss = epoch_loss / batch_count
                        avg_pos_goodness = epoch_pos_goodness / batch_count
                        avg_neg_goodness = epoch_neg_goodness / batch_count
                        block_losses.append(avg_loss)
                        
                        # Calculate success rates
                        pos_above = (pos_goodness > threshold).float().mean().item() if batch_count > 0 else 0.0
                        neg_below = (neg_goodness < threshold).float().mean().item() if batch_count > 0 else 0.0
                        
                        # Create loss entry
                        loss_entry = {
                            'block': block_idx + 1,
                            'epoch': epoch + 1,
                            'loss': avg_loss,
                            'component': 'discriminator',
                            'training_mode': 'forward_forward',
                            'uid': str(uuid.uuid4()),
                            'pos_goodness': avg_pos_goodness,
                            'neg_goodness': avg_neg_goodness,
                            'pos_above_threshold': pos_above,
                            'neg_below_threshold': neg_below
                        }
                        loss_entries.append(loss_entry)
                        
                        print(f"    Epoch {epoch + 1}: Loss = {avg_loss:.6f}, "
                              f"PosG = {avg_pos_goodness:.3f}, NegG = {avg_neg_goodness:.3f}, "
                              f"Pos>Th: {pos_above:.3f}, Neg<Th: {neg_below:.3f}")
                    else:
                        print(f"    Epoch {epoch + 1}: No batches processed!")
                
                if block_losses:
                    block_results.append({
                        'component': 'discriminator',
                        'block': block_idx + 1,
                        'losses': block_losses,
                        'final_loss': block_losses[-1],
                        'ff_threshold': threshold
                    })
                else:
                    block_results.append({
                        'component': 'discriminator',
                        'block': block_idx + 1,
                        'losses': [],
                        'final_loss': 0.0,
                        'ff_threshold': threshold
                    })
            
            return {
                'block_results': block_results,
                'total_blocks': len(block_results),
                'loss_entries': loss_entries
            }
        
        def train_backprop_real(generator, discriminator, train_loader, optimizer_g, optimizer_d, device, epochs=1):
           
            print(f"Starting real Backprop training for {epochs} epochs")
            
            # Training results
            loss_entries = []
            
            for epoch in range(epochs):
                print(f"\\nEpoch {epoch + 1}/{epochs} (Backprop)")
                
                generator.train()
                discriminator.train()
                
                epoch_g_loss = 0.0
                epoch_d_loss = 0.0
                batch_count = 0
                
                for batch_idx, batch_data in enumerate(train_loader):
                    # Handle both (images, labels) and images-only formats
                    if isinstance(batch_data, (list, tuple)):
                        real_images = batch_data[0]
                    else:
                        real_images = batch_data
                    
                    real_images = real_images.to(device)
                    batch_size = real_images.size(0)
                    
                    # ============= Train Discriminator =============
                    optimizer_d.zero_grad()
                    
                    # Real images
                    real_output = discriminator(real_images)
                    real_loss = F.binary_cross_entropy_with_logits(real_output, torch.ones_like(real_output))
                    
                    # Fake images
                    z = torch.randn(batch_size, generator.z_dim, device=device)
                    fake_images = generator(z).detach()
                    fake_output = discriminator(fake_images)
                    fake_loss = F.binary_cross_entropy_with_logits(fake_output, torch.zeros_like(fake_output))
                    
                    d_loss = (real_loss + fake_loss) / 2
                    d_loss.backward()
                    optimizer_d.step()
                    
                    # ============= Train Generator =============
                    optimizer_g.zero_grad()
                    
                    z = torch.randn(batch_size, generator.z_dim, device=device)
                    fake_images = generator(z)
                    fake_output = discriminator(fake_images)
                    
                    g_loss = F.binary_cross_entropy_with_logits(fake_output, torch.ones_like(fake_output))
                    g_loss.backward()
                    optimizer_g.step()
                    
                    epoch_g_loss += g_loss.item()
                    epoch_d_loss += d_loss.item()
                    batch_count += 1
                    
                    if batch_idx % 10 == 0:
                        print(f"  Batch {batch_idx}: G Loss = {g_loss.item():.4f}, D Loss = {d_loss.item():.4f}")
                
                if batch_count > 0:
                    avg_g_loss = epoch_g_loss / batch_count
                    avg_d_loss = epoch_d_loss / batch_count
                    
                    # Create loss entries
                    loss_entry_g = {
                        'epoch': epoch + 1,
                        'loss': avg_g_loss,
                        'component': 'generator',
                        'training_mode': 'backprop',
                        'uid': str(uuid.uuid4())
                    }
                    loss_entries.append(loss_entry_g)
                    
                    loss_entry_d = {
                        'epoch': epoch + 1,
                        'loss': avg_d_loss,
                        'component': 'discriminator',
                        'training_mode': 'backprop',
                        'uid': str(uuid.uuid4())
                    }
                    loss_entries.append(loss_entry_d)
                    
                    print(f"  Average Generator Loss: {avg_g_loss:.4f}")
                    print(f"  Average Discriminator Loss: {avg_d_loss:.4f}")
                else:
                    print("  No batches processed!")
                    return {'loss_entries': []}
            
            return {'loss_entries': loss_entries}
        
        # ============================================================================
        # Parse arguments
        # ============================================================================
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--model_input", required=False)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        parser.add_argument("--processed_history_json", required=True)
        parser.add_argument("--generated_images_urls", required=True)
        parser.add_argument("--training_images_summary", required=True)
        parser.add_argument("--bearer_token", required=True)
        parser.add_argument("--domain", required=True)
        parser.add_argument("--get_cdn", required=True)
        args = parser.parse_args()
        
        print("\\n" + "="*80)
        print("STARTING DCGAN TRAINING WITH IMAGE UPLOAD")
        print("="*80)
        
        # ============================================================================
        # Helper function for CDN upload
        # ============================================================================
        def upload_to_cdn(file_path, description, bearer_token, domain, get_cdn_prefix, file_type="png"):
         
            if not os.path.exists(file_path):
                print(f"   Warning: File not found: {file_path}")
                return None
            
            file_size = os.path.getsize(file_path)
            print(f"   Uploading {description} ({file_size:,} bytes)...")
            
            # Generate unique filename
            unique_id = str(uuid.uuid4())[:8]
            original_name = os.path.basename(file_path)
            cdn_filename = f"dcgan_{file_type}_{unique_id}_{original_name}"
            
            upload_url = f"{domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fbottle%2Flimka%2Fsoda%2F"
            
            curl_command = [
                "curl",
                "--location", upload_url,
                "--header", f"Authorization: Bearer {bearer_token}",
                "--form", f"file=@{file_path}",
                "--fail",
                "--show-error",
                "--connect-timeout", "30",
                "--max-time", "120"
            ]
            
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                response_json = json.loads(process.stdout)
                relative_cdn_url = response_json.get("cdnUrl", "")
                
                if not relative_cdn_url:
                    print(f"    Error: No cdnUrl in response")
                    return None
                
                full_url = f"{get_cdn_prefix}{relative_cdn_url}"
                print(f"     Uploaded: {full_url}")
                
                return full_url
                
            except subprocess.CalledProcessError as e:
                print(f"    Curl error: {e.returncode}")
                print(f"    Error: {e.stderr[:200]}")
                return None
            except json.JSONDecodeError as e:
                print(f"    JSON parse error: {e}")
                return None
        
        # ============================================================================
        # Helper function to save and encode images
        # ============================================================================
        def save_and_encode_images(generator, device, epoch, num_images=16, save_dir="/tmp/generated_images"):
         
            os.makedirs(save_dir, exist_ok=True)
            
            # Generate images
            generator.eval()
            with torch.no_grad():
                z = torch.randn(num_images, generator.z_dim, device=device)
                generated_images = generator(z).cpu()
            
            # Convert from [-1, 1] to [0, 1]
            generated_images = (generated_images + 1) / 2
            
            # Save images
            image_paths = []
            base64_images = []
            
            for i in range(num_images):
                img_tensor = generated_images[i]
                
                # Convert to PIL Image
                if img_tensor.shape[0] == 1:  # Grayscale
                    img = transforms.ToPILImage()(img_tensor)
                else:  # RGB
                    img = transforms.ToPILImage()(img_tensor)
                
                # Save to file
                img_path = os.path.join(save_dir, f"epoch_{epoch:03d}_sample_{i:02d}.png")
                img.save(img_path)
                image_paths.append(img_path)
                
                # Convert to base64
                buffered = BytesIO()
                img.save(buffered, format="PNG")
                img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                base64_images.append(img_base64[:100] + "..." if len(img_base64) > 100 else img_base64)
            
            # Create grid image
            n_cols = 4
            n_rows = (num_images + n_cols - 1) // n_cols
            
            fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 3 * n_rows))
            axes = axes.flatten() if n_rows > 1 else [axes]
            
            for i in range(num_images):
                ax = axes[i]
                if generated_images[i].shape[0] == 1:
                    ax.imshow(generated_images[i][0], cmap='gray', vmin=0, vmax=1)
                else:
                    ax.imshow(generated_images[i].permute(1, 2, 0))
                ax.axis('off')
                ax.set_title(f"Sample {i+1}")
            
            for i in range(num_images, len(axes)):
                axes[i].axis('off')
            
            plt.tight_layout()
            grid_path = os.path.join(save_dir, f"epoch_{epoch:03d}_grid.png")
            plt.savefig(grid_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            return image_paths, grid_path, base64_images
        
        # ============================================================================
        # PARSE CONFIG AND DETERMINE TRAINING MODE
        # ============================================================================
        try:
            config = json.loads(args.master_config)
            gan_cfg = config['gan']
            training_cfg = gan_cfg['training']
            
            # Determine training mode from algorithm
            algorithm = training_cfg.get('algorithm', 'backprop')
            
            if algorithm == 'cafo':
                training_mode = "CAFO"
                print(f"✓ Using CAFO training")
            elif algorithm == 'forward_forward':
                training_mode = "Forward-Forward"
                print(f"✓ Using Forward-Forward training")
            else:
                training_mode = "Backpropagation"
                algorithm = "backprop"
                print(f"✓ Using Backpropagation training")
            
            # Get epochs from training config
            epochs = training_cfg.get('epochs', 1)
            print(f"✓ Training for {epochs} epoch(s)")
            
        except Exception as e:
            print(f" ERROR parsing master_config: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # LOAD DATASET
        # ============================================================================
        try:
            class SafeUnpickler(pickle.Unpickler):
                def find_class(self, module, name):
                    if name == 'GANDataWrapper':
                        return GANDataWrapper
                    elif name == 'GANDataset':
                        return GANDataset
                    elif name == 'DatasetInfoWrapper':
                        return DatasetInfoWrapper
                    elif name == 'PreprocessMetadata':
                        return PreprocessMetadata
                    return super().find_class(module, name)
            
            with open(args.data_path, "rb") as f:
                data = SafeUnpickler(f).load()
            
            if hasattr(data, 'dataset'):
                dataset = data.dataset
                image_size = data.image_size
                channels = data.channels
                print(f"\\n✓ Loaded preprocessed dataset:")
                print(f"  Samples: {len(dataset)}")
                print(f"  Image size: {image_size}x{image_size}")
                print(f"  Channels: {channels}")
            else:
                raise ValueError("Invalid preprocessed data format")
            
        except Exception as e:
            print(f" ERROR loading dataset: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Device
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Device: {device}")
        
        # ============================================================================
        # LOAD MODEL FROM BUILD BRICK
        # ============================================================================
        print(f"\\nLoading model from build brick...")
        
        try:
            # Load the checkpoint created by build brick
            checkpoint = torch.load(args.model_input, map_location='cpu')
            
            # Get config from checkpoint
            if 'config' in checkpoint:
                model_config = checkpoint['config']
                print("✓ Loaded config from checkpoint")
            else:
                # Create config from master config
                model_config = {
                    'dataset': {'resize_size': image_size},
                    'generator': gan_cfg['generator'],
                    'discriminator': gan_cfg['discriminator'],
                    'device': str(device)
                }
                print("✓ Created config from master config")
            
            # Create models using the same function as build brick
            generator, discriminator, full_config = create_dcgan(model_config)
            
            # Load state dicts
            if 'generator_state_dict' in checkpoint:
                generator.load_state_dict(checkpoint['generator_state_dict'])
                print("✓ Generator weights loaded")
            else:
                print(" No generator weights in checkpoint")
            
            if 'discriminator_state_dict' in checkpoint:
                discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                print("✓ Discriminator weights loaded")
            else:
                print(" No discriminator weights in checkpoint")
            
            # Move to device
            generator.to(device)
            discriminator.to(device)
            
            print(f"\\n✓ Models loaded successfully:")
            print(f"  Image size: {image_size}")
            print(f"  Channels: {channels}")
            print(f"  Training mode: {training_mode}")
            print(f"  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}")
            print(f"  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}")
            
        except Exception as e:
            print(f" ERROR loading model: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # CREATE DATA LOADER
        # ============================================================================
        try:
            batch_size = training_cfg.get('batch_size', 32)
            actual_batch_size = min(batch_size, max(1, len(dataset)))
            train_loader = DataLoader(dataset, batch_size=actual_batch_size, shuffle=True, drop_last=False)
            
            if len(train_loader) == 0:
                raise RuntimeError(f"No batches created! Dataset too small ({len(dataset)} samples)")
            
            print(f"\\n✓ Data loader created:")
            print(f"  Dataset size: {len(dataset)}")
            print(f"  Actual batch size: {actual_batch_size}")
            print(f"  Batches per epoch: {len(train_loader)}")
            
        except Exception as e:
            print(f" ERROR creating data loader: {e}")
            sys.exit(1)
        
        # ============================================================================
        # CREATE OPTIMIZERS
        # ============================================================================
        print(f"\\nCreating optimizers...")
        try:
            optimizer_g = OptimizerFactory.create_optimizer(generator, full_config, 'generator')
            optimizer_d = OptimizerFactory.create_optimizer(discriminator, full_config, 'discriminator')
            print("✓ Optimizers created")
        except Exception as e:
            print(f" ERROR creating optimizers: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # TRAINING - DIFFERENT PATHS FOR DIFFERENT ALGORITHMS
        # ============================================================================
        print(f"\\n{'='*60}")
        print(f"STARTING {training_mode.upper()} TRAINING")
        print(f"{'='*60}")
        
        # Training results
        training_history = {
            'training_mode': training_mode,
            'algorithm': algorithm,
            'model_type': 'dcgan',
            'block_results': [],
            'loss_entries': [],
            'generated_images': []
        }
        
        # For images
        generated_images_info = []
        all_epoch_images = []
        
        # Initial images
        print(f"\\nGenerating initial images (before training)...")
        initial_images, initial_grid, initial_base64 = save_and_encode_images(
            generator, device, epoch=0, num_images=16, save_dir="/tmp/generated_images"
        )
        
        # Upload initial grid
        bearer_token = args.bearer_token
        initial_grid_url = upload_to_cdn(
            initial_grid, 
            "Initial generated images grid", 
            bearer_token, args.domain, args.get_cdn
        )
        
        generated_images_info.append({
            'epoch': 0,
            'grid_url': initial_grid_url,
            'description': 'Initial images before training',
            'base64_previews': initial_base64[:4],
            'uid': str(uuid.uuid4())
        })
        
        print(f"\\nInitial images saved")
        if initial_grid_url:
            print(f"Initial grid URL: {initial_grid_url}")
        
        # ============================================================================
        # ALGORITHM-SPECIFIC TRAINING
        # ============================================================================
        
        if algorithm == 'cafo':
            print(f"\\nStarting CAFO training...")
            
            # Use real CAFO training
            epochs_per_block = gan_cfg['generator'].get('cafo_epochs_per_block', 2)
            results = train_cafo_real(generator, discriminator, train_loader, device, epochs_per_block)
            
            if not results['loss_entries']:
                print("ERROR: CAFO training failed - no loss entries recorded")
                sys.exit(1)
                
            training_history['block_results'] = results.get('block_results', [])
            training_history['loss_entries'] = results['loss_entries']
            
            print(f"CAFO training completed: {results.get('total_blocks', 0)} blocks trained")
            
        elif algorithm == 'forward_forward':
            print(f"\\nStarting Forward-Forward training...")
            
            # Use real FF training
            epochs_per_block = gan_cfg['discriminator'].get('ff_epochs_per_block', 2)
            ff_threshold = gan_cfg['discriminator'].get('ff_theta', 2.0)
            
            results = train_forward_forward_real(generator, discriminator, train_loader, device, epochs_per_block, ff_threshold)
            
            if not results['loss_entries']:
                print("ERROR: Forward-Forward training failed - no loss entries recorded")
                sys.exit(1)
                
            training_history['block_results'] = results.get('block_results', [])
            training_history['loss_entries'] = results['loss_entries']
            
            print(f"Forward-Forward training completed: {results.get('total_blocks', 0)} blocks trained")
            
        else:  # backprop
            print(f"\\nStarting Backpropagation training...")
            
            # Use real backprop training
            results = train_backprop_real(generator, discriminator, train_loader, optimizer_g, optimizer_d, device, epochs)
            
            if not results['loss_entries']:
                print("ERROR: Backprop training failed - no loss entries recorded")
                sys.exit(1)
                
            training_history['loss_entries'] = results['loss_entries']
            
            print(f"Backprop training completed: {len(results['loss_entries'])} loss entries recorded")
        
        # ============================================================================
        # GENERATE FINAL IMAGES
        # ============================================================================
        print(f"\\nGenerating final images...")
        final_images, final_grid, final_base64 = save_and_encode_images(
            generator, device, epoch=999, num_images=16, save_dir="/tmp/generated_images"
        )
        
        final_grid_url = upload_to_cdn(
            final_grid, 
            "Final generated images grid", 
            bearer_token, args.domain, args.get_cdn
        )
        
        generated_images_info.append({
            'epoch': 999,
            'grid_url': final_grid_url,
            'description': 'Final images after training',
            'base64_previews': final_base64[:4],
            'uid': str(uuid.uuid4())
        })
        
        all_epoch_images.extend(final_images)
        training_history['generated_images'] = generated_images_info
        
        # ============================================================================
        # SAVE ALL OUTPUTS
        # ============================================================================
        print("\\nSaving outputs...")
        
        try:
            # Save trained model
            os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
            
            checkpoint = {
                'generator_state_dict': generator.state_dict(),
                'discriminator_state_dict': discriminator.state_dict(),
                'optimizer_g_state_dict': optimizer_g.state_dict(),
                'optimizer_d_state_dict': optimizer_d.state_dict(),
                'config': full_config,
                'training_mode': training_mode,
                'algorithm': algorithm,
                'training_history': training_history,
                'generated_images_info': generated_images_info,
                'model_info': {
                    'generator_params': sum(p.numel() for p in generator.parameters()),
                    'discriminator_params': sum(p.numel() for p in discriminator.parameters()),
                    'z_dim': generator.z_dim,
                    'image_size': generator.image_size,
                    'channels': generator.image_channels
                }
            }
            
            torch.save(checkpoint, args.trained_model)
            print(f"✓ Model saved to: {args.trained_model}")
            
            # Save training history
            os.makedirs(os.path.dirname(args.training_history), exist_ok=True)
            with open(args.training_history, "w") as f:
                json.dump(training_history, f, indent=2)
            print(f"✓ Training history saved to: {args.training_history}")
            
            # Create processed history
            os.makedirs(os.path.dirname(args.processed_history_json), exist_ok=True)
            
            # Prepare data for processed history
            processed_data = []
            for entry in training_history['loss_entries']:
                row = {
                    "epoch": entry.get('epoch', 1),
                    "loss": entry['loss'],
                    "component": entry['component'],
                    "type": "train",
                    "training_mode": entry['training_mode'],
                    "uid": entry['uid']
                }
                if 'block' in entry:
                    row["block"] = entry['block']
                processed_data.append(row)
            
            # Get final losses
            final_g_loss = next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'generator'), 0.0)
            final_d_loss = next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'discriminator'), 0.0)
            
            output = {
                "training_completed": True,
                "model_type": "dcgan",
                "training_mode": training_mode,
                "algorithm": algorithm,
                "epoch": len(training_history['loss_entries']) // 2 if training_history['loss_entries'] else 0,
                "loss": final_g_loss,
                "validation_loss": final_d_loss,
                "total_epochs_trained": epochs,
                "image_grids": [img_info['grid_url'] for img_info in generated_images_info if img_info.get('grid_url')],
                "data": processed_data
            }
            
            with open(args.processed_history_json, "w") as f:
                json.dump(output, f, indent=2)
            print(f"✓ Processed history saved to: {args.processed_history_json}")
            
            # Generated images URLs
            os.makedirs(os.path.dirname(args.generated_images_urls), exist_ok=True)
            images_output = {
                "training_mode": training_mode,
                "algorithm": algorithm,
                "model_type": "dcgan",
                "total_images": len(all_epoch_images),
                "image_grids": [{"epoch": img['epoch'], "url": img['grid_url']} for img in generated_images_info if img.get('grid_url')]
            }
            with open(args.generated_images_urls, "w") as f:
                json.dump(images_output, f, indent=2)
            print(f"✓ Generated images URLs saved to: {args.generated_images_urls}")
            
            # Training images summary
            os.makedirs(os.path.dirname(args.training_images_summary), exist_ok=True)
            summary = {
                "training_completed": True,
                "model_type": "dcgan",
                "training_mode": training_mode,
                "algorithm": algorithm,
                "epochs_trained": epochs,
                "total_blocks_trained": training_history.get('total_blocks', 0),
                "final_metrics": {
                    "generator_loss": next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'generator'), 0.0),
                    "discriminator_loss": next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'discriminator'), 0.0)
                },
                "image_progress": [{
                    "epoch": img['epoch'], 
                    "grid_url": img.get('grid_url'),
                    "description": img.get('description', ''),
                    "uid": img.get('uid', '')
                } for img in generated_images_info],
                "model_info": {
                    "generator_params": sum(p.numel() for p in generator.parameters()),
                    "discriminator_params": sum(p.numel() for p in discriminator.parameters()),
                    "z_dim": generator.z_dim,
                    "image_size": generator.image_size,
                    "channels": generator.image_channels
                }
            }
            
            with open(args.training_images_summary, "w") as f:
                json.dump(summary, f, indent=2)
            print(f"✓ Training images summary saved to: {args.training_images_summary}")
            
        except Exception as e:
            print(f" ERROR saving outputs: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # FINAL SUMMARY
        # ============================================================================
        print(f"\\n{'='*80}")
        print(f"SUCCESS: {training_mode.upper()} TRAINING COMPLETED")
        print(f"{'='*80}")
        print(f"✓ Model type: DCGAN")
        print(f"✓ Training mode: {training_mode}")
        print(f"✓ Algorithm: {algorithm}")
        print(f"✓ Epochs/Blocks trained: {epochs}")
        print(f"✓ Loss entries recorded: {len(training_history['loss_entries'])}")
        print(f"✓ Images generated: {len(all_epoch_images)}")
        print(f"✓ Model saved: {args.trained_model}")
        print(f"✓ Initial images URL: {initial_grid_url}")
        print(f"✓ Final images URL: {final_grid_url}")
        
        # Print final metrics
        if training_history['loss_entries']:
            last_g_loss = next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'generator'), 0.0)
            last_d_loss = next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'discriminator'), 0.0)
            print(f"✓ Final Generator Loss: {last_g_loss:.6f}")
            print(f"✓ Final Discriminator Loss: {last_d_loss:.6f}")
        
        print(f"{'='*80}\\n")
    args:
      - --data_path
      - {inputPath: data_path}
      - --master_config
      - {inputValue: master_config}
      - --model_input
      - {inputPath: model_input}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
      - --processed_history_json
      - {outputPath: processed_history_json}
      - --generated_images_urls
      - {outputPath: generated_images_urls}
      - --training_images_summary
      - {outputPath: training_images_summary}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
