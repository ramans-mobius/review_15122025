name: Train DCGAN v28
description: Trains DCGAN with Backprop, CAFO, or Forward-Forward using EnhancedDCGANTrainer
inputs:
  - name: data_path
    type: Dataset
    description: "Processed data from CDN (GANDataWrapper)"
  - name: master_config
    type: String
    description: "Master configuration JSON"
  - name: model_input
    type: Model
    description: "Built DCGAN model from Build brick"
  - name: bearer_token
    type: String
    description: "Bearer token for CDN upload"
  - name: domain
    type: String
    description: "CDN upload domain"
  - name: get_cdn
    type: String
    description: "CDN download prefix"
  
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String
  - name: training_metrics
    type: String
  - name: generated_samples
    type: Dataset
  - name: generated_images_urls
    type: String
  - name: training_images_summary
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -c
      - |
        echo "Installing required packages..."
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        pip install pillow matplotlib > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import argparse, pickle, os, json, sys, time, uuid
        import numpy as np
        import base64
        import subprocess
        from PIL import Image
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader
        from io import BytesIO
        import matplotlib.pyplot as plt
        import warnings
        import traceback
        
        warnings.filterwarnings('ignore')
        
        # Set matplotlib backend
        import matplotlib
        matplotlib.use('Agg')
        
        # Import DCGAN
        print("Importing DCGAN modules...")
        try:
            from nesy_factory.GANs.dcgan import (
                DCGANConfig, TrainingAlgorithm,
                FullyConfigurableDCGANGenerator,
                FullyConfigurableDCGANDiscriminator,
                EnhancedDCGANTrainer,
                validate_config,
                create_dcgan,
                DCGANDataset,
                create_dataloader
            )
            print(" Successfully imported DCGAN modules")
        except ImportError as e:
            print(f" ERROR importing DCGAN: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--model_input", required=True)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        parser.add_argument("--training_metrics", required=True)
        parser.add_argument("--generated_samples", required=True)
        parser.add_argument("--generated_images_urls", required=True)
        parser.add_argument("--training_images_summary", required=True)
        parser.add_argument("--bearer_token", required=True)
        parser.add_argument("--domain", required=True)
        parser.add_argument("--get_cdn", required=True)
        args = parser.parse_args()
        
        print("\\n" + "="*80)
        print("DCGAN TRAINING WITH ENHANCED TRAINER")
        print("="*80)
        
        # ============================================================================
        # PARSE CONFIG AND SETUP
        # ============================================================================
        
        try:
            config = json.loads(args.master_config)
            gan_cfg = config['gan']
            dataset_cfg = config['dataset']
            
            # Determine training algorithm
            algorithm = gan_cfg['training'].get('algorithm', 'backprop')
            
            print(f"Training Algorithm: {algorithm.upper()}")
            print(f"Batch size: {gan_cfg['training'].get('batch_size', 16)}")
            print(f"Epochs: {gan_cfg['training'].get('epochs', 2)}")
            
        except Exception as e:
            print(f"ERROR parsing master_config: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # LOAD DATASET
        # ============================================================================
        
        try:
            # Define dataset classes for unpickling
            class GANDataset:
                def __init__(self, data_list, transform=None, image_size=64, channels=3):
                    self.data_list = data_list
                    self.transform = transform
                    self.image_size = image_size
                    self.channels = channels
                
                def __len__(self):
                    return len(self.data_list)
                
                def __getitem__(self, idx):
                    img_tensor = self.data_list[idx]
                    if self.transform:
                        img_tensor = self.transform(img_tensor)
                    return img_tensor
            
            class GANDataWrapper:
                def __init__(self, dataset, model_type='dcgan', image_size=64, channels=3, transform_params=None):
                    self.dataset = dataset
                    self.model_type = model_type
                    self.image_size = image_size
                    self.channels = channels
                    self.transform_params = transform_params or {}
                
                def __len__(self):
                    return len(self.dataset)
                
                def __getitem__(self, idx):
                    return self.dataset[idx]
            
            class SafeUnpickler(pickle.Unpickler):
                def find_class(self, module, name):
                    if name in ['GANDataWrapper', 'GANDataset']:
                        return globals()[name]
                    return super().find_class(module, name)
            
            with open(args.data_path, "rb") as f:
                data_wrapper = SafeUnpickler(f).load()
            
            if hasattr(data_wrapper, 'dataset'):
                dataset = data_wrapper.dataset
                image_size = data_wrapper.image_size
                channels = data_wrapper.channels
                print(f"\\nLoaded dataset:")
                print(f"  Samples: {len(dataset)}")
                print(f"  Image size: {image_size}")
                print(f"  Channels: {channels}")
                
                # Create DCGANDataset
                train_dataset = DCGANDataset(dataset, normalize=True)
                
            else:
                raise ValueError("Invalid data format")
            
        except Exception as e:
            print(f"ERROR loading dataset: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Create dataloader
        batch_size = gan_cfg['training'].get('batch_size', 16)
        actual_batch_size = min(batch_size, max(1, len(train_dataset)))
        dataloader = DataLoader(
            train_dataset, 
            batch_size=actual_batch_size, 
            shuffle=True, 
            drop_last=True
        )
        
        print(f"Data loader created:")
        print(f"  Dataset size: {len(train_dataset)}")
        print(f"  Batch size: {actual_batch_size}")
        print(f"  Batches per epoch: {len(dataloader)}")
        
        # ============================================================================
        # LOAD MODEL
        # ============================================================================
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Device: {device}")
        
        try:
            # Load checkpoint
            checkpoint = torch.load(args.model_input, map_location='cpu')
            
            # Extract DCGAN config
            if 'config' in checkpoint:
                config_dict = checkpoint['config']
                # Convert dict back to DCGANConfig
                dcgan_config = DCGANConfig.from_dict(config_dict)
            else:
                # Create from master config
                dcgan_config = DCGANConfig(
                    image_size=image_size,
                    channels=channels,
                    latent_dim=gan_cfg.get('generator', {}).get('latent_dim', 100),
                    batch_size=actual_batch_size,
                    epochs=gan_cfg['training'].get('epochs', 2),
                    device=device,
                    training_algorithm=TrainingAlgorithm(algorithm)
                )
            
            # Validate config
            is_valid, errors = validate_config(dcgan_config)
            if not is_valid:
                print("Config validation errors:")
                for error in errors:
                    print(f"  - {error}")
                sys.exit(1)
            
            # Create models
            generator = FullyConfigurableDCGANGenerator(dcgan_config)
            discriminator = FullyConfigurableDCGANDiscriminator(dcgan_config)
            
            # Load weights if available
            if 'generator_state_dict' in checkpoint:
                generator.load_state_dict(checkpoint['generator_state_dict'])
                print("✓ Generator weights loaded")
            if 'discriminator_state_dict' in checkpoint:
                discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                print("✓ Discriminator weights loaded")
            
            # Move to device
            generator.to(device)
            discriminator.to(device)
            
            print(f"\\nModels loaded successfully:")
            print(f"  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}")
            print(f"  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}")
            
        except Exception as e:
            print(f"ERROR loading model: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # CREATE TRAINER AND TRAIN
        # ============================================================================
        
        try:
            # Create EnhancedDCGANTrainer
            print(f"\\nCreating EnhancedDCGANTrainer...")
            trainer = EnhancedDCGANTrainer(dcgan_config)
            
            # Replace trainer's models with our loaded ones
            trainer.generator = generator
            trainer.discriminator = discriminator
            
            print(f"✓ Trainer created for {algorithm.upper()} algorithm")
            print(f"  Block training: {'Enabled' if dcgan_config.block_training.enabled else 'Disabled'}")
            
        except Exception as e:
            print(f"ERROR creating trainer: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # TRAINING
        # ============================================================================
        
        print(f"\\n" + "="*60)
        print(f"STARTING TRAINING")
        print(f"="*60)
        
        start_time = time.time()
        
        try:
            # Train
            training_result = trainer.train(dataloader)
            
            training_time = time.time() - start_time
            print(f"\\nTraining completed in {training_time:.2f}s")
            
        except Exception as e:
            print(f"ERROR during training: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # GENERATE SAMPLES
        # ============================================================================
        
        print(f"\\nGenerating samples...")
        
        def generate_and_save_samples(generator, num_samples=16, save_dir="/tmp/samples"):
            os.makedirs(save_dir, exist_ok=True)
            
            generator.eval()
            with torch.no_grad():
                z = torch.randn(num_samples, generator.latent_dim, device=device)
                samples = generator(z).cpu()
            
            # Convert from [-1, 1] to [0, 1]
            samples = (samples + 1) / 2
            
            # Save images
            image_paths = []
            for i in range(num_samples):
                img_tensor = samples[i]
                if img_tensor.shape[0] == 1:  # Grayscale
                    img = transforms.ToPILImage()(img_tensor)
                else:  # RGB
                    img = transforms.ToPILImage()(img_tensor)
                
                img_path = os.path.join(save_dir, f"sample_{i:02d}.png")
                img.save(img_path)
                image_paths.append(img_path)
            
            return image_paths, samples
        
        # Generate initial and final samples
        init_samples_path, init_samples = generate_and_save_samples(
            generator, num_samples=16, save_dir="/tmp/init_samples"
        )
        
        # Generate final samples with trained generator
        final_samples_path, final_samples = generate_and_save_samples(
            trainer.generator, num_samples=16, save_dir="/tmp/final_samples"
        )
        
        # ============================================================================
        # CDN UPLOAD
        # ============================================================================
        
        def upload_to_cdn(file_path, description, bearer_token, domain, get_cdn_prefix):
            if not os.path.exists(file_path):
                return None
            
            file_size = os.path.getsize(file_path)
            print(f"  Uploading {description} ({file_size:,} bytes)...")
            
            upload_url = f"{domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fdcgan%2F"
            
            curl_command = [
                "curl",
                "--location", upload_url,
                "--header", f"Authorization: Bearer {bearer_token}",
                "--form", f"file=@{file_path}",
                "--fail",
                "--show-error",
                "--connect-timeout", "30",
                "--max-time", "120"
            ]
            
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                response_json = json.loads(process.stdout)
                relative_cdn_url = response_json.get("cdnUrl", "")
                
                if not relative_cdn_url:
                    print(f"    Error: No cdnUrl in response")
                    return None
                
                full_url = f"{get_cdn_prefix}{relative_cdn_url}"
                print(f"    Uploaded: {full_url}")
                return full_url
                
            except subprocess.CalledProcessError as e:
                print(f"    Upload error: {e.stderr[:200]}")
                return None
            except json.JSONDecodeError:
                return None
        
        # Read bearer token
        with open(args.bearer_token, 'r') as f:
            bearer_token = f.read().strip()
        
        # Create sample grid
        def create_sample_grid(samples, title, save_path):
            n_cols = 4
            n_rows = 4
            fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 12))
            axes = axes.flatten()
            
            for i in range(min(16, len(samples))):
                ax = axes[i]
                if samples[i].shape[0] == 1:
                    ax.imshow(samples[i][0], cmap='gray', vmin=0, vmax=1)
                else:
                    ax.imshow(samples[i].permute(1, 2, 0))
                ax.axis('off')
                ax.set_title(f"Sample {i+1}")
            
            for i in range(min(16, len(samples)), len(axes)):
                axes[i].axis('off')
            
            plt.suptitle(title, fontsize=16)
            plt.tight_layout()
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
        
        # Create and upload sample grids
        init_grid_path = "/tmp/init_grid.png"
        create_sample_grid(init_samples, "Initial Samples (Before Training)", init_grid_path)
        init_grid_url = upload_to_cdn(
            init_grid_path, "Initial samples grid", 
            bearer_token, args.domain, args.get_cdn
        )
        
        final_grid_path = "/tmp/final_grid.png"
        create_sample_grid(final_samples, "Final Samples (After Training)", final_grid_path)
        final_grid_url = upload_to_cdn(
            final_grid_path, "Final samples grid", 
            bearer_token, args.domain, args.get_cdn
        )
        
        # ============================================================================
        # CREATE OUTPUTS
        # ============================================================================
        
        print(f"\\nCreating outputs...")
        
        # Extract metrics from trainer
        metrics = trainer.training_history
        
        # Create training history
        training_history_data = {
            'algorithm': algorithm,
            'epochs_completed': dcgan_config.epochs,
            'total_training_time': training_time,
            'generator_losses': metrics.get('generator_losses', []),
            'discriminator_losses': metrics.get('discriminator_losses', []),
            'real_scores': metrics.get('real_scores', []),
            'fake_scores': metrics.get('fake_scores', []),
            'block_training_results': metrics.get('block_training_results', {}),
            'final_metrics': {
                'generator_loss': metrics.get('generator_losses', [-1])[-1] if metrics.get('generator_losses') else 0,
                'discriminator_loss': metrics.get('discriminator_losses', [-1])[-1] if metrics.get('discriminator_losses') else 0,
                'real_score': metrics.get('real_scores', [-1])[-1] if metrics.get('real_scores') else 0.5,
                'fake_score': metrics.get('fake_scores', [-1])[-1] if metrics.get('fake_scores') else 0.5
            }
        }
        
        # Create training metrics
        training_metrics_data = {
            'model_type': 'dcgan',
            'training_algorithm': algorithm,
            'architecture': 'fully_configurable',
            'epochs_completed': dcgan_config.epochs,
            'final_generator_loss': training_history_data['final_metrics']['generator_loss'],
            'final_discriminator_loss': training_history_data['final_metrics']['discriminator_loss'],
            'final_real_score': training_history_data['final_metrics']['real_score'],
            'final_fake_score': training_history_data['final_metrics']['fake_score'],
            'total_training_time': training_time,
            'samples_generated': 16,
            'training_success': True,
            'image_size': image_size,
            'channels': channels,
            'latent_dim': generator.latent_dim,
            'batch_size': actual_batch_size,
            'device': str(device),
            'block_training_enabled': dcgan_config.block_training.enabled
        }
        
        # Prepare generated samples for output
        generated_samples_data = []
        for i, (img_path, sample) in enumerate(zip(final_samples_path, final_samples)):
            with open(img_path, 'rb') as f:
                img_data = f.read()
            
            generated_samples_data.append({
                'sample_id': i,
                'image_data': base64.b64encode(img_data).decode('utf-8'),
                'image_tensor': sample.numpy().tolist(),
                'filename': f'dcgan_{algorithm}_sample_{i}.png'
            })
        
        # Generated images URLs
        generated_images_urls_data = {
            'algorithm': algorithm,
            'model_type': 'dcgan',
            'image_grids': [
                {
                    'phase': 'initial',
                    'url': init_grid_url if init_grid_url else '',
                    'description': 'Initial samples before training'
                },
                {
                    'phase': 'final',
                    'url': final_grid_url if final_grid_url else '',
                    'description': 'Final samples after training'
                }
            ]
        }
        
        # Training images summary
        training_images_summary_data = {
            'training_completed': True,
            'algorithm': algorithm,
            'epochs_trained': dcgan_config.epochs,
            'final_metrics': training_history_data['final_metrics'],
            'image_grid_urls': generated_images_urls_data['image_grids']
        }
        
        # Create trained model checkpoint
        trained_checkpoint = {
            'config': dcgan_config.to_dict(),
            'generator_state_dict': trainer.generator.state_dict(),
            'discriminator_state_dict': trainer.discriminator.state_dict(),
            'trainer_state': {
                'current_epoch': dcgan_config.epochs,
                'current_step': trainer.current_step,
                'training_history': trainer.training_history
            },
            'training_history': training_history_data,
            'training_metrics': training_metrics_data,
            'algorithm': algorithm,
            'epochs_trained': dcgan_config.epochs,
            'master_config': config
        }
        
        # ============================================================================
        # SAVE OUTPUTS
        # ============================================================================
        
        try:
            # Save trained model
            os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
            torch.save(trained_checkpoint, args.trained_model)
            print(f"✓ Trained model saved: {args.trained_model}")
            
            # Save training history
            with open(args.training_history, 'w') as f:
                json.dump(training_history_data, f, indent=2)
            print(f"✓ Training history saved: {args.training_history}")
            
            # Save training metrics
            with open(args.training_metrics, 'w') as f:
                json.dump(training_metrics_data, f, indent=2)
            print(f"✓ Training metrics saved: {args.training_metrics}")
            
            # Save generated samples
            with open(args.generated_samples, 'wb') as f:
                pickle.dump(generated_samples_data, f)
            print(f"✓ Generated samples saved: {args.generated_samples}")
            
            # Save generated images URLs
            with open(args.generated_images_urls, 'w') as f:
                json.dump(generated_images_urls_data, f, indent=2)
            print(f"✓ Generated images URLs saved: {args.generated_images_urls}")
            
            # Save training images summary
            with open(args.training_images_summary, 'w') as f:
                json.dump(training_images_summary_data, f, indent=2)
            print(f"✓ Training images summary saved: {args.training_images_summary}")
            
        except Exception as e:
            print(f"ERROR saving outputs: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # FINAL SUMMARY
        # ============================================================================
        
        print(f"\\n" + "="*80)
        print(f"TRAINING COMPLETED SUCCESSFULLY!")
        print("="*80)
        print(f"Algorithm: {algorithm.upper()}")
        print(f"Epochs: {dcgan_config.epochs}")
        print(f"Total time: {training_time:.2f}s")
        print(f"Final Generator Loss: {training_history_data['final_metrics']['generator_loss']:.4f}")
        print(f"Final Discriminator Loss: {training_history_data['final_metrics']['discriminator_loss']:.4f}")
        print(f"Final Real Score: {training_history_data['final_metrics']['real_score']:.3f}")
        print(f"Final Fake Score: {training_history_data['final_metrics']['fake_score']:.3f}")
        print(f"Samples generated: {len(generated_samples_data)}")
        print(f"Initial images URL: {init_grid_url if init_grid_url else 'Not uploaded'}")
        print(f"Final images URL: {final_grid_url if final_grid_url else 'Not uploaded'}")
        print("="*80)

    args:
      - --data_path
      - {inputPath: data_path}
      - --master_config
      - {inputValue: master_config}
      - --model_input
      - {inputPath: model_input}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
      - --training_metrics
      - {outputPath: training_metrics}
      - --generated_samples
      - {outputPath: generated_samples}
      - --generated_images_urls
      - {outputPath: generated_images_urls}
      - --training_images_summary
      - {outputPath: training_images_summary}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
