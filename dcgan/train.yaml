name: Train DCGAN v39 - WITH BLOCK TRAINING AND CONTINUAL LEARNING
description: Trains DCGAN with Block Training for CAFO/FF and Adversarial Training, with optional Continual Learning via Experience Replay
inputs:
  - name: data_path
    type: Dataset
    description: "Processed data from CDN (Pickle file)"
  - name: master_config
    type: String
    description: "Master configuration JSON"
  - name: model_input
    type: Model
    description: "Built DCGAN model from Build brick"
  - name: bearer_token
    type: String
    description: "Bearer token for CDN upload"
  - name: domain
    type: String
    description: "CDN upload domain"
  - name: get_cdn
    type: String
    description: "CDN download prefix"
  # Continual Learning Parameters
  - name: enable_continual_learning
    type: String
    default: "false"
    description: "Enable continual learning with experience replay"
  - name: replay_buffer_path
    type: String
    description: "Path to saved replay buffer from previous training"
  - name: replay_ratio
    type: Float
    description: "Probability of using replay per batch"
  - name: memory_capacity
    type: Integer
    description: "Maximum samples to store in replay buffer"
  
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String
  - name: training_metrics
    type: String
  - name: generated_samples
    type: Dataset
  - name: generated_images_urls
    type: String
  - name: training_images_summary
    type: String
  - name: block_training_logs
    type: String
  - name: updated_replay_buffer
    type: String
    description: "Updated replay buffer for next continual learning session"

implementation:
  container:
    image: kushagra4761/nesy-factory:t2.6v2
    command:
      - sh
      - -c
      - |
        echo "Installing required packages..."
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        pip install pillow matplotlib > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import argparse, pickle, os, json, sys, time, uuid
        import numpy as np
        import base64
        import subprocess
        from PIL import Image
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader, Dataset, TensorDataset
        from io import BytesIO
        import matplotlib.pyplot as plt
        import warnings
        import traceback
        
        warnings.filterwarnings('ignore')
        
        # Set matplotlib backend
        import matplotlib
        matplotlib.use('Agg')
        
        print("=" * 80)
        print("TRAIN DCGAN v36 - WITH BLOCK TRAINING AND CONTINUAL LEARNING")
        print("=" * 80)
        print(f"Python version: {sys.version}")
        print(f"Torch version: {torch.__version__}")
        
        # ============================================================================
        # CONTINUAL LEARNING COMPONENTS (ADDED)
        # ============================================================================
        
        class DCGANReplayBuffer:
        
            def __init__(self, capacity=500):
                self.capacity = capacity
                self.buffer = []
                self.position = 0
            
            def add_batch(self, real_images):
                
                if not isinstance(real_images, torch.Tensor):
                    return
                
                batch_size = real_images.size(0)
                for i in range(batch_size):
                    img = real_images[i].unsqueeze(0)  # Keep as [1, C, H, W]
                    
                    if len(self.buffer) < self.capacity:
                        self.buffer.append(img)
                    else:
                        self.buffer[self.position] = img
                    
                    self.position = (self.position + 1) % self.capacity
            
            def sample(self, batch_size):
           
                if len(self.buffer) == 0:
                    return None
                
                actual_size = min(batch_size, len(self.buffer))
                indices = np.random.choice(len(self.buffer), actual_size, replace=False)
                samples = [self.buffer[i] for i in indices]
                
                return torch.cat(samples, dim=0)
            
            def save(self, path):
             
                with open(path, 'wb') as f:
                    pickle.dump({
                        'buffer': self.buffer,
                        'capacity': self.capacity,
                        'position': self.position
                    }, f)
            
            def load(self, path):
                
                if os.path.exists(path):
                    with open(path, 'rb') as f:
                        data = pickle.load(f)
                        self.buffer = data['buffer']
                        self.capacity = data.get('capacity', 500)
                        self.position = data.get('position', 0)
            
            def __len__(self):
                return len(self.buffer)
        
        # ============================================================================
        # CREATE ALL NECESSARY CLASS DEFINITIONS FROM PREVIOUS BRICKS
        # ============================================================================
        
        print("\\n" + "-" * 40)
        print("DEFINING COMPATIBILITY CLASSES")
        print("-" * 40)
        
        # From Preprocess v1 brick - CRITICAL FOR LOADING DATA
        class PreprocessedDataset:
            def __init__(self, images, labels, dataset_name, preprocessor_params):
                self.images = images
                self.labels = labels
                self.dataset_name = dataset_name
                self.preprocessed = True
                self.preprocessor_params = preprocessor_params
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx],
                    'index': idx,
                    'dataset': self.dataset_name,
                    'preprocessed': True,
                    'preprocessor_params': self.preprocessor_params
                }
        
        # From Load Raw Dataset v1 brick
        class RawDatasetWrapper:
            def __init__(self, images, labels, dataset_name='mnist'):
                self.images = images  # Raw images
                self.labels = labels  # Raw labels
                self.dataset_name = dataset_name
                self.preprocessed = False  # Mark as raw
                self._num_samples = len(images)
            
            def __len__(self):
                return self._num_samples
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx],
                    'index': idx,
                    'dataset': self.dataset_name,
                    'preprocessed': self.preprocessed
                }
        
        class DatasetInfoWrapper:
            def __init__(self, info_dict):
                self.__dict__.update(info_dict)
        
        # Local wrapper classes for data compatibility
        class ProcessedDatasetWrapper:
            def __init__(self, images, labels=None):
                self.images = images
                self.labels = labels
                self.preprocessed = True
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx] if self.labels is not None else 0,
                    'index': idx,
                    'preprocessed': True
                }
        
        class SimpleDCGANDataset(Dataset):
            def __init__(self, images, normalize=False):
                self.images = images
                self.normalize = normalize
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                img = self.images[idx]
                if self.normalize:
                    # Already normalized from [-1, 1] in preprocess
                    return img
                return img
        
        print("COMPATIBILITY: Compatibility classes defined")
        
        # ============================================================================
        # IMPORT DCGAN WITH FALLBACKS
        # ============================================================================
        
        print("\\n" + "-" * 40)
        print("IMPORTING DCGAN MODULES")
        print("-" * 40)
        
        # First, let's see what's available
        try:
            import nesy_factory.GANs.dcgan as dcgan_module
            print("SUCCESS: Successfully imported nesy_factory.GANs.dcgan")
            
            # Check what's available
            available_attrs = [attr for attr in dir(dcgan_module) if not attr.startswith('_')]
            print(f"INFO: Available attributes ({len(available_attrs)}):")
            for i in range(0, len(available_attrs), 10):
                print(f"   {', '.join(available_attrs[i:i+10])}")
            
            # Try to import specific classes with fallbacks
            try:
                from nesy_factory.GANs.dcgan import DCGANConfig
                print("  IMPORT: DCGANConfig imported")
            except ImportError:
                print("   WARNING: DCGANConfig not found, will create config manually")
                DCGANConfig = None
            
            try:
                from nesy_factory.GANs.dcgan import TrainingAlgorithm
                print("  IMPORT: TrainingAlgorithm imported")
            except ImportError:
                print("   WARNING: TrainingAlgorithm not found")
                TrainingAlgorithm = None
            
            try:
                from nesy_factory.GANs.dcgan import EnhancedDCGANTrainer
                print("  IMPORT: EnhancedDCGANTrainer imported")
            except ImportError:
                print("   ERROR: EnhancedDCGANTrainer not found - this is critical!")
                EnhancedDCGANTrainer = None
            
            try:
                from nesy_factory.GANs.dcgan import validate_config
                print("  IMPORT: validate_config imported")
            except ImportError:
                print("   WARNING: validate_config not found")
                validate_config = None
            
            try:
                from nesy_factory.GANs.dcgan import DCGANDataset
                print("  IMPORT: DCGANDataset imported")
            except ImportError:
                print("   WARNING: DCGANDataset not found, using SimpleDCGANDataset")
                DCGANDataset = SimpleDCGANDataset
            
        except ImportError as e:
            print(f"ERROR: importing nesy_factory: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # MAIN CODE
        # ============================================================================
        
        parser = argparse.ArgumentParser()
        # Existing parameters
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--model_input", required=True)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        parser.add_argument("--training_metrics", required=True)
        parser.add_argument("--generated_samples", required=True)
        parser.add_argument("--generated_images_urls", required=True)
        parser.add_argument("--training_images_summary", required=True)
        parser.add_argument("--block_training_logs", required=True)
        parser.add_argument("--bearer_token", required=True)
        parser.add_argument("--domain", required=True)
        parser.add_argument("--get_cdn", required=True)
        # Continual Learning parameters (ADDED)
        parser.add_argument("--enable_continual_learning", type=str, default="false")
        parser.add_argument("--replay_buffer_path", type=str, default="")
        parser.add_argument("--replay_ratio", type=float, default=0.3)
        parser.add_argument("--memory_capacity", type=int, default=500)
        parser.add_argument("--updated_replay_buffer", required=True)
        args = parser.parse_args()
        
        print("\\n" + "="*80)
        print("DCGAN TRAINING v36 - WITH CONTINUAL LEARNING")
        print("="*80)
        
        # ============================================================================
        # SETUP CONTINUAL LEARNING (ADDED)
        # ============================================================================
        
        enable_cl = args.enable_continual_learning.lower() == 'true'
        replay_ratio = float(args.replay_ratio)
        memory_capacity = int(args.memory_capacity)
        replay_buffer = None
        
        if enable_cl:
            print(f" CONTINUAL LEARNING ENABLED")
            print(f"   Replay ratio: {replay_ratio}")
            print(f"   Memory capacity: {memory_capacity}")
            print(f"   Replay buffer path: {args.replay_buffer_path}")
            
            # Initialize replay buffer
            replay_buffer = DCGANReplayBuffer(capacity=memory_capacity)
            
            # Load existing buffer if provided
            if args.replay_buffer_path and os.path.exists(args.replay_buffer_path):
                try:
                    replay_buffer.load(args.replay_buffer_path)
                    print(f"    Loaded {len(replay_buffer)} samples from replay buffer")
                except Exception as e:
                    print(f"    Could not load replay buffer: {e}")
                    print("   Starting with empty buffer")
            else:
                print("   Starting with empty replay buffer")
        else:
            print(" STANDARD TRAINING (Continual Learning disabled)")
        
        # ============================================================================
        # CREATE ALL OUTPUT DIRECTORIES FIRST
        # ============================================================================
        print("\\n" + "-" * 40)
        print("CREATING OUTPUT DIRECTORIES")
        print("-" * 40)
        
        output_paths = [
            args.trained_model,
            args.training_history,
            args.training_metrics,
            args.generated_samples,
            args.generated_images_urls,
            args.training_images_summary,
            args.block_training_logs,
            args.updated_replay_buffer  # ADDED
        ]
        
        for path in output_paths:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    print(f"  DIRECTORY: Created: {dir_path}")
        
        # ============================================================================
        # PARSE CONFIG AND SETUP
        # ============================================================================
        
        print("\\n" + "-" * 40)
        print("PARSING MASTER CONFIG")
        print("-" * 40)
        
        try:
            config = json.loads(args.master_config)
            gan_cfg = config['gan']
            dataset_cfg = config['dataset']
            
            # Determine training algorithm
            algorithm = gan_cfg['training'].get('algorithm', 'backprop')
            epochs = gan_cfg['training'].get('epochs', 2)
            batch_size = gan_cfg['training'].get('batch_size', 16)
            
            print(f"CONFIG: Training Algorithm: {algorithm.upper()}")
            print(f"CONFIG: Epochs: {epochs}")
            print(f"CONFIG: Batch size: {batch_size}")
            
        except Exception as e:
            print(f"ERROR: parsing master_config: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # LOAD DATASET - COMPATIBLE WITH PREPROCESS v1 OUTPUT
        # ============================================================================
        
        print("\\n" + "-" * 40)
        print("LOADING DATASET")
        print("-" * 40)
        
        try:
            print(f"LOADING: Loading dataset from: {args.data_path}")
            
            # Check if file exists
            if not os.path.exists(args.data_path):
                print(f"ERROR: Data file does not exist: {args.data_path}")
                sys.exit(1)
            
            # List all pickle files in directory if it's a directory
            if os.path.isdir(args.data_path):
                print(f"LOADING: {args.data_path} is a directory, looking for pickle files...")
                pickle_files = [f for f in os.listdir(args.data_path) if f.endswith('.pkl') or f.endswith('.pickle')]
                if pickle_files:
                    data_file = os.path.join(args.data_path, pickle_files[0])
                    print(f"LOADING: Found pickle file: {data_file}")
                else:
                    print(f"ERROR: No pickle files found in directory")
                    sys.exit(1)
            else:
                data_file = args.data_path
            
            file_size = os.path.getsize(data_file)
            print(f"LOADING: File size: {file_size:,} bytes ({file_size/1024:.1f} KB)")
            
            # Load processed data from Preprocess v1
            print("LOADING: Loading pickle file...")
            with open(data_file, 'rb') as f:
                try:
                    data_wrapper = pickle.load(f)
                    print(f"SUCCESS: Pickle loaded successfully")
                except Exception as e:
                    print(f"ERROR: Failed to load pickle: {e}")
                    traceback.print_exc()
                    sys.exit(1)
            
            print(f"INFO: Data wrapper type: {type(data_wrapper)}")
            print(f"INFO: Available attributes: {[a for a in dir(data_wrapper) if not a.startswith('_')]}")
            
            # Handle different data wrapper types from preprocess brick
            if isinstance(data_wrapper, PreprocessedDataset):
                print("DETECTED: PreprocessedDataset type")
                images = data_wrapper.images
                labels = data_wrapper.labels if hasattr(data_wrapper, 'labels') else None
                
            elif hasattr(data_wrapper, 'images'):
                print("DETECTED: wrapper with 'images' attribute")
                images = data_wrapper.images
                labels = data_wrapper.labels if hasattr(data_wrapper, 'labels') else None
            else:
                print("WARNING: Unknown data format, trying to extract images...")
                # Try to extract images directly
                if hasattr(data_wrapper, '__len__'):
                    images_list = []
                    for i in range(min(10, len(data_wrapper))):  # Sample first 10
                        try:
                            img = data_wrapper[i]
                            if isinstance(img, torch.Tensor):
                                images_list.append(img)
                            elif isinstance(img, (list, tuple, np.ndarray)):
                                images_list.append(torch.tensor(img))
                        except:
                            pass
                    
                    if images_list:
                        images = torch.stack(images_list) if len(images_list) > 1 else images_list[0].unsqueeze(0)
                        labels = None
                    else:
                        print(f"ERROR: Could not extract images from dataset")
                        sys.exit(1)
                else:
                    print(f"ERROR: Unsupported data format")
                    sys.exit(1)
            
            # Check tensor shape and convert to proper format
            if isinstance(images, torch.Tensor):
                if images.dim() == 4:
                    # Shape: (N, C, H, W)
                    images_list = [images[i] for i in range(len(images))]
                    channels = images.shape[1]
                    image_size = images.shape[2]
                elif images.dim() == 3:
                    # Shape: (N, H, W) - add channel dimension
                    images_list = [images[i].unsqueeze(0) for i in range(len(images))]
                    channels = 1
                    image_size = images.shape[1]
                else:
                    print(f"ERROR: Unexpected tensor shape: {images.shape}")
                    sys.exit(1)
            else:
                print(f"ERROR: images is not a tensor, type: {type(images)}")
                sys.exit(1)
            
            print(f"SUCCESS: Dataset loaded successfully:")
            print(f"   SAMPLES: Samples: {len(images_list)}")
            print(f"   SHAPE: Image shape: {images_list[0].shape}")
            print(f"   CHANNELS: Channels: {channels}")
            print(f"   SIZE: Image size: {image_size}")
            print(f"   RANGE: Value range: [{images_list[0].min():.3f}, {images_list[0].max():.3f}]")
            
        except Exception as e:
            print(f"ERROR: loading dataset: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Create dataset for training
        if DCGANDataset is not None:
            print("DATASET: Using DCGANDataset for training")
            train_dataset = DCGANDataset(images_list, normalize=False)
        else:
            print("DATASET: Using SimpleDCGANDataset for training")
            train_dataset = SimpleDCGANDataset(images_list, normalize=False)
        
        # Create dataloader
        actual_batch_size = min(batch_size, max(1, len(train_dataset)))
        dataloader = DataLoader(
            train_dataset, 
            batch_size=actual_batch_size, 
            shuffle=True, 
            drop_last=True,
            num_workers=0
        )
        
        print(f"\\nDATALOADER: Data loader created:")
        print(f"   SIZE: Dataset size: {len(train_dataset)}")
        print(f"   BATCH: Batch size: {actual_batch_size}")
        print(f"   BATCHES: Batches per epoch: {len(dataloader)}")
        
        # ============================================================================
        # LOAD MODEL AND SETUP TRAINER
        # ============================================================================
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"\\n" + "-" * 40)
        print(f"DEVICE SETUP")
        print("-" * 40)
        print(f"DEVICE: Device: {device}")
        if torch.cuda.is_available():
            print(f"CUDA: CUDA Device: {torch.cuda.get_device_name(0)}")
            print(f"CUDA: CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        
        try:
            # Check if model file exists
            if not os.path.exists(args.model_input):
                print(f"ERROR: Model file does not exist: {args.model_input}")
                sys.exit(1)
            
            model_file_size = os.path.getsize(args.model_input)
            print(f"MODEL: Model file size: {model_file_size:,} bytes ({model_file_size/1024**2:.2f} MB)")
            
            # Load checkpoint
            print(f"LOADING: Loading model from: {args.model_input}")
            checkpoint = torch.load(args.model_input, map_location='cpu')
            
            # Extract model info
            if 'model_info' in checkpoint:
                model_info = checkpoint['model_info']
                print(f"MODEL INFO: Model source: {model_info.get('model_source', 'unknown')}")
                print(f"MODEL INFO: Model type: {model_info.get('model_type', 'unknown')}")
            
            # Check if we need to create config from scratch
            if EnhancedDCGANTrainer is None:
                print("ERROR: EnhancedDCGANTrainer is not available")
                sys.exit(1)
            
            # Create config for trainer
            trainer = None
            dcgan_config = None
            
            if 'config' in checkpoint and checkpoint['config'] is not None:
                dcgan_config = checkpoint['config']
                print(f"CONFIG: Using config from checkpoint (type: {type(dcgan_config)})")
                
                # Check if config is a DCGANConfig dataclass (not a dict)
                if hasattr(dcgan_config, '__dataclass_fields__'):
                    # It's a dataclass - update attributes directly
                    print("CONFIG: Config is a dataclass, updating attributes...")
                    
                    # Update training parameters - use attribute access for dataclass
                    if hasattr(dcgan_config, 'epochs'):
                        dcgan_config.epochs = epochs
                    if hasattr(dcgan_config, 'batch_size'):
                        dcgan_config.batch_size = actual_batch_size
                    if hasattr(dcgan_config, 'device'):
                        dcgan_config.device = str(device)
                    
                    # Validate config if available
                    if validate_config is not None:
                        is_valid, errors = validate_config(dcgan_config)
                        if not is_valid:
                            print("WARNING: Config validation warnings:")
                            for error in errors:
                                print(f"  WARNING: {error}")
                    
                    # Create trainer with config
                    try:
                        trainer = EnhancedDCGANTrainer(dcgan_config)
                        print("TRAINER: EnhancedDCGANTrainer created with config from checkpoint")
                    except Exception as e:
                        print(f"WARNING: Could not create EnhancedDCGANTrainer with checkpoint config: {e}")
                        print("WARNING: Creating trainer with default config")
                        trainer = EnhancedDCGANTrainer()
                        
                elif isinstance(dcgan_config, dict):
                    # It's a dictionary - need to convert to DCGANConfig
                    print("CONFIG: Config is a dictionary, converting to DCGANConfig...")
                    
                    # Update config dictionary with training parameters
                    dcgan_config['epochs'] = epochs
                    dcgan_config['batch_size'] = actual_batch_size
                    dcgan_config['device'] = str(device)
                    
                    # Try to create DCGANConfig from dict
                    if DCGANConfig is not None:
                        try:
                            if hasattr(DCGANConfig, 'from_dict'):
                                dcgan_config_obj = DCGANConfig.from_dict(dcgan_config)
                                print("CONFIG: DCGANConfig created using from_dict()")
                                
                                # Create trainer with config
                                trainer = EnhancedDCGANTrainer(dcgan_config_obj)
                                print("TRAINER: EnhancedDCGANTrainer created with config from dict")
                            else:
                                # Fallback: create trainer with minimal config
                                print("WARNING: DCGANConfig.from_dict not available")
                                trainer = EnhancedDCGANTrainer()
                        except Exception as e:
                            print(f"WARNING: Error creating DCGANConfig from dict: {e}")
                            trainer = EnhancedDCGANTrainer()
                    else:
                        print("WARNING: DCGANConfig not available")
                        trainer = EnhancedDCGANTrainer()
                else:
                    print(f"WARNING: Unknown config type: {type(dcgan_config)}")
                    trainer = EnhancedDCGANTrainer()
            else:
                # Create minimal trainer
                print("WARNING: No config in checkpoint, creating trainer with minimal configuration...")
                trainer = EnhancedDCGANTrainer()
            
            # Load weights if available
            if 'generator_state_dict' in checkpoint:
                trainer.generator.load_state_dict(checkpoint['generator_state_dict'])
                print("WEIGHTS: Generator weights loaded")
            else:
                print("WARNING: No generator_state_dict in checkpoint")
            
            if 'discriminator_state_dict' in checkpoint:
                trainer.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                print("WEIGHTS: Discriminator weights loaded")
            else:
                print("WARNING: No discriminator_state_dict in checkpoint")
            
            # Set latent dim for sampling
            if hasattr(trainer.generator, 'latent_dim'):
                latent_dim = trainer.generator.latent_dim
            else:
                latent_dim = 100
            
            # Move models to device
            trainer.generator = trainer.generator.to(device)
            trainer.discriminator = trainer.discriminator.to(device)
            
            print(f"SUCCESS: Trainer setup complete")
            print(f"  ALGORITHM: Algorithm: {algorithm.upper()}")
            print(f"  LATENT DIM: Latent dim: {latent_dim}")
            print(f"  GENERATOR PARAMS: Generator parameters: {sum(p.numel() for p in trainer.generator.parameters()):,}")
            print(f"  DISCRIMINATOR PARAMS: Discriminator parameters: {sum(p.numel() for p in trainer.discriminator.parameters()):,}")
            
        except Exception as e:
            print(f"ERROR: setting up trainer: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # PHASE 1: BLOCK TRAINING (For CAFO and Forward-Forward)
        # ============================================================================
        
        block_training_results = {}
        
        # Check if block training should be enabled
        should_do_block_training = False
        if algorithm in ['cafo', 'forward_forward']:
            if hasattr(trainer.config, 'block_training'):
                if trainer.config.block_training.enabled:
                    should_do_block_training = True
            elif hasattr(trainer.config, 'use_cafo') and algorithm == 'cafo':
                should_do_block_training = True
            elif hasattr(trainer.config, 'use_forward_forward') and algorithm == 'forward_forward':
                should_do_block_training = True
        
        if should_do_block_training:
            print(f"\\n" + "="*60)
            print(f"PHASE 1: BLOCK-WISE PRE-TRAINING")
            print(f"Algorithm: {algorithm.upper()}")
            print("="*60)
            
            try:
                # Call the block training method from test script
                if hasattr(trainer, 'train_blocks_with_logging'):
                    print("TRAINING: Starting block training with logging...")
                    block_training_results = trainer.train_blocks_with_logging(dataloader)
                elif hasattr(trainer, 'train_blocks'):
                    print("TRAINING: Starting block training...")
                    block_training_results = trainer.train_blocks(dataloader)
                else:
                    print("WARNING: Block training methods not available in trainer")
                    # Try to manually implement block training
                    print("INFO: Using manual block training...")
                    
                    # Get block training config
                    if hasattr(trainer.config, 'block_training'):
                        block_config = trainer.config.block_training
                    else:
                        # Default block config
                        block_config = type('BlockConfig', (), {
                            'num_blocks': 3,
                            'epochs_per_block': 1,
                            'block_learning_rate': 0.001,
                            'freeze_previous_blocks': True,
                            'train_generator_blocks': True,
                            'train_discriminator_blocks': True
                        })()
                    
                    # Manual block training loop
                    num_blocks = min(block_config.num_blocks, 
                                   len(trainer.generator.blocks),
                                   len(trainer.discriminator.blocks))
                    
                    block_training_results = {
                        'generator_blocks': [],
                        'discriminator_blocks': [],
                        'total_time': 0.0
                    }
                    
                    start_time = time.time()
                    
                    # Train generator blocks
                    if block_config.train_generator_blocks:
                        print(f"\\n PRE-TRAINING GENERATOR BLOCKS (0 to {num_blocks-1}):")
                        
                        for block_idx in range(num_blocks):
                            print(f"\\n--- Generator Block {block_idx+1}/{num_blocks} ---")
                            
                            # Freeze previous blocks if configured
                            if block_config.freeze_previous_blocks and block_idx > 0:
                                for i in range(block_idx):
                                    trainer.generator.freeze_block(i)
                            
                            # Create optimizer for this block
                            block = trainer.generator.blocks[block_idx]
                            block_params = block.get_trainable_params() if hasattr(block, 'get_trainable_params') else block.parameters()
                            
                            if block_params:
                                optimizer = torch.optim.Adam(block_params, lr=block_config.block_learning_rate)
                                
                                # Training loop for this block
                                block_losses = []
                                for epoch in range(block_config.epochs_per_block):
                                    epoch_loss = 0.0
                                    batch_count = 0
                                    
                                    for batch_data in dataloader:
                                        real_data = batch_data.to(device) if torch.is_tensor(batch_data) else batch_data[0].to(device)
                                        batch_size_real = real_data.size(0)
                                        
                                        optimizer.zero_grad()
                                        
                                        # Forward through blocks up to current block
                                        if algorithm == 'forward_forward':
                                            # For FF: positive examples are good latents
                                            pos_latent = torch.randn(batch_size_real, latent_dim, device=device)
                                            pos_features = trainer.generator(pos_latent, block_idx)
                                            
                                            if hasattr(block, 'compute_goodness'):
                                                goodness = block.compute_goodness(pos_features)
                                                # FF loss: maximize goodness
                                                loss = -goodness.mean()
                                            else:
                                                # Simple reconstruction loss
                                                loss = torch.mean(pos_features ** 2)
                                        elif algorithm == 'cafo':
                                            # For CAFO: try to produce realistic features
                                            latent = torch.randn(batch_size_real, latent_dim, device=device)
                                            features = trainer.generator(latent, block_idx)
                                            
                                            if hasattr(block, 'predict_local'):
                                                predictions = block.predict_local(features)
                                                targets = torch.ones(batch_size_real, 1, device=device)
                                                loss = nn.functional.binary_cross_entropy(predictions, targets)
                                            else:
                                                # Simple feature loss
                                                loss = torch.mean(features ** 2)
                                        else:
                                            # Default: simple feature loss
                                            latent = torch.randn(batch_size_real, latent_dim, device=device)
                                            features = trainer.generator(latent, block_idx)
                                            loss = torch.mean(features ** 2)
                                        
                                        loss.backward()
                                        optimizer.step()
                                        
                                        epoch_loss += loss.item()
                                        batch_count += 1
                                    
                                    avg_loss = epoch_loss / max(batch_count, 1)
                                    block_losses.append(avg_loss)
                                    
                                    print(f"  Epoch {epoch+1}: Loss = {avg_loss:.6f}")
                                
                                block_result = {
                                    'block_idx': block_idx,
                                    'epoch_losses': block_losses,
                                    'final_loss': block_losses[-1] if block_losses else 0.0
                                }
                                block_training_results['generator_blocks'].append(block_result)
                                
                                # Mark block as trained
                                if hasattr(trainer.generator, 'mark_block_trained'):
                                    trainer.generator.mark_block_trained(block_idx)
                    
                    # Train discriminator blocks
                    if block_config.train_discriminator_blocks:
                        print(f"\\n PRE-TRAINING DISCRIMINATOR BLOCKS (0 to {num_blocks-1}):")
                        
                        for block_idx in range(num_blocks):
                            print(f"\\n--- Discriminator Block {block_idx+1}/{num_blocks} ---")
                            
                            # Freeze previous blocks if configured
                            if block_config.freeze_previous_blocks and block_idx > 0:
                                for i in range(block_idx):
                                    trainer.discriminator.freeze_block(i)
                            
                            # Create optimizer for this block
                            block = trainer.discriminator.blocks[block_idx]
                            block_params = block.get_trainable_params() if hasattr(block, 'get_trainable_params') else block.parameters()
                            
                            if block_params:
                                optimizer = torch.optim.Adam(block_params, lr=block_config.block_learning_rate)
                                
                                # Training loop for this block
                                block_losses = []
                                for epoch in range(block_config.epochs_per_block):
                                    epoch_loss = 0.0
                                    batch_count = 0
                                    
                                    for batch_data in dataloader:
                                        real_data = batch_data.to(device) if torch.is_tensor(batch_data) else batch_data[0].to(device)
                                        batch_size_real = real_data.size(0)
                                        
                                        optimizer.zero_grad()
                                        
                                        if algorithm == 'forward_forward':
                                            # For FF: positive examples are real data
                                            pos_features = trainer.discriminator(real_data, block_idx)
                                            
                                            # Negative examples: generated data
                                            with torch.no_grad():
                                                z = torch.randn(batch_size_real, latent_dim, device=device)
                                                neg_data = trainer.generator(z)
                                            neg_features = trainer.discriminator(neg_data, block_idx)
                                            
                                            if hasattr(block, 'compute_goodness'):
                                                pos_goodness = block.compute_goodness(pos_features)
                                                neg_goodness = block.compute_goodness(neg_features)
                                                
                                                # FF loss: maximize pos_goodness, minimize neg_goodness
                                                pos_loss = torch.log1p(torch.exp(-(pos_goodness - 2.0)))
                                                neg_loss = torch.log1p(torch.exp(neg_goodness))
                                                loss = (pos_loss + neg_loss).mean()
                                            else:
                                                # Simple discrimination loss
                                                loss = torch.mean(pos_features) - torch.mean(neg_features)
                                        elif algorithm == 'cafo':
                                            # Real data
                                            real_features = trainer.discriminator(real_data, block_idx)
                                            if hasattr(block, 'predict_local'):
                                                real_pred = block.predict_local(real_features)
                                                real_target = torch.ones(batch_size_real, 1, device=device)
                                                real_loss = nn.functional.binary_cross_entropy(real_pred, real_target)
                                            else:
                                                real_loss = -torch.mean(real_features)
                                            
                                            # Fake data
                                            with torch.no_grad():
                                                z = torch.randn(batch_size_real, latent_dim, device=device)
                                                fake_data = trainer.generator(z)
                                            fake_features = trainer.discriminator(fake_data, block_idx)
                                            
                                            if hasattr(block, 'predict_local'):
                                                fake_pred = block.predict_local(fake_features)
                                                fake_target = torch.zeros(batch_size_real, 1, device=device)
                                                fake_loss = nn.functional.binary_cross_entropy(fake_pred, fake_target)
                                            else:
                                                fake_loss = torch.mean(fake_features)
                                            
                                            loss = (real_loss + fake_loss) / 2
                                        else:
                                            # Default: simple discrimination
                                            real_features = trainer.discriminator(real_data, block_idx)
                                            loss = -torch.mean(real_features)
                                        
                                        loss.backward()
                                        optimizer.step()
                                        
                                        epoch_loss += loss.item()
                                        batch_count += 1
                                    
                                    avg_loss = epoch_loss / max(batch_count, 1)
                                    block_losses.append(avg_loss)
                                    
                                    print(f"  Epoch {epoch+1}: Loss = {avg_loss:.6f}")
                                
                                block_result = {
                                    'block_idx': block_idx,
                                    'epoch_losses': block_losses,
                                    'final_loss': block_losses[-1] if block_losses else 0.0
                                }
                                block_training_results['discriminator_blocks'].append(block_result)
                                
                                # Mark block as trained
                                if hasattr(trainer.discriminator, 'mark_block_trained'):
                                    trainer.discriminator.mark_block_trained(block_idx)
                    
                    block_training_results['total_time'] = time.time() - start_time
                    print(f"\\n BLOCK PRE-TRAINING COMPLETED")
                    print(f"   Time: {block_training_results['total_time']:.2f}s")
                
            except Exception as e:
                print(f"ERROR: during block training: {e}")
                traceback.print_exc()
                block_training_results['error'] = str(e)
        
        # ============================================================================
        # PHASE 2: ADVERSARIAL TRAINING WITH CONTINUAL LEARNING SUPPORT
        # ============================================================================
        
        print(f"\\n" + "="*60)
        print(f"PHASE 2: ADVERSARIAL TRAINING")
        if enable_cl:
            print(f"WITH CONTINUAL LEARNING (Replay Ratio: {replay_ratio})")
        print("="*60)
        
        start_time = time.time()
        training_success = False
        training_history = {
            'epoch_losses': [],
            'generator_losses': [],
            'discriminator_losses': [],
            'continual_learning_stats': []  # ADDED
        }
        
        try:
            # Simple training loop
            print(f"\\nTRAINING: Training for {epochs} epochs...")
            
            trainer.generator.train()
            trainer.discriminator.train()
            
            for epoch in range(epochs):
                print(f"\\nEPOCH {epoch+1}/{epochs}:")
                
                epoch_g_loss = []
                epoch_d_loss = []
                cl_stats = {  # ADDED
                    'replay_used_count': 0,
                    'samples_added_to_buffer': 0
                }
                
                for batch_idx, batch_data in enumerate(dataloader):
                    if batch_idx > 10:  # Limit batches for testing
                        print(f"  BATCH: Limiting to 10 batches for testing, stopping at batch {batch_idx}")
                        break
                    
                    # Get real data
                    real_data = batch_data.to(device)
                    batch_size_real = real_data.size(0)
                    
                    # ====================================================================
                    # TRAIN DISCRIMINATOR WITH CONTINUAL LEARNING SUPPORT
                    # ====================================================================
                    
                    if hasattr(trainer, 'disc_optimizer'):
                        trainer.disc_optimizer.zero_grad()
                    
                    # Train on real data
                    real_output = trainer.discriminator(real_data)
                    if real_output.dim() > 1:
                        real_output = real_output.view(-1)
                    
                    real_labels = torch.ones(batch_size_real, device=device)
                    d_loss_real = nn.functional.binary_cross_entropy_with_logits(real_output, real_labels)
                    
                    # Train on fake data
                    z = torch.randn(batch_size_real, latent_dim, device=device)
                    fake_data = trainer.generator(z).detach()
                    fake_output = trainer.discriminator(fake_data)
                    if fake_output.dim() > 1:
                        fake_output = fake_output.view(-1)
                    
                    fake_labels = torch.zeros(batch_size_real, device=device)
                    d_loss_fake = nn.functional.binary_cross_entropy_with_logits(fake_output, fake_labels)
                    
                    # CONTINUAL LEARNING: Add replay if enabled (ADDED)
                    if enable_cl and replay_buffer and len(replay_buffer) > 0:
                        # Decide whether to use replay in this batch
                        if np.random.random() < replay_ratio:
                            replay_batch = replay_buffer.sample(batch_size_real // 2)
                            if replay_batch is not None:
                                replay_batch = replay_batch.to(device)
                                
                                # Train on replayed old data
                                replay_output = trainer.discriminator(replay_batch)
                                if replay_output.dim() > 1:
                                    replay_output = replay_output.view(-1)
                                
                                replay_labels = torch.ones(replay_batch.size(0), device=device)
                                d_loss_replay = nn.functional.binary_cross_entropy_with_logits(replay_output, replay_labels)
                                
                                # Combined loss: 40% real, 40% fake, 20% replay
                                d_loss = (0.4 * d_loss_real) + (0.4 * d_loss_fake) + (0.2 * d_loss_replay)
                                
                                cl_stats['replay_used_count'] += 1
                                print(f"  [CL] Batch {batch_idx}: Replay used ({replay_batch.size(0)} samples)")
                            else:
                                d_loss = (d_loss_real + d_loss_fake) / 2
                        else:
                            d_loss = (d_loss_real + d_loss_fake) / 2
                    else:
                        d_loss = (d_loss_real + d_loss_fake) / 2
                    
                    d_loss.backward()
                    
                    if hasattr(trainer, 'disc_optimizer'):
                        trainer.disc_optimizer.step()
                    
                    # ====================================================================
                    # TRAIN GENERATOR (No changes needed for CL)
                    # ====================================================================
                    
                    if hasattr(trainer, 'gen_optimizer'):
                        trainer.gen_optimizer.zero_grad()
                    
                    z = torch.randn(batch_size_real, latent_dim, device=device)
                    fake_data = trainer.generator(z)
                    fake_output = trainer.discriminator(fake_data)
                    if fake_output.dim() > 1:
                        fake_output = fake_output.view(-1)
                    
                    g_loss = nn.functional.binary_cross_entropy_with_logits(fake_output, real_labels)
                    g_loss.backward()
                    
                    if hasattr(trainer, 'gen_optimizer'):
                        trainer.gen_optimizer.step()
                    
                    # CONTINUAL LEARNING: Add current batch to replay buffer (ADDED)
                    if enable_cl and replay_buffer:
                        replay_buffer.add_batch(real_data.detach().cpu())
                        cl_stats['samples_added_to_buffer'] += batch_size_real
                    
                    epoch_g_loss.append(g_loss.item())
                    epoch_d_loss.append(d_loss.item())
                    
                    if batch_idx % 2 == 0:
                        cl_info = ""
                        if enable_cl:
                            cl_info = f", Replays: {cl_stats['replay_used_count']}"
                        print(f"  BATCH {batch_idx}: G={g_loss.item():.4f}, D={d_loss.item():.4f}{cl_info}")
                
                avg_g_loss = np.mean(epoch_g_loss) if epoch_g_loss else 0
                avg_d_loss = np.mean(epoch_d_loss) if epoch_d_loss else 0
                
                training_history['generator_losses'].append(avg_g_loss)
                training_history['discriminator_losses'].append(avg_d_loss)
                training_history['epoch_losses'].append({
                    'epoch': epoch + 1,
                    'generator_loss': avg_g_loss,
                    'discriminator_loss': avg_d_loss
                })
                
                # ADDED: Store continual learning stats
                if enable_cl:
                    training_history['continual_learning_stats'].append({
                        'epoch': epoch + 1,
                        'replay_used_count': cl_stats['replay_used_count'],
                        'samples_added': cl_stats['samples_added_to_buffer'],
                        'buffer_size': len(replay_buffer) if replay_buffer else 0
                    })
                
                cl_info = ""
                if enable_cl and replay_buffer:
                    cl_info = f", Buffer: {len(replay_buffer)} samples"
                print(f"  EPOCH SUMMARY: G={avg_g_loss:.4f}, D={avg_d_loss:.4f}{cl_info}")
            
            training_time = time.time() - start_time
            print(f"\\nTRAINING COMPLETE: Training completed in {training_time:.2f}s")
            if enable_cl and replay_buffer:
                print(f"CONTINUAL LEARNING: Final buffer size: {len(replay_buffer)} samples")
            training_success = True
            
        except Exception as e:
            print(f"ERROR: during training: {e}")
            traceback.print_exc()
            training_success = False
        
        # ============================================================================
        # GENERATE SAMPLES
        # ============================================================================
        
        print(f"\\nGENERATING SAMPLES...")
        
        try:
            trainer.generator.eval()
            with torch.no_grad():
                # Generate samples
                num_samples = 16
                z = torch.randn(num_samples, latent_dim, device=device)
                samples = trainer.generator(z).cpu()
                
                # Convert from [-1, 1] to [0, 1] for saving
                samples = (samples + 1) / 2
                samples = torch.clamp(samples, 0, 1)
                
                print(f"SUCCESS: Generated {len(samples)} samples")
                print(f"  SHAPE: Sample shape: {samples[0].shape}")
                print(f"  RANGE: Sample range: [{samples.min():.3f}, {samples.max():.3f}]")
                
        except Exception as e:
            print(f"ERROR: generating samples: {e}")
            traceback.print_exc()
            samples = torch.randn(16, channels, image_size, image_size) * 0.5 + 0.5
        
        # ============================================================================
        # SAVE BLOCK TRAINING LOGS
        # ============================================================================
        
        print(f"\\nSAVING BLOCK TRAINING LOGS...")
        
        try:
            # Save block training results
            with open(args.block_training_logs, 'w') as f:
                json.dump(block_training_results, f, indent=2)
            print(f"SAVED: Block training logs saved: {args.block_training_logs}")
            
        except Exception as e:
            print(f"ERROR: saving block training logs: {e}")
        
        # ============================================================================
        # SAVE REPLAY BUFFER FOR CONTINUAL LEARNING (ADDED)
        # ============================================================================
        
        print(f"\\nSAVING REPLAY BUFFER...")
        
        try:
            if enable_cl and replay_buffer:
                replay_buffer.save(args.updated_replay_buffer)
                print(f"SAVED: Replay buffer saved: {args.updated_replay_buffer}")
                print(f"  SAMPLES: Buffer contains {len(replay_buffer)} samples")
            else:
                # Create empty buffer file if CL not enabled
                empty_buffer = DCGANReplayBuffer(capacity=0)
                empty_buffer.save(args.updated_replay_buffer)
                print(f"SAVED: Empty replay buffer saved (continual learning disabled)")
        except Exception as e:
            print(f"ERROR: saving replay buffer: {e}")
        
        # ============================================================================
        # SAVE ALL OTHER OUTPUT FILES
        # ============================================================================
        
        print(f"\\nSAVING ALL OUTPUT FILES...")
        
        # 1. Save trained model
        print(f"SAVING TRAINED MODEL...")
        try:
            checkpoint = {
                'model_source': 'trained',
                'model_type': 'dcgan',
                'algorithm': algorithm,
                'config': trainer.config if hasattr(trainer, 'config') else {},
                'generator_state_dict': trainer.generator.state_dict(),
                'discriminator_state_dict': trainer.discriminator.state_dict(),
                'training_history': training_history,
                'epoch': epochs,
                'batch_size': batch_size,
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'latent_dim': latent_dim,
                'image_size': image_size,
                'channels': channels,
                'continual_learning_enabled': enable_cl  # ADDED
            }
            
            torch.save(checkpoint, args.trained_model)
            print(f"SAVED: Trained model saved: {args.trained_model}")
        except Exception as e:
            print(f"ERROR: saving trained model: {e}")
        
        # 2. Save training history
        print(f"SAVING TRAINING HISTORY...")
        try:
            history_data = {
                'epoch_losses': training_history['epoch_losses'],
                'generator_losses': training_history['generator_losses'],
                'discriminator_losses': training_history['discriminator_losses'],
                'continual_learning_stats': training_history.get('continual_learning_stats', []),  # ADDED
                'epochs': epochs,
                'batch_size': batch_size,
                'algorithm': algorithm,
                'training_time': training_time if 'training_time' in locals() else 0,
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'num_samples': len(train_dataset),
                'block_training_results': block_training_results,
                'continual_learning_enabled': enable_cl,  # ADDED
                'replay_ratio_used': replay_ratio if enable_cl else 0,
                'memory_capacity': memory_capacity if enable_cl else 0
            }
            
            with open(args.training_history, 'w') as f:
                json.dump(history_data, f, indent=2)
            print(f"SAVED: Training history saved: {args.training_history}")
        except Exception as e:
            print(f"ERROR: saving training history: {e}")
        
        # 3. Save training metrics
        print(f"SAVING TRAINING METRICS...")
        try:
            final_g_loss = training_history['generator_losses'][-1] if training_history['generator_losses'] else 0
            final_d_loss = training_history['discriminator_losses'][-1] if training_history['discriminator_losses'] else 0
            
            metrics_data = {
                'final_generator_loss': float(final_g_loss),
                'final_discriminator_loss': float(final_d_loss),
                'training_time': float(training_time) if 'training_time' in locals() else 0,
                'epochs_completed': epochs,
                'samples_trained': len(train_dataset) * epochs,
                'algorithm': algorithm,
                'device': str(device),
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'model_parameters': {
                    'generator': sum(p.numel() for p in trainer.generator.parameters()),
                    'discriminator': sum(p.numel() for p in trainer.discriminator.parameters())
                },
                'continual_learning': {  # ADDED
                    'enabled': enable_cl,
                    'replay_ratio': replay_ratio if enable_cl else 0,
                    'memory_capacity': memory_capacity if enable_cl else 0,
                    'final_buffer_size': len(replay_buffer) if enable_cl and replay_buffer else 0
                }
            }
            
            with open(args.training_metrics, 'w') as f:
                json.dump(metrics_data, f, indent=2)
            print(f"SAVED: Training metrics saved: {args.training_metrics}")
        except Exception as e:
            print(f"ERROR: saving training metrics: {e}")
        
        # 4. Save generated samples
        print(f"SAVING GENERATED SAMPLES...")
        try:
            generated_dataset = PreprocessedDataset(
                samples,
                torch.zeros(len(samples)),
                f"dcgan_{algorithm}_generated_{int(time.time())}",
                {}
            )
            
            with open(args.generated_samples, 'wb') as f:
                pickle.dump(generated_dataset, f)
            print(f"SAVED: Generated samples saved: {args.generated_samples}")
        except Exception as e:
            print(f"ERROR: saving generated samples: {e}")
        
        # 5. Save generated images URLs (empty for now)
        print(f"SAVING GENERATED IMAGES URLS...")
        try:
            urls_data = {
                'generated_images': [],
                'message': 'Images not uploaded to CDN in training brick',
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ')
            }
            
            with open(args.generated_images_urls, 'w') as f:
                json.dump(urls_data, f, indent=2)
            print(f"SAVED: Generated images URLs saved: {args.generated_images_urls}")
        except Exception as e:
            print(f"ERROR: saving generated images URLs: {e}")
        
        # 6. Save training images summary
        print(f"SAVING TRAINING IMAGES SUMMARY...")
        try:
            continual_info = ""
            if enable_cl:
                continual_info = f'''
                Continual Learning:
                - Enabled: Yes
                - Replay Ratio: {replay_ratio}
                - Memory Capacity: {memory_capacity}
                - Final Buffer Size: {len(replay_buffer) if replay_buffer else 0} samples
                - Replays Used: {sum(stats.get('replay_used_count', 0) for stats in training_history.get('continual_learning_stats', []))}
                '''
            else:
                continual_info = '''
                Continual Learning:
                - Enabled: No (Standard Training)
                '''
            
            summary_content = f'''DCGAN Training Summary
            ==========================
            Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}
            Algorithm: {algorithm.upper()}
            Epochs: {epochs}
            Batch Size: {batch_size}
            Training Time: {training_time:.2f}s
            Device: {device}
            
            Model Parameters:
            - Generator: {sum(p.numel() for p in trainer.generator.parameters()):,}
            - Discriminator: {sum(p.numel() for p in trainer.discriminator.parameters()):,}
            
            Final Losses:
            - Generator: {final_g_loss:.4f}
            - Discriminator: {final_d_loss:.4f}
            
            Dataset:
            - Samples: {len(train_dataset)}
            - Image Size: {image_size}
            - Channels: {channels}
            
            Generated Samples:
            - Count: {len(samples)}
            - Shape: {tuple(samples.shape)}
            - Range: [{samples.min():.3f}, {samples.max():.3f}]
            
            Block Training:
            - Enabled: {should_do_block_training}
            - Generator Blocks Trained: {len(block_training_results.get('generator_blocks', []))}
            - Discriminator Blocks Trained: {len(block_training_results.get('discriminator_blocks', []))}
            
            {continual_info}
            '''
            
            with open(args.training_images_summary, 'w') as f:
                f.write(summary_content)
            print(f"SAVED: Training images summary saved: {args.training_images_summary}")
        except Exception as e:
            print(f"ERROR: saving training images summary: {e}")
        
        # ============================================================================
        # PRINT FINAL SUMMARY
        # ============================================================================
        
        print(f"\\n" + "="*80)
        print(f"TRAINING COMPLETE - ALL OUTPUTS SAVED")
        print("="*80)
        print(f"Algorithm: {algorithm.upper()}")
        print(f"Epochs: {epochs}")
        print(f"Batch Size: {batch_size}")
        print(f"Training Time: {training_time:.2f}s")
        print(f"Device: {device}")
        print(f"Final Losses - G: {final_g_loss:.4f}, D: {final_d_loss:.4f}")
        print(f"Generated Samples: {len(samples)}")
        
        if enable_cl:
            print(f"\\n CONTINUAL LEARNING SUMMARY:")
            print(f"   Replay Ratio: {replay_ratio}")
            print(f"   Memory Capacity: {memory_capacity}")
            print(f"   Final Buffer Size: {len(replay_buffer) if replay_buffer else 0} samples")
            print(f"   Updated Buffer Saved: {args.updated_replay_buffer}")
        
        print(f"\\n OUTPUT FILES SAVED:")
        print(f"   Model: {args.trained_model}")
        print(f"   Training History: {args.training_history}")
        print(f"   Training Metrics: {args.training_metrics}")
        print(f"   Generated Samples: {args.generated_samples}")
        print(f"   Generated Images URLs: {args.generated_images_urls}")
        print(f"   Training Summary: {args.training_images_summary}")
        print(f"   Block Training Logs: {args.block_training_logs}")
        print(f"   Replay Buffer: {args.updated_replay_buffer}")
        print("="*80)
        
    args:
      - --data_path
      - {inputPath: data_path}
      - --master_config
      - {inputValue: master_config}
      - --model_input
      - {inputPath: model_input}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
      - --training_metrics
      - {outputPath: training_metrics}
      - --generated_samples
      - {outputPath: generated_samples}
      - --generated_images_urls
      - {outputPath: generated_images_urls}
      - --training_images_summary
      - {outputPath: training_images_summary}
      - --block_training_logs
      - {outputPath: block_training_logs}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
      # Continual Learning args (ADDED)
      - --enable_continual_learning
      - {inputValue: enable_continual_learning}
      - --replay_buffer_path
      - {inputValue: replay_buffer_path}
      - --replay_ratio
      - {inputValue: replay_ratio}
      - --memory_capacity
      - {inputValue: memory_capacity}
      - --updated_replay_buffer
      - {outputPath: updated_replay_buffer}
