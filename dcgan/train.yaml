name: Train v5
description: Trains DCGAN using nesyfactory with NO fallbacks - throws errors on failure
inputs:
  - name: data_path
    type: Dataset
  - name: master_config
    type: String
  - name: model_input
    type: Model
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String
  - name: processed_history_json
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -c
      - |
        echo "Checking for torchvision..."
        python3 -c "import torchvision; print(f'torchvision version: {torchvision.__version__}')" 2>/dev/null || {
          echo "torchvision not found, installing 0.17.0..."
          pip install torchvision==0.17.0 pillow
        }
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse, pickle, os, json, sys, io, traceback
        import numpy as np
        from torch.utils.data import DataLoader
        from PIL import Image
        import torchvision.transforms as transforms
        
        # ============================================================================
        # Define classes needed for unpickling
        # ============================================================================
        class GANDataset:
            def __init__(self, data_list, transform=None, image_size=64, channels=3):
                self.data_list = data_list
                self.transform = transform
                self.image_size = image_size
                self.channels = channels
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                item = self.data_list[idx]
                try:
                    # Create a dummy image since we don't have real images
                    if self.channels == 1:
                        img = Image.new('L', (self.image_size, self.image_size), color=128)
                    else:
                        img = Image.new('RGB', (self.image_size, self.image_size), color=(128, 128, 128))
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    # Return (image, dummy_label) - GANs need this format
                    return img, torch.tensor(0.0, dtype=torch.float32)
                except Exception as e:
                    print(f"Error creating dummy image {idx}: {e}")
                    raise RuntimeError(f"Failed to create dummy image: {e}")
        
        class GANDataWrapper:
            def __init__(self, dataset, model_type='dcgan', image_size=64, channels=3, 
                        transform_params=None):
                self.dataset = dataset
                self.model_type = model_type
                self.image_size = image_size
                self.channels = channels
                self.transform_params = transform_params or {}
                self.num_samples = len(dataset)
            
            def __len__(self):
                return len(self.dataset)
            
            def __getitem__(self, idx):
                return self.dataset[idx]
        
        # ============================================================================
        # Import DCGAN modules - NO FALLBACK
        # ============================================================================
        print("Importing nesy_factory.GANs.dcgan...")
        try:
            # Import the entire module
            import nesy_factory.GANs.dcgan as dcgan_module
            
            # Get all necessary components - THROW ERROR IF NOT FOUND
            required_components = [
                'create_dcgan', 'OptimizerFactory', 'TrainerFactory',
                'BackpropTrainer', 'ForwardForwardTrainer', 'CAFOTrainer'
            ]
            
            for component in required_components:
                if not hasattr(dcgan_module, component):
                    raise ImportError(f"Required component '{component}' not found in nesy_factory.GANs.dcgan")
            
            # Import all components
            create_dcgan = dcgan_module.create_dcgan
            OptimizerFactory = dcgan_module.OptimizerFactory
            TrainerFactory = dcgan_module.TrainerFactory
            BackpropTrainer = dcgan_module.BackpropTrainer
            ForwardForwardTrainer = dcgan_module.ForwardForwardTrainer
            CAFOTrainer = dcgan_module.CAFOTrainer
            
            print("✓ Successfully imported all required DCGAN components")
            print(f"Available trainers: BackpropTrainer, ForwardForwardTrainer, CAFOTrainer")
            
        except Exception as e:
            print(f" ERROR importing from nesy_factory: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--model_input", required=False)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        parser.add_argument("--processed_history_json", required=True)
        args = parser.parse_args()
        
        print("\\n" + "="*60)
        print("STARTING DCGAN TRAINING - NO FALLBACKS")
        print("="*60)
        
        # ============================================================================
        # PARSE CONFIG AND DETERMINE TRAINING MODE
        # ============================================================================
        try:
            config = json.loads(args.master_config)
            gan_cfg = config['gan']
            training_cfg = gan_cfg['training']
            
            # Check generator and discriminator configs for training mode flags
            generator_cfg = gan_cfg['generator']
            discriminator_cfg = gan_cfg['discriminator']
            
            # Determine training mode based on use_forward_forward and use_cafo flags
            use_ff_generator = generator_cfg.get('use_forward_forward', False)
            use_ff_discriminator = discriminator_cfg.get('use_forward_forward', False)
            use_cafo_generator = generator_cfg.get('use_cafo', False)
            use_cafo_discriminator = discriminator_cfg.get('use_cafo', False)
            
            print(f"\\nTraining mode detection from config:")
            print(f"  Generator use_forward_forward: {use_ff_generator}")
            print(f"  Discriminator use_forward_forward: {use_ff_discriminator}")
            print(f"  Generator use_cafo: {use_cafo_generator}")
            print(f"  Discriminator use_cafo: {use_cafo_discriminator}")
            
            # Determine training mode (priority: CAFO > Forward-Forward > Backprop)
            if use_cafo_generator or use_cafo_discriminator:
                training_mode = "CAFO"
                algorithm = "cafo"
                print(f"✓ Using CAFO training (detected from use_cafo flags)")
            elif use_ff_generator or use_ff_discriminator:
                training_mode = "Forward-Forward"
                algorithm = "forward_forward"
                print(f"✓ Using Forward-Forward training (detected from use_forward_forward flags)")
            else:
                training_mode = "Backpropagation"
                algorithm = "backprop"
                print(f"✓ Using Backpropagation training (default)")
            
            # Also check algorithm field for backward compatibility
            algorithm_from_training = training_cfg.get('algorithm', '').lower()
            if algorithm_from_training:
                print(f"  Note: Found algorithm field in training config: '{algorithm_from_training}'")
                # Map 'ff' to 'forward_forward'
                if algorithm_from_training == 'ff':
                    algorithm_from_training = 'forward_forward'
                
                # Warn if there's a conflict
                if algorithm_from_training != algorithm:
                    print(f"  Warning: Algorithm from training config '{algorithm_from_training}' differs from detected mode '{algorithm}'")
                    print(f"  Using detected mode from use_* flags: {algorithm}")
            
        except Exception as e:
            print(f" ERROR parsing master_config: {e}")
            sys.exit(1)
        
        # ============================================================================
        # LOAD DATASET - NO FALLBACK
        # ============================================================================
        try:
            class SafeUnpickler(pickle.Unpickler):
                def find_class(self, module, name):
                    # Allow our custom classes
                    if name == 'GANDataWrapper':
                        return GANDataWrapper
                    elif name == 'GANDataset':
                        return GANDataset
                    return super().find_class(module, name)
            
            with open(args.data_path, "rb") as f:
                unpickler = SafeUnpickler(f)
                data_wrapper = unpickler.load()
            
            if not hasattr(data_wrapper, 'dataset'):
                raise ValueError("Invalid preprocessed data format - missing 'dataset' attribute")
            
            dataset = data_wrapper.dataset
            image_size = data_wrapper.image_size
            channels = data_wrapper.channels
            
            print(f"\\n✓ Loaded preprocessed dataset:")
            print(f"  Samples: {len(dataset)}")
            print(f"  Image size: {image_size}x{image_size}")
            print(f"  Channels: {channels}")
            
        except Exception as e:
            print(f" ERROR loading dataset: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Device
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Device: {device}")
        
        # ============================================================================
        # LOAD MODEL - NO FALLBACK
        # ============================================================================
        try:
            if not args.model_input or not os.path.exists(args.model_input):
                raise FileNotFoundError(f"Model input not found: {args.model_input}")
            
            print(f"\\nLoading model from: {args.model_input}")
            checkpoint = torch.load(args.model_input, map_location='cpu')
            
            if not isinstance(checkpoint, dict):
                raise ValueError("Invalid checkpoint format - expected dict")
            
            if 'config' in checkpoint:
                model_config = checkpoint['config']
                print("✓ Found config in checkpoint")
            else:
                # Create config from master config - IMPORTANT: Include use_* flags
                model_config = {
                    'dataset': {'resize_size': image_size},
                    'generator': gan_cfg['generator'],
                    'discriminator': gan_cfg['discriminator'],
                    'train': {
                        'algorithm': algorithm,  # Add algorithm to config for TrainerFactory
                        'epochs': training_cfg.get('epochs', 10),
                        'batch_size': training_cfg.get('batch_size', 32)
                    }
                }
                print("✓ Created config from master config")
            
            # Ensure training algorithm is in config for TrainerFactory
            if 'train' not in model_config:
                model_config['train'] = {}
            model_config['train']['algorithm'] = algorithm
            
            model_config['device'] = str(device)
            
            print(f"\\nModel configuration for create_dcgan:")
            print(f"  Training algorithm: {model_config['train']['algorithm']}")
            print(f"  Generator use_forward_forward: {model_config['generator'].get('use_forward_forward', False)}")
            print(f"  Discriminator use_forward_forward: {model_config['discriminator'].get('use_forward_forward', False)}")
            print(f"  Generator use_cafo: {model_config['generator'].get('use_cafo', False)}")
            print(f"  Discriminator use_cafo: {model_config['discriminator'].get('use_cafo', False)}")
            
            # Create DCGAN models
            generator, discriminator, full_config = create_dcgan(model_config)
            
            if generator is None or discriminator is None:
                raise RuntimeError("Failed to create models - generator or discriminator is None")
            
            # Load state dict
            if 'generator_state_dict' in checkpoint:
                generator.load_state_dict(checkpoint['generator_state_dict'], strict=True)
                print("✓ Generator state dict loaded")
            else:
                raise KeyError("Checkpoint missing 'generator_state_dict'")
            
            if 'discriminator_state_dict' in checkpoint:
                discriminator.load_state_dict(checkpoint['discriminator_state_dict'], strict=True)
                print("✓ Discriminator state dict loaded")
            else:
                raise KeyError("Checkpoint missing 'discriminator_state_dict'")
            
            print(f"\\n✓ Models loaded successfully")
            print(f"  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}")
            print(f"  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}")
            
        except Exception as e:
            print(f" ERROR loading model: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Move to device
        generator.to(device)
        discriminator.to(device)
        
        # ============================================================================
        # CREATE DATA LOADER - NO FALLBACK
        # ============================================================================
        try:
            batch_size = training_cfg.get('batch_size', 32)
            actual_batch_size = min(batch_size, max(1, len(dataset)))
            train_loader = DataLoader(dataset, batch_size=actual_batch_size, shuffle=True, drop_last=False)
            
            if len(train_loader) == 0:
                raise RuntimeError(f"No batches created! Dataset too small ({len(dataset)} samples)")
            
            print(f"\\n✓ Data loader created:")
            print(f"  Dataset size: {len(dataset)}")
            print(f"  Actual batch size: {actual_batch_size}")
            print(f"  Batches per epoch: {len(train_loader)}")
            
        except Exception as e:
            print(f" ERROR creating data loader: {e}")
            sys.exit(1)
        
        # ============================================================================
        # TRAINING - NO FALLBACK
        # ============================================================================
        print(f"\\n{'='*60}")
        print(f"STARTING {training_mode.upper()} TRAINING")
        print(f"{'='*60}")
        
        try:
            # Create trainer based on algorithm using TrainerFactory
            trainer = TrainerFactory.create_trainer(full_config, device)
            print(f"✓ Trainer created: {type(trainer).__name__}")
            
            # Create optimizers
            optimizer_g = OptimizerFactory.create_optimizer(generator, full_config, 'generator')
            optimizer_d = OptimizerFactory.create_optimizer(discriminator, full_config, 'discriminator')
            print("✓ Optimizers created")
            
        except Exception as e:
            print(f" ERROR creating trainer/optimizers: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Training loop
        epochs = training_cfg.get('epochs', 1)
        results = {
            'epochs': epochs,
            'algorithm': algorithm,
            'g_loss': [],
            'd_loss': [],
            'real_score': [],
            'fake_score': []
        }
        
        for epoch in range(epochs):
            print(f"\\nEpoch {epoch+1}/{epochs} ({training_mode})")
            
            try:
                # Train one epoch
                metrics = trainer.train_epoch(
                    generator, discriminator, train_loader,
                    optimizer_g, optimizer_d, epoch
                )
                
                # Validate metrics
                required_metrics = ['g_loss', 'd_loss']
                for metric in required_metrics:
                    if metric not in metrics:
                        raise KeyError(f"Missing metric '{metric}' in training results")
                
                # Store results
                results['g_loss'].append(float(metrics['g_loss']))
                results['d_loss'].append(float(metrics['d_loss']))
                
                # Optional metrics
                if 'real_score' in metrics:
                    results['real_score'].append(float(metrics['real_score']))
                if 'fake_score' in metrics:
                    results['fake_score'].append(float(metrics['fake_score']))
                
                # Log epoch results
                print(f"  Generator Loss: {results['g_loss'][-1]:.4f}")
                print(f"  Discriminator Loss: {results['d_loss'][-1]:.4f}")
                if 'real_score' in metrics and 'fake_score' in metrics:
                    print(f"  D(real): {metrics['real_score']:.4f}, D(fake): {metrics['fake_score']:.4f}")
                
            except Exception as e:
                print(f" ERROR in epoch {epoch+1}: {e}")
                traceback.print_exc()
                sys.exit(1)
        
        # ============================================================================
        # SAVE RESULTS - NO FALLBACK
        # ============================================================================
        print("\\nSaving model and training history...")
        
        try:
            os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
            os.makedirs(os.path.dirname(args.training_history), exist_ok=True)
            os.makedirs(os.path.dirname(args.processed_history_json), exist_ok=True)
            
            # Create checkpoint
            checkpoint = {
                'config': full_config,
                'generator_state_dict': generator.state_dict(),
                'discriminator_state_dict': discriminator.state_dict(),
                'training_mode': training_mode,
                'algorithm_used': algorithm,
                'model_info': {
                    'generator_params': sum(p.numel() for p in generator.parameters()),
                    'discriminator_params': sum(p.numel() for p in discriminator.parameters()),
                    'image_size': generator.image_size,
                    'channels': generator.image_channels,
                    'z_dim': generator.z_dim
                },
                'master_config': config
            }
            torch.save(checkpoint, args.trained_model)
            print(f"✓ Model saved to: {args.trained_model}")
            
        except Exception as e:
            print(f" ERROR saving model: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # CREATE TRAINING HISTORY - NO FALLBACK
        # ============================================================================
        try:
            history = {
                "training_mode": training_mode,
                "algorithm": algorithm,
                "results": results,
                "config": {
                    "model": gan_cfg,
                    "training": training_cfg
                },
                "epochs": epochs,
                "dataset_size": len(dataset),
                "batch_size": actual_batch_size
            }
            
            with open(args.training_history, "w") as f:
                json.dump(history, f, indent=2)
            print(f"✓ Training history saved to: {args.training_history}")
            
        except Exception as e:
            print(f" ERROR saving training history: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # PROCESS HISTORY FOR OUTPUT - NO FALLBACK
        # ============================================================================
        try:
            processed_rows = []
            
            # For DCGAN, we have both generator and discriminator losses
            g_losses = results.get("g_loss", [])
            d_losses = results.get("d_loss", [])
            
            if not isinstance(g_losses, list) or not isinstance(d_losses, list):
                raise TypeError("Losses must be lists")
            
            if len(g_losses) == 0 or len(d_losses) == 0:
                raise ValueError("No training loss data available")
            
            # Create rows for both generator and discriminator
            for epoch_idx in range(len(g_losses)):
                # Generator row
                row = {
                    "epoch": epoch_idx + 1,
                    "loss": float(g_losses[epoch_idx]),
                    "component": "generator",
                    "type": "train"
                }
                processed_rows.append(row)
                
                # Discriminator row
                if epoch_idx < len(d_losses):
                    row = {
                        "epoch": epoch_idx + 1,
                        "loss": float(d_losses[epoch_idx]),
                        "component": "discriminator",
                        "type": "train"
                    }
                    processed_rows.append(row)
            
            # Create output format (matching your CNN format)
            # Get last epoch data
            last_epoch = processed_rows[-1]["epoch"]
            last_g_loss = None
            last_d_loss = None
            
            for row in processed_rows:
                if row["epoch"] == last_epoch:
                    if row["component"] == "generator":
                        last_g_loss = row["loss"]
                    elif row["component"] == "discriminator":
                        last_d_loss = row["loss"]
            
            if last_g_loss is None:
                raise ValueError("No generator loss found for last epoch")
            
            output = {
                "epoch": int(last_epoch),
                "loss": float(last_g_loss),
                "validation_loss": float(last_d_loss) if last_d_loss is not None else 0.0,
                "training_mode": training_mode,
                "algorithm": algorithm,
                "data": processed_rows[:10]  # Limit to first 10 rows
            }
            
            with open(args.processed_history_json, "w") as f:
                json.dump(output, f, indent=2)
            print(f"✓ Processed history saved to: {args.processed_history_json}")
            
        except Exception as e:
            print(f" ERROR processing history: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # FINAL SUCCESS MESSAGE
        # ============================================================================
        print(f"\\n{'✓'*60}")
        print(f"SUCCESS: {training_mode} TRAINING COMPLETED WITHOUT FALLBACKS")
        print(f"{'✓'*60}")
        print(f"✓ Final Generator Loss: {results['g_loss'][-1]:.4f}")
        print(f"✓ Final Discriminator Loss: {results['d_loss'][-1]:.4f}")
        print(f"✓ Training epochs: {epochs}")
        print(f"✓ Algorithm used: {algorithm}")
        print(f"✓ Training mode detected from flags: {training_mode}")
        
    args:
      - --data_path
      - {inputPath: data_path}
      - --master_config
      - {inputValue: master_config}
      - --model_input
      - {inputPath: model_input}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
      - --processed_history_json
      - {outputPath: processed_history_json}
