name: Train v20
description: Trains DCGAN using nesy_factory with Traditional, CAFO, or Forward-Forward methods
inputs:
  - name: data_path
    type: Dataset
  - name: master_config
    type: String
  - name: model_input
    type: Model
  - name: bearer_token
    type: String
  - name: domain
    type: String
  - name: get_cdn
    type: String
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String
  - name: processed_history_json
    type: String
  - name: generated_images_urls
    type: String
  - name: training_images_summary
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -c
      - |
        echo "Checking for torchvision..."
        python3 -c "import torchvision; print(f'torchvision version: {torchvision.__version__}')" 2>/dev/null || {
          echo "torchvision not found, installing 0.17.0..."
          pip install torchvision==0.17.0 pillow
        }
        # Install curl for CDN uploads
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import argparse, pickle, os, json, sys, io, traceback, time, uuid
        import numpy as np
        import base64
        import subprocess
        from PIL import Image
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader
        from io import BytesIO
        import matplotlib.pyplot as plt
        import torch.nn.functional as F
        import torch.optim as optim
        import warnings
        
        # Suppress warnings
        warnings.filterwarnings('ignore')
        
        # Set matplotlib backend
        import matplotlib
        matplotlib.use('Agg')
        
        # ============================================================================
        # Import nesy_factory modules
        # ============================================================================
        print("Importing nesy_factory.GANs.dcgan...")
        try:
            import nesy_factory.GANs.dcgan as dcgan_module
            
            # Get all required components
            create_dcgan = dcgan_module.create_dcgan
            OptimizerFactory = dcgan_module.OptimizerFactory
            
            print("✓ Successfully imported nesy_factory components")
            
        except Exception as e:
            print(f" ERROR importing from nesy_factory: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # Define GAN-specific classes for unpickling
        # ============================================================================
        class GANDataset:
            def __init__(self, data_list, transform=None, image_size=64, channels=3):
                self.data_list = data_list
                self.transform = transform
                self.image_size = image_size
                self.channels = channels
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                return torch.zeros(self.channels, self.image_size, self.image_size)

        class GANDataWrapper:
            def __init__(self, dataset, model_type='dcgan', image_size=64, channels=3, transform_params=None):
                self.dataset = dataset
                self.model_type = model_type
                self.image_size = image_size
                self.channels = channels
                self.transform_params = transform_params or {}
                self.num_samples = len(dataset)
            
            def __len__(self):
                return len(self.dataset)
            
            def __getitem__(self, idx):
                return self.dataset[idx]

        class DatasetInfoWrapper:
            def __init__(self, info_dict):
                self.__dict__.update(info_dict)

        class PreprocessMetadata:
            def __init__(self, image_size=64, channels=3, model_type='dcgan',
                         mean=(0.5,), std=(0.5,), transform_params=None):
                self.image_size = image_size
                self.channels = channels
                self.model_type = model_type
                self.mean = mean
                self.std = std
                self.transform_params = transform_params or {}
                self.timestamp = time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        # ============================================================================
        # ROBUST TRAINING FUNCTION
        # ============================================================================
        
        def train_algorithm_robust(generator, discriminator, train_loader, optimizer_g, optimizer_d, 
                                 device, algorithm='backprop', epochs=1, n_critic=1):
          
            print(f"\\nTraining with algorithm: {algorithm.upper()}")
            
            # Training results
            loss_entries = []
            
            for epoch in range(epochs):
                print(f"\\nEpoch {epoch + 1}/{epochs} ({algorithm.upper()})")
                
                generator.train()
                discriminator.train()
                
                epoch_g_loss = 0.0
                epoch_d_loss = 0.0
                batch_count = 0
                
                for batch_idx, batch_data in enumerate(train_loader):
                    # ============= DATA VALIDATION =============
                    # Handle data format
                    if isinstance(batch_data, (list, tuple)):
                        if len(batch_data) == 2:
                            real_images = batch_data[0]
                        else:
                            real_images = batch_data[0] if len(batch_data) > 0 else batch_data
                    else:
                        real_images = batch_data
                    
                    # Verify tensor exists and has data
                    if real_images is None:
                        print(f"  Warning: Batch {batch_idx} has None data, skipping")
                        continue
                    
                    # Verify tensor is a torch tensor
                    if not isinstance(real_images, torch.Tensor):
                        print(f"  Warning: Batch {batch_idx} is not a tensor, skipping")
                        continue
                    
                    # Verify tensor has correct dimensions
                    if real_images.dim() == 3:  # [C, H, W] - single image
                        real_images = real_images.unsqueeze(0)  # Add batch dimension -> [1, C, H, W]
                    elif real_images.dim() == 2:  # [H, W] - grayscale single image
                        real_images = real_images.unsqueeze(0).unsqueeze(0)  # -> [1, 1, H, W]
                    elif real_images.dim() != 4:  # Should be [B, C, H, W]
                        print(f"  Warning: Batch {batch_idx} has unexpected dimension {real_images.dim()}, skipping")
                        continue
                    
                    # Verify tensor has non-zero size
                    if real_images.numel() == 0:
                        print(f"  Warning: Batch {batch_idx} has zero elements, skipping")
                        continue
                    
                    # Verify tensor has finite values
                    if not torch.isfinite(real_images).all():
                        print(f"  Warning: Batch {batch_idx} has non-finite values, skipping")
                        continue
                    
                    real_images = real_images.to(device)
                    batch_size = real_images.size(0)
                    
                    # Ensure batch size is valid
                    if batch_size < 1:
                        print(f"  Warning: Batch {batch_idx} has invalid batch size {batch_size}, skipping")
                        continue
                    
                    # ============= TRAIN DISCRIMINATOR =============
                    optimizer_d.zero_grad()
                    
                    # Real images - verify discriminator output
                    try:
                        real_output = discriminator(real_images)
                        
                        # Verify discriminator output
                        if real_output is None:
                            print(f"  Warning: Discriminator returned None for real images")
                            continue
                        
                        # Ensure output is a tensor
                        if not isinstance(real_output, torch.Tensor):
                            print(f"  Warning: Discriminator output is not a tensor")
                            continue
                        
                        # Handle scalar output
                        if real_output.dim() == 0:
                            real_output = real_output.unsqueeze(0)
                        
                        # Verify output has correct shape
                        if real_output.size(0) != batch_size:
                            print(f"  Warning: Discriminator output batch mismatch")
                            continue
                        
                        real_loss = F.binary_cross_entropy_with_logits(real_output, torch.ones_like(real_output))
                    except Exception as e:
                        print(f"  Warning: Discriminator forward failed: {e}")
                        continue
                    
                    # Generate fake images with verification
                    try:
                        z = torch.randn(batch_size, generator.z_dim, device=device)
                        
                        # Verify noise tensor
                        if not torch.isfinite(z).all():
                            print(f"  Warning: Noise tensor has non-finite values")
                            continue
                        
                        fake_images = generator(z).detach()
                        
                        # Verify generated images
                        if fake_images is None or not isinstance(fake_images, torch.Tensor):
                            print(f"  Warning: Generator returned invalid output")
                            continue
                        
                        # Verify generated image dimensions
                        if fake_images.dim() != 4 or fake_images.size(0) != batch_size:
                            print(f"  Warning: Generated images have invalid dimensions")
                            continue
                        
                        fake_output = discriminator(fake_images)
                        
                        # Verify fake output
                        if fake_output is None or not isinstance(fake_output, torch.Tensor):
                            print(f"  Warning: Discriminator returned invalid output for fake images")
                            continue
                        
                        if fake_output.dim() == 0:
                            fake_output = fake_output.unsqueeze(0)
                        
                        if fake_output.size(0) != batch_size:
                            print(f"  Warning: Fake output batch mismatch")
                            continue
                        
                        fake_loss = F.binary_cross_entropy_with_logits(fake_output, torch.zeros_like(fake_output))
                    except Exception as e:
                        print(f"  Warning: Fake image generation failed: {e}")
                        continue
                    
                    d_loss = (real_loss + fake_loss) / 2
                    
                    # Verify loss is finite
                    if not torch.isfinite(d_loss):
                        print(f"  Warning: Discriminator loss is not finite")
                        continue
                    
                    try:
                        d_loss.backward()
                        
                        # Verify gradients are finite
                        for param in discriminator.parameters():
                            if param.grad is not None and not torch.isfinite(param.grad).all():
                                print(f"  Warning: Discriminator gradients are not finite")
                                # Clear gradients to prevent issues
                                optimizer_d.zero_grad()
                                break
                        else:
                            optimizer_d.step()
                    except Exception as e:
                        print(f"  Warning: Discriminator backward failed: {e}")
                        optimizer_d.zero_grad()
                        continue
                    
                    # ============= TRAIN GENERATOR =============
                    optimizer_g.zero_grad()
                    
                    try:
                        z = torch.randn(batch_size, generator.z_dim, device=device)
                        
                        # Verify noise tensor
                        if not torch.isfinite(z).all():
                            print(f"  Warning: Generator noise has non-finite values")
                            continue
                        
                        fake_images = generator(z)
                        
                        # Verify generator output
                        if fake_images is None or not isinstance(fake_images, torch.Tensor):
                            print(f"  Warning: Generator returned invalid output")
                            continue
                        
                        fake_output = discriminator(fake_images)
                        
                        # Verify discriminator output for generator training
                        if fake_output is None or not isinstance(fake_output, torch.Tensor):
                            print(f"  Warning: Discriminator returned invalid output for generator training")
                            continue
                        
                        if fake_output.dim() == 0:
                            fake_output = fake_output.unsqueeze(0)
                        
                        g_loss = F.binary_cross_entropy_with_logits(fake_output, torch.ones_like(fake_output))
                        
                        # Verify loss is finite
                        if not torch.isfinite(g_loss):
                            print(f"  Warning: Generator loss is not finite")
                            continue
                        
                        g_loss.backward()
                        
                        # Verify gradients are finite
                        for param in generator.parameters():
                            if param.grad is not None and not torch.isfinite(param.grad).all():
                                print(f"  Warning: Generator gradients are not finite")
                                optimizer_g.zero_grad()
                                break
                        else:
                            optimizer_g.step()
                            
                    except Exception as e:
                        print(f"  Warning: Generator training failed: {e}")
                        optimizer_g.zero_grad()
                        continue
                    
                    # ============= RECORD METRICS =============
                    epoch_g_loss += g_loss.item()
                    epoch_d_loss += d_loss.item()
                    batch_count += 1
                    
                    if batch_count % 5 == 0:
                        print(f"  Batch {batch_idx}: G Loss = {g_loss.item():.4f}, D Loss = {d_loss.item():.4f}")
                
                # ============= EPOCH SUMMARY =============
                if batch_count > 0:
                    avg_g_loss = epoch_g_loss / batch_count
                    avg_d_loss = epoch_d_loss / batch_count
                    
                    # Create loss entries
                    loss_entry_g = {
                        'epoch': epoch + 1,
                        'loss': avg_g_loss,
                        'component': 'generator',
                        'training_mode': algorithm,
                        'uid': str(uuid.uuid4())
                    }
                    loss_entries.append(loss_entry_g)
                    
                    loss_entry_d = {
                        'epoch': epoch + 1,
                        'loss': avg_d_loss,
                        'component': 'discriminator',
                        'training_mode': algorithm,
                        'uid': str(uuid.uuid4())
                    }
                    loss_entries.append(loss_entry_d)
                    
                    print(f"  Average Generator Loss: {avg_g_loss:.4f}")
                    print(f"  Average Discriminator Loss: {avg_d_loss:.4f}")
                    print(f"  Batches processed: {batch_count}")
                else:
                    print("  ERROR: No valid batches processed in this epoch!")
                    # Create dummy entries to avoid empty results
                    loss_entry_g = {
                        'epoch': epoch + 1,
                        'loss': 0.0,
                        'component': 'generator',
                        'training_mode': algorithm,
                        'uid': str(uuid.uuid4()),
                        'note': 'no_valid_batches'
                    }
                    loss_entries.append(loss_entry_g)
                    
                    loss_entry_d = {
                        'epoch': epoch + 1,
                        'loss': 0.0,
                        'component': 'discriminator',
                        'training_mode': algorithm,
                        'uid': str(uuid.uuid4()),
                        'note': 'no_valid_batches'
                    }
                    loss_entries.append(loss_entry_d)
            
            return {'loss_entries': loss_entries, 'batches_processed': batch_count}
        
        # ============================================================================
        # Parse arguments
        # ============================================================================
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--model_input", required=False)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        parser.add_argument("--processed_history_json", required=True)
        parser.add_argument("--generated_images_urls", required=True)
        parser.add_argument("--training_images_summary", required=True)
        parser.add_argument("--bearer_token", required=True)
        parser.add_argument("--domain", required=True)
        parser.add_argument("--get_cdn", required=True)
        args = parser.parse_args()
        
        print("\\n" + "="*80)
        print("STARTING DCGAN TRAINING WITH IMAGE UPLOAD")
        print("="*80)
        
        # ============================================================================
        # Helper function for CDN upload
        # ============================================================================
        def upload_to_cdn(file_path, description, bearer_token, domain, get_cdn_prefix, file_type="png"):
           
            if not os.path.exists(file_path):
                print(f"   Warning: File not found: {file_path}")
                return None
            
            file_size = os.path.getsize(file_path)
            print(f"   Uploading {description} ({file_size:,} bytes)...")
            
            upload_url = f"{domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fbottle%2Flimka%2Fsoda%2F"
            
            curl_command = [
                "curl",
                "--location", upload_url,
                "--header", f"Authorization: Bearer {bearer_token}",
                "--form", f"file=@{file_path}",
                "--fail",
                "--show-error",
                "--connect-timeout", "30",
                "--max-time", "120"
            ]
            
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                response_json = json.loads(process.stdout)
                relative_cdn_url = response_json.get("cdnUrl", "")
                
                if not relative_cdn_url:
                    print(f"    Error: No cdnUrl in response")
                    return None
                
                full_url = f"{get_cdn_prefix}{relative_cdn_url}"
                print(f"     Uploaded: {full_url}")
                
                return full_url
                
            except subprocess.CalledProcessError as e:
                print(f"    Curl error: {e.returncode}")
                print(f"    Error: {e.stderr[:200]}")
                return None
            except json.JSONDecodeError as e:
                print(f"    JSON parse error: {e}")
                return None
        
        # ============================================================================
        # Helper function to save and encode images
        # ============================================================================
        def save_and_encode_images(generator, device, epoch, num_images=16, save_dir="/tmp/generated_images"):
           
            os.makedirs(save_dir, exist_ok=True)
            
            # Generate images with validation
            generator.eval()
            with torch.no_grad():
                try:
                    z = torch.randn(num_images, generator.z_dim, device=device)
                    
                    # Verify noise tensor
                    if not torch.isfinite(z).all():
                        print("  Warning: Noise tensor has non-finite values, using zeros")
                        z = torch.zeros(num_images, generator.z_dim, device=device)
                    
                    generated_images = generator(z).cpu()
                    
                    # Verify generated images
                    if generated_images is None or not isinstance(generated_images, torch.Tensor):
                        print("  ERROR: Generator returned None or invalid output")
                        return [], None, []
                    
                    # Verify dimensions
                    if generated_images.dim() != 4:
                        print(f"  Warning: Generated images have wrong dimension {generated_images.dim()}")
                        return [], None, []
                    
                except Exception as e:
                    print(f"  ERROR: Image generation failed: {e}")
                    return [], None, []
            
            # Convert from [-1, 1] to [0, 1] with clipping
            generated_images = (generated_images + 1) / 2
            generated_images = torch.clamp(generated_images, 0, 1)
            
            # Save images
            image_paths = []
            base64_images = []
            
            for i in range(min(num_images, generated_images.size(0))):
                img_tensor = generated_images[i]
                
                # Verify image tensor
                if not torch.isfinite(img_tensor).all():
                    print(f"  Warning: Image {i} has non-finite values, skipping")
                    continue
                
                # Convert to PIL Image
                try:
                    if img_tensor.shape[0] == 1:  # Grayscale
                        img = transforms.ToPILImage()(img_tensor)
                    else:  # RGB
                        img = transforms.ToPILImage()(img_tensor)
                except Exception as e:
                    print(f"  Warning: Failed to convert image {i} to PIL: {e}")
                    continue
                
                # Save to file
                img_path = os.path.join(save_dir, f"epoch_{epoch:03d}_sample_{i:02d}.png")
                try:
                    img.save(img_path)
                    image_paths.append(img_path)
                except Exception as e:
                    print(f"  Warning: Failed to save image {i}: {e}")
                    continue
                
                # Convert to base64
                try:
                    buffered = BytesIO()
                    img.save(buffered, format="PNG")
                    img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                    base64_images.append(img_base64[:100] + "..." if len(img_base64) > 100 else img_base64)
                except Exception as e:
                    print(f"  Warning: Failed to encode image {i}: {e}")
                    base64_images.append("")
            
            # Create grid image if we have any valid images
            if len(image_paths) > 0:
                n_cols = 4
                n_rows = (len(image_paths) + n_cols - 1) // n_cols
                
                fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 3 * n_rows))
                axes = axes.flatten() if n_rows > 1 else [axes]
                
                for i in range(len(image_paths)):
                    ax = axes[i]
                    if generated_images[i].shape[0] == 1:
                        ax.imshow(generated_images[i][0], cmap='gray', vmin=0, vmax=1)
                    else:
                        ax.imshow(generated_images[i].permute(1, 2, 0))
                    ax.axis('off')
                    ax.set_title(f"Sample {i+1}")
                
                for i in range(len(image_paths), len(axes)):
                    axes[i].axis('off')
                
                plt.tight_layout()
                grid_path = os.path.join(save_dir, f"epoch_{epoch:03d}_grid.png")
                try:
                    plt.savefig(grid_path, dpi=150, bbox_inches='tight')
                    plt.close()
                except Exception as e:
                    print(f"  ERROR: Failed to save grid image: {e}")
                    grid_path = None
                    plt.close()
            else:
                grid_path = None
            
            return image_paths, grid_path, base64_images
        
        # ============================================================================
        # PARSE CONFIG AND DETERMINE TRAINING MODE
        # ============================================================================
        try:
            config = json.loads(args.master_config)
            gan_cfg = config['gan']
            training_cfg = gan_cfg['training']
            
            # Determine training mode from algorithm
            algorithm = training_cfg.get('algorithm', 'backprop')
            
            if algorithm == 'cafo':
                training_mode = "CAFO"
                print(f"✓ Using CAFO training")
            elif algorithm == 'forward_forward':
                training_mode = "Forward-Forward"
                print(f"✓ Using Forward-Forward training")
            else:
                training_mode = "Backpropagation"
                algorithm = "backprop"
                print(f"✓ Using Backpropagation training")
            
            # Get training parameters
            epochs = training_cfg.get('epochs', 1)
            batch_size = training_cfg.get('batch_size', 32)
            n_critic = training_cfg.get('n_critic', 1)
            
            print(f"✓ Training for {epochs} epoch(s)")
            print(f"✓ Batch size: {batch_size}")
            print(f"✓ Discriminator steps per generator step: {n_critic}")
            
        except Exception as e:
            print(f" ERROR parsing master_config: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # LOAD DATASET
        # ============================================================================
        try:
            class SafeUnpickler(pickle.Unpickler):
                def find_class(self, module, name):
                    if name == 'GANDataWrapper':
                        return GANDataWrapper
                    elif name == 'GANDataset':
                        return GANDataset
                    elif name == 'DatasetInfoWrapper':
                        return DatasetInfoWrapper
                    elif name == 'PreprocessMetadata':
                        return PreprocessMetadata
                    return super().find_class(module, name)
            
            with open(args.data_path, "rb") as f:
                data = SafeUnpickler(f).load()
            
            if hasattr(data, 'dataset'):
                dataset = data.dataset
                image_size = data.image_size
                channels = data.channels
                print(f"\\n✓ Loaded preprocessed dataset:")
                print(f"  Samples: {len(dataset)}")
                print(f"  Image size: {image_size}x{image_size}")
                print(f"  Channels: {channels}")
            else:
                raise ValueError("Invalid preprocessed data format")
            
        except Exception as e:
            print(f" ERROR loading dataset: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Device
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Device: {device}")
        
        # ============================================================================
        # LOAD MODEL FROM BUILD BRICK
        # ============================================================================
        print(f"\\nLoading model from build brick...")
        
        try:
            # Load the checkpoint created by build brick
            checkpoint = torch.load(args.model_input, map_location='cpu')
            
            # Get config from checkpoint
            if 'config' in checkpoint:
                model_config = checkpoint['config']
                print("✓ Loaded config from checkpoint")
            else:
                # Create config from master config
                model_config = {
                    'dataset': {'resize_size': image_size},
                    'generator': gan_cfg['generator'],
                    'discriminator': gan_cfg['discriminator'],
                    'device': str(device)
                }
                print("✓ Created config from master config")
            
            # Create models using the same function as build brick
            generator, discriminator, full_config = create_dcgan(model_config)
            
            # Load state dicts
            if 'generator_state_dict' in checkpoint:
                generator.load_state_dict(checkpoint['generator_state_dict'])
                print("✓ Generator weights loaded")
            else:
                print(" No generator weights in checkpoint")
            
            if 'discriminator_state_dict' in checkpoint:
                discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                print("✓ Discriminator weights loaded")
            else:
                print(" No discriminator weights in checkpoint")
            
            # Move to device
            generator.to(device)
            discriminator.to(device)
            
            print(f"\\n✓ Models loaded successfully:")
            print(f"  Image size: {image_size}")
            print(f"  Channels: {channels}")
            print(f"  Training mode: {training_mode}")
            print(f"  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}")
            print(f"  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}")
            
        except Exception as e:
            print(f" ERROR loading model: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # CREATE DATA LOADER
        # ============================================================================
        try:
            actual_batch_size = min(batch_size, max(1, len(dataset)))
            train_loader = DataLoader(dataset, batch_size=actual_batch_size, shuffle=True, drop_last=False)
            
            if len(train_loader) == 0:
                raise RuntimeError(f"No batches created! Dataset too small ({len(dataset)} samples)")
            
            print(f"\\n✓ Data loader created:")
            print(f"  Dataset size: {len(dataset)}")
            print(f"  Actual batch size: {actual_batch_size}")
            print(f"  Batches per epoch: {len(train_loader)}")
            
        except Exception as e:
            print(f" ERROR creating data loader: {e}")
            sys.exit(1)
        
        # ============================================================================
        # CREATE OPTIMIZERS
        # ============================================================================
        print(f"\\nCreating optimizers...")
        try:
            optimizer_g = OptimizerFactory.create_optimizer(generator, full_config, 'generator')
            optimizer_d = OptimizerFactory.create_optimizer(discriminator, full_config, 'discriminator')
            print("✓ Optimizers created")
        except Exception as e:
            print(f" ERROR creating optimizers: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # TRAINING
        # ============================================================================
        print(f"\\n{'='*60}")
        print(f"STARTING {training_mode.upper()} TRAINING")
        print(f"{'='*60}")
        
        # Training results
        training_history = {
            'training_mode': training_mode,
            'algorithm': algorithm,
            'model_type': 'dcgan',
            'loss_entries': [],
            'generated_images': []
        }
        
        # For images
        generated_images_info = []
        all_epoch_images = []
        
        # Initial images
        print(f"\\nGenerating initial images (before training)...")
        initial_images, initial_grid, initial_base64 = save_and_encode_images(
            generator, device, epoch=0, num_images=16, save_dir="/tmp/generated_images"
        )
        
        # Upload initial grid
        bearer_token = args.bearer_token
        initial_grid_url = None
        if initial_grid and os.path.exists(initial_grid):
            initial_grid_url = upload_to_cdn(
                initial_grid, 
                "Initial generated images grid", 
                bearer_token, args.domain, args.get_cdn
            )
        
        generated_images_info.append({
            'epoch': 0,
            'grid_url': initial_grid_url,
            'description': 'Initial images before training',
            'base64_previews': initial_base64[:4] if initial_base64 else [],
            'uid': str(uuid.uuid4())
        })
        
        print(f"\\nInitial images saved")
        if initial_grid_url:
            print(f"Initial grid URL: {initial_grid_url}")
        
        # ============================================================================
        # PERFORM TRAINING
        # ============================================================================
        results = train_algorithm_robust(
            generator, discriminator, train_loader,
            optimizer_g, optimizer_d, device,
            algorithm=algorithm,
            epochs=epochs,
            n_critic=n_critic
        )
        
        if not results['loss_entries']:
            print(f"ERROR: {training_mode} training failed - no loss entries recorded")
            sys.exit(1)
            
        training_history['loss_entries'] = results['loss_entries']
        
        print(f"\\n{training_mode} training completed: {len(results['loss_entries'])} loss entries recorded")
        print(f"Total batches processed: {results.get('batches_processed', 0)}")
        
        # ============================================================================
        # GENERATE FINAL IMAGES
        # ============================================================================
        print(f"\\nGenerating final images...")
        final_images, final_grid, final_base64 = save_and_encode_images(
            generator, device, epoch=epochs, num_images=16, save_dir="/tmp/generated_images"
        )
        
        final_grid_url = None
        if final_grid and os.path.exists(final_grid):
            final_grid_url = upload_to_cdn(
                final_grid, 
                "Final generated images grid", 
                bearer_token, args.domain, args.get_cdn
            )
        
        generated_images_info.append({
            'epoch': epochs,
            'grid_url': final_grid_url,
            'description': 'Final images after training',
            'base64_previews': final_base64[:4] if final_base64 else [],
            'uid': str(uuid.uuid4())
        })
        
        all_epoch_images.extend(final_images)
        training_history['generated_images'] = generated_images_info
        
        # ============================================================================
        # SAVE ALL OUTPUTS
        # ============================================================================
        print("\\nSaving outputs...")
        
        try:
            # Save trained model
            os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
            
            checkpoint = {
                'generator_state_dict': generator.state_dict(),
                'discriminator_state_dict': discriminator.state_dict(),
                'optimizer_g_state_dict': optimizer_g.state_dict(),
                'optimizer_d_state_dict': optimizer_d.state_dict(),
                'config': full_config,
                'training_mode': training_mode,
                'algorithm': algorithm,
                'training_history': training_history,
                'generated_images_info': generated_images_info,
                'model_info': {
                    'generator_params': sum(p.numel() for p in generator.parameters()),
                    'discriminator_params': sum(p.numel() for p in discriminator.parameters()),
                    'z_dim': generator.z_dim,
                    'image_size': generator.image_size,
                    'channels': generator.image_channels
                }
            }
            
            torch.save(checkpoint, args.trained_model)
            print(f"✓ Model saved to: {args.trained_model}")
            
            # Save training history
            os.makedirs(os.path.dirname(args.training_history), exist_ok=True)
            with open(args.training_history, "w") as f:
                json.dump(training_history, f, indent=2)
            print(f"✓ Training history saved to: {args.training_history}")
            
            # Create processed history
            os.makedirs(os.path.dirname(args.processed_history_json), exist_ok=True)
            
            # Prepare data for processed history
            processed_data = []
            for entry in training_history['loss_entries']:
                row = {
                    "epoch": entry.get('epoch', 1),
                    "loss": entry['loss'],
                    "component": entry['component'],
                    "type": "train",
                    "training_mode": entry['training_mode'],
                    "uid": entry['uid']
                }
                if 'note' in entry:
                    row["note"] = entry['note']
                processed_data.append(row)
            
            # Get final losses
            final_g_loss = next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'generator'), 0.0)
            final_d_loss = next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'discriminator'), 0.0)
            
            output = {
                "training_completed": True,
                "model_type": "dcgan",
                "training_mode": training_mode,
                "algorithm": algorithm,
                "epoch": len(training_history['loss_entries']) // 2 if training_history['loss_entries'] else 0,
                "loss": final_g_loss,
                "validation_loss": final_d_loss,
                "total_epochs_trained": epochs,
                "image_grids": [img_info['grid_url'] for img_info in generated_images_info if img_info.get('grid_url')],
                "data": processed_data
            }
            
            with open(args.processed_history_json, "w") as f:
                json.dump(output, f, indent=2)
            print(f"✓ Processed history saved to: {args.processed_history_json}")
            
            # Generated images URLs
            os.makedirs(os.path.dirname(args.generated_images_urls), exist_ok=True)
            images_output = {
                "training_mode": training_mode,
                "algorithm": algorithm,
                "model_type": "dcgan",
                "total_images": len(all_epoch_images),
                "image_grids": [{"epoch": img['epoch'], "url": img['grid_url']} for img in generated_images_info if img.get('grid_url')]
            }
            with open(args.generated_images_urls, "w") as f:
                json.dump(images_output, f, indent=2)
            print(f"✓ Generated images URLs saved to: {args.generated_images_urls}")
            
            # Training images summary
            os.makedirs(os.path.dirname(args.training_images_summary), exist_ok=True)
            summary = {
                "training_completed": True,
                "model_type": "dcgan",
                "training_mode": training_mode,
                "algorithm": algorithm,
                "epochs_trained": epochs,
                "batch_size": batch_size,
                "n_critic": n_critic,
                "final_metrics": {
                    "generator_loss": final_g_loss,
                    "discriminator_loss": final_d_loss
                },
                "image_progress": [{
                    "epoch": img['epoch'], 
                    "grid_url": img.get('grid_url'),
                    "description": img.get('description', ''),
                    "uid": img.get('uid', '')
                } for img in generated_images_info],
                "model_info": {
                    "generator_params": sum(p.numel() for p in generator.parameters()),
                    "discriminator_params": sum(p.numel() for p in discriminator.parameters()),
                    "z_dim": generator.z_dim,
                    "image_size": generator.image_size,
                    "channels": generator.image_channels
                }
            }
            
            with open(args.training_images_summary, "w") as f:
                json.dump(summary, f, indent=2)
            print(f"✓ Training images summary saved to: {args.training_images_summary}")
            
        except Exception as e:
            print(f" ERROR saving outputs: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # FINAL SUMMARY
        # ============================================================================
        print(f"\\n{'='*80}")
        print(f"SUCCESS: {training_mode.upper()} TRAINING COMPLETED")
        print(f"{'='*80}")
        print(f"✓ Model type: DCGAN")
        print(f"✓ Training mode: {training_mode}")
        print(f"✓ Algorithm: {algorithm}")
        print(f"✓ Epochs trained: {epochs}")
        print(f"✓ Loss entries recorded: {len(training_history['loss_entries'])}")
        print(f"✓ Images generated: {len(all_epoch_images)}")
        print(f"✓ Model saved: {args.trained_model}")
        if initial_grid_url:
            print(f"✓ Initial images URL: {initial_grid_url}")
        if final_grid_url:
            print(f"✓ Final images URL: {final_grid_url}")
        
        # Print final metrics
        if training_history['loss_entries']:
            last_g_loss = next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'generator'), 0.0)
            last_d_loss = next((x['loss'] for x in reversed(training_history['loss_entries']) if x['component'] == 'discriminator'), 0.0)
            print(f"✓ Final Generator Loss: {last_g_loss:.6f}")
            print(f"✓ Final Discriminator Loss: {last_d_loss:.6f}")
        
        print(f"{'='*80}\\n")
    args:
      - --data_path
      - {inputPath: data_path}
      - --master_config
      - {inputValue: master_config}
      - --model_input
      - {inputPath: model_input}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
      - --processed_history_json
      - {outputPath: processed_history_json}
      - --generated_images_urls
      - {outputPath: generated_images_urls}
      - --training_images_summary
      - {outputPath: training_images_summary}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
