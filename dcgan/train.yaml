name: Train DCGAN v33 - FIXED
description: Trains DCGAN with Backprop, CAFO, or Forward-Forward using EnhancedDCGANTrainer
inputs:
  - name: data_path
    type: Dataset
    description: "Processed data from CDN (Pickle file)"
  - name: master_config
    type: String
    description: "Master configuration JSON"
  - name: model_input
    type: Model
    description: "Built DCGAN model from Build brick"
  - name: bearer_token
    type: String
    description: "Bearer token for CDN upload"
  - name: domain
    type: String
    description: "CDN upload domain"
  - name: get_cdn
    type: String
    description: "CDN download prefix"
  
outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String
  - name: training_metrics
    type: String
  - name: generated_samples
    type: Dataset
  - name: generated_images_urls
    type: String
  - name: training_images_summary
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -c
      - |
        echo "Installing required packages..."
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        pip install pillow matplotlib > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import argparse, pickle, os, json, sys, time, uuid
        import numpy as np
        import base64
        import subprocess
        from PIL import Image
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader, Dataset, TensorDataset
        from io import BytesIO
        import matplotlib.pyplot as plt
        import warnings
        import traceback
        
        warnings.filterwarnings('ignore')
        
        # Set matplotlib backend
        import matplotlib
        matplotlib.use('Agg')
        
        print("=" * 80)
        print("TRAIN DCGAN v29 - COMPLETE FIX")
        print("=" * 80)
        print(f"Python version: {sys.version}")
        print(f"Torch version: {torch.__version__}")
        
        # ============================================================================
        # CREATE ALL NECESSARY CLASS DEFINITIONS FROM PREVIOUS BRICKS
        # ============================================================================
        
        print("\\n" + "-" * 40)
        print("DEFINING COMPATIBILITY CLASSES")
        print("-" * 40)
        
        # From Preprocess v1 brick - CRITICAL FOR LOADING DATA
        class PreprocessedDataset:
            def __init__(self, images, labels, dataset_name, preprocessor_params):
                self.images = images
                self.labels = labels
                self.dataset_name = dataset_name
                self.preprocessed = True
                self.preprocessor_params = preprocessor_params
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx],
                    'index': idx,
                    'dataset': self.dataset_name,
                    'preprocessed': True,
                    'preprocessor_params': self.preprocessor_params
                }
        
        # From Load Raw Dataset v1 brick
        class RawDatasetWrapper:
            def __init__(self, images, labels, dataset_name='mnist'):
                self.images = images  # Raw images
                self.labels = labels  # Raw labels
                self.dataset_name = dataset_name
                self.preprocessed = False  # Mark as raw
                self._num_samples = len(images)
            
            def __len__(self):
                return self._num_samples
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx],
                    'index': idx,
                    'dataset': self.dataset_name,
                    'preprocessed': self.preprocessed
                }
        
        class DatasetInfoWrapper:
            def __init__(self, info_dict):
                self.__dict__.update(info_dict)
        
        # Local wrapper classes for data compatibility
        class ProcessedDatasetWrapper:
            def __init__(self, images, labels=None):
                self.images = images
                self.labels = labels
                self.preprocessed = True
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                return self.images[idx]
            
            def get_sample(self, idx):
                return {
                    'image': self.images[idx],
                    'label': self.labels[idx] if self.labels is not None else 0,
                    'index': idx,
                    'preprocessed': True
                }
        
        class SimpleDCGANDataset(Dataset):
            def __init__(self, images, normalize=False):
                self.images = images
                self.normalize = normalize
            
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                img = self.images[idx]
                if self.normalize:
                    # Already normalized from [-1, 1] in preprocess
                    return img
                return img
        
        print("COMPATIBILITY: Compatibility classes defined")
        
        # ============================================================================
        # IMPORT DCGAN WITH FALLBACKS
        # ============================================================================
        
        print("\\n" + "-" * 40)
        print("IMPORTING DCGAN MODULES")
        print("-" * 40)
        
        # First, let's see what's available
        try:
            import nesy_factory.GANs.dcgan as dcgan_module
            print("SUCCESS: Successfully imported nesy_factory.GANs.dcgan")
            
            # Check what's available
            available_attrs = [attr for attr in dir(dcgan_module) if not attr.startswith('_')]
            print(f"INFO: Available attributes ({len(available_attrs)}):")
            for i in range(0, len(available_attrs), 10):
                print(f"   {', '.join(available_attrs[i:i+10])}")
            
            # Try to import specific classes with fallbacks
            try:
                from nesy_factory.GANs.dcgan import DCGANConfig
                print("  IMPORT: DCGANConfig imported")
            except ImportError:
                print("   WARNING: DCGANConfig not found, will create config manually")
                DCGANConfig = None
            
            try:
                from nesy_factory.GANs.dcgan import TrainingAlgorithm
                print("  IMPORT: TrainingAlgorithm imported")
            except ImportError:
                print("   WARNING: TrainingAlgorithm not found")
                TrainingAlgorithm = None
            
            try:
                from nesy_factory.GANs.dcgan import EnhancedDCGANTrainer
                print("  IMPORT: EnhancedDCGANTrainer imported")
            except ImportError:
                print("   ERROR: EnhancedDCGANTrainer not found - this is critical!")
                EnhancedDCGANTrainer = None
            
            try:
                from nesy_factory.GANs.dcgan import validate_config
                print("  IMPORT: validate_config imported")
            except ImportError:
                print("   WARNING: validate_config not found")
                validate_config = None
            
            try:
                from nesy_factory.GANs.dcgan import DCGANDataset
                print("  IMPORT: DCGANDataset imported")
            except ImportError:
                print("   WARNING: DCGANDataset not found, using SimpleDCGANDataset")
                DCGANDataset = SimpleDCGANDataset
            
        except ImportError as e:
            print(f"ERROR: importing nesy_factory: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # MAIN CODE
        # ============================================================================
        
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--master_config", required=True)
        parser.add_argument("--model_input", required=True)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        parser.add_argument("--training_metrics", required=True)
        parser.add_argument("--generated_samples", required=True)
        parser.add_argument("--generated_images_urls", required=True)
        parser.add_argument("--training_images_summary", required=True)
        parser.add_argument("--bearer_token", required=True)
        parser.add_argument("--domain", required=True)
        parser.add_argument("--get_cdn", required=True)
        args = parser.parse_args()
        
        print("\\n" + "="*80)
        print("DCGAN TRAINING v29 - FIXED")
        print("="*80)
        
        # ============================================================================
        # CREATE ALL OUTPUT DIRECTORIES FIRST
        # ============================================================================
        print("\\n" + "-" * 40)
        print("CREATING OUTPUT DIRECTORIES")
        print("-" * 40)
        
        output_paths = [
            args.trained_model,
            args.training_history,
            args.training_metrics,
            args.generated_samples,
            args.generated_images_urls,
            args.training_images_summary
        ]
        
        for path in output_paths:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    print(f"  DIRECTORY: Created: {dir_path}")
        
        # ============================================================================
        # PARSE CONFIG AND SETUP
        # ============================================================================
        
        print("\\n" + "-" * 40)
        print("PARSING MASTER CONFIG")
        print("-" * 40)
        
        try:
            config = json.loads(args.master_config)
            gan_cfg = config['gan']
            dataset_cfg = config['dataset']
            
            # Determine training algorithm
            algorithm = gan_cfg['training'].get('algorithm', 'backprop')
            epochs = gan_cfg['training'].get('epochs', 2)
            batch_size = gan_cfg['training'].get('batch_size', 16)
            
            print(f"CONFIG: Training Algorithm: {algorithm.upper()}")
            print(f"CONFIG: Epochs: {epochs}")
            print(f"CONFIG: Batch size: {batch_size}")
            
        except Exception as e:
            print(f"ERROR: parsing master_config: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # LOAD DATASET - COMPATIBLE WITH PREPROCESS v1 OUTPUT
        # ============================================================================
        
        print("\\n" + "-" * 40)
        print("LOADING DATASET")
        print("-" * 40)
        
        try:
            print(f"LOADING: Loading dataset from: {args.data_path}")
            
            # Check if file exists
            if not os.path.exists(args.data_path):
                print(f"ERROR: Data file does not exist: {args.data_path}")
                sys.exit(1)
            
            # List all pickle files in directory if it's a directory
            if os.path.isdir(args.data_path):
                print(f"LOADING: {args.data_path} is a directory, looking for pickle files...")
                pickle_files = [f for f in os.listdir(args.data_path) if f.endswith('.pkl') or f.endswith('.pickle')]
                if pickle_files:
                    data_file = os.path.join(args.data_path, pickle_files[0])
                    print(f"LOADING: Found pickle file: {data_file}")
                else:
                    print(f"ERROR: No pickle files found in directory")
                    sys.exit(1)
            else:
                data_file = args.data_path
            
            file_size = os.path.getsize(data_file)
            print(f"LOADING: File size: {file_size:,} bytes ({file_size/1024:.1f} KB)")
            
            # Load processed data from Preprocess v1
            print("LOADING: Loading pickle file...")
            with open(data_file, 'rb') as f:
                try:
                    data_wrapper = pickle.load(f)
                    print(f"SUCCESS: Pickle loaded successfully")
                except Exception as e:
                    print(f"ERROR: Failed to load pickle: {e}")
                    traceback.print_exc()
                    sys.exit(1)
            
            print(f"INFO: Data wrapper type: {type(data_wrapper)}")
            print(f"INFO: Available attributes: {[a for a in dir(data_wrapper) if not a.startswith('_')]}")
            
            # Handle different data wrapper types from preprocess brick
            if isinstance(data_wrapper, PreprocessedDataset):
                print("DETECTED: PreprocessedDataset type")
                images = data_wrapper.images
                labels = data_wrapper.labels if hasattr(data_wrapper, 'labels') else None
                
            elif hasattr(data_wrapper, 'images'):
                print("DETECTED: wrapper with 'images' attribute")
                images = data_wrapper.images
                labels = data_wrapper.labels if hasattr(data_wrapper, 'labels') else None
            else:
                print("WARNING: Unknown data format, trying to extract images...")
                # Try to extract images directly
                if hasattr(data_wrapper, '__len__'):
                    images_list = []
                    for i in range(min(10, len(data_wrapper))):  # Sample first 10
                        try:
                            img = data_wrapper[i]
                            if isinstance(img, torch.Tensor):
                                images_list.append(img)
                            elif isinstance(img, (list, tuple, np.ndarray)):
                                images_list.append(torch.tensor(img))
                        except:
                            pass
                    
                    if images_list:
                        images = torch.stack(images_list) if len(images_list) > 1 else images_list[0].unsqueeze(0)
                        labels = None
                    else:
                        print(f"ERROR: Could not extract images from dataset")
                        sys.exit(1)
                else:
                    print(f"ERROR: Unsupported data format")
                    sys.exit(1)
            
            # Check tensor shape and convert to proper format
            if isinstance(images, torch.Tensor):
                if images.dim() == 4:
                    # Shape: (N, C, H, W)
                    images_list = [images[i] for i in range(len(images))]
                    channels = images.shape[1]
                    image_size = images.shape[2]
                elif images.dim() == 3:
                    # Shape: (N, H, W) - add channel dimension
                    images_list = [images[i].unsqueeze(0) for i in range(len(images))]
                    channels = 1
                    image_size = images.shape[1]
                else:
                    print(f"ERROR: Unexpected tensor shape: {images.shape}")
                    sys.exit(1)
            else:
                print(f"ERROR: images is not a tensor, type: {type(images)}")
                sys.exit(1)
            
            print(f"SUCCESS: Dataset loaded successfully:")
            print(f"   SAMPLES: Samples: {len(images_list)}")
            print(f"   SHAPE: Image shape: {images_list[0].shape}")
            print(f"   CHANNELS: Channels: {channels}")
            print(f"   SIZE: Image size: {image_size}")
            print(f"   RANGE: Value range: [{images_list[0].min():.3f}, {images_list[0].max():.3f}]")
            
        except Exception as e:
            print(f"ERROR: loading dataset: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # Create dataset for training
        if DCGANDataset is not None:
            print("DATASET: Using DCGANDataset for training")
            train_dataset = DCGANDataset(images_list, normalize=False)
        else:
            print("DATASET: Using SimpleDCGANDataset for training")
            train_dataset = SimpleDCGANDataset(images_list, normalize=False)
        
        # Create dataloader
        actual_batch_size = min(batch_size, max(1, len(train_dataset)))
        dataloader = DataLoader(
            train_dataset, 
            batch_size=actual_batch_size, 
            shuffle=True, 
            drop_last=True,
            num_workers=0
        )
        
        print(f"\\nDATALOADER: Data loader created:")
        print(f"   SIZE: Dataset size: {len(train_dataset)}")
        print(f"   BATCH: Batch size: {actual_batch_size}")
        print(f"   BATCHES: Batches per epoch: {len(dataloader)}")
        
        # ============================================================================
        # LOAD MODEL AND SETUP TRAINER
        # ============================================================================
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"\\n" + "-" * 40)
        print(f"DEVICE SETUP")
        print("-" * 40)
        print(f"DEVICE: Device: {device}")
        if torch.cuda.is_available():
            print(f"CUDA: CUDA Device: {torch.cuda.get_device_name(0)}")
            print(f"CUDA: CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        
        try:
            # Check if model file exists
            if not os.path.exists(args.model_input):
                print(f"ERROR: Model file does not exist: {args.model_input}")
                sys.exit(1)
            
            model_file_size = os.path.getsize(args.model_input)
            print(f"MODEL: Model file size: {model_file_size:,} bytes ({model_file_size/1024**2:.2f} MB)")
            
            # Load checkpoint
            print(f"LOADING: Loading model from: {args.model_input}")
            checkpoint = torch.load(args.model_input, map_location='cpu')
            
            # Extract model info
            if 'model_info' in checkpoint:
                model_info = checkpoint['model_info']
                print(f"MODEL INFO: Model source: {model_info.get('model_source', 'unknown')}")
                print(f"MODEL INFO: Model type: {model_info.get('model_type', 'unknown')}")
            
            # Check if we need to create config from scratch
            if EnhancedDCGANTrainer is None:
                print("ERROR: EnhancedDCGANTrainer is not available")
                sys.exit(1)
            
            # Create config for trainer - FIXED: Handle DCGANConfig dataclass properly
            trainer = None
            
            if 'config' in checkpoint and checkpoint['config'] is not None:
                dcgan_config = checkpoint['config']
                print(f"CONFIG: Using config from checkpoint (type: {type(dcgan_config)})")
                
                # Check if config is a DCGANConfig dataclass (not a dict)
                if hasattr(dcgan_config, '__dataclass_fields__'):
                    # It's a dataclass - update attributes directly
                    print("CONFIG: Config is a dataclass, updating attributes...")
                    
                    # Update training parameters - use attribute access for dataclass
                    if hasattr(dcgan_config, 'epochs'):
                        dcgan_config.epochs = epochs
                    if hasattr(dcgan_config, 'batch_size'):
                        dcgan_config.batch_size = actual_batch_size
                    if hasattr(dcgan_config, 'device'):
                        dcgan_config.device = str(device)
                    
                    # Set algorithm flags
                    if algorithm == 'cafo':
                        if hasattr(dcgan_config, 'use_cafo'):
                            dcgan_config.use_cafo = True
                        if hasattr(dcgan_config, 'block_training') and dcgan_config.block_training is not None:
                            dcgan_config.block_training.enabled = True
                    elif algorithm == 'forward_forward':
                        if hasattr(dcgan_config, 'use_forward_forward'):
                            dcgan_config.use_forward_forward = True
                        if hasattr(dcgan_config, 'block_training') and dcgan_config.block_training is not None:
                            dcgan_config.block_training.enabled = True
                    else:
                        if hasattr(dcgan_config, 'block_training') and dcgan_config.block_training is not None:
                            dcgan_config.block_training.enabled = False
                    
                    # Validate config if available
                    if validate_config is not None:
                        is_valid, errors = validate_config(dcgan_config)
                        if not is_valid:
                            print("WARNING: Config validation warnings:")
                            for error in errors:
                                print(f"  WARNING: {error}")
                    
                    # Create trainer with config
                    try:
                        trainer = EnhancedDCGANTrainer(dcgan_config)
                        print("TRAINER: Trainer created with config from checkpoint")
                    except Exception as e:
                        print(f"WARNING: Could not create trainer with checkpoint config: {e}")
                        print("WARNING: Creating trainer with default config")
                        trainer = EnhancedDCGANTrainer()
                        
                elif isinstance(dcgan_config, dict):
                    # It's a dictionary - need to convert to DCGANConfig
                    print("CONFIG: Config is a dictionary, converting to DCGANConfig...")
                    
                    # Update config dictionary with training parameters
                    dcgan_config['epochs'] = epochs
                    dcgan_config['batch_size'] = actual_batch_size
                    dcgan_config['device'] = str(device)
                    
                    # Set algorithm flags in dictionary
                    if algorithm == 'cafo':
                        dcgan_config['use_cafo'] = True
                        if 'block_training' in dcgan_config:
                            dcgan_config['block_training']['enabled'] = True
                    elif algorithm == 'forward_forward':
                        dcgan_config['use_forward_forward'] = True
                        if 'block_training' in dcgan_config:
                            dcgan_config['block_training']['enabled'] = True
                    else:
                        if 'block_training' in dcgan_config:
                            dcgan_config['block_training']['enabled'] = False
                    
                    # Try to create DCGANConfig from dict
                    if DCGANConfig is not None:
                        try:
                            if hasattr(DCGANConfig, 'from_dict'):
                                dcgan_config_obj = DCGANConfig.from_dict(dcgan_config)
                                print("CONFIG: DCGANConfig created using from_dict()")
                                
                                # Create trainer with config
                                trainer = EnhancedDCGANTrainer(dcgan_config_obj)
                                print("TRAINER: Trainer created with config from dict")
                            else:
                                # Fallback: create trainer with minimal config
                                print("WARNING: DCGANConfig.from_dict not available")
                                trainer = EnhancedDCGANTrainer()
                        except Exception as e:
                            print(f"WARNING: Error creating DCGANConfig from dict: {e}")
                            trainer = EnhancedDCGANTrainer()
                    else:
                        print("WARNING: DCGANConfig not available")
                        trainer = EnhancedDCGANTrainer()
                else:
                    print(f"WARNING: Unknown config type: {type(dcgan_config)}")
                    trainer = EnhancedDCGANTrainer()
            else:
                # Create minimal trainer
                print("WARNING: No config in checkpoint, creating trainer with minimal configuration...")
                trainer = EnhancedDCGANTrainer()
            
            # Load weights if available
            if 'generator_state_dict' in checkpoint:
                trainer.generator.load_state_dict(checkpoint['generator_state_dict'])
                print("WEIGHTS: Generator weights loaded")
            else:
                print("WARNING: No generator_state_dict in checkpoint")
            
            if 'discriminator_state_dict' in checkpoint:
                trainer.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
                print("WEIGHTS: Discriminator weights loaded")
            else:
                print("WARNING: No discriminator_state_dict in checkpoint")
            
            # Set latent dim for sampling
            if hasattr(trainer.generator, 'latent_dim'):
                latent_dim = trainer.generator.latent_dim
            else:
                latent_dim = 100
            
            # Move models to device
            trainer.generator = trainer.generator.to(device)
            trainer.discriminator = trainer.discriminator.to(device)
            
            print(f"SUCCESS: Trainer setup complete")
            print(f"  ALGORITHM: Algorithm: {algorithm.upper()}")
            print(f"  LATENT DIM: Latent dim: {latent_dim}")
            print(f"  GENERATOR PARAMS: Generator parameters: {sum(p.numel() for p in trainer.generator.parameters()):,}")
            print(f"  DISCRIMINATOR PARAMS: Discriminator parameters: {sum(p.numel() for p in trainer.discriminator.parameters()):,}")
            
        except Exception as e:
            print(f"ERROR: setting up trainer: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # TRAINING
        # ============================================================================
        
        print(f"\\n" + "="*60)
        print(f"STARTING TRAINING")
        print("="*60)
        
        start_time = time.time()
        training_success = False
        
        try:
            # Simple training loop
            print(f"\\nTRAINING: Training for {epochs} epochs...")
            
            trainer.generator.train()
            trainer.discriminator.train()
            
            # Store training history
            training_history = {
                'epoch_losses': [],
                'generator_losses': [],
                'discriminator_losses': []
            }
            
            for epoch in range(epochs):
                print(f"\\nEPOCH {epoch+1}/{epochs}:")
                
                epoch_g_loss = []
                epoch_d_loss = []
                
                for batch_idx, batch_data in enumerate(dataloader):
                    if batch_idx > 10:  # Limit batches for testing
                        print(f"  BATCH: Limiting to 10 batches for testing, stopping at batch {batch_idx}")
                        break
                    
                    # Get real data
                    real_data = batch_data.to(device)
                    batch_size_real = real_data.size(0)
                    
                    # Train discriminator
                    if hasattr(trainer, 'disc_optimizer'):
                        trainer.disc_optimizer.zero_grad()
                    
                    # Real data
                    real_output = trainer.discriminator(real_data)
                    if real_output.dim() > 1:
                        real_output = real_output.view(-1)
                    
                    real_labels = torch.ones(batch_size_real, device=device)
                    d_loss_real = nn.functional.binary_cross_entropy_with_logits(real_output, real_labels)
                    
                    # Fake data - FIXED: Remove spatial dimensions, use 2D tensor
                    z = torch.randn(batch_size_real, latent_dim, device=device)  # Shape: (batch_size, 100)
                    fake_data = trainer.generator(z).detach()
                    fake_output = trainer.discriminator(fake_data)
                    if fake_output.dim() > 1:
                        fake_output = fake_output.view(-1)
                    
                    fake_labels = torch.zeros(batch_size_real, device=device)
                    d_loss_fake = nn.functional.binary_cross_entropy_with_logits(fake_output, fake_labels)
                    
                    d_loss = (d_loss_real + d_loss_fake) / 2
                    d_loss.backward()
                    
                    if hasattr(trainer, 'disc_optimizer'):
                        trainer.disc_optimizer.step()
                    
                    # Train generator
                    if hasattr(trainer, 'gen_optimizer'):
                        trainer.gen_optimizer.zero_grad()
                    
                    z = torch.randn(batch_size_real, latent_dim, device=device)  # Shape: (batch_size, 100)
                    fake_data = trainer.generator(z)
                    fake_output = trainer.discriminator(fake_data)
                    if fake_output.dim() > 1:
                        fake_output = fake_output.view(-1)
                    
                    g_loss = nn.functional.binary_cross_entropy_with_logits(fake_output, real_labels)
                    g_loss.backward()
                    
                    if hasattr(trainer, 'gen_optimizer'):
                        trainer.gen_optimizer.step()
                    
                    epoch_g_loss.append(g_loss.item())
                    epoch_d_loss.append(d_loss.item())
                    
                    if batch_idx % 2 == 0:
                        print(f"  BATCH {batch_idx}: G={g_loss.item():.4f}, D={d_loss.item():.4f}")
                
                avg_g_loss = np.mean(epoch_g_loss) if epoch_g_loss else 0
                avg_d_loss = np.mean(epoch_d_loss) if epoch_d_loss else 0
                
                training_history['generator_losses'].append(avg_g_loss)
                training_history['discriminator_losses'].append(avg_d_loss)
                training_history['epoch_losses'].append({
                    'epoch': epoch + 1,
                    'generator_loss': avg_g_loss,
                    'discriminator_loss': avg_d_loss
                })
                
                print(f"  EPOCH SUMMARY: G={avg_g_loss:.4f}, D={avg_d_loss:.4f}")
            
            training_time = time.time() - start_time
            print(f"\\nTRAINING COMPLETE: Training completed in {training_time:.2f}s")
            training_success = True
            
        except Exception as e:
            print(f"ERROR: during training: {e}")
            traceback.print_exc()
            training_success = False
        
        # ============================================================================
        # GENERATE SAMPLES
        # ============================================================================
        
        print(f"\\nGENERATING SAMPLES...")
        
        try:
            trainer.generator.eval()
            with torch.no_grad():
                # Generate samples
                num_samples = 16
                z = torch.randn(num_samples, latent_dim, device=device)  # FIXED: 2D tensor, not 4D
                samples = trainer.generator(z).cpu()
                
                # Convert from [-1, 1] to [0, 1] for saving
                samples = (samples + 1) / 2
                samples = torch.clamp(samples, 0, 1)
                
                print(f"SUCCESS: Generated {len(samples)} samples")
                print(f"  SHAPE: Sample shape: {samples[0].shape}")
                print(f"  RANGE: Sample range: [{samples.min():.3f}, {samples.max():.3f}]")
                
        except Exception as e:
            print(f"ERROR: generating samples: {e}")
            traceback.print_exc()
            samples = torch.randn(16, channels, image_size, image_size) * 0.5 + 0.5
        
        # ============================================================================
        # CDN UPLOAD FUNCTION
        # ============================================================================
        
        def upload_to_cdn(file_path, description, bearer_token, domain, get_cdn_prefix):
            if not os.path.exists(file_path):
                print(f"  UPLOAD ERROR: File does not exist: {file_path}")
                return None
            
            file_size = os.path.getsize(file_path)
            print(f"  UPLOAD: Uploading {description} ({file_size:,} bytes)...")
            
            # Generate unique filename
            unique_id = str(uuid.uuid4())[:8]
            cdn_filename = f"dcgan_{description.replace(' ', '_')}_{unique_id}.png"
            
            upload_url = f"{domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fdcgan%2F"
            
            curl_command = [
                "curl",
                "--location", upload_url,
                "--header", f"Authorization: Bearer {bearer_token}",
                "--form", f"file=@{file_path}",
                "--form", f"filename={cdn_filename}",
                "--fail",
                "--show-error",
                "--connect-timeout", "30",
                "--max-time", "120"
            ]
            
            try:
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                response_json = json.loads(process.stdout)
                relative_cdn_url = response_json.get("cdnUrl", "")
                
                if not relative_cdn_url:
                    print(f"    UPLOAD ERROR: No cdnUrl in response")
                    return None
                
                full_url = f"{get_cdn_prefix}{relative_cdn_url}"
                print(f"    UPLOAD SUCCESS: Uploaded: {full_url[:80]}...")
                return full_url
                
            except subprocess.CalledProcessError as e:
                print(f"    UPLOAD ERROR: {e.stderr[:200]}")
                return None
            except json.JSONDecodeError:
                print(f"    UPLOAD ERROR: Invalid JSON response")
                return None
        
        # Create sample grid
        def create_sample_grid(samples, title, save_path):
            n_cols = 4
            n_rows = 4
            fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 12))
            axes = axes.flatten()
            
            for i in range(min(16, len(samples))):
                ax = axes[i]
                sample = samples[i]
                
                if sample.dim() == 3:
                    if sample.shape[0] == 1:  # Grayscale
                        ax.imshow(sample[0], cmap='gray', vmin=0, vmax=1)
                    else:  # RGB
                        ax.imshow(sample.permute(1, 2, 0))
                elif sample.dim() == 2:  # 2D grayscale
                    ax.imshow(sample, cmap='gray', vmin=0, vmax=1)
                
                ax.axis('off')
                ax.set_title(f"Sample {i+1}", fontsize=8)
            
            for i in range(min(16, len(samples)), len(axes)):
                axes[i].axis('off')
            
            plt.suptitle(title, fontsize=16)
            plt.tight_layout()
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"  SAVED: Saved grid to: {save_path}")
        
        # Read bearer token - FIX: Save to a temporary file first
        try:
            with open(args.bearer_token, 'r') as f:
                bearer_token_content = f.read().strip()
            
            # Save to a shorter filename
            bearer_token_file = "/tmp/bearer_token.txt"
            with open(bearer_token_file, 'w') as f:
                f.write(bearer_token_content)
            
            print(f"AUTH: Bearer token loaded ({len(bearer_token_content)} chars)")
        except Exception as e:
            print(f"ERROR: Could not read bearer token: {e}")
            bearer_token_content = ""
            bearer_token_file = ""
        
        # Create and upload sample grid
        if samples is not None:
            final_grid_path = "/tmp/final_samples_grid.png"
            create_sample_grid(samples, f"DCGAN Samples ({algorithm.upper()})", final_grid_path)
            
            if bearer_token_file:
                final_grid_url = upload_to_cdn(
                    final_grid_path, "dcgan_final_samples", 
                    bearer_token_content,
                    args.domain,
                    args.get_cdn
                )
            else:
                final_grid_url = None
                print("WARNING: No bearer token, skipping CDN upload")
        else:
            final_grid_path = None
            final_grid_url = None
            print("WARNING: No samples generated, skipping grid creation")
        
        # ============================================================================
        # CREATE OUTPUTS
        # ============================================================================
        
        print(f"\\nCREATING OUTPUTS...")
        
        # Create training history
        training_history_data = {
            'algorithm': algorithm,
            'epochs_completed': epochs,
            'total_training_time': training_time,
            'training_success': training_success,
            'generator_losses': training_history.get('generator_losses', []),
            'discriminator_losses': training_history.get('discriminator_losses', []),
            'epoch_losses': training_history.get('epoch_losses', []),
            'final_metrics': {
                'generator_loss': training_history.get('generator_losses', [0])[-1],
                'discriminator_loss': training_history.get('discriminator_losses', [0])[-1]
            }
        }
        
        # Create training metrics
        training_metrics_data = {
            'model_type': 'dcgan',
            'training_algorithm': algorithm,
            'epochs_completed': epochs,
            'final_generator_loss': training_history_data['final_metrics']['generator_loss'],
            'final_discriminator_loss': training_history_data['final_metrics']['discriminator_loss'],
            'total_training_time': training_time,
            'training_success': training_success,
            'samples_generated': len(samples) if samples is not None else 0,
            'image_size': image_size,
            'channels': channels,
            'latent_dim': latent_dim,
            'batch_size': actual_batch_size,
            'device': str(device)
        }
        
        # Prepare generated samples for output
        if samples is not None:
            generated_samples_data = ProcessedDatasetWrapper(samples)
        else:
            generated_samples_data = ProcessedDatasetWrapper(torch.zeros(0))
        
        # Generated images URLs
        generated_images_urls_data = {
            'algorithm': algorithm,
            'model_type': 'dcgan',
            'image_grids': [
                {
                    'phase': 'final',
                    'url': final_grid_url if final_grid_url else '',
                    'description': f'DCGAN {algorithm.upper()} samples after training',
                    'grid_path': final_grid_path if final_grid_path else ''
                }
            ]
        }
        
        # Training images summary
        training_images_summary_data = {
            'training_completed': training_success,
            'algorithm': algorithm,
            'epochs_trained': epochs,
            'final_metrics': training_history_data['final_metrics'],
            'image_grid_url': final_grid_url if final_grid_url else '',
            'training_time': training_time,
            'samples_generated': len(samples) if samples is not None else 0
        }
        
        # Create trained model checkpoint
        trained_checkpoint = {
            'generator_state_dict': trainer.generator.state_dict(),
            'discriminator_state_dict': trainer.discriminator.state_dict(),
            'training_history': training_history_data,
            'training_metrics': training_metrics_data,
            'algorithm': algorithm,
            'epochs_trained': epochs,
            'master_config': config,
            'model_info': checkpoint.get('model_info', {}) if 'checkpoint' in locals() else {}
        }
        
        # Add the config to checkpoint if available
        if 'dcgan_config' in locals() and dcgan_config is not None:
            trained_checkpoint['config'] = dcgan_config
        
        # ============================================================================
        # SAVE OUTPUTS
        # ============================================================================
        
        try:
            # Save trained model
            torch.save(trained_checkpoint, args.trained_model)
            model_size = os.path.getsize(args.trained_model)
            print(f"SAVED: Trained model saved: {args.trained_model} ({model_size:,} bytes)")
            
            # Save training history
            with open(args.training_history, 'w') as f:
                json.dump(training_history_data, f, indent=2)
            print(f"SAVED: Training history saved: {args.training_history}")
            
            # Save training metrics
            with open(args.training_metrics, 'w') as f:
                json.dump(training_metrics_data, f, indent=2)
            print(f"SAVED: Training metrics saved: {args.training_metrics}")
            
            # Save generated samples
            with open(args.generated_samples, 'wb') as f:
                pickle.dump(generated_samples_data, f)
            print(f"SAVED: Generated samples saved: {args.generated_samples}")
            
            # Save generated images URLs
            with open(args.generated_images_urls, 'w') as f:
                json.dump(generated_images_urls_data, f, indent=2)
            print(f"SAVED: Generated images URLs saved: {args.generated_images_urls}")
            
            # Save training images summary
            with open(args.training_images_summary, 'w') as f:
                json.dump(training_images_summary_data, f, indent=2)
            print(f"SAVED: Training images summary saved: {args.training_images_summary}")
            
        except Exception as e:
            print(f"ERROR: saving outputs: {e}")
            traceback.print_exc()
            sys.exit(1)
        
        # ============================================================================
        # FINAL SUMMARY
        # ============================================================================
        
        print(f"\\n" + "="*80)
        if training_success:
            print(f" TRAINING COMPLETED SUCCESSFULLY!")
        else:
            print(f" TRAINING COMPLETED WITH ISSUES")
        print("="*80)
        print(f"Algorithm: {algorithm.upper()}")
        print(f"Epochs completed: {epochs}")
        print(f"Total time: {training_time:.2f}s")
        print(f"Final Generator Loss: {training_history_data['final_metrics']['generator_loss']:.4f}")
        print(f"Final Discriminator Loss: {training_history_data['final_metrics']['discriminator_loss']:.4f}")
        print(f"Samples generated: {len(samples) if samples is not None else 0}")
        print(f"Image size: {image_size}x{image_size}")
        print(f"Channels: {channels}")
        print(f"Latent dim: {latent_dim}")
        if final_grid_url:
            print(f"Sample grid URL: {final_grid_url[:80]}...")
        else:
            print(f"Sample grid: Not uploaded (saved locally)")
        print("="*80)

    args:
      - --data_path
      - {inputPath: data_path}
      - --master_config
      - {inputValue: master_config}
      - --model_input
      - {inputPath: model_input}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
      - --training_metrics
      - {outputPath: training_metrics}
      - --generated_samples
      - {outputPath: generated_samples}
      - --generated_images_urls
      - {outputPath: generated_images_urls}
      - --training_images_summary
      - {outputPath: training_images_summary}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --get_cdn
      - {inputValue: get_cdn}
