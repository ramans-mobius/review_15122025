name: Upload CDN Model As PT File v2
description: Uploads model as .pt file and shows full response
inputs:
  - name: trained_model
    type: Model
    description: "Trained DCGAN model"
  - name: bearer_token
    type: String
    description: "Bearer token"
  - name: domain
    type: String
    default: "https://ig.gov-cloud.ai"
    description: "API domain"
  - name: cdn_base
    type: String
    default: "https://cdn-new.gov-cloud.ai"
    description: "CDN base URL"
  
outputs:
  - name: cdn_url
    type: String
    description: "CDN URL for .pt file"
  - name: upload_response
    type: String
    description: "Full upload response JSON"
  - name: raw_response
    type: String
    description: "Raw response text"

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.9
    command:
      - sh
      - -ec
      - |
        apt-get update > /dev/null && apt-get install -y curl jq > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, subprocess, json, os, uuid, sys, time, textwrap
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--bearer_token', type=str, required=True)
        parser.add_argument('--domain', type=str, default="https://ig.mobiusdtaas.ai")
        parser.add_argument('--cdn_base', type=str, default="https://cdn-new.gov-cloud.ai")
        parser.add_argument('--cdn_url', type=str, required=True)
        parser.add_argument('--upload_response', type=str, required=True)
        parser.add_argument('--raw_response', type=str, required=True)
        
        args = parser.parse_args()
        
        # Create output directories
        os.makedirs(os.path.dirname(args.cdn_url), exist_ok=True)
        os.makedirs(os.path.dirname(args.upload_response), exist_ok=True)
        os.makedirs(os.path.dirname(args.raw_response), exist_ok=True)
        
        bearer_token = args.bearer_token.strip()
        
        print("=" * 80)
        print("UPLOAD MODEL AS .PT FILE v1")
        print("=" * 80)
        
        # STEP 1: Verify model file
        if not os.path.exists(args.trained_model):
            print(f"✗ ERROR: Model file does not exist: {args.trained_model}")
            sys.exit(1)
        
        model_size = os.path.getsize(args.trained_model)
        print(f"✓ Model file: {args.trained_model}")
        print(f"✓ File size: {model_size:,} bytes ({model_size/1024/1024:.2f} MB)")
        
        # STEP 2: Prepare upload - Use data endpoint for .pt file
        print("\\n" + "=" * 80)
        print("2. PREPARING UPLOAD")
        print("=" * 80)
        
        # Try different endpoints to get proper .pt file URL
        upload_url = f"{args.domain}/mobius-content-service/v1.0/content/upload?filePathAccess=private&filePath=%2Fdcgan%2Fmodels%2F"
        print(f"Upload URL: {upload_url}")
        print(f"Domain: {args.domain}")
        print(f"CDN Base: {args.cdn_base}")
        
        timestamp = int(time.time())
        unique_id = str(uuid.uuid4())[:8]
        filename = f"dcgan_model_{timestamp}_{unique_id}.pt"
        
        print(f"Generated filename: {filename}")
        print(f"File extension: .pt (PyTorch model file)")
        
        # STEP 3: Execute upload
        print("\\n" + "=" * 80)
        print("3. EXECUTING UPLOAD")
        print("=" * 80)
        
        curl_command = [
            "curl",
            "--location", upload_url,
            "--header", f"Authorization: Bearer {bearer_token}",
            "--form", f"file=@{args.trained_model}",
            "--form", f"filename={filename}",
            "--fail",
            "--show-error",
            "--connect-timeout", "60",
            "--max-time", "300",
            "--verbose"
        ]
        
        # Print the curl command (with token redacted)
        debug_cmd = ' '.join(curl_command).replace(bearer_token, '***REDACTED***')
        print("CURL COMMAND:")
        print("-" * 40)
        print(debug_cmd)
        print("-" * 40)
        
        # Execute with capture
        print("\\nEXECUTING CURL...")
        try:
            process = subprocess.run(
                curl_command,
                capture_output=True,
                text=True,
                check=False
            )
            
            # Save raw response immediately
            raw_output = process.stdout + process.stderr
            with open(args.raw_response, 'w') as f:
                f.write(raw_output)
            
            print("\\n" + "=" * 80)
            print("4. FULL CURL OUTPUT")
            print("=" * 80)
            
            # Print stderr (verbose info)
            if process.stderr:
                print("STDERR (VERBOSE OUTPUT):")
                print("-" * 40)
                # Print only important parts of verbose output
                for line in process.stderr.split('\\n'):
                    if any(x in line for x in ['HTTP/', '< HTTP/', '> POST', 'cdnUrl', 'Content-Type', 'Content-Length']):
                        print(line)
                print("-" * 40)
            
            # Print stdout (response body)
            print("\\nSTDOUT (RESPONSE BODY):")
            print("-" * 40)
            print(process.stdout)
            print("-" * 40)
            
            print(f"\\nExit code: {process.returncode}")
            
            if process.returncode != 0:
                print("✗ Upload failed!")
                sys.exit(1)
            
            # STEP 4: Parse and analyze response
            print("\\n" + "=" * 80)
            print("5. PARSING RESPONSE")
            print("=" * 80)
            
            response_data = None
            cdn_url_result = None
            
            try:
                response_data = json.loads(process.stdout)
                print("✓ Response is valid JSON")
                
                # Pretty print the JSON
                print("\\nRESPONSE JSON (PRETTY PRINTED):")
                print("-" * 40)
                print(json.dumps(response_data, indent=2))
                print("-" * 40)
                
                # Analyze the response structure
                print("\\nRESPONSE ANALYSIS:")
                print("-" * 40)
                print(f"Response type: {type(response_data)}")
                print(f"Response keys: {list(response_data.keys())}")
                
                # Extract CDN URL
                cdn_path = None
                
                # First check for cdnUrl at top level
                if 'cdnUrl' in response_data:
                    cdn_path = response_data['cdnUrl']
                    print(f"✓ Found 'cdnUrl' at top level: {cdn_path}")
                # Check in info object if exists
                elif 'info' in response_data and 'cdnUrl' in response_data['info']:
                    cdn_path = response_data['info']['cdnUrl']
                    print(f"✓ Found 'cdnUrl' in info object: {cdn_path}")
                # Check for url field
                elif 'url' in response_data:
                    cdn_path = response_data['url']
                    print(f"✓ Found 'url': {cdn_path}")
                
                if cdn_path:
                    # Fix common issues with CDN URLs
                    # 1. Remove trailing dots if present
                    if cdn_path.endswith('.'):
                        original_path = cdn_path
                        cdn_path = cdn_path.rstrip('.')
                        print(f"✓ Removed trailing dot from CDN path")
                        print(f"  Original: {original_path}")
                        print(f"  Fixed: {cdn_path}")
                    
                    # 2. Ensure it has .pt extension if missing
                    if not cdn_path.endswith('.pt'):
                        print(f"⚠ CDN path doesn't end with .pt: {cdn_path}")
                        # Check if we should add .pt extension
                        if 'name' in response_data.get('info', {}):
                            original_name = response_data['info']['name']
                            if original_name.endswith('.pt'):
                                print(f"  Original filename has .pt: {original_name}")
                    
                    # Construct full URL
                    if cdn_path.startswith("http"):
                        full_url = cdn_path
                        print(f"✓ URL is already complete: {full_url}")
                    else:
                        full_url = f"{args.cdn_base}{cdn_path}"
                        print(f"✓ Constructed full URL: {full_url}")
                    
                    cdn_url_result = full_url
                    
                    # Save the URL
                    with open(args.cdn_url, 'w') as f:
                        f.write(full_url)
                    print(f"\\n✓ CDN URL saved to: {args.cdn_url}")
                    
                    # Verify the filename in response
                    if 'info' in response_data and 'name' in response_data['info']:
                        uploaded_filename = response_data['info']['name']
                        print(f"✓ Uploaded filename in response: {uploaded_filename}")
                        if uploaded_filename.endswith('.pt'):
                            print(f" File has .pt extension in CDN")
                        else:
                            print(f"⚠ File does NOT have .pt extension in CDN: {uploaded_filename}")
                    
                else:
                    print("\\n✗ No CDN URL found in response!")
                    print("Trying alternative parsing...")
                    
                    # Try to find any URL-like string in the response
                    import re
                    url_patterns = [
                        r'/_[\w\-/]+/[\w\-]+_\$\$_V1_[\w\.\-]+',
                        r'cdn-new\.gov-cloud\.ai[/\w\-\._]+',
                        r"https?://[^\s\"']+"  # FIXED LINE: Changed from r'https?://[^\s"']+' to r"https?://[^\s\"']+"
                    ]
                    
                    for pattern in url_patterns:
                        matches = re.findall(pattern, process.stdout)
                        if matches:
                            print(f"Found potential URL with pattern {pattern}:")
                            for match in matches[:3]:  # Show first 3 matches
                                print(f"  - {match}")
                            if matches:
                                cdn_path = matches[0]
                                if not cdn_path.startswith("http"):
                                    cdn_path = f"{args.cdn_base}{cdn_path}"
                                cdn_url_result = cdn_path
                                with open(args.cdn_url, 'w') as f:
                                    f.write(cdn_path)
                                print(f"✓ Using found URL: {cdn_path}")
                                break
                
            except json.JSONDecodeError as e:
                print(f"✗ Response is NOT valid JSON")
                print(f"Error: {e}")
                print(f"\\nRaw response text:")
                print("-" * 40)
                print(process.stdout[:500] + "..." if len(process.stdout) > 500 else process.stdout)
                print("-" * 40)
                
                # Save empty response
                response_data = {"error": "Invalid JSON", "raw_response": process.stdout[:500]}
                
                # Save empty URL
                with open(args.cdn_url, 'w') as f:
                    f.write("")
            
            # STEP 5: Save processed response
            print("\\n" + "=" * 80)
            print("6. SAVING RESULTS")
            print("=" * 80)
            
            processed_response = {
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                'upload_success': process.returncode == 0,
                'curl_exit_code': process.returncode,
                'model_file': args.trained_model,
                'model_size': model_size,
                'upload_url': upload_url,
                'filename_used': filename,
                'cdn_url': cdn_url_result,
                'parsed_response': response_data,
                'domain': args.domain,
                'cdn_base': args.cdn_base,
                'is_pt_file': filename.endswith('.pt')
            }
            
            with open(args.upload_response, 'w') as f:
                json.dump(processed_response, f, indent=2)
            
            print(f"✓ Processed response saved to: {args.upload_response}")
            print(f"✓ Raw response saved to: {args.raw_response}")
            
            if cdn_url_result:
                print(f"✓ CDN URL: {cdn_url_result}")
                
                # Check if URL ends with .pt
                if cdn_url_result.endswith('.pt'):
                    print(f" CDN URL has .pt extension")
                else:
                    print(f"⚠ CDN URL does NOT have .pt extension")
            else:
                print("✗ No CDN URL extracted from response")
            
            # STEP 6: Test download if we got a URL
            if cdn_url_result:
                print("\\n" + "=" * 80)
                print("7. TESTING DOWNLOAD")
                print("=" * 80)
                
                test_file = "/tmp/downloaded_model.pt"
                
                # First HEAD request
                print("Testing with HEAD request...")
                head_command = [
                    "curl",
                    "--head",
                    "--location", cdn_url_result,
                    "--header", f"Authorization: Bearer {bearer_token}",
                    "--connect-timeout", "30",
                    "--max-time", "60",
                    "--silent"
                ]
                
                try:
                    head_process = subprocess.run(
                        head_command,
                        capture_output=True,
                        text=True,
                        check=False
                    )
                    
                    print("HEAD Response:")
                    print("-" * 40)
                    for line in head_process.stdout.split('\\n'):
                        if line.strip():
                            print(line)
                    print("-" * 40)
                    
                    # Check if it's a 200 OK
                    if "200" in head_process.stdout:
                        print(" HEAD request successful (HTTP 200)")
                        
                        # Try to download the file
                        print("\\nAttempting to download file...")
                        download_command = [
                            "curl",
                            "--location", cdn_url_result,
                            "--header", f"Authorization: Bearer {bearer_token}",
                            "--output", test_file,
                            "--connect-timeout", "30",
                            "--max-time", "120",
                            "--silent",
                            "--show-error"
                        ]
                        
                        download_process = subprocess.run(
                            download_command,
                            capture_output=True,
                            text=True,
                            check=False
                        )
                        
                        if download_process.returncode == 0 and os.path.exists(test_file):
                            downloaded_size = os.path.getsize(test_file)
                            print(f"✓ Download successful: {downloaded_size:,} bytes")
                            
                            if downloaded_size == model_size:
                                print(f" Downloaded file size matches original: {downloaded_size:,} bytes")
                            else:
                                print(f"⚠ Downloaded file size mismatch:")
                                print(f"  Original: {model_size:,} bytes")
                                print(f"  Downloaded: {downloaded_size:,} bytes")
                        else:
                            print(f"✗ Download failed: {download_process.stderr[:200]}")
                            
                    else:
                        print(f"⚠ HEAD request returned non-200 status")
                        
                except Exception as e:
                    print(f"✗ Test failed: {str(e)}")
            
        except Exception as e:
            print(f"✗ Fatal error during upload: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        
        print("\\n" + "=" * 80)
        if cdn_url_result:
            if cdn_url_result.endswith('.pt'):
                print(" UPLOAD COMPLETE - .PT FILE AVAILABLE")
            else:
                print("⚠ UPLOAD COMPLETE BUT NOT A .PT FILE")
        else:
            print("⚠ UPLOAD COMPLETE BUT NO CDN URL EXTRACTED")
        print("=" * 80)
        
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --bearer_token
      - {inputValue: bearer_token}
      - --domain
      - {inputValue: domain}
      - --cdn_base
      - {inputValue: cdn_base}
      - --cdn_url
      - {outputPath: cdn_url}
      - --upload_response
      - {outputPath: upload_response}
      - --raw_response
      - {outputPath: raw_response}
