name: Preprocess Image
description: Takes UI components training data with base64 images, fits ResNet preprocessing on train only.
inputs:
  - name: train_x
    type: Dataset
    description: 'Training images data (base64 encoded)'
  - name: train_y
    type: Dataset
    description: 'Training labels'
  - name: dataset_info
    type: DatasetInfo
    description: 'Dataset information including classes and label mappings'
  - name: model_config
    type: String
    description: 'Model configuration as JSON string'
outputs:
  - name: preprocessing_metadata
    type: Dataset
    description: 'Fitted preprocessing transforms and metadata'
  - name: preprocessing_config
    type: String
    description: 'JSON configuration of applied preprocessing'

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v38-gpu
    command:
      - sh
      - -c
      - |
        # Install necessary packages
        pip install torchvision==0.17.0 pillow numpy --quiet
        
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import pickle, json, base64, io, numpy as np
        from PIL import Image
        import torch
        import torchvision.transforms as transforms
        import os
        
        parser = argparse.ArgumentParser(description='Preprocess UI Components Dataset')
        parser.add_argument('--train_x_path', type=str, required=True)
        parser.add_argument('--train_y_path', type=str, required=True)
        parser.add_argument('--dataset_info_path', type=str, required=True)
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--metadata_path', type=str, required=True)
        parser.add_argument('--config_path', type=str, required=True)
        
        args = parser.parse_args()
        
        print('Starting preprocessing (train-only fitting)...')
        print(f'Train X path: {args.train_x_path}')
        print(f'Train Y path: {args.train_y_path}')
        
        # Load data
        with open(args.train_x_path, 'rb') as f: 
            train_x_data = pickle.load(f)
        with open(args.train_y_path, 'rb') as f: 
            train_y_labels = pickle.load(f)
        with open(args.dataset_info_path, 'rb') as f: 
            dataset_info = pickle.load(f)
        
        # Load config
        config = json.loads(args.model_config)
        batch_size = config.get('training', {}).get('batch_size', 16)
        image_size = config.get('preprocessing', {}).get('image_size', 224)
        
        print(f'Config - Batch size: {batch_size}, Image size: {image_size}')
        
        # Get data source type for appropriate preprocessing
        data_source_type = dataset_info.get('data_source_type', 'cdn_zip')
        print(f'Data source type: {data_source_type}')
        
        # Get counts
        if isinstance(train_x_data, dict):
            train_images = train_x_data.get('images', [])
        else:
            train_images = train_x_data
        
        print(f'Loaded: {len(train_images)} train images, {len(train_y_labels)} train labels')
        
        # Sync counts
        if len(train_images) != len(train_y_labels):
            print(f'Warning: Mismatch - images: {len(train_images)}, labels: {len(train_y_labels)}')
            min_count = min(len(train_images), len(train_y_labels))
            
            if isinstance(train_x_data, dict):
                train_x_data['images'] = train_x_data['images'][:min_count]
                for key in ['filenames', 'label_names']:
                    if key in train_x_data:
                        train_x_data[key] = train_x_data[key][:min_count]
            else:
                train_x_data = train_x_data[:min_count]
            
            train_y_labels = train_y_labels[:min_count]
        
        # Determine appropriate normalization based on dataset
        if data_source_type == 'torchvision':
            dataset_name = dataset_info.get('source_info', {}).get('dataset_name', '').lower()
            
            # Use dataset-specific normalization
            if dataset_name in ['mnist', 'fashionmnist', 'kmnist', 'emnist', 'qmnist', 'usps', 'semeion']:
                # Grayscale datasets
                normalize_mean = [0.5]
                normalize_std = [0.5]
                image_channels = 1
            elif dataset_name in ['cifar10', 'cifar100', 'stl10']:
                # Color datasets with specific stats
                if dataset_name == 'cifar10':
                    normalize_mean = [0.4914, 0.4822, 0.4465]
                    normalize_std = [0.2470, 0.2435, 0.2616]
                elif dataset_name == 'cifar100':
                    normalize_mean = [0.5071, 0.4867, 0.4408]
                    normalize_std = [0.2675, 0.2565, 0.2761]
                else:
                    normalize_mean = [0.485, 0.456, 0.406]
                    normalize_std = [0.229, 0.224, 0.225]
                image_channels = 3
            else:
                # Default ImageNet stats for other datasets
                normalize_mean = [0.485, 0.456, 0.406]
                normalize_std = [0.229, 0.224, 0.225]
                image_channels = 3
        else:
            # For CDN datasets, use ImageNet stats
            normalize_mean = [0.485, 0.456, 0.406]
            normalize_std = [0.229, 0.224, 0.225]
            image_channels = 3
        
        print(f'Normalization - Mean: {normalize_mean}, Std: {normalize_std}')
        print(f'Image channels: {image_channels}')
        
        # Define transforms
        normalize = transforms.Normalize(mean=normalize_mean, std=normalize_std)
        
        # Training transforms
        train_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            normalize
        ])
        
        # Evaluation transforms
        eval_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(image_size),
            transforms.ToTensor(),
            normalize
        ])
        
        # Get class info
        class_names = dataset_info.get('classes', [])
        label_to_idx = dataset_info.get('label_to_idx', {})
        
        if not class_names:
            num_classes = dataset_info.get('output_dim', len(set(train_y_labels)))
            class_names = [f'class_{i}' for i in range(num_classes)]
            label_to_idx = {name: i for i, name in enumerate(class_names)}
        
        print(f'Classes ({len(class_names)}): {class_names}')
        
        # Create preprocessing metadata
        preprocessing_metadata = {
            'metadata_version': '2.0',
            'fitted_on_train_only': True,
            'train_samples_count': len(train_y_labels),
            'data_source_type': data_source_type,
            'transforms': {
                'train': train_transform,
                'eval': eval_transform
            },
            'parameters': {
                'image_size': image_size,
                'batch_size': batch_size,
                'image_channels': image_channels,
                'normalization_mean': normalize_mean,
                'normalization_std': normalize_std,
                'num_classes': len(class_names)
            },
            'label_mappings': {
                'label_to_idx': label_to_idx,
                'idx_to_label': {idx: label for label, idx in label_to_idx.items()},
                'class_names': class_names
            },
            'dataset_info': dataset_info,
            'usage': {
                'for_training': 'Use transforms[\"train\"]',
                'for_evaluation': 'Use transforms[\"eval\"]',
                'note': 'Both transforms use same normalization parameters fitted on train data'
            }
        }
        
        # Save metadata
        os.makedirs(os.path.dirname(args.metadata_path) or '.', exist_ok=True)
        with open(args.metadata_path, 'wb') as f:
            pickle.dump(preprocessing_metadata, f)
        
        # Create and save config
        preprocessing_config = {
            'preprocessing_applied': True,
            'train_samples': len(train_y_labels),
            'image_size': image_size,
            'batch_size': batch_size,
            'num_classes': len(class_names),
            'classes': class_names,
            'normalization': {
                'mean': normalize_mean,
                'std': normalize_std,
                'channels': image_channels
            },
            'data_source_type': data_source_type,
            'transforms_applied': {
                'train': [str(t) for t in train_transform.transforms],
                'eval': [str(t) for t in eval_transform.transforms]
            },
            'label_mapping': label_to_idx
        }
        
        os.makedirs(os.path.dirname(args.config_path) or '.', exist_ok=True)
        with open(args.config_path, 'w') as f:
            json.dump(preprocessing_config, f, indent=2)
        
        print('\\n' + '='*80)
        print('PREPROCESSING COMPLETE')
        print('='*80)
        print(f'✓ Metadata saved: {args.metadata_path}')
        print(f'✓ Config saved: {args.config_path}')
        print(f'✓ Fitted on {len(train_y_labels)} train samples')
        print(f'✓ Image size: {image_size}x{image_size}')
        print(f'✓ Classes: {len(class_names)}')
        print(f'✓ Normalization adapted for: {data_source_type}')
        print('='*80)
    args:
      - --train_x_path
      - {inputPath: train_x}
      - --train_y_path
      - {inputPath: train_y}
      - --dataset_info_path
      - {inputPath: dataset_info}
      - --model_config
      - {inputValue: model_config}
      - --metadata_path
      - {outputPath: preprocessing_metadata}
      - --config_path
      - {outputPath: preprocessing_config}
