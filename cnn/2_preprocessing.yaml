name: Image Preprocessing
description: Takes UI components training data with base64 images, fits ResNet preprocessing on train only.
inputs:
  - name: train_x
    type: Dataset
    description: 'Training images data (base64 encoded)'
  - name: train_y
    type: Dataset
    description: 'Training labels'
  - name: dataset_info
    type: DatasetInfo
    description: 'Dataset information including classes and label mappings'
  - name: model_config
    type: String
    description: 'ResNet configuration as JSON string'
outputs:
  - name: preprocessing_metadata
    type: Dataset
    description: 'Fitted preprocessing transforms and metadata'
  - name: preprocessing_config
    type: String
    description: 'JSON configuration of applied preprocessing'
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - python
      - -c
      - |
        import argparse
        import sys
        import os
        
        # Parse arguments
        parser = argparse.ArgumentParser(description='Preprocess UI Components Dataset')
        parser.add_argument('--train_x_path', type=str, required=True)
        parser.add_argument('--train_y_path', type=str, required=True)
        parser.add_argument('--dataset_info_path', type=str, required=True)
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--metadata_path', type=str, required=True)
        parser.add_argument('--config_path', type=str, required=True)
        
        args = parser.parse_args()
        
        # Now run the actual script
        import pickle, json, base64, io, numpy as np
        from PIL import Image
        import torch
        import torchvision.transforms as transforms
        from torch.utils.data import Dataset
        
        print('Starting preprocessing (train-only fitting)...')
        print(f'Train X path: {args.train_x_path}')
        print(f'Train Y path: {args.train_y_path}')
        
        # Custom Dataset class
        class Base64ImageDataset(Dataset):
            def __init__(self, images_data, labels, transform=None):
                if isinstance(images_data, dict) and 'images' in images_data:
                    self.images = images_data['images']
                    self.filenames = images_data.get('filenames', [])
                    self.label_names = images_data.get('label_names', [])
                else:
                    self.images = images_data
                    self.filenames = []
                    self.label_names = []
                
                self.labels = labels
                self.transform = transform
                
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                try:
                    img_data = base64.b64decode(self.images[idx])
                    img = Image.open(io.BytesIO(img_data)).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    label = torch.tensor(self.labels[idx], dtype=torch.long)
                    return img, label
                    
                except Exception as e:
                    print(f'Error loading image {idx}: {e}')
                    dummy_img = torch.zeros(3, 224, 224)
                    label = torch.tensor(0, dtype=torch.long)
                    return dummy_img, label
        
        # Load config
        config = json.loads(args.model_config)
        batch_size = config.get('training', {}).get('batch_size', 16)
        image_size = config.get('preprocessing', {}).get('image_size', 224)
        
        print(f'Config - Batch size: {batch_size}, Image size: {image_size}')
        
        # Load data
        with open(args.train_x_path, 'rb') as f: 
            train_x_data = pickle.load(f)
        with open(args.train_y_path, 'rb') as f: 
            train_y_labels = pickle.load(f)
        with open(args.dataset_info_path, 'rb') as f: 
            dataset_info = pickle.load(f)
        
        # Get counts
        if isinstance(train_x_data, dict):
            train_images = train_x_data.get('images', [])
        else:
            train_images = train_x_data
        
        print(f'Loaded: {len(train_images)} train images, {len(train_y_labels)} train labels')
        
        # Sync counts
        if len(train_images) != len(train_y_labels):
            print(f'Warning: Mismatch - images: {len(train_images)}, labels: {len(train_y_labels)}')
            min_count = min(len(train_images), len(train_y_labels))
            
            if isinstance(train_x_data, dict):
                train_x_data['images'] = train_x_data['images'][:min_count]
                for key in ['filenames', 'label_names']:
                    if key in train_x_data:
                        train_x_data[key] = train_x_data[key][:min_count]
            else:
                train_x_data = train_x_data[:min_count]
            
            train_y_labels = train_y_labels[:min_count]
        
        # Define transforms with standard ImageNet stats
        normalize = transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )
        
        # Training transforms
        train_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            normalize
        ])
        
        # Evaluation transforms
        eval_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(image_size),
            transforms.ToTensor(),
            normalize
        ])
        
        # Get class info
        class_names = dataset_info.get('classes', [])
        label_to_idx = dataset_info.get('label_to_idx', {})
        
        if not class_names:
            num_classes = dataset_info.get('output_dim', len(set(train_y_labels)))
            class_names = [f'class_{i}' for i in range(num_classes)]
            label_to_idx = {name: i for i, name in enumerate(class_names)}
        
        print(f'Classes ({len(class_names)}): {class_names}')
        
        # Create preprocessing metadata
        preprocessing_metadata = {
            'metadata_version': '1.0',
            'fitted_on_train_only': True,
            'train_samples_count': len(train_y_labels),
            'transforms': {
                'train': train_transform,
                'eval': eval_transform
            },
            'parameters': {
                'image_size': image_size,
                'batch_size': batch_size,
                'normalization_mean': [0.485, 0.456, 0.406],
                'normalization_std': [0.229, 0.224, 0.225]
            },
            'label_mappings': {
                'label_to_idx': label_to_idx,
                'idx_to_label': {idx: label for label, idx in label_to_idx.items()},
                'class_names': class_names,
                'num_classes': len(class_names)
            },
            'dataset_info': dataset_info
        }
        
        # Save metadata
        os.makedirs(os.path.dirname(args.metadata_path) or '.', exist_ok=True)
        with open(args.metadata_path, 'wb') as f:
            pickle.dump(preprocessing_metadata, f)
        
        # Create and save config
        preprocessing_config = {
            'preprocessing_applied': True,
            'train_samples': len(train_y_labels),
            'image_size': image_size,
            'batch_size': batch_size,
            'num_classes': len(class_names),
            'classes': class_names,
            'transforms_applied': {
                'train': [str(t) for t in train_transform.transforms],
                'eval': [str(t) for t in eval_transform.transforms]
            },
            'label_mapping': label_to_idx
        }
        
        os.makedirs(os.path.dirname(args.config_path) or '.', exist_ok=True)
        with open(args.config_path, 'w') as f:
            json.dump(preprocessing_config, f, indent=2)
        
        print('\\n' + '='*80)
        print('PREPROCESSING COMPLETE')
        print('='*80)
        print(f'✓ Metadata saved: {args.metadata_path}')
        print(f'✓ Config saved: {args.config_path}')
        print(f'✓ Fitted on {len(train_y_labels)} train samples')
        print(f'✓ Image size: {image_size}x{image_size}')
        print(f'✓ Classes: {len(class_names)}')
        print('='*80)
    args:
      - {inputPath: train_x}
      - {inputPath: train_y}
      - {inputPath: dataset_info}
      - {inputValue: model_config}
      - {outputPath: preprocessing_metadata}
      - {outputPath: preprocessing_config}
