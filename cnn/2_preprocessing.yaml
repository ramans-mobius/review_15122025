name: Image Preprocessing
description: Takes UI components datasets with base64 images, applies ResNet preprocessing, and outputs processed data loaders with preprocessing metadata.
inputs:
  - name: train_x
    type: Dataset
  - name: train_y
    type: Dataset
  - name: test_x
    type: Dataset
  - name: test_y
    type: Dataset
  - name: dataset_info
    type: DatasetInfo
  - name: model_config
    type: String
    description: 'ResNet configuration as JSON string'
outputs:
  - name: processed_data_pickle
    type: Dataset
    description: 'Processed PyTorch datasets and data loaders'
  - name: preprocessing_metadata
    type: Dataset
    description: 'Preprocessing transforms and metadata for consistent evaluation'
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - sh
      - -c
      - |
        python -c "
        import sys, os, pickle, json, base64, io, numpy as np
        from PIL import Image
        import torch
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader, Dataset
        import copy
        
        print('Starting preprocessing with metadata generation...')
        
        # Get args
        if len(sys.argv) < 9:
            raise ValueError(f'Expected 9 arguments, got {len(sys.argv)}')
        
        train_x_path = sys.argv[1]
        train_y_path = sys.argv[2]
        test_x_path = sys.argv[3]
        test_y_path = sys.argv[4]
        info_path = sys.argv[5]
        config_str = sys.argv[6]
        out_path = sys.argv[7]
        metadata_path = sys.argv[8]
        
        print(f'Train X path: {train_x_path}')
        print(f'Train Y path: {train_y_path}')
        
        # Custom Dataset class for base64 images
        class Base64ImageDataset(Dataset):
            def __init__(self, images_data, labels, transform=None, return_filenames=False):
                # Handle both dictionary and list formats
                if isinstance(images_data, dict) and 'images' in images_data:
                    self.images = images_data['images']
                    self.filenames = images_data.get('filenames', [])
                    self.label_names = images_data.get('label_names', [])
                    self.original_indices = images_data.get('original_indices', list(range(len(self.images))))
                else:
                    self.images = images_data
                    self.filenames = []
                    self.label_names = []
                    self.original_indices = list(range(len(self.images)))
                
                self.labels = labels
                self.transform = transform
                self.return_filenames = return_filenames
                
            def __len__(self):
                return len(self.images)
            
            def __getitem__(self, idx):
                try:
                    # Decode base64 image
                    img_data = base64.b64decode(self.images[idx])
                    img = Image.open(io.BytesIO(img_data)).convert('RGB')
                    
                    # Apply transformations if specified
                    if self.transform:
                        img = self.transform(img)
                    
                    # Get label
                    label = torch.tensor(self.labels[idx], dtype=torch.long)
                    
                    if self.return_filenames and self.filenames:
                        return img, label, self.filenames[idx]
                    else:
                        return img, label
                        
                except Exception as e:
                    print(f'Error loading image {idx}: {e}')
                    # Return a dummy image if there's an error
                    dummy_img = torch.zeros(3, 224, 224)
                    label = torch.tensor(0, dtype=torch.long)
                    if self.return_filenames and self.filenames:
                        return dummy_img, label, self.filenames[idx] if idx < len(self.filenames) else f'error_{idx}'
                    else:
                        return dummy_img, label
        
        class DataWrapper:
            def __init__(self, data_dict): 
                self.__dict__.update(data_dict)
        
        # Load config
        config = json.loads(config_str)
        batch_size = config.get('training', {}).get('batch_size', 16)
        image_size = config.get('preprocessing', {}).get('image_size', 224)
        
        print(f'Batch size: {batch_size}, Image size: {image_size}')
        
        # Load data
        with open(train_x_path, 'rb') as f: 
            train_x_data = pickle.load(f)
        with open(train_y_path, 'rb') as f: 
            train_y_labels = pickle.load(f)
        with open(test_x_path, 'rb') as f: 
            test_x_data = pickle.load(f)
        with open(test_y_path, 'rb') as f: 
            test_y_labels = pickle.load(f)
        with open(info_path, 'rb') as f: 
            dataset_info = pickle.load(f)
        
        # Get counts
        train_images_count = len(train_x_data['images']) if isinstance(train_x_data, dict) else len(train_x_data)
        test_images_count = len(test_x_data['images']) if isinstance(test_x_data, dict) else len(test_x_data)
        
        print(f'Loaded: {train_images_count} train images, {len(train_y_labels)} train labels')
        print(f'Loaded: {test_images_count} test images, {len(test_y_labels)} test labels')
        
        # Sync counts if mismatch
        def sync_data(images_data, labels, data_type='train'):
            if isinstance(images_data, dict):
                images_count = len(images_data['images'])
            else:
                images_count = len(images_data)
                
            if images_count != len(labels):
                print(f'Warning: {data_type} images ({images_count}) and labels ({len(labels)}) count mismatch!')
                min_count = min(images_count, len(labels))
                
                if isinstance(images_data, dict):
                    images_data['images'] = images_data['images'][:min_count]
                    for key in ['filenames', 'label_names', 'original_indices']:
                        if key in images_data:
                            images_data[key] = images_data[key][:min_count]
                else:
                    images_data = images_data[:min_count]
                
                labels = labels[:min_count]
            
            return images_data, labels
        
        train_x_data, train_y_labels = sync_data(train_x_data, train_y_labels, 'train')
        test_x_data, test_y_labels = sync_data(test_x_data, test_y_labels, 'test')
        
        # Define transforms (same as ResNet preprocessing)
        normalize = transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )
        
        # Training transforms with augmentation
        train_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            normalize
        ])
        
        # Validation/test transforms (no augmentation)
        test_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            normalize
        ])
        
        # Create datasets
        train_dataset = Base64ImageDataset(train_x_data, train_y_labels, transform=train_transform)
        test_dataset = Base64ImageDataset(test_x_data, test_y_labels, transform=test_transform)
        
        print(f'Created train dataset: {len(train_dataset)} samples')
        print(f'Created test dataset: {len(test_dataset)} samples')
        
        # Create data loaders
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True, 
            num_workers=2,
            pin_memory=True,
            drop_last=True
        )
        
        test_loader = DataLoader(
            test_dataset, 
            batch_size=batch_size, 
            shuffle=False, 
            num_workers=2,
            pin_memory=True,
            drop_last=False
        )
        
        # Get class info
        class_names = dataset_info.get('classes', [])
        label_to_idx = dataset_info.get('label_to_idx', {})
        
        if not class_names:
            num_classes = dataset_info.get('output_dim', len(set(train_y_labels + test_y_labels)))
            class_names = [f'class_{i}' for i in range(num_classes)]
            label_to_idx = {name: i for i, name in enumerate(class_names)}
        
        print(f'Classes ({len(class_names)}): {class_names}')
        
        # Save processed data wrapper
        data_wrapper = DataWrapper({
            'train_loader': train_loader, 
            'test_loader': test_loader,
            'train_dataset': train_dataset,
            'test_dataset': test_dataset,
            'num_classes': len(class_names), 
            'class_names': class_names,
            'label_to_idx': label_to_idx, 
            'idx_to_label': {idx: label for label, idx in label_to_idx.items()},
            'image_size': image_size, 
            'batch_size': batch_size,
            'dataset_info': dataset_info,
            'train_samples': len(train_dataset),
            'test_samples': len(test_dataset),
            'transforms': {
                'train': train_transform,
                'test': test_transform
            }
        })
        
        os.makedirs(os.path.dirname(out_path) or '.', exist_ok=True)
        with open(out_path, 'wb') as f: 
            pickle.dump(data_wrapper, f)
        
        # ======================================================
        # CREATE PREPROCESSING METADATA FOR EVALUATOR
        # ======================================================
        
        # Create preprocessing functions that can be serialized
        class SerializablePreprocessor:
            def __init__(self, transform, label_mapping, class_names, image_size):
                self.transform = transform
                self.label_to_idx = label_mapping
                self.idx_to_label = {idx: label for label, idx in label_mapping.items()}
                self.class_names = class_names
                self.image_size = image_size
                self.normalize_mean = [0.485, 0.456, 0.406]
                self.normalize_std = [0.229, 0.224, 0.225]
            
            def preprocess_image(self, base64_string):
        
                try:
                    img_data = base64.b64decode(base64_string)
                    img = Image.open(io.BytesIO(img_data)).convert('RGB')
                    if self.transform:
                        img = self.transform(img)
                    return img
                except Exception as e:
                    print(f'Error preprocessing image: {e}')
                    return torch.zeros(3, self.image_size, self.image_size)
            
            def preprocess_batch(self, base64_strings):
            
                processed_images = []
                for img_str in base64_strings:
                    processed_images.append(self.preprocess_image(img_str))
                return torch.stack(processed_images) if processed_images else torch.tensor([])
            
            def encode_labels(self, label_strings):
              
                return [self.label_to_idx.get(label, -1) for label in label_strings]
            
            def decode_labels(self, label_indices):
              
                return [self.idx_to_label.get(idx, f'unknown_{idx}') for idx in label_indices]
            
            def get_transform_description(self):
              
                transforms_list = []
                if hasattr(self.transform, 'transforms'):
                    for t in self.transform.transforms:
                        transforms_list.append(str(t))
                return transforms_list
        
        # Create preprocessors for train and test modes
        train_preprocessor = SerializablePreprocessor(
            train_transform, label_to_idx, class_names, image_size
        )
        
        test_preprocessor = SerializablePreprocessor(
            test_transform, label_to_idx, class_names, image_size
        )
        
        # Create metadata dictionary
        preprocessing_metadata = {
            'metadata_version': '1.0',
            'preprocessors': {
                'train': train_preprocessor,
                'test': test_preprocessor
            },
            'config': {
                'image_size': image_size,
                'batch_size': batch_size,
                'num_classes': len(class_names),
                'class_names': class_names,
                'label_to_idx': label_to_idx,
                'idx_to_label': {idx: label for label, idx in label_to_idx.items()},
                'normalization': {
                    'mean': [0.485, 0.456, 0.406],
                    'std': [0.229, 0.224, 0.225]
                },
                'transforms': {
                    'train': str(train_transform),
                    'test': str(test_transform)
                },
                'transforms_components': {
                    'train': [str(t) for t in train_transform.transforms],
                    'test': [str(t) for t in test_transform.transforms]
                }
            },
            'statistics': {
                'train_samples': len(train_dataset),
                'test_samples': len(test_dataset),
                'class_distribution': dataset_info.get('class_distribution', {}),
                'original_dataset_info': dataset_info
            },
            'functions': {
                'preprocess_image': 'Call preprocessors[\"test\"].preprocess_image(base64_string)',
                'preprocess_batch': 'Call preprocessors[\"test\"].preprocess_batch(base64_strings)',
                'encode_labels': 'Call preprocessors[\"test\"].encode_labels(label_strings)',
                'decode_labels': 'Call preprocessors[\"test\"].decode_labels(label_indices)'
            }
        }
        
        # Save metadata
        os.makedirs(os.path.dirname(metadata_path) or '.', exist_ok=True)
        with open(metadata_path, 'wb') as f:
            pickle.dump(preprocessing_metadata, f)
        
        # Also save a JSON version for readability
        json_metadata_path = metadata_path.replace('.pkl', '.json').replace('.pickle', '.json')
        json_metadata = {
            'metadata_version': preprocessing_metadata['metadata_version'],
            'config': preprocessing_metadata['config'],
            'statistics': preprocessing_metadata['statistics'],
            'functions': preprocessing_metadata['functions']
        }
        with open(json_metadata_path, 'w') as f:
            json.dump(json_metadata, f, indent=2, default=str)
        
        print('\\n' + '='*80)
        print('PREPROCESSING COMPLETE')
        print('='*80)
        print(f'Processed data saved to: {out_path}')
        print(f'Preprocessing metadata saved to: {metadata_path}')
        print(f'Readable JSON version saved to: {json_metadata_path}')
        print(f'\\nMetadata includes:')
        print(f'  - Train/test preprocessors for consistent evaluation')
        print(f'  - Label mappings: {len(label_to_idx)} classes')
        print(f'  - Transform descriptions for both train and test modes')
        print(f'  - Normalization parameters')
        print(f'  - Dataset statistics')
        print(f'\\nTrain loader: {len(train_loader)} batches ({len(train_dataset)} samples)')
        print(f'Test loader: {len(test_loader)} batches ({len(test_dataset)} samples)')
        print('='*80)
        
        # Verify first batch
        if len(train_loader) > 0:
            train_iter = iter(train_loader)
            images, labels = next(train_iter)
            print(f'\\nVerification - First batch:')
            print(f'  Images shape: {images.shape}')
            print(f'  Labels shape: {labels.shape}')
            print(f'  Label values: {labels[:5].tolist()}')
            print(f'  Image range: [{images.min():.3f}, {images.max():.3f}]')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6" "$7" "$8"
    args:
      - {inputPath: train_x}
      - {inputPath: train_y}
      - {inputPath: test_x}
      - {inputPath: test_y}
      - {inputPath: dataset_info}
      - {inputValue: model_config}
      - {outputPath: processed_data_pickle}
      - {outputPath: preprocessing_metadata}
