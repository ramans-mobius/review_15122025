name: Download Dataset From CDN v2
description: Downloads dataset pickle file from CDN and extracts DataWrapper object with URL encoding support
inputs:
  - {name: pickle_cdn_url, type: String}
  - {name: config_cdn_url, type: String}
  - {name: bearer_token, type: String}
outputs:
  - {name: data_wrapper_pickle, type: Artifact}
  - {name: config_json, type: Artifact}
implementation:
  container:
    image: python:3.8-slim
    command:
      - sh
      - -c
      - |
        if ! command -v curl &> /dev/null; then
            echo "curl could not be found, installing..."
            apt-get update > /dev/null && apt-get install -y curl > /dev/null
        fi
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import subprocess
        import json
        import os
        import urllib.parse
        import pickle

        parser = argparse.ArgumentParser(description="Download dataset from CDN.")
        parser.add_argument('--pickle_cdn_url', type=str, required=True, help='URL to the uploaded pickle file.')
        parser.add_argument('--config_cdn_url', type=str, required=True, help='URL to the uploaded config string.')
        parser.add_argument('--bearer_token', type=str, required=True, help='Bearer token for CDN authentication.')
        args = parser.parse_args()

        # Read bearer token
        with open(args.bearer_token, 'r') as f:
            bearer_token = f.read().strip()

        print(f"Bearer token length: {len(bearer_token)} chars")
        print(f"First 20 chars: {bearer_token[:20]}...")

        def prepare_cdn_url(url):
        
            print(f"\\nOriginal URL length: {len(url)} chars")
            print(f"First 150 chars: \\n{url[:150]}")
            
            # Step 1: Remove any extra whitespace
            url = url.strip()
            print(f"After removing spaces: \\n{url[:150]}")
            
            # Step 2: CRITICAL - Preserve $$ pattern first
            # Replace $$ with a unique placeholder before any encoding
            url = url.replace("$$", "__DOUBLE_DOLLAR_PLACEHOLDER__")
            
            # Step 3: Handle _ENC( pattern - it should NOT be encoded
            # Replace _ENC( with placeholder
            url = url.replace("_ENC(", "__ENC_PAREN_PLACEHOLDER__")
            
            # Step 4: Now unquote to handle already encoded parts
            url = urllib.parse.unquote(url)
            print(f"After unquote: \\n{url[:150]}")
            
            # Step 5: Encode special characters but preserve : / ? = & %
            # We need to encode parentheses and other special chars
            parsed = list(urllib.parse.urlsplit(url))
            # Encode the path component
            parsed[2] = urllib.parse.quote(parsed[2], safe="/")
            url = urllib.parse.urlunsplit(parsed)
            
            # Step 6: Restore the placeholders
            url = url.replace("__DOUBLE_DOLLAR_PLACEHOLDER__", "$$")
            url = url.replace("__ENC_PAREN_PLACEHOLDER__", "_ENC(")
            
            print(f"Found $$ pattern preserved: {'$$' in url}")
            print(f"Found _ENC( pattern preserved: {'_ENC(' in url}")
            print(f"Final URL for curl: \\n{url[:150]}")
            
            return url

        # Prepare both URLs
        pickle_url = prepare_cdn_url(args.pickle_cdn_url)
        config_url = prepare_cdn_url(args.config_cdn_url)

        print("\\n=== Prepared URLs ===")
        print(f"Pickle URL: \\n{pickle_url[:200]}...")
        print(f"Config URL: \\n{config_url[:200]}...")
        print("=" * 60)

        # Download dataset pickle
        print("\\n============================================================")
        print("ATTEMPTING TO DOWNLOAD DATASET PICKLE")
        print("============================================================")
        
        pickle_path = "/tmp/downloaded_dataset.pkl"
        
        # Test URL first with a HEAD request
        print("\\n=== Testing URL accessibility ===")
        test_cmd = [
            "curl", "--head",
            "--location", pickle_url,
            "--header", f"Authorization: Bearer {bearer_token}",
            "--max-time", "30",
            "--fail",
            "--show-error"
        ]
        
        try:
            test_result = subprocess.run(
                test_cmd,
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if test_result.returncode == 0:
                print("✓ URL is accessible (HEAD request succeeded)")
                print(f"Response headers: {test_result.stdout[:200]}...")
            else:
                print(f"✗ HEAD request failed with code: {test_result.returncode}")
                print(f"Error: {test_result.stderr}")
        except Exception as e:
            print(f"HEAD request error: {e}")

        print("\\n=== Downloading dataset pickle ===")
        
        # Create curl command with proper escaping
        curl_cmd = [
            "curl",
            "--location",
            "--header", f"Authorization: Bearer {bearer_token}",
            "--output", pickle_path,
            "--max-time", "120",  # 2 minutes timeout
            "--retry", "3",
            "--retry-delay", "5",
            "--fail",
            "--show-error"
        ]

        # Add URL as the last argument
        curl_cmd.append(pickle_url)
        
        # Print simplified command for debugging
        print(f"Curl command (simplified): curl --location [URL] --header 'Authorization: Bearer ...' --output {pickle_path}")
        print(f"Full URL: \\n{pickle_url[:200]}...")
        
        # Execute download
        try:
            result = subprocess.run(
                curl_cmd,
                capture_output=True,
                text=True,
                timeout=180  # 3 minutes timeout
            )
            
            if result.returncode == 0:
                print("✓ Download successful!")
                print(f"File size: {os.path.getsize(pickle_path)} bytes")
                
                # Verify it's a valid pickle file
                try:
                    with open(pickle_path, 'rb') as f:
                        data = pickle.load(f)
                    print(f"✓ Valid pickle file loaded. Object type: {type(data)}")
                except Exception as e:
                    print(f"✗ Downloaded file is not a valid pickle: {e}")
                    raise
                    
            else:
                print(f"✗ Download failed!")
                print(f"Exit code: {result.returncode}")
                print(f"Error output: {result.stderr}")
                print(f"Standard output: {result.stdout}")
                print("\\n CRITICAL: Failed to download dataset pickle!")
                print(f"URL used: \\n{pickle_url[:200]}...")
                print("Please check:")
                print("1. URL is correct")
                print("2. Bearer token is valid")
                print("3. File exists on CDN")
                print("4. Network connectivity")
                raise Exception(f"Failed to download dataset from CDN: \\n{pickle_url[:200]}...")
                
        except subprocess.TimeoutExpired:
            print("✗ Download timeout after 3 minutes")
            raise
        except Exception as e:
            print(f"✗ Download failed with exception: {e}")
            raise

        # Download config JSON
        print("\\n============================================================")
        print("ATTEMPTING TO DOWNLOAD CONFIG JSON")
        print("============================================================")
        
        config_path = "/tmp/downloaded_config.json"
        
        curl_cmd_config = [
            "curl",
            "--location",
            "--header", f"Authorization: Bearer {bearer_token}",
            "--output", config_path,
            "--max-time", "60",
            "--fail",
            "--show-error"
        ]
        
        curl_cmd_config.append(config_url)
        
        print(f"Curl command for config: curl --location [URL] --header 'Authorization: Bearer ...' --output {config_path}")
        print(f"Config URL: \\n{config_url[:200]}...")
        
        try:
            result = subprocess.run(
                curl_cmd_config,
                capture_output=True,
                text=True,
                timeout=120
            )
            
            if result.returncode == 0:
                print("✓ Config download successful!")
                print(f"Config file size: {os.path.getsize(config_path)} bytes")
                
                # Verify it's valid JSON
                try:
                    with open(config_path, 'r') as f:
                        config_data = json.load(f)
                    print(f"✓ Valid JSON config loaded")
                except Exception as e:
                    print(f"✗ Downloaded config is not valid JSON: {e}")
                    raise
                    
            else:
                print(f"✗ Config download failed!")
                print(f"Exit code: {result.returncode}")
                print(f"Error output: {result.stderr}")
                raise Exception(f"Failed to download config from CDN")
                
        except Exception as e:
            print(f"✗ Config download failed with exception: {e}")
            raise

        # Save outputs
        output_pickle_path = "/tmp/outputs/data_wrapper_pickle/data"
        output_config_path = "/tmp/outputs/config_json/data"
        
        os.makedirs(os.path.dirname(output_pickle_path), exist_ok=True)
        os.makedirs(os.path.dirname(output_config_path), exist_ok=True)
        
        # Copy pickle file
        os.system(f"cp {pickle_path} {output_pickle_path}")
        print(f"✓ Saved pickle to: {output_pickle_path}")
        
        # Copy config file
        os.system(f"cp {config_path} {output_config_path}")
        print(f"✓ Saved config to: {output_config_path}")
        
        print("\\n============================================================")
        print("DOWNLOAD COMPLETE!")
        print("============================================================")
    args:
      - --pickle_cdn_url
      - {inputValue: pickle_cdn_url}
      - --config_cdn_url
      - {inputValue: config_cdn_url}
      - --bearer_token
      - {inputPath: bearer_token}
