name: Generic Data Loader
description: Loads datasets from CDN ZIP or torchvision datasets using configuration from model_config
inputs:
  - name: model_config
    type: String
    description: 'Model and dataset configuration as JSON string'
outputs:
  - name: train_x
    type: Dataset
    description: 'Training images data'
  - name: train_y
    type: Dataset
    description: 'Training labels'
  - name: test_x
    type: Dataset
    description: 'Test images data'
  - name: test_y
    type: Dataset
    description: 'Test labels'
  - name: dataset_info
    type: DatasetInfo
    description: 'Dataset information'
  - name: data_analysis_report
    type: Dataset
    description: 'Data analysis report'

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v38-gpu
    command:
      - sh
      - -c
      - |
        # Install torchvision with compatible torch version
        pip install --no-deps torchvision==0.17.0 pillow requests numpy --quiet
        
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import pickle, json, base64, io, zipfile, numpy as np, datetime, os, sys, time
        from collections import Counter, defaultdict
        import torch
        import requests
        from urllib.parse import unquote
        import warnings
        
        warnings.filterwarnings('ignore', category=UserWarning)
        
        parser = argparse.ArgumentParser(description='Generic Data Loader')
        parser.add_argument('--model_config', type=str, required=True)
        parser.add_argument('--train_x_path', type=str, required=True)
        parser.add_argument('--train_y_path', type=str, required=True)
        parser.add_argument('--test_x_path', type=str, required=True)
        parser.add_argument('--test_y_path', type=str, required=True)
        parser.add_argument('--dataset_info_path', type=str, required=True)
        parser.add_argument('--data_analysis_path', type=str, required=True)
        
        args = parser.parse_args()
        
        print('Starting Generic Data Loader...')
        print(f'Torch version: {torch.__version__}')
        
        # Parse model config
        config = json.loads(args.model_config)
        
        # Extract dataset config from model_config
        dataset_config = config.get('dataset', {})
        if not dataset_config:
            print('Warning: No dataset configuration found in model_config, using defaults')
            dataset_config = {
                'data_source_type': 'torchvision',
                'dataset_name': 'mnist'
            }
        
        data_source_type = dataset_config.get('data_source_type', 'torchvision')
        print(f'Data source type: {data_source_type}')
        
        def load_cdn_zip_dataset(dataset_config):
            cdn_url = dataset_config.get('cdn_url', '')
            train_split = dataset_config.get('train_split', 0.7)
            shuffle_seed = dataset_config.get('shuffle_seed', 42)
            
            if not cdn_url:
                # If no CDN URL, fall back to a test dataset
                print('No CDN URL provided, using MNIST as fallback')
                return load_torchvision_dataset({'dataset_name': 'mnist'})
            
            print(f'Loading from CDN ZIP: {cdn_url}')
            print(f'Train split: {train_split}, Shuffle seed: {shuffle_seed}')
            
            decoded_url = unquote(cdn_url)
            print(f'Downloading from: {decoded_url}')
            
            headers = {'User-Agent': 'Mozilla/5.0'}
            max_retries = 3
            retry_delay = 5  # seconds
            
            for attempt in range(max_retries):
                try:
                    response = requests.get(decoded_url, headers=headers, timeout=120)
                    response.raise_for_status()
                    break
                except requests.exceptions.HTTPError as e:
                    if e.response.status_code >= 500 and attempt < max_retries - 1:
                        print(f'Server error {e.response.status_code}, retrying in {retry_delay} seconds... (Attempt {attempt + 1}/{max_retries})')
                        time.sleep(retry_delay)
                        continue
                    elif e.response.status_code == 404:
                        print(f'Error: URL not found (404). Using MNIST as fallback.')
                        return load_torchvision_dataset({'dataset_name': 'mnist'})
                    else:
                        raise
                except Exception as e:
                    if attempt < max_retries - 1:
                        print(f'Error: {e}, retrying in {retry_delay} seconds... (Attempt {attempt + 1}/{max_retries})')
                        time.sleep(retry_delay)
                    else:
                        print(f'Failed after {max_retries} attempts. Using MNIST as fallback.')
                        return load_torchvision_dataset({'dataset_name': 'mnist'})
            
            zip_content = io.BytesIO(response.content)
            images = []
            labels = []
            filenames = []
            
            with zipfile.ZipFile(zip_content, 'r') as zip_file:
                all_files = zip_file.namelist()
                # Look for various image formats
                image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']
                image_files = [f for f in all_files if any(f.lower().endswith(ext) for ext in image_extensions)]
                print(f'Found {len(image_files)} image files out of {len(all_files)} total files')
                
                for file_path in image_files:
                    parts = file_path.split('/')
                    # Try to extract label from path
                    if len(parts) >= 2:
                        # Look for label in various positions
                        label = parts[-2] if len(parts) >= 2 else 'unknown'
                    else:
                        label = 'unknown'
                    
                    try:
                        with zip_file.open(file_path) as image_file:
                            image_data = image_file.read()
                            base64_image = base64.b64encode(image_data).decode('utf-8')
                            
                            images.append(base64_image)
                            labels.append(label)
                            filenames.append(file_path)
                    except Exception as e:
                        print(f'Warning: Could not read {file_path}: {e}')
            
            if not images:
                print('No images found in ZIP, using MNIST as fallback')
                return load_torchvision_dataset({'dataset_name': 'mnist'})
            
            return images, labels, filenames, all_files, {
                'source_type': 'cdn_zip',
                'url': cdn_url,
                'train_split': train_split,
                'shuffle_seed': shuffle_seed,
                'success': True
            }
        
        def tensor_to_pil_image(tensor):
            from PIL import Image
            
            if isinstance(tensor, torch.Tensor):
                tensor = tensor.cpu()
                
                # Handle different tensor shapes
                if tensor.dim() == 3:
                    # Shape: (C, H, W) or (H, W, C)
                    if tensor.shape[0] == 1 or tensor.shape[0] == 3:  # Likely (C, H, W)
                        # Move channel to last dimension
                        tensor = tensor.permute(1, 2, 0)
                
                # Convert to numpy and scale to 0-255
                img_array = tensor.numpy()
                
                # Handle different data types
                if img_array.dtype == np.float32 or img_array.dtype == np.float64:
                    if img_array.max() <= 1.0:
                        img_array = (img_array * 255).astype(np.uint8)
                    else:
                        img_array = img_array.astype(np.uint8)
                elif img_array.dtype == np.uint8:
                    pass  # Already correct
                else:
                    img_array = img_array.astype(np.uint8)
                
                # Squeeze single channel if needed
                if img_array.shape[-1] == 1:
                    img_array = img_array.squeeze(-1)
                
                # Convert to PIL Image
                return Image.fromarray(img_array)
            else:
                # If it's already a PIL Image
                return tensor
        
        def load_torchvision_dataset(dataset_config):
          
            dataset_name = dataset_config.get('dataset_name', 'mnist').lower()
            download = dataset_config.get('download', True)
            data_dir = dataset_config.get('data_dir', './data')
            
            print(f'Loading torchvision dataset: {dataset_name}')
            print(f'Data directory: {data_dir}, Download: {download}')
            
            try:
                # Import torchvision here (after installation)
                import torchvision
                from torchvision import transforms
                from PIL import Image
                import io
                
                # Define available datasets
                dataset_map = {
                    'mnist': torchvision.datasets.MNIST,
                    'cifar10': torchvision.datasets.CIFAR10,
                    'cifar100': torchvision.datasets.CIFAR100,
                    'fashionmnist': torchvision.datasets.FashionMNIST,
                    'kmnist': torchvision.datasets.KMNIST,
                    'emnist': torchvision.datasets.EMNIST,
                    'qmnist': torchvision.datasets.QMNIST,
                    'svhn': torchvision.datasets.SVHN,
                    'stl10': torchvision.datasets.STL10,
                }
                
                if dataset_name not in dataset_map:
                    available = ', '.join(dataset_map.keys())
                    print(f'Dataset {dataset_name} not available. Available: {available}')
                    # Fallback to MNIST
                    dataset_name = 'mnist'
                    dataset_class = dataset_map[dataset_name]
                else:
                    dataset_class = dataset_map[dataset_name]
                
                # Create datasets with simple transform
                if dataset_name in ['svhn', 'stl10']:
                    train_dataset = dataset_class(
                        root=data_dir,
                        split='train',
                        download=download,
                        transform=transforms.ToTensor()
                    )
                    test_dataset = dataset_class(
                        root=data_dir,
                        split='test',
                        download=download,
                        transform=transforms.ToTensor()
                    )
                else:
                    train_dataset = dataset_class(
                        root=data_dir,
                        train=True,
                        download=download,
                        transform=transforms.ToTensor()
                    )
                    test_dataset = dataset_class(
                        root=data_dir,
                        train=False,
                        download=download,
                        transform=transforms.ToTensor()
                    )
                
                print(f'Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}')
                
                # Convert to base64 format
                def dataset_to_base64(dataset, dataset_name):
                    images = []
                    labels = []
                    filenames = []
                    
                    for idx, (img_tensor, label) in enumerate(dataset):
                        try:
                            # Convert tensor to PIL Image using our helper
                            img = tensor_to_pil_image(img_tensor)
                            
                            # Convert to base64
                            buffer = io.BytesIO()
                            img.save(buffer, format='PNG')
                            base64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')
                            
                            images.append(base64_image)
                            labels.append(int(label))  # Ensure label is int
                            filenames.append(f'{dataset_name}_{idx}.png')
                            
                            # Progress indication
                            if idx % 1000 == 0 and idx > 0:
                                print(f'  Processed {idx} images...')
                        except Exception as e:
                            print(f'Warning: Could not process image {idx}: {e}')
                            continue
                    
                    return images, labels, filenames
                
                print('Converting train dataset to base64 format...')
                train_images, train_labels, train_filenames = dataset_to_base64(train_dataset, dataset_name)
                print('Converting test dataset to base64 format...')
                test_images, test_labels, test_filenames = dataset_to_base64(test_dataset, dataset_name)
                
                print(f'Train images converted: {len(train_images)}')
                print(f'Test images converted: {len(test_images)}')
                
                # For torchvision, we already have train/test split
                all_images = train_images + test_images
                all_labels = train_labels + test_labels
                all_filenames = train_filenames + test_filenames
                
                return all_images, all_labels, all_filenames, [], {
                    'source_type': 'torchvision',
                    'dataset_name': dataset_name,
                    'data_dir': data_dir,
                    'original_train_size': len(train_dataset),
                    'original_test_size': len(test_dataset),
                    'success': True
                }
                
            except Exception as e:
                print(f'Error loading torchvision dataset: {e}')
                import traceback
                traceback.print_exc()
                
                # Create a dummy dataset as last resort
                print('Creating dummy dataset for testing...')
                from PIL import Image
                import io
                
                images = []
                labels = []
                filenames = []
                
                # Create 100 dummy images
                for i in range(100):
                    dummy_img = np.random.randint(0, 255, (28, 28), dtype=np.uint8)
                    img = Image.fromarray(dummy_img)
                    buffer = io.BytesIO()
                    img.save(buffer, format='PNG')
                    base64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')
                    
                    images.append(base64_image)
                    labels.append(i % 10)  # 10 classes
                    filenames.append(f'dummy_{i}.png')
                
                return images, labels, filenames, [], {
                    'source_type': 'dummy',
                    'dataset_name': 'dummy',
                    'success': False,
                    'error': str(e)
                }
        
        # Load data based on source type
        if data_source_type == 'cdn_zip':
            all_images, all_labels, all_filenames, all_files, source_info = load_cdn_zip_dataset(dataset_config)
            train_split = dataset_config.get('train_split', 0.7)
            
            # Split data
            indices = list(range(len(all_images)))
            rng = np.random.RandomState(dataset_config.get('shuffle_seed', 42))
            rng.shuffle(indices)
            
            train_size = int(train_split * len(all_images))
            train_indices = indices[:train_size]
            test_indices = indices[train_size:]
            
            # Create train data
            train_data = {
                'images': [all_images[i] for i in train_indices],
                'labels': [all_labels[i] for i in train_indices],
                'label_names': [str(all_labels[i]) for i in train_indices],
                'filenames': [all_filenames[i] for i in train_indices]
            }
            
            # Create test data
            test_data = {
                'images': [all_images[i] for i in test_indices],
                'labels': [all_labels[i] for i in test_indices],
                'label_names': [str(all_labels[i]) for i in test_indices],
                'filenames': [all_filenames[i] for i in test_indices]
            }
            
            # For CDN, we need to create numeric labels
            unique_labels = sorted(list(set(all_labels)))
            label_to_idx = {str(label): idx for idx, label in enumerate(unique_labels)}
            train_data['labels'] = [label_to_idx[str(label)] for label in train_data['labels']]
            test_data['labels'] = [label_to_idx[str(label)] for label in test_data['labels']]
            
        else:  # torchvision or fallback
            all_images, all_labels, all_filenames, all_files, source_info = load_torchvision_dataset(dataset_config)
            
            # For torchvision, we already have the split in the data loading
            if 'original_train_size' in source_info:
                original_train_size = source_info['original_train_size']
                original_test_size = source_info['original_test_size']
                
                train_data = {
                    'images': all_images[:original_train_size],
                    'labels': all_labels[:original_train_size],
                    'label_names': [str(label) for label in all_labels[:original_train_size]],
                    'filenames': all_filenames[:original_train_size]
                }
                
                test_data = {
                    'images': all_images[original_train_size:],
                    'labels': all_labels[original_train_size:],
                    'label_names': [str(label) for label in all_labels[original_train_size:]],
                    'filenames': all_filenames[original_train_size:]
                }
            else:
                # For dummy or error cases, split 80/20
                train_size = int(0.8 * len(all_images))
                train_data = {
                    'images': all_images[:train_size],
                    'labels': all_labels[:train_size],
                    'label_names': [str(label) for label in all_labels[:train_size]],
                    'filenames': all_filenames[:train_size]
                }
                test_data = {
                    'images': all_images[train_size:],
                    'labels': all_labels[train_size:],
                    'label_names': [str(label) for label in all_labels[train_size:]],
                    'filenames': all_filenames[train_size:]
                }
            
            # Create label mapping
            unique_labels = sorted(list(set(all_labels)))
            label_to_idx = {str(label): label for label in unique_labels}
        
        print(f'\\nData loaded successfully!')
        print(f'Train samples: {len(train_data["images"])}')
        print(f'Test samples: {len(test_data["images"])}')
        print(f'Unique labels: {len(unique_labels)}')
        
        # Create dataset info
        dataset_info = {
            'total_samples': len(all_images),
            'classes': [str(label) for label in unique_labels],
            'class_distribution': dict(Counter([str(label) for label in all_labels])),
            'label_to_idx': label_to_idx,
            'idx_to_label': {idx: str(label) for label, idx in label_to_idx.items()},
            'output_dim': len(unique_labels),
            'data_source_type': data_source_type,
            'source_info': source_info,
            'original_config': config
        }
        
        # Create analysis report
        data_analysis = {
            'timestamp': datetime.datetime.now().isoformat(),
            'data_source': data_source_type,
            'source_info': source_info,
            'statistics': {
                'total_samples': len(all_images),
                'train_samples': len(train_data['images']),
                'test_samples': len(test_data['images']),
                'num_classes': len(unique_labels),
                'class_distribution': dict(Counter([str(label) for label in all_labels])),
                'average_image_size': len(all_images[0]) if all_images else 0
            },
            'data_format': {
                'images_format': 'base64_encoded_png',
                'labels_format': 'numeric_indices',
                'metadata_included': True
            },
            'config_used': config,
            'status': 'success' if source_info.get('success', False) else 'fallback_used'
        }
        
        # Save outputs
        os.makedirs(os.path.dirname(args.train_x_path) or '.', exist_ok=True)
        with open(args.train_x_path, 'wb') as f:
            pickle.dump(train_data, f)
        
        os.makedirs(os.path.dirname(args.train_y_path) or '.', exist_ok=True)
        with open(args.train_y_path, 'wb') as f:
            pickle.dump(train_data['labels'], f)
        
        os.makedirs(os.path.dirname(args.test_x_path) or '.', exist_ok=True)
        with open(args.test_x_path, 'wb') as f:
            pickle.dump(test_data, f)
        
        os.makedirs(os.path.dirname(args.test_y_path) or '.', exist_ok=True)
        with open(args.test_y_path, 'wb') as f:
            pickle.dump(test_data['labels'], f)
        
        os.makedirs(os.path.dirname(args.dataset_info_path) or '.', exist_ok=True)
        with open(args.dataset_info_path, 'wb') as f:
            pickle.dump(dataset_info, f)
        
        os.makedirs(os.path.dirname(args.data_analysis_path) or '.', exist_ok=True)
        with open(args.data_analysis_path, 'wb') as f:
            pickle.dump(data_analysis, f)
        
        print('\\n' + '='*80)
        print('DATA LOADING COMPLETE')
        print('='*80)
        print(f'Data source: {data_source_type}')
        print(f'Train samples: {len(train_data["images"])}')
        print(f'Test samples: {len(test_data["images"])}')
        print(f'Classes: {len(unique_labels)}')
        print(f'Status: {data_analysis["status"]}')
        print('='*80)
    args:
      - --model_config
      - {inputValue: model_config}
      - --train_x_path
      - {outputPath: train_x}
      - --train_y_path
      - {outputPath: train_y}
      - --test_x_path
      - {outputPath: test_x}
      - --test_y_path
      - {outputPath: test_y}
      - --dataset_info_path
      - {outputPath: dataset_info}
      - --data_analysis_path
      - {outputPath: data_analysis_report}
