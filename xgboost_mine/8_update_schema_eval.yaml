name: XGBoost Evaluation Schema Updater v300
description: Updates the evaluation schema with XGBoost evaluation metrics

inputs:
  - { name: schema_id, type: String, description: "The ID of the evaluation schema to update." }
  - { name: schema_evaluation_metrics, type: String, description: "Schema evaluation metrics JSON string from Evaluator output." }
  - { name: model_id, type: String, description: "The ID of the model." }
  - { name: execution_id, type: String, description: "The ID of the execution." }
  - { name: tenant_id, type: String, description: "The ID of the tenant." }
  - { name: project_id, type: String, description: "The ID of the project." }
  - { name: bearer_auth_token, type: String, description: "Bearer token for authentication." }
  - { name: domain, type: String, description: "The domain for the API endpoint." }
  - { name: model_name, type: String, description: "Model name.", default: "XGBoost" }
  - { name: model_type, type: String, description: "Model type.", default: "Classification" }

outputs:
  - { name: evaluation_schema_updated, type: String, description: "Confirmation of evaluation schema update." }

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:vtest4
    command:
      - sh
      - -c
      - |
        pip install requests
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import json
        import argparse
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        import os

        parser = argparse.ArgumentParser()
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--schema_evaluation_metrics', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--bearer_auth_token', type=str, required=True)
        parser.add_argument('--domain', type=str, required=True)
        parser.add_argument('--model_name', type=str, default="XGBoost")
        parser.add_argument('--model_type', type=str, default="Classification")
        parser.add_argument('--evaluation_schema_updated', type=str, required=True)
        args = parser.parse_args()

        # Create output directory first
        output_dir = os.path.dirname(args.evaluation_schema_updated)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)

        # Read the JSON file
        print(f"Reading schema metrics from: {args.schema_evaluation_metrics}")
        print(f"File exists: {os.path.exists(args.schema_evaluation_metrics)}")
        
        try:
            with open(args.schema_evaluation_metrics, 'r') as f:
                schema_metrics = json.load(f)
            print(f"Successfully loaded schema metrics JSON")
            print(f"Schema metrics keys: {list(schema_metrics.keys())}")
            
        except Exception as e:
            print(f"Error reading schema metrics JSON: {e}")
            print(f"Falling back to empty metrics")
            schema_metrics = {}
        
        with open(args.bearer_auth_token, 'r') as f:
            bearer_auth_token = f.read().strip()
        
        with open(args.tenant_id, 'r') as f:
            tenant_id = f.read().strip()

        # Parse execution_id to int (primary key)
        try:
            execution_id_int = int(args.execution_id)
        except (ValueError, TypeError):
            print(f"Warning: execution_id '{args.execution_id}' is not a valid integer. Using 0 as default.")
            execution_id_int = 0

        # Helper function to safely convert to float
        def safe_float(value, default=0.0):
            try:
                return float(value)
            except:
                return float(default)

        # Helper function to convert to integer (for roc_auc)
        def safe_int(value, default=0):
            try:
                # Convert float to int (round or truncate as needed)
                if isinstance(value, float):
                    return int(round(value * 1000))  # Multiply to preserve precision
                return int(value)
            except:
                return default

        # Parse confusion_matrix - ensure it's a list of floats
        confusion_matrix = []
        if "confusion_matrix" in schema_metrics:
            cm = schema_metrics["confusion_matrix"]
            if isinstance(cm, list):
                confusion_matrix = [float(x) for x in cm]

        # Convert metrics to correct types as per schema:
        # 1. loss must be FLOAT (not string)
        loss_value = safe_float(schema_metrics.get('loss', 0.0))
        
        # 2. roc_auc must be INTEGER (not float)
        roc_auc_value = safe_int(schema_metrics.get('roc_auc', 0.0))
        
        # 3. accuracy, precision, recall, f1_score, r2_score, mse, rmse_score must be FLOAT
        accuracy_value = safe_float(schema_metrics.get('accuracy', 0.0))
        precision_score_val = safe_float(schema_metrics.get('precision', 0.0))
        recall_val = safe_float(schema_metrics.get('recall', 0.0))
        f1_score_val = safe_float(schema_metrics.get('f1_score', 0.0))
        r2_score_val = safe_float(schema_metrics.get('r2_score', 0.0))
        mse_val = 0.0  # Not in schema_metrics, use 0.0
        rmse_score_val = safe_float(schema_metrics.get('rmse', 0.0))
        
        # 4. rmse must be STRING (different from rmse_score!)
        rmse_string = str(schema_metrics.get('rmse', '0.0'))

        # Create evaluation schema row - MATCHING EXACT SCHEMA TYPES
        evaluation_row = {
            "execution_id": execution_id_int,  # number
            "model_id": args.model_id,  # string
            "projectId": args.project_id,  # string
            "accuracy": accuracy_value,  # float
            "precision_score": precision_score_val,  # float
            "recall": recall_val,  # float
            "f1_score": f1_score_val,  # float
            "roc_auc": roc_auc_value,  # integer (not float!)
            "loss": loss_value,  # float (not string!)
            "confusion_matrix": confusion_matrix,  # float_array
            "tenant_id": tenant_id,  # string
            "model_name": args.model_name,  # string
            "model_type": args.model_type,  # string
            "r2_score": r2_score_val,  # float
            "mse": mse_val,  # float
            "rmse_score": rmse_score_val,  # float
            "rmse": rmse_string  # string (ADDED - was missing!)
        }

        print(f"Evaluation row being sent (with correct types):")
        print(f"  execution_id: {evaluation_row['execution_id']} (type: {type(evaluation_row['execution_id']).__name__})")
        print(f"  accuracy: {evaluation_row['accuracy']} (type: {type(evaluation_row['accuracy']).__name__})")
        print(f"  precision_score: {evaluation_row['precision_score']} (type: {type(evaluation_row['precision_score']).__name__})")
        print(f"  recall: {evaluation_row['recall']} (type: {type(evaluation_row['recall']).__name__})")
        print(f"  f1_score: {evaluation_row['f1_score']} (type: {type(evaluation_row['f1_score']).__name__})")
        print(f"  roc_auc: {evaluation_row['roc_auc']} (type: {type(evaluation_row['roc_auc']).__name__}) ← INTEGER")
        print(f"  loss: {evaluation_row['loss']} (type: {type(evaluation_row['loss']).__name__}) ← FLOAT")
        print(f"  r2_score: {evaluation_row['r2_score']} (type: {type(evaluation_row['r2_score']).__name__})")
        print(f"  mse: {evaluation_row['mse']} (type: {type(evaluation_row['mse']).__name__})")
        print(f"  rmse_score: {evaluation_row['rmse_score']} (type: {type(evaluation_row['rmse_score']).__name__})")
        print(f"  rmse: {evaluation_row['rmse']} (type: {type(evaluation_row['rmse']).__name__}) ← STRING")
        print(f"  confusion_matrix: {len(evaluation_row['confusion_matrix'])} values")

        # Set up API call
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {bearer_auth_token}'
        }

        retry_strategy = Retry(
            total=3,
            status_forcelist=[408, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "PUT", "POST", "DELETE", "OPTIONS", "TRACE"],
            backoff_factor=1
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        http = requests.Session()
        http.mount("https://", adapter)
        http.mount("http://", adapter)

        # Check if row exists
        check_url = f"{args.domain}/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/list"
        check_payload = {
            "dbType": "TIDB",
            "ownedOnly": True,
            "filter": {
                "execution_id": execution_id_int,
                "model_id": args.model_id,
                "projectId": args.project_id
            }
        }

        print(f"Checking for existing evaluation record with execution_id: {execution_id_int}, model_id: {args.model_id}")
        
        try:
            response = http.post(check_url, headers=headers, json=check_payload, timeout=60)
            response.raise_for_status()
            response_data = response.json()
            
            if response_data.get("content"):
                print("Evaluation record found: Updating row")
                update_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                update_payload = {
                    "dbType": "TIDB",
                    "conditionalFilter": {
                        "conditions": [
                            {"field": "execution_id", "operator": "EQUAL", "value": execution_id_int},
                            {"field": "model_id", "operator": "EQUAL", "value": args.model_id},
                            {"field": "projectId", "operator": "EQUAL", "value": args.project_id}
                        ]
                    },
                    "partialUpdateRequests": [{
                        "patch": [
                            {"operation": "REPLACE", "path": "accuracy", "value": evaluation_row["accuracy"]},
                            {"operation": "REPLACE", "path": "precision_score", "value": evaluation_row["precision_score"]},
                            {"operation": "REPLACE", "path": "recall", "value": evaluation_row["recall"]},
                            {"operation": "REPLACE", "path": "f1_score", "value": evaluation_row["f1_score"]},
                            {"operation": "REPLACE", "path": "roc_auc", "value": evaluation_row["roc_auc"]},
                            {"operation": "REPLACE", "path": "loss", "value": evaluation_row["loss"]},
                            {"operation": "REPLACE", "path": "confusion_matrix", "value": evaluation_row["confusion_matrix"]},
                            {"operation": "REPLACE", "path": "model_name", "value": evaluation_row["model_name"]},
                            {"operation": "REPLACE", "path": "model_type", "value": evaluation_row["model_type"]},
                            {"operation": "REPLACE", "path": "r2_score", "value": evaluation_row["r2_score"]},
                            {"operation": "REPLACE", "path": "mse", "value": evaluation_row["mse"]},
                            {"operation": "REPLACE", "path": "rmse_score", "value": evaluation_row["rmse_score"]},
                            {"operation": "REPLACE", "path": "rmse", "value": evaluation_row["rmse"]}
                        ]
                    }]
                }
                
                response = http.patch(update_url, headers=headers, json=update_payload, timeout=60)
                response.raise_for_status()
                print("Successfully updated evaluation record.")
            else:
                print("No evaluation record found: Creating new row")
                create_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                create_payload = {"data": [evaluation_row]}
                
                response = http.post(create_url, headers=headers, json=create_payload, timeout=60)
                response.raise_for_status()
                print("Successfully created new evaluation record.")
            
            print(f"Response: {response.json()}")
            
            # Write success confirmation
            with open(args.evaluation_schema_updated, 'w') as f:
                json.dump({"status": "success", "message": "Evaluation schema updated successfully"}, f)

        except requests.exceptions.RequestException as e:
            print(f"Error: {e}")
            if e.response is not None:
                print(f"Response Status Code: {e.response.status_code}")
                print(f"Response Content: {e.response.text}")
            with open(args.evaluation_schema_updated, 'w') as f:
                json.dump({"status": "error", "message": str(e), "row_data": evaluation_row}, f)
            exit(1)

    args:
      - --schema_id
      - {inputValue: schema_id}
      - --schema_evaluation_metrics
      - {inputPath: schema_evaluation_metrics}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputPath: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --bearer_auth_token
      - {inputPath: bearer_auth_token}
      - --domain
      - {inputValue: domain}
      - --model_name
      - {inputValue: model_name}
      - --model_type
      - {inputValue: model_type}
      - --evaluation_schema_updated
      - {outputPath: evaluation_schema_updated}
