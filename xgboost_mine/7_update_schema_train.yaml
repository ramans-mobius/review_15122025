name: XGBoost Training Schema Updater
description: Updates the training schema with XGBoost training metrics

inputs:
  - { name: schema_id, type: String, description: "The ID of the training schema to update." }
  - { name: schema_training_metrics, type: String, description: "Schema training metrics JSON from Trainer output." }
  - { name: model_id, type: String, description: "The ID of the model." }
  - { name: execution_id, type: String, description: "The ID of the execution." }
  - { name: tenant_id, type: String, description: "The ID of the tenant." }
  - { name: project_id, type: String, description: "The ID of the project." }
  - { name: bearer_auth_token, type: String, description: "Bearer token for authentication." }
  - { name: domain, type: String, description: "The domain for the API endpoint." }

outputs:
  - { name: training_schema_updated, type: String, description: "Confirmation of training schema update." }

implementation:
  container:
    image: python:3.9-slim
    command:
      - sh
      - -c
      - |
        pip install requests
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import json
        import argparse
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry

        parser = argparse.ArgumentParser()
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--schema_training_metrics', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--bearer_auth_token', type=str, required=True)
        parser.add_argument('--domain', type=str, required=True)
        parser.add_argument('--training_schema_updated', type=str, required=True)
        args = parser.parse_args()

        # Read input files
        with open(args.schema_training_metrics, 'r') as f:
            schema_metrics = json.load(f)
        
        with open(args.bearer_auth_token, 'r') as f:
            bearer_auth_token = f.read().strip()
        
        with open(args.tenant_id, 'r') as f:
            tenant_id = f.read().strip()

        # Parse execution_id to int (primary key)
        try:
            execution_id_int = int(args.execution_id) if args.execution_id and args.execution_id.isdigit() else 0
        except:
            execution_id_int = 0

        # Helper function to safely convert to float
        def safe_float(value, default=0.0):
            try:
                return float(value)
            except:
                return float(default)

        # Prepare custom metrics from schema_metrics
        # Based on your Trainer output, schema_training_metrics should contain:
        # {
        #   'epoch': 100,
        #   'loss': 0.123,
        #   'accuracy': 0.85,
        #   'validation_loss': 0.145,
        #   'validation_accuracy': 0.82,
        #   'test_accuracy': 0.82,
        #   'test_precision': 0.81,
        #   'test_recall': 0.83,
        #   'test_f1_score': 0.82,
        #   'test_roc_auc': 0.89,
        #   'algorithm': 'XGBoost',
        #   'task': 'classification',
        #   ...
        # }
        
        task = schema_metrics.get('task', 'classification')
        
        if task == 'regression':
            custom_metrics = {
                "train_r2_score": safe_float(schema_metrics.get('loss', 0.0)),  # For regression, loss is MSE/RMSE
                "train_mae": safe_float(schema_metrics.get('train_mae', 0.0)),
                "train_rmse": safe_float(schema_metrics.get('train_rmse', 0.0)),
                "validation_r2_score": safe_float(schema_metrics.get('validation_loss', 0.0)),
                "validation_mae": safe_float(schema_metrics.get('validation_mae', 0.0)),
                "validation_rmse": safe_float(schema_metrics.get('validation_rmse', 0.0))
            }
        else:
            # Classification metrics
            custom_metrics = {
                "train_precision": safe_float(schema_metrics.get('test_precision', 0.0)),
                "train_recall": safe_float(schema_metrics.get('test_recall', 0.0)),
                "train_f1_score": safe_float(schema_metrics.get('test_f1_score', 0.0)),
                "train_roc_auc": safe_float(schema_metrics.get('test_roc_auc', 0.0)),
                "validation_precision": safe_float(schema_metrics.get('test_precision', 0.0)),
                "validation_recall": safe_float(schema_metrics.get('test_recall', 0.0)),
                "validation_f1_score": safe_float(schema_metrics.get('test_f1_score', 0.0)),
                "validation_roc_auc": safe_float(schema_metrics.get('test_roc_auc', 0.0))
            }

        # Create training schema row with proper data types
        training_row = {
            "execution_id": execution_id_int,  # number (Primary key)
            "projectId": args.project_id,  # string (primary key)
            "model_id": args.model_id,  # string (primary key)
            "epoch": int(schema_metrics.get("epoch", 0)),  # int
            "loss": safe_float(schema_metrics.get("loss", 0.0)),  # float
            "accuracy": safe_float(schema_metrics.get("accuracy", 0.0)),  # float
            "validation_loss": safe_float(schema_metrics.get("validation_loss", 0.0)),  # float
            "validation_accuracy": safe_float(schema_metrics.get("validation_accuracy", 0.0)),  # float
            "custom_metrics": json.dumps(custom_metrics),  # json string {metric_name: float}
            "tenant_id": tenant_id  # string
        }

        # Set up API call
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {bearer_auth_token}'
        }

        retry_strategy = Retry(
            total=3,
            status_forcelist=[408, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "PUT", "POST", "DELETE", "OPTIONS", "TRACE"],
            backoff_factor=1
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        http = requests.Session()
        http.mount("https://", adapter)
        http.mount("http://", adapter)

        # Check if row exists
        check_url = f"{args.domain}/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/list"
        check_payload = {
            "dbType": "TIDB",
            "ownedOnly": True,
            "filter": {
                "execution_id": execution_id_int,
                "model_id": args.model_id,
                "projectId": args.project_id
            }
        }

        print(f"Checking for existing training record with execution_id: {execution_id_int}, model_id: {args.model_id}")
        
        try:
            response = http.post(check_url, headers=headers, json=check_payload, timeout=60)
            response.raise_for_status()
            response_data = response.json()
            
            if response_data.get("content"):
                print("Training record found: Updating row")
                update_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                update_payload = {
                    "dbType": "TIDB",
                    "conditionalFilter": {
                        "conditions": [
                            {"field": "execution_id", "operator": "EQUAL", "value": execution_id_int},
                            {"field": "model_id", "operator": "EQUAL", "value": args.model_id},
                            {"field": "projectId", "operator": "EQUAL", "value": args.project_id}
                        ]
                    },
                    "partialUpdateRequests": [{
                        "patch": [
                            {"operation": "REPLACE", "path": "epoch", "value": training_row["epoch"]},
                            {"operation": "REPLACE", "path": "loss", "value": training_row["loss"]},
                            {"operation": "REPLACE", "path": "accuracy", "value": training_row["accuracy"]},
                            {"operation": "REPLACE", "path": "validation_loss", "value": training_row["validation_loss"]},
                            {"operation": "REPLACE", "path": "validation_accuracy", "value": training_row["validation_accuracy"]},
                            {"operation": "REPLACE", "path": "custom_metrics", "value": training_row["custom_metrics"]}
                        ]
                    }]
                }
                
                response = http.patch(update_url, headers=headers, json=update_payload, timeout=60)
                response.raise_for_status()
                print("Successfully updated training record.")
            else:
                print("No training record found: Creating new row")
                create_url = f"{args.domain}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                create_payload = {"data": [training_row]}
                
                response = http.post(create_url, headers=headers, json=create_payload, timeout=60)
                response.raise_for_status()
                print("Successfully created new training record.")
            
            print(f"Response: {response.json()}")
            
            # Write success confirmation
            with open(args.training_schema_updated, 'w') as f:
                json.dump({"status": "success", "message": "Training schema updated successfully"}, f)

        except requests.exceptions.RequestException as e:
            print(f"Error: {e}")
            if e.response is not None:
                print(f"Response Status Code: {e.response.status_code}")
                print(f"Response Content: {e.response.text}")
            # Write error confirmation
            with open(args.training_schema_updated, 'w') as f:
                json.dump({"status": "error", "message": str(e)}, f)
            exit(1)

    args:
      - --schema_id
      - {inputValue: schema_id}
      - --schema_training_metrics
      - {inputPath: schema_training_metrics}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputPath: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --bearer_auth_token
      - {inputPath: bearer_auth_token}
      - --domain
      - {inputValue: domain}
      - --training_schema_updated
      - {outputPath: training_schema_updated}
